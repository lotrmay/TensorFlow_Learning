{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSA6Kw2VjDm3D9ANQAmxG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbSeoWpB3mO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCY-aVPMK1aO"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "d8d59ff8-c57f-4fad-b8ca-280e47d4ab8e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(train.shape)#vypíše nám dimenzionalitu našeho dataframu (2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "train['team_one_name']=pd.Categorical(train['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "train['team_two_name']=pd.Categorical(train['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "#https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "#frac=1 znamená, vrať všechny řádky\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "\n",
        "train.pop('playerAAAdr')\n",
        "train.pop('playerABAdr')\n",
        "train.pop('playerACAdr')\n",
        "train.pop('playerADAdr')\n",
        "train.pop('playerAEAdr')\n",
        "train.pop('playerBAAdr')\n",
        "train.pop('playerBBAdr')\n",
        "train.pop('playerBCAdr')\n",
        "train.pop('playerBDAdr')\n",
        "train.pop('playerBEAdr')\n",
        "\n",
        "train.pop('playerAADpr')\n",
        "train.pop('playerABDpr')\n",
        "train.pop('playerACDpr')\n",
        "train.pop('playerADDpr')\n",
        "train.pop('playerAEDpr')\n",
        "train.pop('playerBADpr')\n",
        "train.pop('playerBBDpr')\n",
        "train.pop('playerBCDpr')\n",
        "train.pop('playerBDDpr')\n",
        "train.pop('playerBEDpr')\n",
        "\n",
        "train.pop('playerAAKpr')\n",
        "train.pop('playerABKpr')\n",
        "train.pop('playerACKpr')\n",
        "train.pop('playerADKpr')\n",
        "train.pop('playerAEKpr')\n",
        "train.pop('playerBAKpr')\n",
        "train.pop('playerBBKpr')\n",
        "train.pop('playerBCKpr')\n",
        "train.pop('playerBDKpr')\n",
        "train.pop('playerBEKpr')\n",
        "\n",
        "train.pop('playerAAImpact')\n",
        "train.pop('playerABImpact')\n",
        "train.pop('playerACImpact')\n",
        "train.pop('playerADImpact')\n",
        "train.pop('playerAEImpact')\n",
        "train.pop('playerBAImpact')\n",
        "train.pop('playerBBImpact')\n",
        "train.pop('playerBCImpact')\n",
        "train.pop('playerBDImpact')\n",
        "train.pop('playerBEImpact')\n",
        "\n",
        "train.pop('playerAAHs')\n",
        "train.pop('playerABHs')\n",
        "train.pop('playerACHs')\n",
        "train.pop('playerADHs')\n",
        "train.pop('playerAEHs')\n",
        "train.pop('playerBAHs')\n",
        "train.pop('playerBBHs')\n",
        "train.pop('playerBCHs')\n",
        "train.pop('playerBDHs')\n",
        "train.pop('playerBEHs')\n",
        "\n",
        "train.pop('playerAARating')\n",
        "train.pop('playerABRating')\n",
        "train.pop('playerACRating')\n",
        "train.pop('playerADRating')\n",
        "train.pop('playerAERating')\n",
        "train.pop('playerBARating')\n",
        "train.pop('playerBBRating')\n",
        "train.pop('playerBCRating')\n",
        "train.pop('playerBDRating')\n",
        "train.pop('playerBERating')\n",
        "'''\n",
        "#predictors nám vybere všechny sloupce, které jsou využity pro predikování výsledků neboli target_column\n",
        "target_column = ['Result'] \n",
        "\n",
        "predictionScaler=StandardScaler()\n",
        "y = train['Result'].values\n",
        "train.pop('Result')\n",
        "X = train.values\n",
        "\n",
        "#predictionScaler.fit(scalerData)\n",
        "\n",
        "#n = 100 # Max number of neighbours you want to consider\n",
        "#param_grid = {'n_neighbors': np.arange(n)}\n",
        "#grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "#grid.fit(X,y)\n",
        "#print(grid.best_params_)\n",
        "\n",
        "\n",
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#5% dat \n",
        "\n",
        "lof = LocalOutlierFactor(contamination=0.1,n_neighbors=96)\n",
        "yhat = lof.fit_predict(X)\n",
        "mask = yhat != -1\n",
        "X, y= X[mask, :], y[mask]\n",
        "print(X.shape)\n",
        "\n",
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)#32 #888 887\n",
        "\n",
        "#validační set bude 15% \n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1875) # 0.11 x 0.9 = 0.1 podívat se na cross-validation\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) #součet odpovídá X.shape\n",
        "\n",
        "#vytvoříme scaler, který nám data přetransformuje na formát lepší pro model ?\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=CSV_COLUMN_NAMES2)\n",
        "X_test=pd.DataFrame(X_test, columns=CSV_COLUMN_NAMES2)\n",
        "X_val=pd.DataFrame(X_val, columns=CSV_COLUMN_NAMES2)\n",
        "\n",
        "predictionScaler.fit(X_train)\n",
        "\n",
        "X_train=predictionScaler.transform(X_train)#fit transform na training data viz:https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
        "X_test=predictionScaler.transform(X_test)\n",
        "X_val=predictionScaler.transform(X_val)\n",
        "\n",
        "#64 32\n",
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu', kernel_initializer=tf.initializers.lecun_uniform,bias_initializer=tf.initializers.lecun_normal))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_initializer=tf.initializers.lecun_uniform,bias_initializer=tf.initializers.lecun_normal))\n",
        "model.add(keras.layers.Dropout(0.5))#50% inputů dropne abz se příliš nespoléhala na vybrané inputy\n",
        "#jelikož děláme binární klasifikaci, tak aktivační funkce bude sigmoid popř. softmax, zde by mezi těmito dvěmi neměl být výkonově rozdíl viz:https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer\n",
        "model.add(Dense(1, activation='sigmoid'))#menší než 0.5 = 0 a větší než 0.5 = 1\n",
        "\n",
        "\n",
        "#tady jsem skončil s vysvětlováním!!!\n",
        "#model zkompilujeme s parametry:\n",
        "#Common values of [momentum] used in practice include .5, .9, and .99.\n",
        "#optimizer bude ? optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.5)\n",
        "#loss funkce bude BinaryCrossentropy, jelikož máme binární klasifikátor\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=['binary_accuracy'])#metrics=['accuracy'] je to jedno accuracy se vnitřně přetransformuje na binary accuracy, kvůli binary crossentropy loss funkci\n",
        "#metrics = (\"accuracy\")\n",
        "#metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None)\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])\n",
        "#[tf.keras.metrics.BinaryAccuracy()]\n",
        "#optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#Adagrad(learning_rate=0.01) kolem 100 epochs a 32 batch_size je kolem 0.67\n",
        "\n",
        "#shuffle=true?\n",
        "history = model.fit(X_train, y_train, epochs=700,shuffle=True,batch_size=64,validation_data=(X_val, y_val))#validační data pro změny při tréninku sítě\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "pred_test= model.predict(X_test)\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "\n",
        "#plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')#'accuracy'\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky!!\n",
        "#optimální batch_size je 128 zjištěno zkoušením\n",
        "#zatím nejlepší model měl 64 16 4 \n",
        "#dense layers používají defaultně tf.initializers.glorot_uniform,ale pro můj model je přesnější glorot_normal\n",
        "\n",
        "\n",
        "#kernel inity\n",
        "#he_uniform>he_normal\n",
        "#lecun uniform>lecun normal asi\n",
        "#orthogonal a variance scaling použitelné\n",
        "\n",
        "#bias inity\n",
        "#lecun normal >he normal, variance_scaling\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/initializers\n",
        "\n",
        "\n",
        "#zvýšil jsem dropout z 0.2 na 0.5, tak možná budu muset zvýšit learning_rate (*10 a zvýšit epochs na 1000), ale pokud budou vykazovat tu velkou mezeru, tak dropout snížit"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18930, 102)\n",
            "(17037, 98)\n",
            "(11765, 98)\n",
            "(2556, 98)\n",
            "(2716, 98)\n",
            "Epoch 1/700\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.8496 - binary_accuracy: 0.5088 - val_loss: 0.6748 - val_binary_accuracy: 0.5817\n",
            "Epoch 2/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.7322 - binary_accuracy: 0.5273 - val_loss: 0.6741 - val_binary_accuracy: 0.6024\n",
            "Epoch 3/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.7037 - binary_accuracy: 0.5365 - val_loss: 0.6725 - val_binary_accuracy: 0.6053\n",
            "Epoch 4/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6926 - binary_accuracy: 0.5445 - val_loss: 0.6719 - val_binary_accuracy: 0.6163\n",
            "Epoch 5/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6866 - binary_accuracy: 0.5533 - val_loss: 0.6700 - val_binary_accuracy: 0.6163\n",
            "Epoch 6/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6836 - binary_accuracy: 0.5540 - val_loss: 0.6692 - val_binary_accuracy: 0.6141\n",
            "Epoch 7/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6793 - binary_accuracy: 0.5642 - val_loss: 0.6655 - val_binary_accuracy: 0.6244\n",
            "Epoch 8/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6780 - binary_accuracy: 0.5686 - val_loss: 0.6638 - val_binary_accuracy: 0.6296\n",
            "Epoch 9/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6765 - binary_accuracy: 0.5729 - val_loss: 0.6619 - val_binary_accuracy: 0.6267\n",
            "Epoch 10/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6736 - binary_accuracy: 0.5765 - val_loss: 0.6590 - val_binary_accuracy: 0.6289\n",
            "Epoch 11/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6740 - binary_accuracy: 0.5783 - val_loss: 0.6582 - val_binary_accuracy: 0.6314\n",
            "Epoch 12/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6712 - binary_accuracy: 0.5889 - val_loss: 0.6566 - val_binary_accuracy: 0.6333\n",
            "Epoch 13/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6712 - binary_accuracy: 0.5774 - val_loss: 0.6556 - val_binary_accuracy: 0.6359\n",
            "Epoch 14/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6675 - binary_accuracy: 0.5918 - val_loss: 0.6526 - val_binary_accuracy: 0.6311\n",
            "Epoch 15/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6699 - binary_accuracy: 0.5849 - val_loss: 0.6523 - val_binary_accuracy: 0.6384\n",
            "Epoch 16/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6673 - binary_accuracy: 0.5942 - val_loss: 0.6501 - val_binary_accuracy: 0.6359\n",
            "Epoch 17/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6657 - binary_accuracy: 0.5901 - val_loss: 0.6493 - val_binary_accuracy: 0.6388\n",
            "Epoch 18/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6664 - binary_accuracy: 0.5899 - val_loss: 0.6483 - val_binary_accuracy: 0.6447\n",
            "Epoch 19/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6639 - binary_accuracy: 0.5867 - val_loss: 0.6449 - val_binary_accuracy: 0.6388\n",
            "Epoch 20/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6615 - binary_accuracy: 0.5888 - val_loss: 0.6439 - val_binary_accuracy: 0.6395\n",
            "Epoch 21/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6630 - binary_accuracy: 0.5973 - val_loss: 0.6437 - val_binary_accuracy: 0.6414\n",
            "Epoch 22/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6626 - binary_accuracy: 0.5908 - val_loss: 0.6434 - val_binary_accuracy: 0.6414\n",
            "Epoch 23/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6595 - binary_accuracy: 0.5922 - val_loss: 0.6417 - val_binary_accuracy: 0.6399\n",
            "Epoch 24/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6612 - binary_accuracy: 0.5992 - val_loss: 0.6416 - val_binary_accuracy: 0.6421\n",
            "Epoch 25/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6600 - binary_accuracy: 0.5961 - val_loss: 0.6413 - val_binary_accuracy: 0.6436\n",
            "Epoch 26/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6611 - binary_accuracy: 0.5979 - val_loss: 0.6414 - val_binary_accuracy: 0.6414\n",
            "Epoch 27/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6582 - binary_accuracy: 0.6020 - val_loss: 0.6376 - val_binary_accuracy: 0.6429\n",
            "Epoch 28/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6565 - binary_accuracy: 0.6094 - val_loss: 0.6383 - val_binary_accuracy: 0.6440\n",
            "Epoch 29/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6592 - binary_accuracy: 0.5992 - val_loss: 0.6384 - val_binary_accuracy: 0.6443\n",
            "Epoch 30/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6564 - binary_accuracy: 0.6047 - val_loss: 0.6364 - val_binary_accuracy: 0.6436\n",
            "Epoch 31/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6580 - binary_accuracy: 0.6042 - val_loss: 0.6374 - val_binary_accuracy: 0.6436\n",
            "Epoch 32/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6557 - binary_accuracy: 0.6062 - val_loss: 0.6353 - val_binary_accuracy: 0.6462\n",
            "Epoch 33/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6561 - binary_accuracy: 0.6048 - val_loss: 0.6348 - val_binary_accuracy: 0.6469\n",
            "Epoch 34/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6539 - binary_accuracy: 0.6120 - val_loss: 0.6351 - val_binary_accuracy: 0.6495\n",
            "Epoch 35/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6529 - binary_accuracy: 0.6110 - val_loss: 0.6332 - val_binary_accuracy: 0.6499\n",
            "Epoch 36/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6540 - binary_accuracy: 0.6121 - val_loss: 0.6321 - val_binary_accuracy: 0.6491\n",
            "Epoch 37/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6504 - binary_accuracy: 0.6103 - val_loss: 0.6309 - val_binary_accuracy: 0.6476\n",
            "Epoch 38/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6525 - binary_accuracy: 0.6084 - val_loss: 0.6311 - val_binary_accuracy: 0.6491\n",
            "Epoch 39/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6547 - binary_accuracy: 0.6076 - val_loss: 0.6315 - val_binary_accuracy: 0.6506\n",
            "Epoch 40/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6512 - binary_accuracy: 0.6143 - val_loss: 0.6295 - val_binary_accuracy: 0.6521\n",
            "Epoch 41/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6512 - binary_accuracy: 0.6100 - val_loss: 0.6284 - val_binary_accuracy: 0.6480\n",
            "Epoch 42/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6540 - binary_accuracy: 0.6124 - val_loss: 0.6306 - val_binary_accuracy: 0.6502\n",
            "Epoch 43/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6163 - val_loss: 0.6292 - val_binary_accuracy: 0.6546\n",
            "Epoch 44/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6515 - binary_accuracy: 0.6141 - val_loss: 0.6300 - val_binary_accuracy: 0.6550\n",
            "Epoch 45/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6496 - binary_accuracy: 0.6088 - val_loss: 0.6271 - val_binary_accuracy: 0.6535\n",
            "Epoch 46/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6508 - binary_accuracy: 0.6093 - val_loss: 0.6290 - val_binary_accuracy: 0.6521\n",
            "Epoch 47/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6521 - binary_accuracy: 0.6127 - val_loss: 0.6286 - val_binary_accuracy: 0.6557\n",
            "Epoch 48/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6484 - binary_accuracy: 0.6155 - val_loss: 0.6278 - val_binary_accuracy: 0.6524\n",
            "Epoch 49/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6160 - val_loss: 0.6272 - val_binary_accuracy: 0.6524\n",
            "Epoch 50/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6466 - binary_accuracy: 0.6125 - val_loss: 0.6250 - val_binary_accuracy: 0.6510\n",
            "Epoch 51/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6495 - binary_accuracy: 0.6139 - val_loss: 0.6265 - val_binary_accuracy: 0.6546\n",
            "Epoch 52/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6154 - val_loss: 0.6273 - val_binary_accuracy: 0.6561\n",
            "Epoch 53/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6490 - binary_accuracy: 0.6127 - val_loss: 0.6284 - val_binary_accuracy: 0.6565\n",
            "Epoch 54/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6490 - binary_accuracy: 0.6185 - val_loss: 0.6249 - val_binary_accuracy: 0.6587\n",
            "Epoch 55/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6477 - binary_accuracy: 0.6191 - val_loss: 0.6239 - val_binary_accuracy: 0.6580\n",
            "Epoch 56/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6149 - val_loss: 0.6245 - val_binary_accuracy: 0.6591\n",
            "Epoch 57/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6497 - binary_accuracy: 0.6178 - val_loss: 0.6261 - val_binary_accuracy: 0.6580\n",
            "Epoch 58/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6163 - val_loss: 0.6241 - val_binary_accuracy: 0.6568\n",
            "Epoch 59/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6435 - binary_accuracy: 0.6202 - val_loss: 0.6226 - val_binary_accuracy: 0.6605\n",
            "Epoch 60/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6207 - val_loss: 0.6216 - val_binary_accuracy: 0.6587\n",
            "Epoch 61/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6165 - val_loss: 0.6215 - val_binary_accuracy: 0.6561\n",
            "Epoch 62/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6450 - binary_accuracy: 0.6246 - val_loss: 0.6218 - val_binary_accuracy: 0.6561\n",
            "Epoch 63/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6198 - val_loss: 0.6209 - val_binary_accuracy: 0.6565\n",
            "Epoch 64/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6193 - val_loss: 0.6220 - val_binary_accuracy: 0.6594\n",
            "Epoch 65/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6458 - binary_accuracy: 0.6189 - val_loss: 0.6223 - val_binary_accuracy: 0.6572\n",
            "Epoch 66/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6491 - binary_accuracy: 0.6201 - val_loss: 0.6234 - val_binary_accuracy: 0.6587\n",
            "Epoch 67/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6461 - binary_accuracy: 0.6236 - val_loss: 0.6229 - val_binary_accuracy: 0.6580\n",
            "Epoch 68/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6239 - val_loss: 0.6203 - val_binary_accuracy: 0.6602\n",
            "Epoch 69/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6459 - binary_accuracy: 0.6242 - val_loss: 0.6181 - val_binary_accuracy: 0.6580\n",
            "Epoch 70/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6476 - binary_accuracy: 0.6155 - val_loss: 0.6200 - val_binary_accuracy: 0.6583\n",
            "Epoch 71/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6447 - binary_accuracy: 0.6234 - val_loss: 0.6197 - val_binary_accuracy: 0.6613\n",
            "Epoch 72/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6218 - val_loss: 0.6224 - val_binary_accuracy: 0.6580\n",
            "Epoch 73/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6213 - val_loss: 0.6202 - val_binary_accuracy: 0.6602\n",
            "Epoch 74/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6246 - val_loss: 0.6206 - val_binary_accuracy: 0.6602\n",
            "Epoch 75/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6415 - binary_accuracy: 0.6276 - val_loss: 0.6186 - val_binary_accuracy: 0.6631\n",
            "Epoch 76/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6415 - binary_accuracy: 0.6238 - val_loss: 0.6165 - val_binary_accuracy: 0.6627\n",
            "Epoch 77/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6430 - binary_accuracy: 0.6254 - val_loss: 0.6158 - val_binary_accuracy: 0.6602\n",
            "Epoch 78/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6393 - binary_accuracy: 0.6298 - val_loss: 0.6166 - val_binary_accuracy: 0.6627\n",
            "Epoch 79/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6418 - binary_accuracy: 0.6322 - val_loss: 0.6169 - val_binary_accuracy: 0.6642\n",
            "Epoch 80/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6231 - val_loss: 0.6164 - val_binary_accuracy: 0.6609\n",
            "Epoch 81/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6423 - binary_accuracy: 0.6271 - val_loss: 0.6176 - val_binary_accuracy: 0.6620\n",
            "Epoch 82/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6392 - binary_accuracy: 0.6289 - val_loss: 0.6170 - val_binary_accuracy: 0.6649\n",
            "Epoch 83/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6418 - binary_accuracy: 0.6292 - val_loss: 0.6164 - val_binary_accuracy: 0.6642\n",
            "Epoch 84/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6449 - binary_accuracy: 0.6251 - val_loss: 0.6186 - val_binary_accuracy: 0.6624\n",
            "Epoch 85/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6251 - val_loss: 0.6169 - val_binary_accuracy: 0.6664\n",
            "Epoch 86/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6423 - binary_accuracy: 0.6289 - val_loss: 0.6156 - val_binary_accuracy: 0.6653\n",
            "Epoch 87/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6402 - binary_accuracy: 0.6309 - val_loss: 0.6164 - val_binary_accuracy: 0.6642\n",
            "Epoch 88/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6383 - binary_accuracy: 0.6309 - val_loss: 0.6148 - val_binary_accuracy: 0.6627\n",
            "Epoch 89/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6320 - val_loss: 0.6152 - val_binary_accuracy: 0.6602\n",
            "Epoch 90/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6263 - val_loss: 0.6141 - val_binary_accuracy: 0.6649\n",
            "Epoch 91/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6287 - val_loss: 0.6146 - val_binary_accuracy: 0.6657\n",
            "Epoch 92/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6246 - val_loss: 0.6153 - val_binary_accuracy: 0.6653\n",
            "Epoch 93/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6425 - binary_accuracy: 0.6188 - val_loss: 0.6142 - val_binary_accuracy: 0.6649\n",
            "Epoch 94/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6396 - binary_accuracy: 0.6275 - val_loss: 0.6148 - val_binary_accuracy: 0.6642\n",
            "Epoch 95/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6389 - binary_accuracy: 0.6307 - val_loss: 0.6150 - val_binary_accuracy: 0.6642\n",
            "Epoch 96/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.6248 - val_loss: 0.6140 - val_binary_accuracy: 0.6646\n",
            "Epoch 97/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6418 - binary_accuracy: 0.6292 - val_loss: 0.6170 - val_binary_accuracy: 0.6635\n",
            "Epoch 98/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6414 - binary_accuracy: 0.6244 - val_loss: 0.6140 - val_binary_accuracy: 0.6631\n",
            "Epoch 99/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6393 - binary_accuracy: 0.6266 - val_loss: 0.6134 - val_binary_accuracy: 0.6613\n",
            "Epoch 100/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6398 - binary_accuracy: 0.6285 - val_loss: 0.6129 - val_binary_accuracy: 0.6631\n",
            "Epoch 101/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6391 - binary_accuracy: 0.6335 - val_loss: 0.6114 - val_binary_accuracy: 0.6657\n",
            "Epoch 102/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6297 - val_loss: 0.6156 - val_binary_accuracy: 0.6627\n",
            "Epoch 103/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6404 - binary_accuracy: 0.6308 - val_loss: 0.6170 - val_binary_accuracy: 0.6642\n",
            "Epoch 104/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.6304 - val_loss: 0.6146 - val_binary_accuracy: 0.6620\n",
            "Epoch 105/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6373 - binary_accuracy: 0.6321 - val_loss: 0.6125 - val_binary_accuracy: 0.6635\n",
            "Epoch 106/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6408 - binary_accuracy: 0.6275 - val_loss: 0.6138 - val_binary_accuracy: 0.6631\n",
            "Epoch 107/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6275 - val_loss: 0.6147 - val_binary_accuracy: 0.6598\n",
            "Epoch 108/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6296 - val_loss: 0.6144 - val_binary_accuracy: 0.6638\n",
            "Epoch 109/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6306 - val_loss: 0.6118 - val_binary_accuracy: 0.6627\n",
            "Epoch 110/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6303 - val_loss: 0.6136 - val_binary_accuracy: 0.6653\n",
            "Epoch 111/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6291 - val_loss: 0.6121 - val_binary_accuracy: 0.6638\n",
            "Epoch 112/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6350 - val_loss: 0.6125 - val_binary_accuracy: 0.6649\n",
            "Epoch 113/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6374 - binary_accuracy: 0.6286 - val_loss: 0.6102 - val_binary_accuracy: 0.6657\n",
            "Epoch 114/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6395 - binary_accuracy: 0.6274 - val_loss: 0.6116 - val_binary_accuracy: 0.6624\n",
            "Epoch 115/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6260 - val_loss: 0.6104 - val_binary_accuracy: 0.6624\n",
            "Epoch 116/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6336 - val_loss: 0.6110 - val_binary_accuracy: 0.6627\n",
            "Epoch 117/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6381 - binary_accuracy: 0.6350 - val_loss: 0.6150 - val_binary_accuracy: 0.6631\n",
            "Epoch 118/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6328 - val_loss: 0.6091 - val_binary_accuracy: 0.6675\n",
            "Epoch 119/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6405 - binary_accuracy: 0.6303 - val_loss: 0.6129 - val_binary_accuracy: 0.6653\n",
            "Epoch 120/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6376 - val_loss: 0.6132 - val_binary_accuracy: 0.6616\n",
            "Epoch 121/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6367 - binary_accuracy: 0.6337 - val_loss: 0.6120 - val_binary_accuracy: 0.6642\n",
            "Epoch 122/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6376 - binary_accuracy: 0.6355 - val_loss: 0.6100 - val_binary_accuracy: 0.6649\n",
            "Epoch 123/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6342 - val_loss: 0.6111 - val_binary_accuracy: 0.6657\n",
            "Epoch 124/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6324 - val_loss: 0.6116 - val_binary_accuracy: 0.6624\n",
            "Epoch 125/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6326 - val_loss: 0.6111 - val_binary_accuracy: 0.6627\n",
            "Epoch 126/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6322 - val_loss: 0.6118 - val_binary_accuracy: 0.6642\n",
            "Epoch 127/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6370 - binary_accuracy: 0.6323 - val_loss: 0.6102 - val_binary_accuracy: 0.6635\n",
            "Epoch 128/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6379 - binary_accuracy: 0.6352 - val_loss: 0.6116 - val_binary_accuracy: 0.6649\n",
            "Epoch 129/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6412 - val_loss: 0.6094 - val_binary_accuracy: 0.6646\n",
            "Epoch 130/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6398 - binary_accuracy: 0.6329 - val_loss: 0.6103 - val_binary_accuracy: 0.6638\n",
            "Epoch 131/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6367 - binary_accuracy: 0.6314 - val_loss: 0.6106 - val_binary_accuracy: 0.6627\n",
            "Epoch 132/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6314 - val_loss: 0.6095 - val_binary_accuracy: 0.6661\n",
            "Epoch 133/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6326 - binary_accuracy: 0.6389 - val_loss: 0.6101 - val_binary_accuracy: 0.6613\n",
            "Epoch 134/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6357 - binary_accuracy: 0.6360 - val_loss: 0.6083 - val_binary_accuracy: 0.6649\n",
            "Epoch 135/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6405 - val_loss: 0.6099 - val_binary_accuracy: 0.6642\n",
            "Epoch 136/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6336 - val_loss: 0.6131 - val_binary_accuracy: 0.6646\n",
            "Epoch 137/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6366 - val_loss: 0.6102 - val_binary_accuracy: 0.6635\n",
            "Epoch 138/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6383 - binary_accuracy: 0.6303 - val_loss: 0.6082 - val_binary_accuracy: 0.6627\n",
            "Epoch 139/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6313 - val_loss: 0.6085 - val_binary_accuracy: 0.6620\n",
            "Epoch 140/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6331 - val_loss: 0.6079 - val_binary_accuracy: 0.6627\n",
            "Epoch 141/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6354 - val_loss: 0.6105 - val_binary_accuracy: 0.6609\n",
            "Epoch 142/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6371 - val_loss: 0.6077 - val_binary_accuracy: 0.6627\n",
            "Epoch 143/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6386 - val_loss: 0.6077 - val_binary_accuracy: 0.6631\n",
            "Epoch 144/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6411 - val_loss: 0.6088 - val_binary_accuracy: 0.6624\n",
            "Epoch 145/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6307 - val_loss: 0.6121 - val_binary_accuracy: 0.6587\n",
            "Epoch 146/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6366 - val_loss: 0.6087 - val_binary_accuracy: 0.6635\n",
            "Epoch 147/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6327 - val_loss: 0.6073 - val_binary_accuracy: 0.6620\n",
            "Epoch 148/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6369 - binary_accuracy: 0.6331 - val_loss: 0.6110 - val_binary_accuracy: 0.6616\n",
            "Epoch 149/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6344 - binary_accuracy: 0.6369 - val_loss: 0.6092 - val_binary_accuracy: 0.6627\n",
            "Epoch 150/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6352 - val_loss: 0.6072 - val_binary_accuracy: 0.6631\n",
            "Epoch 151/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6380 - val_loss: 0.6073 - val_binary_accuracy: 0.6631\n",
            "Epoch 152/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6367 - val_loss: 0.6096 - val_binary_accuracy: 0.6627\n",
            "Epoch 153/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6360 - val_loss: 0.6069 - val_binary_accuracy: 0.6631\n",
            "Epoch 154/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6394 - val_loss: 0.6089 - val_binary_accuracy: 0.6616\n",
            "Epoch 155/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6343 - binary_accuracy: 0.6357 - val_loss: 0.6090 - val_binary_accuracy: 0.6631\n",
            "Epoch 156/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6367 - val_loss: 0.6069 - val_binary_accuracy: 0.6605\n",
            "Epoch 157/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6353 - val_loss: 0.6078 - val_binary_accuracy: 0.6587\n",
            "Epoch 158/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6426 - val_loss: 0.6064 - val_binary_accuracy: 0.6620\n",
            "Epoch 159/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6378 - val_loss: 0.6083 - val_binary_accuracy: 0.6616\n",
            "Epoch 160/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6433 - val_loss: 0.6073 - val_binary_accuracy: 0.6605\n",
            "Epoch 161/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6351 - binary_accuracy: 0.6349 - val_loss: 0.6085 - val_binary_accuracy: 0.6620\n",
            "Epoch 162/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6385 - val_loss: 0.6065 - val_binary_accuracy: 0.6620\n",
            "Epoch 163/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6360 - val_loss: 0.6067 - val_binary_accuracy: 0.6613\n",
            "Epoch 164/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6377 - val_loss: 0.6045 - val_binary_accuracy: 0.6646\n",
            "Epoch 165/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6389 - val_loss: 0.6055 - val_binary_accuracy: 0.6609\n",
            "Epoch 166/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6355 - val_loss: 0.6077 - val_binary_accuracy: 0.6635\n",
            "Epoch 167/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6377 - val_loss: 0.6076 - val_binary_accuracy: 0.6635\n",
            "Epoch 168/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6404 - val_loss: 0.6051 - val_binary_accuracy: 0.6646\n",
            "Epoch 169/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6363 - val_loss: 0.6061 - val_binary_accuracy: 0.6624\n",
            "Epoch 170/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6343 - val_loss: 0.6090 - val_binary_accuracy: 0.6620\n",
            "Epoch 171/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6411 - val_loss: 0.6069 - val_binary_accuracy: 0.6620\n",
            "Epoch 172/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6412 - val_loss: 0.6092 - val_binary_accuracy: 0.6646\n",
            "Epoch 173/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6416 - val_loss: 0.6063 - val_binary_accuracy: 0.6642\n",
            "Epoch 174/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6343 - binary_accuracy: 0.6394 - val_loss: 0.6075 - val_binary_accuracy: 0.6620\n",
            "Epoch 175/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6330 - binary_accuracy: 0.6405 - val_loss: 0.6071 - val_binary_accuracy: 0.6609\n",
            "Epoch 176/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6399 - val_loss: 0.6072 - val_binary_accuracy: 0.6624\n",
            "Epoch 177/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6411 - val_loss: 0.6069 - val_binary_accuracy: 0.6624\n",
            "Epoch 178/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6337 - binary_accuracy: 0.6383 - val_loss: 0.6053 - val_binary_accuracy: 0.6624\n",
            "Epoch 179/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6353 - binary_accuracy: 0.6404 - val_loss: 0.6070 - val_binary_accuracy: 0.6631\n",
            "Epoch 180/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6370 - val_loss: 0.6051 - val_binary_accuracy: 0.6631\n",
            "Epoch 181/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6372 - val_loss: 0.6057 - val_binary_accuracy: 0.6635\n",
            "Epoch 182/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6345 - val_loss: 0.6088 - val_binary_accuracy: 0.6616\n",
            "Epoch 183/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6412 - val_loss: 0.6067 - val_binary_accuracy: 0.6631\n",
            "Epoch 184/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6347 - val_loss: 0.6071 - val_binary_accuracy: 0.6613\n",
            "Epoch 185/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6394 - val_loss: 0.6055 - val_binary_accuracy: 0.6620\n",
            "Epoch 186/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6372 - val_loss: 0.6058 - val_binary_accuracy: 0.6620\n",
            "Epoch 187/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6328 - binary_accuracy: 0.6273 - val_loss: 0.6056 - val_binary_accuracy: 0.6653\n",
            "Epoch 188/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6422 - val_loss: 0.6049 - val_binary_accuracy: 0.6635\n",
            "Epoch 189/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6353 - binary_accuracy: 0.6383 - val_loss: 0.6098 - val_binary_accuracy: 0.6624\n",
            "Epoch 190/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6423 - val_loss: 0.6072 - val_binary_accuracy: 0.6624\n",
            "Epoch 191/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6420 - val_loss: 0.6071 - val_binary_accuracy: 0.6635\n",
            "Epoch 192/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6395 - val_loss: 0.6093 - val_binary_accuracy: 0.6631\n",
            "Epoch 193/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6411 - val_loss: 0.6065 - val_binary_accuracy: 0.6624\n",
            "Epoch 194/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6391 - val_loss: 0.6073 - val_binary_accuracy: 0.6631\n",
            "Epoch 195/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6391 - val_loss: 0.6075 - val_binary_accuracy: 0.6649\n",
            "Epoch 196/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6325 - binary_accuracy: 0.6405 - val_loss: 0.6055 - val_binary_accuracy: 0.6627\n",
            "Epoch 197/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6373 - binary_accuracy: 0.6348 - val_loss: 0.6086 - val_binary_accuracy: 0.6616\n",
            "Epoch 198/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6333 - binary_accuracy: 0.6381 - val_loss: 0.6065 - val_binary_accuracy: 0.6624\n",
            "Epoch 199/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6363 - val_loss: 0.6060 - val_binary_accuracy: 0.6631\n",
            "Epoch 200/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6388 - val_loss: 0.6074 - val_binary_accuracy: 0.6635\n",
            "Epoch 201/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6416 - val_loss: 0.6044 - val_binary_accuracy: 0.6624\n",
            "Epoch 202/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6426 - val_loss: 0.6081 - val_binary_accuracy: 0.6635\n",
            "Epoch 203/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6328 - binary_accuracy: 0.6396 - val_loss: 0.6075 - val_binary_accuracy: 0.6627\n",
            "Epoch 204/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6393 - val_loss: 0.6068 - val_binary_accuracy: 0.6642\n",
            "Epoch 205/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6360 - val_loss: 0.6043 - val_binary_accuracy: 0.6605\n",
            "Epoch 206/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6415 - val_loss: 0.6055 - val_binary_accuracy: 0.6616\n",
            "Epoch 207/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6400 - val_loss: 0.6041 - val_binary_accuracy: 0.6620\n",
            "Epoch 208/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6392 - val_loss: 0.6048 - val_binary_accuracy: 0.6624\n",
            "Epoch 209/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6372 - val_loss: 0.6089 - val_binary_accuracy: 0.6620\n",
            "Epoch 210/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6310 - binary_accuracy: 0.6407 - val_loss: 0.6046 - val_binary_accuracy: 0.6627\n",
            "Epoch 211/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6437 - val_loss: 0.6050 - val_binary_accuracy: 0.6609\n",
            "Epoch 212/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6418 - val_loss: 0.6031 - val_binary_accuracy: 0.6609\n",
            "Epoch 213/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6416 - val_loss: 0.6047 - val_binary_accuracy: 0.6616\n",
            "Epoch 214/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6450 - val_loss: 0.6054 - val_binary_accuracy: 0.6638\n",
            "Epoch 215/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6395 - val_loss: 0.6037 - val_binary_accuracy: 0.6627\n",
            "Epoch 216/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6345 - val_loss: 0.6102 - val_binary_accuracy: 0.6624\n",
            "Epoch 217/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6371 - val_loss: 0.6054 - val_binary_accuracy: 0.6602\n",
            "Epoch 218/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6411 - val_loss: 0.6040 - val_binary_accuracy: 0.6613\n",
            "Epoch 219/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6354 - val_loss: 0.6031 - val_binary_accuracy: 0.6664\n",
            "Epoch 220/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6337 - binary_accuracy: 0.6409 - val_loss: 0.6080 - val_binary_accuracy: 0.6624\n",
            "Epoch 221/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6432 - val_loss: 0.6034 - val_binary_accuracy: 0.6653\n",
            "Epoch 222/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6413 - val_loss: 0.6061 - val_binary_accuracy: 0.6661\n",
            "Epoch 223/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6441 - val_loss: 0.6058 - val_binary_accuracy: 0.6624\n",
            "Epoch 224/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6423 - val_loss: 0.6035 - val_binary_accuracy: 0.6642\n",
            "Epoch 225/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6442 - val_loss: 0.6029 - val_binary_accuracy: 0.6638\n",
            "Epoch 226/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6392 - val_loss: 0.6032 - val_binary_accuracy: 0.6627\n",
            "Epoch 227/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6325 - binary_accuracy: 0.6407 - val_loss: 0.6059 - val_binary_accuracy: 0.6646\n",
            "Epoch 228/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6488 - val_loss: 0.6032 - val_binary_accuracy: 0.6631\n",
            "Epoch 229/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6415 - val_loss: 0.6064 - val_binary_accuracy: 0.6635\n",
            "Epoch 230/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6465 - val_loss: 0.6039 - val_binary_accuracy: 0.6646\n",
            "Epoch 231/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6383 - val_loss: 0.6047 - val_binary_accuracy: 0.6624\n",
            "Epoch 232/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6326 - binary_accuracy: 0.6392 - val_loss: 0.6045 - val_binary_accuracy: 0.6638\n",
            "Epoch 233/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6433 - val_loss: 0.6031 - val_binary_accuracy: 0.6613\n",
            "Epoch 234/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6435 - val_loss: 0.6054 - val_binary_accuracy: 0.6631\n",
            "Epoch 235/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6407 - val_loss: 0.6033 - val_binary_accuracy: 0.6646\n",
            "Epoch 236/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6371 - val_loss: 0.6046 - val_binary_accuracy: 0.6672\n",
            "Epoch 237/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6462 - val_loss: 0.6041 - val_binary_accuracy: 0.6627\n",
            "Epoch 238/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6462 - val_loss: 0.6068 - val_binary_accuracy: 0.6627\n",
            "Epoch 239/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6423 - val_loss: 0.6047 - val_binary_accuracy: 0.6627\n",
            "Epoch 240/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6418 - val_loss: 0.6021 - val_binary_accuracy: 0.6627\n",
            "Epoch 241/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6458 - val_loss: 0.6047 - val_binary_accuracy: 0.6649\n",
            "Epoch 242/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6294 - binary_accuracy: 0.6426 - val_loss: 0.6029 - val_binary_accuracy: 0.6642\n",
            "Epoch 243/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6415 - val_loss: 0.6075 - val_binary_accuracy: 0.6657\n",
            "Epoch 244/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6466 - val_loss: 0.6040 - val_binary_accuracy: 0.6635\n",
            "Epoch 245/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6441 - val_loss: 0.6038 - val_binary_accuracy: 0.6638\n",
            "Epoch 246/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6422 - val_loss: 0.6057 - val_binary_accuracy: 0.6642\n",
            "Epoch 247/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6403 - val_loss: 0.6046 - val_binary_accuracy: 0.6635\n",
            "Epoch 248/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6447 - val_loss: 0.6036 - val_binary_accuracy: 0.6631\n",
            "Epoch 249/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6426 - val_loss: 0.6038 - val_binary_accuracy: 0.6649\n",
            "Epoch 250/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6469 - val_loss: 0.6021 - val_binary_accuracy: 0.6642\n",
            "Epoch 251/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6417 - val_loss: 0.6022 - val_binary_accuracy: 0.6642\n",
            "Epoch 252/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6420 - val_loss: 0.6036 - val_binary_accuracy: 0.6646\n",
            "Epoch 253/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6434 - val_loss: 0.6061 - val_binary_accuracy: 0.6638\n",
            "Epoch 254/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6410 - val_loss: 0.6046 - val_binary_accuracy: 0.6672\n",
            "Epoch 255/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6440 - val_loss: 0.6052 - val_binary_accuracy: 0.6661\n",
            "Epoch 256/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6433 - val_loss: 0.6041 - val_binary_accuracy: 0.6646\n",
            "Epoch 257/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6439 - val_loss: 0.6030 - val_binary_accuracy: 0.6631\n",
            "Epoch 258/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6456 - val_loss: 0.6016 - val_binary_accuracy: 0.6649\n",
            "Epoch 259/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6427 - val_loss: 0.6053 - val_binary_accuracy: 0.6631\n",
            "Epoch 260/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6405 - val_loss: 0.6040 - val_binary_accuracy: 0.6646\n",
            "Epoch 261/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6481 - val_loss: 0.6034 - val_binary_accuracy: 0.6635\n",
            "Epoch 262/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6405 - val_loss: 0.6040 - val_binary_accuracy: 0.6642\n",
            "Epoch 263/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6462 - val_loss: 0.6028 - val_binary_accuracy: 0.6631\n",
            "Epoch 264/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6464 - val_loss: 0.6017 - val_binary_accuracy: 0.6653\n",
            "Epoch 265/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6443 - val_loss: 0.6044 - val_binary_accuracy: 0.6672\n",
            "Epoch 266/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6412 - val_loss: 0.6037 - val_binary_accuracy: 0.6653\n",
            "Epoch 267/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6398 - val_loss: 0.6070 - val_binary_accuracy: 0.6642\n",
            "Epoch 268/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6439 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 269/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6464 - val_loss: 0.6006 - val_binary_accuracy: 0.6661\n",
            "Epoch 270/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6426 - val_loss: 0.5990 - val_binary_accuracy: 0.6638\n",
            "Epoch 271/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6463 - val_loss: 0.6030 - val_binary_accuracy: 0.6638\n",
            "Epoch 272/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6333 - binary_accuracy: 0.6410 - val_loss: 0.6029 - val_binary_accuracy: 0.6661\n",
            "Epoch 273/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6496 - val_loss: 0.6034 - val_binary_accuracy: 0.6646\n",
            "Epoch 274/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6398 - val_loss: 0.6067 - val_binary_accuracy: 0.6642\n",
            "Epoch 275/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6456 - val_loss: 0.6013 - val_binary_accuracy: 0.6613\n",
            "Epoch 276/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6491 - val_loss: 0.6023 - val_binary_accuracy: 0.6657\n",
            "Epoch 277/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6451 - val_loss: 0.6029 - val_binary_accuracy: 0.6661\n",
            "Epoch 278/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6437 - val_loss: 0.6002 - val_binary_accuracy: 0.6661\n",
            "Epoch 279/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6488 - val_loss: 0.6023 - val_binary_accuracy: 0.6657\n",
            "Epoch 280/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6460 - val_loss: 0.6034 - val_binary_accuracy: 0.6631\n",
            "Epoch 281/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6438 - val_loss: 0.6049 - val_binary_accuracy: 0.6668\n",
            "Epoch 282/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6473 - val_loss: 0.6048 - val_binary_accuracy: 0.6649\n",
            "Epoch 283/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6416 - val_loss: 0.6059 - val_binary_accuracy: 0.6664\n",
            "Epoch 284/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6418 - val_loss: 0.6058 - val_binary_accuracy: 0.6646\n",
            "Epoch 285/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6447 - val_loss: 0.6040 - val_binary_accuracy: 0.6631\n",
            "Epoch 286/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6448 - val_loss: 0.6043 - val_binary_accuracy: 0.6642\n",
            "Epoch 287/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6504 - val_loss: 0.6030 - val_binary_accuracy: 0.6635\n",
            "Epoch 288/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6484 - val_loss: 0.6031 - val_binary_accuracy: 0.6661\n",
            "Epoch 289/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6483 - val_loss: 0.6053 - val_binary_accuracy: 0.6646\n",
            "Epoch 290/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6442 - val_loss: 0.6043 - val_binary_accuracy: 0.6653\n",
            "Epoch 291/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6445 - val_loss: 0.6074 - val_binary_accuracy: 0.6638\n",
            "Epoch 292/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6448 - val_loss: 0.6036 - val_binary_accuracy: 0.6620\n",
            "Epoch 293/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6450 - val_loss: 0.6031 - val_binary_accuracy: 0.6646\n",
            "Epoch 294/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6506 - val_loss: 0.6052 - val_binary_accuracy: 0.6646\n",
            "Epoch 295/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6416 - val_loss: 0.6060 - val_binary_accuracy: 0.6635\n",
            "Epoch 296/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6528 - val_loss: 0.6033 - val_binary_accuracy: 0.6668\n",
            "Epoch 297/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6416 - val_loss: 0.6067 - val_binary_accuracy: 0.6664\n",
            "Epoch 298/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6330 - binary_accuracy: 0.6418 - val_loss: 0.6021 - val_binary_accuracy: 0.6646\n",
            "Epoch 299/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6408 - val_loss: 0.6039 - val_binary_accuracy: 0.6653\n",
            "Epoch 300/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6447 - val_loss: 0.6010 - val_binary_accuracy: 0.6638\n",
            "Epoch 301/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6449 - val_loss: 0.6011 - val_binary_accuracy: 0.6661\n",
            "Epoch 302/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6456 - val_loss: 0.6020 - val_binary_accuracy: 0.6646\n",
            "Epoch 303/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6503 - val_loss: 0.6028 - val_binary_accuracy: 0.6635\n",
            "Epoch 304/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6478 - val_loss: 0.6007 - val_binary_accuracy: 0.6653\n",
            "Epoch 305/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6450 - val_loss: 0.6032 - val_binary_accuracy: 0.6642\n",
            "Epoch 306/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6471 - val_loss: 0.6006 - val_binary_accuracy: 0.6661\n",
            "Epoch 307/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6475 - val_loss: 0.5994 - val_binary_accuracy: 0.6653\n",
            "Epoch 308/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6467 - val_loss: 0.6044 - val_binary_accuracy: 0.6657\n",
            "Epoch 309/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6473 - val_loss: 0.6007 - val_binary_accuracy: 0.6661\n",
            "Epoch 310/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6454 - val_loss: 0.6060 - val_binary_accuracy: 0.6672\n",
            "Epoch 311/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6459 - val_loss: 0.6016 - val_binary_accuracy: 0.6664\n",
            "Epoch 312/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6410 - val_loss: 0.6028 - val_binary_accuracy: 0.6657\n",
            "Epoch 313/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6479 - val_loss: 0.6032 - val_binary_accuracy: 0.6664\n",
            "Epoch 314/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6439 - val_loss: 0.6025 - val_binary_accuracy: 0.6675\n",
            "Epoch 315/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6477 - val_loss: 0.6040 - val_binary_accuracy: 0.6657\n",
            "Epoch 316/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6456 - val_loss: 0.6012 - val_binary_accuracy: 0.6638\n",
            "Epoch 317/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6491 - val_loss: 0.5996 - val_binary_accuracy: 0.6657\n",
            "Epoch 318/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6494 - val_loss: 0.6006 - val_binary_accuracy: 0.6649\n",
            "Epoch 319/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6456 - val_loss: 0.6033 - val_binary_accuracy: 0.6679\n",
            "Epoch 320/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6439 - val_loss: 0.6035 - val_binary_accuracy: 0.6661\n",
            "Epoch 321/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6468 - val_loss: 0.6000 - val_binary_accuracy: 0.6638\n",
            "Epoch 322/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6482 - val_loss: 0.6014 - val_binary_accuracy: 0.6664\n",
            "Epoch 323/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6325 - binary_accuracy: 0.6416 - val_loss: 0.6085 - val_binary_accuracy: 0.6683\n",
            "Epoch 324/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6368 - val_loss: 0.6027 - val_binary_accuracy: 0.6657\n",
            "Epoch 325/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6433 - val_loss: 0.6001 - val_binary_accuracy: 0.6649\n",
            "Epoch 326/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6467 - val_loss: 0.6028 - val_binary_accuracy: 0.6668\n",
            "Epoch 327/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6496 - val_loss: 0.6016 - val_binary_accuracy: 0.6638\n",
            "Epoch 328/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6443 - val_loss: 0.6033 - val_binary_accuracy: 0.6646\n",
            "Epoch 329/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6326 - binary_accuracy: 0.6440 - val_loss: 0.6055 - val_binary_accuracy: 0.6635\n",
            "Epoch 330/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6482 - val_loss: 0.6007 - val_binary_accuracy: 0.6661\n",
            "Epoch 331/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6439 - val_loss: 0.6019 - val_binary_accuracy: 0.6664\n",
            "Epoch 332/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6451 - val_loss: 0.6022 - val_binary_accuracy: 0.6657\n",
            "Epoch 333/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6454 - val_loss: 0.6029 - val_binary_accuracy: 0.6664\n",
            "Epoch 334/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6312 - binary_accuracy: 0.6486 - val_loss: 0.6031 - val_binary_accuracy: 0.6668\n",
            "Epoch 335/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6435 - val_loss: 0.6037 - val_binary_accuracy: 0.6675\n",
            "Epoch 336/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6490 - val_loss: 0.6003 - val_binary_accuracy: 0.6679\n",
            "Epoch 337/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6456 - val_loss: 0.6038 - val_binary_accuracy: 0.6668\n",
            "Epoch 338/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6507 - val_loss: 0.6019 - val_binary_accuracy: 0.6668\n",
            "Epoch 339/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6422 - val_loss: 0.6042 - val_binary_accuracy: 0.6672\n",
            "Epoch 340/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6446 - val_loss: 0.6020 - val_binary_accuracy: 0.6661\n",
            "Epoch 341/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6445 - val_loss: 0.6024 - val_binary_accuracy: 0.6675\n",
            "Epoch 342/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6479 - val_loss: 0.6035 - val_binary_accuracy: 0.6675\n",
            "Epoch 343/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6481 - val_loss: 0.5995 - val_binary_accuracy: 0.6642\n",
            "Epoch 344/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6466 - val_loss: 0.6017 - val_binary_accuracy: 0.6668\n",
            "Epoch 345/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6511 - val_loss: 0.6025 - val_binary_accuracy: 0.6635\n",
            "Epoch 346/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6450 - val_loss: 0.6055 - val_binary_accuracy: 0.6653\n",
            "Epoch 347/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6483 - val_loss: 0.5997 - val_binary_accuracy: 0.6672\n",
            "Epoch 348/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6407 - val_loss: 0.6017 - val_binary_accuracy: 0.6642\n",
            "Epoch 349/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6476 - val_loss: 0.6018 - val_binary_accuracy: 0.6657\n",
            "Epoch 350/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6433 - val_loss: 0.6036 - val_binary_accuracy: 0.6653\n",
            "Epoch 351/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6476 - val_loss: 0.6013 - val_binary_accuracy: 0.6653\n",
            "Epoch 352/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6480 - val_loss: 0.6017 - val_binary_accuracy: 0.6679\n",
            "Epoch 353/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6486 - val_loss: 0.6039 - val_binary_accuracy: 0.6683\n",
            "Epoch 354/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6424 - val_loss: 0.6012 - val_binary_accuracy: 0.6653\n",
            "Epoch 355/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6493 - val_loss: 0.5998 - val_binary_accuracy: 0.6649\n",
            "Epoch 356/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6428 - val_loss: 0.6036 - val_binary_accuracy: 0.6646\n",
            "Epoch 357/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6496 - val_loss: 0.6004 - val_binary_accuracy: 0.6627\n",
            "Epoch 358/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6472 - val_loss: 0.6037 - val_binary_accuracy: 0.6638\n",
            "Epoch 359/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6472 - val_loss: 0.6004 - val_binary_accuracy: 0.6624\n",
            "Epoch 360/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6479 - val_loss: 0.6010 - val_binary_accuracy: 0.6653\n",
            "Epoch 361/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6475 - val_loss: 0.6047 - val_binary_accuracy: 0.6657\n",
            "Epoch 362/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6484 - val_loss: 0.5999 - val_binary_accuracy: 0.6646\n",
            "Epoch 363/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6459 - val_loss: 0.5997 - val_binary_accuracy: 0.6653\n",
            "Epoch 364/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6462 - val_loss: 0.6023 - val_binary_accuracy: 0.6653\n",
            "Epoch 365/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6491 - val_loss: 0.6009 - val_binary_accuracy: 0.6661\n",
            "Epoch 366/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6492 - val_loss: 0.6025 - val_binary_accuracy: 0.6661\n",
            "Epoch 367/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6400 - val_loss: 0.6040 - val_binary_accuracy: 0.6649\n",
            "Epoch 368/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6508 - val_loss: 0.6007 - val_binary_accuracy: 0.6668\n",
            "Epoch 369/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6479 - val_loss: 0.6024 - val_binary_accuracy: 0.6646\n",
            "Epoch 370/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6495 - val_loss: 0.6014 - val_binary_accuracy: 0.6679\n",
            "Epoch 371/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6512 - val_loss: 0.6001 - val_binary_accuracy: 0.6646\n",
            "Epoch 372/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6512 - val_loss: 0.6023 - val_binary_accuracy: 0.6664\n",
            "Epoch 373/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6448 - val_loss: 0.6014 - val_binary_accuracy: 0.6657\n",
            "Epoch 374/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6462 - val_loss: 0.6011 - val_binary_accuracy: 0.6649\n",
            "Epoch 375/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6481 - val_loss: 0.6018 - val_binary_accuracy: 0.6683\n",
            "Epoch 376/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6459 - val_loss: 0.6029 - val_binary_accuracy: 0.6683\n",
            "Epoch 377/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6506 - val_loss: 0.6029 - val_binary_accuracy: 0.6661\n",
            "Epoch 378/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6464 - val_loss: 0.5990 - val_binary_accuracy: 0.6661\n",
            "Epoch 379/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6468 - val_loss: 0.6012 - val_binary_accuracy: 0.6679\n",
            "Epoch 380/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6445 - val_loss: 0.5998 - val_binary_accuracy: 0.6653\n",
            "Epoch 381/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6442 - val_loss: 0.6018 - val_binary_accuracy: 0.6664\n",
            "Epoch 382/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6461 - val_loss: 0.6033 - val_binary_accuracy: 0.6646\n",
            "Epoch 383/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6537 - val_loss: 0.6066 - val_binary_accuracy: 0.6661\n",
            "Epoch 384/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6483 - val_loss: 0.6011 - val_binary_accuracy: 0.6646\n",
            "Epoch 385/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6431 - val_loss: 0.6013 - val_binary_accuracy: 0.6675\n",
            "Epoch 386/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6513 - val_loss: 0.6029 - val_binary_accuracy: 0.6672\n",
            "Epoch 387/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6488 - val_loss: 0.6037 - val_binary_accuracy: 0.6649\n",
            "Epoch 388/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6440 - val_loss: 0.6029 - val_binary_accuracy: 0.6649\n",
            "Epoch 389/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6513 - val_loss: 0.6009 - val_binary_accuracy: 0.6627\n",
            "Epoch 390/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6473 - val_loss: 0.6022 - val_binary_accuracy: 0.6668\n",
            "Epoch 391/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6484 - val_loss: 0.6022 - val_binary_accuracy: 0.6675\n",
            "Epoch 392/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6469 - val_loss: 0.6042 - val_binary_accuracy: 0.6661\n",
            "Epoch 393/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6479 - val_loss: 0.6006 - val_binary_accuracy: 0.6653\n",
            "Epoch 394/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6473 - val_loss: 0.6000 - val_binary_accuracy: 0.6664\n",
            "Epoch 395/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6480 - val_loss: 0.5994 - val_binary_accuracy: 0.6661\n",
            "Epoch 396/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6488 - val_loss: 0.6036 - val_binary_accuracy: 0.6646\n",
            "Epoch 397/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6499 - val_loss: 0.6016 - val_binary_accuracy: 0.6686\n",
            "Epoch 398/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6469 - val_loss: 0.6025 - val_binary_accuracy: 0.6679\n",
            "Epoch 399/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6444 - val_loss: 0.6009 - val_binary_accuracy: 0.6679\n",
            "Epoch 400/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6473 - val_loss: 0.6029 - val_binary_accuracy: 0.6672\n",
            "Epoch 401/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6504 - val_loss: 0.5998 - val_binary_accuracy: 0.6646\n",
            "Epoch 402/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6487 - val_loss: 0.6040 - val_binary_accuracy: 0.6638\n",
            "Epoch 403/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6453 - val_loss: 0.6032 - val_binary_accuracy: 0.6642\n",
            "Epoch 404/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6522 - val_loss: 0.6007 - val_binary_accuracy: 0.6661\n",
            "Epoch 405/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6498 - val_loss: 0.5978 - val_binary_accuracy: 0.6661\n",
            "Epoch 406/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6485 - val_loss: 0.6035 - val_binary_accuracy: 0.6635\n",
            "Epoch 407/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6474 - val_loss: 0.5999 - val_binary_accuracy: 0.6668\n",
            "Epoch 408/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6255 - binary_accuracy: 0.6486 - val_loss: 0.6022 - val_binary_accuracy: 0.6646\n",
            "Epoch 409/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6379 - val_loss: 0.6026 - val_binary_accuracy: 0.6668\n",
            "Epoch 410/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6449 - val_loss: 0.5977 - val_binary_accuracy: 0.6653\n",
            "Epoch 411/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6484 - val_loss: 0.6004 - val_binary_accuracy: 0.6649\n",
            "Epoch 412/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6450 - val_loss: 0.6032 - val_binary_accuracy: 0.6672\n",
            "Epoch 413/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6460 - val_loss: 0.5994 - val_binary_accuracy: 0.6675\n",
            "Epoch 414/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6477 - val_loss: 0.6014 - val_binary_accuracy: 0.6683\n",
            "Epoch 415/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6466 - val_loss: 0.6061 - val_binary_accuracy: 0.6672\n",
            "Epoch 416/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6485 - val_loss: 0.6005 - val_binary_accuracy: 0.6679\n",
            "Epoch 417/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6463 - val_loss: 0.5990 - val_binary_accuracy: 0.6661\n",
            "Epoch 418/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6467 - val_loss: 0.6002 - val_binary_accuracy: 0.6672\n",
            "Epoch 419/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6494 - val_loss: 0.6016 - val_binary_accuracy: 0.6661\n",
            "Epoch 420/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6506 - val_loss: 0.6024 - val_binary_accuracy: 0.6668\n",
            "Epoch 421/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6536 - val_loss: 0.5982 - val_binary_accuracy: 0.6675\n",
            "Epoch 422/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6478 - val_loss: 0.6007 - val_binary_accuracy: 0.6661\n",
            "Epoch 423/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6504 - val_loss: 0.6006 - val_binary_accuracy: 0.6661\n",
            "Epoch 424/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6530 - val_loss: 0.6024 - val_binary_accuracy: 0.6657\n",
            "Epoch 425/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6438 - val_loss: 0.6022 - val_binary_accuracy: 0.6679\n",
            "Epoch 426/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6500 - val_loss: 0.6042 - val_binary_accuracy: 0.6697\n",
            "Epoch 427/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6487 - val_loss: 0.6035 - val_binary_accuracy: 0.6675\n",
            "Epoch 428/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6553 - val_loss: 0.6002 - val_binary_accuracy: 0.6683\n",
            "Epoch 429/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6522 - val_loss: 0.5989 - val_binary_accuracy: 0.6686\n",
            "Epoch 430/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6481 - val_loss: 0.5987 - val_binary_accuracy: 0.6679\n",
            "Epoch 431/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6491 - val_loss: 0.6009 - val_binary_accuracy: 0.6679\n",
            "Epoch 432/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6497 - val_loss: 0.6011 - val_binary_accuracy: 0.6675\n",
            "Epoch 433/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6500 - val_loss: 0.6021 - val_binary_accuracy: 0.6675\n",
            "Epoch 434/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6506 - val_loss: 0.6026 - val_binary_accuracy: 0.6686\n",
            "Epoch 435/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6451 - val_loss: 0.6026 - val_binary_accuracy: 0.6653\n",
            "Epoch 436/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6478 - val_loss: 0.6025 - val_binary_accuracy: 0.6686\n",
            "Epoch 437/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6473 - val_loss: 0.5993 - val_binary_accuracy: 0.6661\n",
            "Epoch 438/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6499 - val_loss: 0.6054 - val_binary_accuracy: 0.6661\n",
            "Epoch 439/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6436 - val_loss: 0.6014 - val_binary_accuracy: 0.6679\n",
            "Epoch 440/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6521 - val_loss: 0.6013 - val_binary_accuracy: 0.6679\n",
            "Epoch 441/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6530 - val_loss: 0.5982 - val_binary_accuracy: 0.6697\n",
            "Epoch 442/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6479 - val_loss: 0.6003 - val_binary_accuracy: 0.6694\n",
            "Epoch 443/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6459 - val_loss: 0.6008 - val_binary_accuracy: 0.6694\n",
            "Epoch 444/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6252 - binary_accuracy: 0.6513 - val_loss: 0.5991 - val_binary_accuracy: 0.6686\n",
            "Epoch 445/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6441 - val_loss: 0.6041 - val_binary_accuracy: 0.6683\n",
            "Epoch 446/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6476 - val_loss: 0.6021 - val_binary_accuracy: 0.6701\n",
            "Epoch 447/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6565 - val_loss: 0.5991 - val_binary_accuracy: 0.6672\n",
            "Epoch 448/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6517 - val_loss: 0.6007 - val_binary_accuracy: 0.6701\n",
            "Epoch 449/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6513 - val_loss: 0.5989 - val_binary_accuracy: 0.6690\n",
            "Epoch 450/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6501 - val_loss: 0.6010 - val_binary_accuracy: 0.6701\n",
            "Epoch 451/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6452 - val_loss: 0.5997 - val_binary_accuracy: 0.6646\n",
            "Epoch 452/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6437 - val_loss: 0.6019 - val_binary_accuracy: 0.6675\n",
            "Epoch 453/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6474 - val_loss: 0.5988 - val_binary_accuracy: 0.6649\n",
            "Epoch 454/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6475 - val_loss: 0.5999 - val_binary_accuracy: 0.6705\n",
            "Epoch 455/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6481 - val_loss: 0.6054 - val_binary_accuracy: 0.6672\n",
            "Epoch 456/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6448 - val_loss: 0.6060 - val_binary_accuracy: 0.6661\n",
            "Epoch 457/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6415 - val_loss: 0.5985 - val_binary_accuracy: 0.6686\n",
            "Epoch 458/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6278 - binary_accuracy: 0.6476 - val_loss: 0.5985 - val_binary_accuracy: 0.6668\n",
            "Epoch 459/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6473 - val_loss: 0.6044 - val_binary_accuracy: 0.6672\n",
            "Epoch 460/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6496 - val_loss: 0.6037 - val_binary_accuracy: 0.6661\n",
            "Epoch 461/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6473 - val_loss: 0.6032 - val_binary_accuracy: 0.6694\n",
            "Epoch 462/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6497 - val_loss: 0.5986 - val_binary_accuracy: 0.6675\n",
            "Epoch 463/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6485 - val_loss: 0.6005 - val_binary_accuracy: 0.6683\n",
            "Epoch 464/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6509 - val_loss: 0.5995 - val_binary_accuracy: 0.6668\n",
            "Epoch 465/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6486 - val_loss: 0.5990 - val_binary_accuracy: 0.6683\n",
            "Epoch 466/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6523 - val_loss: 0.6001 - val_binary_accuracy: 0.6653\n",
            "Epoch 467/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6519 - val_loss: 0.6033 - val_binary_accuracy: 0.6694\n",
            "Epoch 468/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6471 - val_loss: 0.6024 - val_binary_accuracy: 0.6683\n",
            "Epoch 469/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6507 - val_loss: 0.6024 - val_binary_accuracy: 0.6646\n",
            "Epoch 470/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6286 - binary_accuracy: 0.6526 - val_loss: 0.6036 - val_binary_accuracy: 0.6664\n",
            "Epoch 471/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6463 - val_loss: 0.6012 - val_binary_accuracy: 0.6683\n",
            "Epoch 472/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6507 - val_loss: 0.6012 - val_binary_accuracy: 0.6642\n",
            "Epoch 473/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6526 - val_loss: 0.6002 - val_binary_accuracy: 0.6675\n",
            "Epoch 474/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6524 - val_loss: 0.6016 - val_binary_accuracy: 0.6661\n",
            "Epoch 475/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6467 - val_loss: 0.6048 - val_binary_accuracy: 0.6675\n",
            "Epoch 476/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6498 - val_loss: 0.6011 - val_binary_accuracy: 0.6686\n",
            "Epoch 477/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6480 - val_loss: 0.6023 - val_binary_accuracy: 0.6661\n",
            "Epoch 478/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6480 - val_loss: 0.6037 - val_binary_accuracy: 0.6668\n",
            "Epoch 479/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6524 - val_loss: 0.6024 - val_binary_accuracy: 0.6697\n",
            "Epoch 480/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6479 - val_loss: 0.6004 - val_binary_accuracy: 0.6668\n",
            "Epoch 481/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6484 - val_loss: 0.5978 - val_binary_accuracy: 0.6686\n",
            "Epoch 482/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6247 - binary_accuracy: 0.6474 - val_loss: 0.5992 - val_binary_accuracy: 0.6675\n",
            "Epoch 483/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6482 - val_loss: 0.6008 - val_binary_accuracy: 0.6679\n",
            "Epoch 484/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6479 - val_loss: 0.5984 - val_binary_accuracy: 0.6668\n",
            "Epoch 485/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6501 - val_loss: 0.6016 - val_binary_accuracy: 0.6690\n",
            "Epoch 486/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6477 - val_loss: 0.5995 - val_binary_accuracy: 0.6697\n",
            "Epoch 487/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6489 - val_loss: 0.5979 - val_binary_accuracy: 0.6701\n",
            "Epoch 488/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6478 - val_loss: 0.6079 - val_binary_accuracy: 0.6701\n",
            "Epoch 489/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6476 - val_loss: 0.6010 - val_binary_accuracy: 0.6705\n",
            "Epoch 490/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6501 - val_loss: 0.6012 - val_binary_accuracy: 0.6675\n",
            "Epoch 491/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6483 - val_loss: 0.5976 - val_binary_accuracy: 0.6690\n",
            "Epoch 492/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6272 - binary_accuracy: 0.6462 - val_loss: 0.6021 - val_binary_accuracy: 0.6664\n",
            "Epoch 493/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6518 - val_loss: 0.6010 - val_binary_accuracy: 0.6701\n",
            "Epoch 494/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6484 - val_loss: 0.6000 - val_binary_accuracy: 0.6672\n",
            "Epoch 495/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6479 - val_loss: 0.6005 - val_binary_accuracy: 0.6690\n",
            "Epoch 496/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6525 - val_loss: 0.6015 - val_binary_accuracy: 0.6675\n",
            "Epoch 497/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6516 - val_loss: 0.6036 - val_binary_accuracy: 0.6705\n",
            "Epoch 498/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6474 - val_loss: 0.6001 - val_binary_accuracy: 0.6683\n",
            "Epoch 499/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6497 - val_loss: 0.5989 - val_binary_accuracy: 0.6664\n",
            "Epoch 500/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6510 - val_loss: 0.5990 - val_binary_accuracy: 0.6675\n",
            "Epoch 501/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6490 - val_loss: 0.6021 - val_binary_accuracy: 0.6638\n",
            "Epoch 502/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6575 - val_loss: 0.6014 - val_binary_accuracy: 0.6675\n",
            "Epoch 503/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6498 - val_loss: 0.6013 - val_binary_accuracy: 0.6694\n",
            "Epoch 504/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6462 - val_loss: 0.6046 - val_binary_accuracy: 0.6661\n",
            "Epoch 505/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6519 - val_loss: 0.5986 - val_binary_accuracy: 0.6653\n",
            "Epoch 506/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6566 - val_loss: 0.5994 - val_binary_accuracy: 0.6701\n",
            "Epoch 507/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6482 - val_loss: 0.6005 - val_binary_accuracy: 0.6635\n",
            "Epoch 508/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6501 - val_loss: 0.6013 - val_binary_accuracy: 0.6679\n",
            "Epoch 509/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6532 - val_loss: 0.5977 - val_binary_accuracy: 0.6653\n",
            "Epoch 510/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6430 - val_loss: 0.5999 - val_binary_accuracy: 0.6694\n",
            "Epoch 511/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6484 - val_loss: 0.5997 - val_binary_accuracy: 0.6690\n",
            "Epoch 512/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6526 - val_loss: 0.5999 - val_binary_accuracy: 0.6675\n",
            "Epoch 513/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6530 - val_loss: 0.5972 - val_binary_accuracy: 0.6694\n",
            "Epoch 514/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6520 - val_loss: 0.6001 - val_binary_accuracy: 0.6683\n",
            "Epoch 515/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6581 - val_loss: 0.6001 - val_binary_accuracy: 0.6694\n",
            "Epoch 516/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6480 - val_loss: 0.5991 - val_binary_accuracy: 0.6679\n",
            "Epoch 517/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6399 - val_loss: 0.6053 - val_binary_accuracy: 0.6668\n",
            "Epoch 518/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6486 - val_loss: 0.5979 - val_binary_accuracy: 0.6686\n",
            "Epoch 519/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6533 - val_loss: 0.5989 - val_binary_accuracy: 0.6686\n",
            "Epoch 520/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6506 - val_loss: 0.5999 - val_binary_accuracy: 0.6694\n",
            "Epoch 521/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6544 - val_loss: 0.6022 - val_binary_accuracy: 0.6701\n",
            "Epoch 522/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6490 - val_loss: 0.6002 - val_binary_accuracy: 0.6675\n",
            "Epoch 523/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6479 - val_loss: 0.6003 - val_binary_accuracy: 0.6668\n",
            "Epoch 524/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6271 - binary_accuracy: 0.6458 - val_loss: 0.6006 - val_binary_accuracy: 0.6649\n",
            "Epoch 525/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6480 - val_loss: 0.6041 - val_binary_accuracy: 0.6668\n",
            "Epoch 526/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6252 - binary_accuracy: 0.6479 - val_loss: 0.5995 - val_binary_accuracy: 0.6679\n",
            "Epoch 527/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6513 - val_loss: 0.5987 - val_binary_accuracy: 0.6697\n",
            "Epoch 528/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6513 - val_loss: 0.6024 - val_binary_accuracy: 0.6679\n",
            "Epoch 529/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6553 - val_loss: 0.6002 - val_binary_accuracy: 0.6672\n",
            "Epoch 530/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6496 - val_loss: 0.5994 - val_binary_accuracy: 0.6672\n",
            "Epoch 531/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6509 - val_loss: 0.5981 - val_binary_accuracy: 0.6661\n",
            "Epoch 532/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6445 - val_loss: 0.6021 - val_binary_accuracy: 0.6708\n",
            "Epoch 533/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6520 - val_loss: 0.5985 - val_binary_accuracy: 0.6712\n",
            "Epoch 534/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6486 - val_loss: 0.5996 - val_binary_accuracy: 0.6712\n",
            "Epoch 535/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_accuracy: 0.6534 - val_loss: 0.5992 - val_binary_accuracy: 0.6679\n",
            "Epoch 536/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.6528 - val_loss: 0.5987 - val_binary_accuracy: 0.6694\n",
            "Epoch 537/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6474 - val_loss: 0.6020 - val_binary_accuracy: 0.6657\n",
            "Epoch 538/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6535 - val_loss: 0.6006 - val_binary_accuracy: 0.6679\n",
            "Epoch 539/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6442 - val_loss: 0.6004 - val_binary_accuracy: 0.6638\n",
            "Epoch 540/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6544 - val_loss: 0.6007 - val_binary_accuracy: 0.6697\n",
            "Epoch 541/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6503 - val_loss: 0.6019 - val_binary_accuracy: 0.6686\n",
            "Epoch 542/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6600 - val_loss: 0.6001 - val_binary_accuracy: 0.6672\n",
            "Epoch 543/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6510 - val_loss: 0.6022 - val_binary_accuracy: 0.6679\n",
            "Epoch 544/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6554 - val_loss: 0.5992 - val_binary_accuracy: 0.6690\n",
            "Epoch 545/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6513 - val_loss: 0.6003 - val_binary_accuracy: 0.6672\n",
            "Epoch 546/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6513 - val_loss: 0.6003 - val_binary_accuracy: 0.6683\n",
            "Epoch 547/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6260 - binary_accuracy: 0.6501 - val_loss: 0.6020 - val_binary_accuracy: 0.6675\n",
            "Epoch 548/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6552 - val_loss: 0.5975 - val_binary_accuracy: 0.6679\n",
            "Epoch 549/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6516 - val_loss: 0.6001 - val_binary_accuracy: 0.6694\n",
            "Epoch 550/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6522 - val_loss: 0.5980 - val_binary_accuracy: 0.6705\n",
            "Epoch 551/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6568 - val_loss: 0.5990 - val_binary_accuracy: 0.6701\n",
            "Epoch 552/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6537 - val_loss: 0.5970 - val_binary_accuracy: 0.6679\n",
            "Epoch 553/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6465 - val_loss: 0.6002 - val_binary_accuracy: 0.6675\n",
            "Epoch 554/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.6484 - val_loss: 0.5991 - val_binary_accuracy: 0.6701\n",
            "Epoch 555/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6530 - val_loss: 0.5984 - val_binary_accuracy: 0.6683\n",
            "Epoch 556/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6541 - val_loss: 0.5964 - val_binary_accuracy: 0.6679\n",
            "Epoch 557/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6558 - val_loss: 0.5990 - val_binary_accuracy: 0.6697\n",
            "Epoch 558/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6530 - val_loss: 0.5993 - val_binary_accuracy: 0.6664\n",
            "Epoch 559/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6490 - val_loss: 0.6019 - val_binary_accuracy: 0.6694\n",
            "Epoch 560/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6572 - val_loss: 0.5989 - val_binary_accuracy: 0.6694\n",
            "Epoch 561/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6480 - val_loss: 0.6034 - val_binary_accuracy: 0.6716\n",
            "Epoch 562/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6459 - val_loss: 0.5996 - val_binary_accuracy: 0.6675\n",
            "Epoch 563/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6467 - val_loss: 0.5991 - val_binary_accuracy: 0.6712\n",
            "Epoch 564/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_accuracy: 0.6496 - val_loss: 0.5992 - val_binary_accuracy: 0.6697\n",
            "Epoch 565/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6229 - binary_accuracy: 0.6484 - val_loss: 0.6015 - val_binary_accuracy: 0.6683\n",
            "Epoch 566/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6541 - val_loss: 0.5992 - val_binary_accuracy: 0.6697\n",
            "Epoch 567/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6535 - val_loss: 0.5997 - val_binary_accuracy: 0.6694\n",
            "Epoch 568/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6507 - val_loss: 0.6030 - val_binary_accuracy: 0.6697\n",
            "Epoch 569/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6619 - val_loss: 0.5978 - val_binary_accuracy: 0.6679\n",
            "Epoch 570/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6504 - val_loss: 0.6011 - val_binary_accuracy: 0.6705\n",
            "Epoch 571/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6526 - val_loss: 0.6029 - val_binary_accuracy: 0.6697\n",
            "Epoch 572/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6494 - val_loss: 0.6000 - val_binary_accuracy: 0.6679\n",
            "Epoch 573/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6267 - binary_accuracy: 0.6466 - val_loss: 0.6017 - val_binary_accuracy: 0.6690\n",
            "Epoch 574/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6288 - binary_accuracy: 0.6531 - val_loss: 0.5989 - val_binary_accuracy: 0.6708\n",
            "Epoch 575/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6485 - val_loss: 0.5973 - val_binary_accuracy: 0.6697\n",
            "Epoch 576/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6526 - val_loss: 0.6010 - val_binary_accuracy: 0.6694\n",
            "Epoch 577/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6454 - val_loss: 0.6007 - val_binary_accuracy: 0.6672\n",
            "Epoch 578/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6479 - val_loss: 0.6030 - val_binary_accuracy: 0.6675\n",
            "Epoch 579/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6534 - val_loss: 0.5995 - val_binary_accuracy: 0.6697\n",
            "Epoch 580/700\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.6246 - binary_accuracy: 0.6542 - val_loss: 0.6014 - val_binary_accuracy: 0.6668\n",
            "Epoch 581/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6479 - val_loss: 0.6001 - val_binary_accuracy: 0.6664\n",
            "Epoch 582/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6496 - val_loss: 0.5985 - val_binary_accuracy: 0.6716\n",
            "Epoch 583/700\n",
            "184/184 [==============================] - 1s 3ms/step - loss: 0.6261 - binary_accuracy: 0.6497 - val_loss: 0.6029 - val_binary_accuracy: 0.6716\n",
            "Epoch 584/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6479 - val_loss: 0.6016 - val_binary_accuracy: 0.6697\n",
            "Epoch 585/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6255 - binary_accuracy: 0.6485 - val_loss: 0.5981 - val_binary_accuracy: 0.6708\n",
            "Epoch 586/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6538 - val_loss: 0.5991 - val_binary_accuracy: 0.6679\n",
            "Epoch 587/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6518 - val_loss: 0.6003 - val_binary_accuracy: 0.6708\n",
            "Epoch 588/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6509 - val_loss: 0.6029 - val_binary_accuracy: 0.6705\n",
            "Epoch 589/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6511 - val_loss: 0.5990 - val_binary_accuracy: 0.6690\n",
            "Epoch 590/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6543 - val_loss: 0.5970 - val_binary_accuracy: 0.6723\n",
            "Epoch 591/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6536 - val_loss: 0.5994 - val_binary_accuracy: 0.6679\n",
            "Epoch 592/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6507 - val_loss: 0.6004 - val_binary_accuracy: 0.6679\n",
            "Epoch 593/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6253 - binary_accuracy: 0.6482 - val_loss: 0.5978 - val_binary_accuracy: 0.6690\n",
            "Epoch 594/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6494 - val_loss: 0.6012 - val_binary_accuracy: 0.6708\n",
            "Epoch 595/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6500 - val_loss: 0.5987 - val_binary_accuracy: 0.6701\n",
            "Epoch 596/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6547 - val_loss: 0.6000 - val_binary_accuracy: 0.6701\n",
            "Epoch 597/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6524 - val_loss: 0.5992 - val_binary_accuracy: 0.6690\n",
            "Epoch 598/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6480 - val_loss: 0.5978 - val_binary_accuracy: 0.6697\n",
            "Epoch 599/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6535 - val_loss: 0.6017 - val_binary_accuracy: 0.6694\n",
            "Epoch 600/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6509 - val_loss: 0.5972 - val_binary_accuracy: 0.6701\n",
            "Epoch 601/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6476 - val_loss: 0.6004 - val_binary_accuracy: 0.6705\n",
            "Epoch 602/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6240 - binary_accuracy: 0.6547 - val_loss: 0.6022 - val_binary_accuracy: 0.6690\n",
            "Epoch 603/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6535 - val_loss: 0.5999 - val_binary_accuracy: 0.6657\n",
            "Epoch 604/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6546 - val_loss: 0.6011 - val_binary_accuracy: 0.6683\n",
            "Epoch 605/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6547 - val_loss: 0.5982 - val_binary_accuracy: 0.6694\n",
            "Epoch 606/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6510 - val_loss: 0.5981 - val_binary_accuracy: 0.6701\n",
            "Epoch 607/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6480 - val_loss: 0.6007 - val_binary_accuracy: 0.6679\n",
            "Epoch 608/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6481 - val_loss: 0.6030 - val_binary_accuracy: 0.6675\n",
            "Epoch 609/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6485 - val_loss: 0.6031 - val_binary_accuracy: 0.6694\n",
            "Epoch 610/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6495 - val_loss: 0.6026 - val_binary_accuracy: 0.6690\n",
            "Epoch 611/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6555 - val_loss: 0.6017 - val_binary_accuracy: 0.6657\n",
            "Epoch 612/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6540 - val_loss: 0.6004 - val_binary_accuracy: 0.6683\n",
            "Epoch 613/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6483 - val_loss: 0.5999 - val_binary_accuracy: 0.6683\n",
            "Epoch 614/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6546 - val_loss: 0.6005 - val_binary_accuracy: 0.6683\n",
            "Epoch 615/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6272 - binary_accuracy: 0.6527 - val_loss: 0.6016 - val_binary_accuracy: 0.6683\n",
            "Epoch 616/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6513 - val_loss: 0.5989 - val_binary_accuracy: 0.6683\n",
            "Epoch 617/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6542 - val_loss: 0.6021 - val_binary_accuracy: 0.6679\n",
            "Epoch 618/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.6558 - val_loss: 0.6008 - val_binary_accuracy: 0.6694\n",
            "Epoch 619/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6489 - val_loss: 0.5981 - val_binary_accuracy: 0.6701\n",
            "Epoch 620/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6549 - val_loss: 0.6004 - val_binary_accuracy: 0.6675\n",
            "Epoch 621/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6524 - val_loss: 0.6013 - val_binary_accuracy: 0.6690\n",
            "Epoch 622/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6531 - val_loss: 0.6009 - val_binary_accuracy: 0.6686\n",
            "Epoch 623/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6517 - val_loss: 0.6018 - val_binary_accuracy: 0.6668\n",
            "Epoch 624/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6502 - val_loss: 0.6006 - val_binary_accuracy: 0.6679\n",
            "Epoch 625/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6518 - val_loss: 0.5997 - val_binary_accuracy: 0.6679\n",
            "Epoch 626/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6506 - val_loss: 0.6010 - val_binary_accuracy: 0.6694\n",
            "Epoch 627/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6525 - val_loss: 0.6000 - val_binary_accuracy: 0.6686\n",
            "Epoch 628/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6613 - val_loss: 0.5991 - val_binary_accuracy: 0.6686\n",
            "Epoch 629/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6207 - binary_accuracy: 0.6534 - val_loss: 0.5986 - val_binary_accuracy: 0.6672\n",
            "Epoch 630/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6478 - val_loss: 0.6011 - val_binary_accuracy: 0.6686\n",
            "Epoch 631/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6467 - val_loss: 0.5985 - val_binary_accuracy: 0.6683\n",
            "Epoch 632/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6502 - val_loss: 0.6003 - val_binary_accuracy: 0.6679\n",
            "Epoch 633/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6482 - val_loss: 0.5973 - val_binary_accuracy: 0.6683\n",
            "Epoch 634/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6250 - binary_accuracy: 0.6529 - val_loss: 0.5996 - val_binary_accuracy: 0.6675\n",
            "Epoch 635/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6491 - val_loss: 0.5991 - val_binary_accuracy: 0.6675\n",
            "Epoch 636/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6506 - val_loss: 0.6010 - val_binary_accuracy: 0.6672\n",
            "Epoch 637/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6541 - val_loss: 0.5987 - val_binary_accuracy: 0.6686\n",
            "Epoch 638/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6229 - binary_accuracy: 0.6517 - val_loss: 0.5992 - val_binary_accuracy: 0.6683\n",
            "Epoch 639/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6545 - val_loss: 0.5957 - val_binary_accuracy: 0.6705\n",
            "Epoch 640/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6500 - val_loss: 0.5974 - val_binary_accuracy: 0.6690\n",
            "Epoch 641/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6502 - val_loss: 0.6022 - val_binary_accuracy: 0.6672\n",
            "Epoch 642/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6230 - binary_accuracy: 0.6535 - val_loss: 0.5983 - val_binary_accuracy: 0.6668\n",
            "Epoch 643/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6545 - val_loss: 0.6012 - val_binary_accuracy: 0.6672\n",
            "Epoch 644/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6527 - val_loss: 0.6001 - val_binary_accuracy: 0.6661\n",
            "Epoch 645/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6467 - val_loss: 0.6016 - val_binary_accuracy: 0.6668\n",
            "Epoch 646/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6543 - val_loss: 0.6000 - val_binary_accuracy: 0.6679\n",
            "Epoch 647/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6535 - val_loss: 0.5985 - val_binary_accuracy: 0.6675\n",
            "Epoch 648/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6518 - val_loss: 0.6009 - val_binary_accuracy: 0.6690\n",
            "Epoch 649/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6240 - binary_accuracy: 0.6535 - val_loss: 0.6019 - val_binary_accuracy: 0.6683\n",
            "Epoch 650/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6496 - val_loss: 0.5978 - val_binary_accuracy: 0.6675\n",
            "Epoch 651/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6552 - val_loss: 0.6007 - val_binary_accuracy: 0.6679\n",
            "Epoch 652/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6507 - val_loss: 0.5981 - val_binary_accuracy: 0.6686\n",
            "Epoch 653/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6520 - val_loss: 0.6006 - val_binary_accuracy: 0.6668\n",
            "Epoch 654/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6518 - val_loss: 0.5993 - val_binary_accuracy: 0.6683\n",
            "Epoch 655/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6470 - val_loss: 0.6027 - val_binary_accuracy: 0.6683\n",
            "Epoch 656/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6504 - val_loss: 0.5979 - val_binary_accuracy: 0.6694\n",
            "Epoch 657/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6527 - val_loss: 0.6002 - val_binary_accuracy: 0.6672\n",
            "Epoch 658/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6530 - val_loss: 0.5989 - val_binary_accuracy: 0.6686\n",
            "Epoch 659/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6526 - val_loss: 0.5999 - val_binary_accuracy: 0.6683\n",
            "Epoch 660/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6527 - val_loss: 0.5977 - val_binary_accuracy: 0.6690\n",
            "Epoch 661/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6521 - val_loss: 0.6010 - val_binary_accuracy: 0.6672\n",
            "Epoch 662/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6501 - val_loss: 0.5993 - val_binary_accuracy: 0.6686\n",
            "Epoch 663/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6517 - val_loss: 0.6024 - val_binary_accuracy: 0.6675\n",
            "Epoch 664/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6537 - val_loss: 0.5975 - val_binary_accuracy: 0.6675\n",
            "Epoch 665/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6507 - val_loss: 0.5994 - val_binary_accuracy: 0.6668\n",
            "Epoch 666/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6510 - val_loss: 0.6011 - val_binary_accuracy: 0.6672\n",
            "Epoch 667/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6507 - val_loss: 0.6002 - val_binary_accuracy: 0.6672\n",
            "Epoch 668/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6517 - val_loss: 0.5980 - val_binary_accuracy: 0.6679\n",
            "Epoch 669/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6479 - val_loss: 0.6021 - val_binary_accuracy: 0.6672\n",
            "Epoch 670/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6526 - val_loss: 0.5998 - val_binary_accuracy: 0.6653\n",
            "Epoch 671/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6555 - val_loss: 0.6012 - val_binary_accuracy: 0.6661\n",
            "Epoch 672/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6203 - binary_accuracy: 0.6547 - val_loss: 0.6028 - val_binary_accuracy: 0.6683\n",
            "Epoch 673/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6524 - val_loss: 0.5974 - val_binary_accuracy: 0.6683\n",
            "Epoch 674/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6511 - val_loss: 0.6028 - val_binary_accuracy: 0.6705\n",
            "Epoch 675/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.6526 - val_loss: 0.5989 - val_binary_accuracy: 0.6690\n",
            "Epoch 676/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6500 - val_loss: 0.6032 - val_binary_accuracy: 0.6668\n",
            "Epoch 677/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6490 - val_loss: 0.6011 - val_binary_accuracy: 0.6664\n",
            "Epoch 678/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6518 - val_loss: 0.6011 - val_binary_accuracy: 0.6675\n",
            "Epoch 679/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6523 - val_loss: 0.5986 - val_binary_accuracy: 0.6690\n",
            "Epoch 680/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6558 - val_loss: 0.5973 - val_binary_accuracy: 0.6675\n",
            "Epoch 681/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6513 - val_loss: 0.5976 - val_binary_accuracy: 0.6694\n",
            "Epoch 682/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6508 - val_loss: 0.5998 - val_binary_accuracy: 0.6672\n",
            "Epoch 683/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6238 - binary_accuracy: 0.6510 - val_loss: 0.5992 - val_binary_accuracy: 0.6668\n",
            "Epoch 684/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6555 - val_loss: 0.6018 - val_binary_accuracy: 0.6686\n",
            "Epoch 685/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6519 - val_loss: 0.6011 - val_binary_accuracy: 0.6672\n",
            "Epoch 686/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6252 - binary_accuracy: 0.6554 - val_loss: 0.5997 - val_binary_accuracy: 0.6697\n",
            "Epoch 687/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6530 - val_loss: 0.6025 - val_binary_accuracy: 0.6675\n",
            "Epoch 688/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6497 - val_loss: 0.5977 - val_binary_accuracy: 0.6686\n",
            "Epoch 689/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6542 - val_loss: 0.6007 - val_binary_accuracy: 0.6668\n",
            "Epoch 690/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6202 - binary_accuracy: 0.6549 - val_loss: 0.5980 - val_binary_accuracy: 0.6675\n",
            "Epoch 691/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6488 - val_loss: 0.6004 - val_binary_accuracy: 0.6675\n",
            "Epoch 692/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6530 - val_loss: 0.5979 - val_binary_accuracy: 0.6664\n",
            "Epoch 693/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6506 - val_loss: 0.6002 - val_binary_accuracy: 0.6675\n",
            "Epoch 694/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6250 - binary_accuracy: 0.6549 - val_loss: 0.6005 - val_binary_accuracy: 0.6675\n",
            "Epoch 695/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6470 - val_loss: 0.6002 - val_binary_accuracy: 0.6668\n",
            "Epoch 696/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6521 - val_loss: 0.6015 - val_binary_accuracy: 0.6672\n",
            "Epoch 697/700\n",
            "184/184 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.6484 - val_loss: 0.5994 - val_binary_accuracy: 0.6672\n",
            "Epoch 698/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6518 - val_loss: 0.5984 - val_binary_accuracy: 0.6683\n",
            "Epoch 699/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6514 - val_loss: 0.6016 - val_binary_accuracy: 0.6675\n",
            "Epoch 700/700\n",
            "184/184 [==============================] - 0s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6533 - val_loss: 0.5970 - val_binary_accuracy: 0.6679\n",
            "Accuracy on training data: 0.6807479858398438% \n",
            " Error on training data: 0.31925201416015625\n",
            "Accuracy on test data: 0.6514084339141846% \n",
            " Error on test data: 0.34859156608581543\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iUZdbA4d9JIY0QCAk1dOkgLRRBERUUQcSCgmVX/VTshbWBlXUt6Ora145tVURERUQp0lQQCL33QEINCYH0+nx/PG+SSTKBBJhMAue+rlyZeducGcJ75ulijEEppZQqycfbASillKqaNEEopZRySxOEUkoptzRBKKWUcksThFJKKbc0QSillHJLE4RSp4CIfCoiz5Xz2FgRGXiy11HK0zRBKKWUcksThFJKKbc0QagzhlO184iIrBGRNBH5WETqi8gvIpIiInNEpI7L8ZeLyHoRSRaR+SLS3mVfNxFZ4Zz3DRBY4rUuE5FVzrmLROTsE4z5dhHZJiJJIjJNRBo520VEXhORgyJyVETWikgnZ98QEdngxLZHRB4+oQ9MnfE0QagzzdXAIKANMAz4BXgciMT+f7gfQETaAF8DDzr7ZgA/iUgNEakB/AB8AYQD3zrXxTm3GzARuAOoC7wPTBORgIoEKiIXAi8C1wINgV3AJGf3xUB/532EOcckOvs+Bu4wxoQCnYC5FXldpQpoglBnmreMMQeMMXuA34ElxpiVxphM4Hugm3PcSOBnY8xsY0wO8AoQBPQF+gD+wOvGmBxjzBRgmctrjAbeN8YsMcbkGWM+A7Kc8yriBmCiMWaFMSYLGAecIyLNgRwgFGgHiDFmozFmn3NeDtBBRGoZYw4bY1ZU8HWVAjRBqDPPAZfHGW6e13QeN8J+YwfAGJMPxAGNnX17TPGZLne5PG4GPORULyWLSDLQxDmvIkrGkIotJTQ2xswF3gbeAQ6KyAciUss59GpgCLBLRBaIyDkVfF2lAE0QSpVlL/ZGD9g6f+xNfg+wD2jsbCvQ1OVxHPC8Maa2y0+wMebrk4whBFtltQfAGPOmMaYH0AFb1fSIs32ZMWY4UA9bFTa5gq+rFKAJQqmyTAaGishFIuIPPIStJloELAZygftFxF9ErgJ6uZz7IXCniPR2GpNDRGSoiIRWMIavgVtEpKvTfvECtkosVkR6Otf3B9KATCDfaSO5QUTCnKqxo0D+SXwO6gymCUIpN4wxm4EbgbeAQ9gG7WHGmGxjTDZwFXAzkIRtr5jqcm4McDu2CugwsM05tqIxzAGeAr7DllpaAaOc3bWwiegwthoqEfi3s+9vQKyIHAXuxLZlKFVhogsGKaWUckdLEEoppdzSBKGUUsotTRBKKaXc0gShlFLKLT9vB3CqREREmObNm3s7DKWUqlaWL19+yBgT6W7faZMgmjdvTkxMjLfDUEqpakVEdpW1T6uYlFJKuaUJQimllFuaIJRSSrl12rRBuJOTk0N8fDyZmZneDsXjAgMDiYqKwt/f39uhKKVOE6d1goiPjyc0NJTmzZtTfOLN04sxhsTEROLj42nRooW3w1FKnSY8WsUkIoNFZLOzZOJYN/ubisg8EVnpLAM5xNneXEQynCUbV4nIeyfy+pmZmdStW/e0Tg4AIkLdunXPiJKSUqryeKwEISK+2MVMBgHxwDIRmWaM2eBy2JPAZGPMuyLSAbusY3Nn33ZjTNdTEMfJXqJaOFPep1Kq8niyBNEL2GaM2eFMjzwJGF7iGIOdthjsurp7PRiPW3n5hv1HMknPyq3sl1ZKqSrNkwmiMXZlrQLxzjZX44EbRSQeW3q4z2VfC6fqaYGInOfuBURktIjEiEhMQkLCCQWZbwwHUzJJz8k7ofOPJzk5mf/+978VPm/IkCEkJyd7ICKllCofb3dzvQ741BgThV1D9wsR8cEujtLUGNMN+Afwlct6u4WMMR8YY6KNMdGRkW5Hih+XpytmykoQubnHLrHMmDGD2rVreyospZQ6Lk/2YtqDXcO3QJSzzdWtwGAAY8xiEQkEIowxB7HLO2KMWS4i27Fr7la7uTTGjh3L9u3b6dq1K/7+/gQGBlKnTh02bdrEli1buOKKK4iLiyMzM5MHHniA0aNHA0VTh6SmpnLppZdy7rnnsmjRIho3bsyPP/5IUFCQl9+ZUup058kEsQxoLSItsIlhFHB9iWN2AxcBn4pIeyAQSBCRSCDJGJMnIi2B1sCOkwnmnz+tZ8Peo6W2GyA9K5cafj74+1asQNWhUS2eGdbxmMdMmDCBdevWsWrVKubPn8/QoUNZt25dYXfUiRMnEh4eTkZGBj179uTqq6+mbt26xa6xdetWvv76az788EOuvfZavvvuO2688cYKxaqUUhXlsQRhjMkVkXuBmYAvMNEYs15EngVijDHTsAvBfygiY7D36puNMUZE+gPPikgOdsH1O40xSZ6KtTL16tWr2FiFN998k++//x6AuLg4tm7dWipBtGjRgq5dbYeuHj16EBsbW2nxKqXOXB4dKGeMmYFtfHbd9rTL4w1APzfnfYddqP2UKeubfm5+Phv2HqVhWBCRoQGn8iXdCgkJKXw8f/585syZw+LFiwkODmbAgAFuxzIEBBTF5evrS0ZGhsfjVEopbzdSe52nG6lDQ0NJSUlxu+/IkSPUqVOH4OBgNm3axF9//eXhaJRSqvxO66k2yqcgRRiPXL1u3br069ePTp06ERQURP369Qv3DR48mPfee4/27dvTtm1b+vTp45EYlFLqRIgxnrkxVrbo6GhTcsGgjRs30r59+2Oel5dvWL/3CA3DAokMDfRkiB5XnverlFKuRGS5MSba3b4zvoqpwOmRJpVS6tQ54xOEzmCklFLunfEJopAWIZRSqhhNEFqEUEoptzRBKKWUcuuMTxCe7eSqlFLV1xmfIKqamjVrejsEpZQCNEEopZQqg46k9rCxY8fSpEkT7rnnHgDGjx+Pn58f8+bN4/Dhw+Tk5PDcc88xfHjJxfaUUsq7zpwE8ctY2L+21GYBWjrTfVPB6b5p0BkunXDMQ0aOHMmDDz5YmCAmT57MzJkzuf/++6lVqxaHDh2iT58+XH755bqutFKqSjlzEoSXdOvWjYMHD7J3714SEhKoU6cODRo0YMyYMSxcuBAfHx/27NnDgQMHaNCggbfDVUqpQmdOgjjGN/2d8clEhgbSIMwzczFdc801TJkyhf379zNy5Ei+/PJLEhISWL58Of7+/jRv3tztNN9KKeVNZ06COCbBkx1dR44cye23386hQ4dYsGABkydPpl69evj7+zNv3jx27drlsddWSqkTpQmiEnTs2JGUlBQaN25Mw4YNueGGGxg2bBidO3cmOjqadu3aeTtEpZQqRRMEgHh+oNzatUUN5BERESxevNjtcampqR6ORCmlykfHQSillHJLEwQ6X59SSrlz2ieI02XFvOM5U96nUqrynNYJIjAwkMTExPLdPKvx/dUYQ2JiIoGB1XvJVKVU1XJaN1JHRUURHx9PQkLCMY87kJxBaoAfyUH+lRTZqRcYGEhUVJS3w1BKnUZO6wTh7+9PixYtjnvcNc/M5NroJjw9rH0lRKWUUtXDaV3FVF52mFw1rmNSSikP0AQBdhyE5gellCpGEwTgo7OoKqVUKZogABHI1yKEUkoVowkCpw1C84NSShWjCQIQEW2kVkqpEjyaIERksIhsFpFtIjLWzf6mIjJPRFaKyBoRGeKyb5xz3mYRucSjcaIlCKWUKslj4yBExBd4BxgExAPLRGSaMWaDy2FPApONMe+KSAdgBtDceTwK6Ag0AuaISBtjTJ6HYtXyg1JKleDJEkQvYJsxZocxJhuYBAwvcYwBajmPw4C9zuPhwCRjTJYxZiewzbmeR4joXEZKKVWSJxNEYyDO5Xm8s83VeOBGEYnHlh7uq8C5iMhoEYkRkZjjTadxLFrFpJRSpXm7kfo64FNjTBQwBPhCRModkzHmA2NMtDEmOjIy8oSDEB0op5RSpXhyLqY9QBOX51HONle3AoMBjDGLRSQQiCjnuaeMj/ZiUkqpUjxZglgGtBaRFiJSA9voPK3EMbuBiwBEpD0QCCQ4x40SkQARaQG0BpZ6KlAB8jU/KKVUMR4rQRhjckXkXmAm4AtMNMasF5FngRhjzDTgIeBDERmDbbC+2djW4vUiMhnYAOQC93iqBxM4vZg0QSilVDEene7bGDMD2/jsuu1pl8cbgH5lnPs88Lwn4yv2elrFpJRSxXi7kbpK8PGhWq8op5RSnqAJAhBEJ+tTSqkSNEHgdHP1dhBKKVXFaIJAB8oppZQ7miDQuZiUUsodTRDoXExKKeWOJgi0ikkppdzRBIEuGKSUUu5ogkBLEEop5Y4mCJzJ+jRBKKVUMZogsI3UOlBOKaWK0wTh0PSglFLFaYJAZ3NVSil3NEFgG6m1DKGUUsVpgsDO5qolCKWUKk4TBDqbq1JKuaMJAp3NVSml3NEEgQ6UU0opdzRBoLO5KqWUO5og0NlclVLKHU0QaBWTUkq5owkCnc1VKaXc0QSBliCUUsodTRDobK5KKeWOJggAnc1VKaVK0QSBU8Xk7SCUUqqK0QSB7eaqGUIppYrTBIHTBqEZQimlitEEQcGKct6OQimlqhZNENjZXHUktVJKFefRBCEig0Vks4hsE5Gxbva/JiKrnJ8tIpLssi/PZd80z8apTRBKKVWSn6cuLCK+wDvAICAeWCYi04wxGwqOMcaMcTn+PqCbyyUyjDFdPRVfSVqAUEqp4jxZgugFbDPG7DDGZAOTgOHHOP464GsPxlMmO1BOM4RSSrnyZIJoDMS5PI93tpUiIs2AFsBcl82BIhIjIn+JyBVlnDfaOSYmISHhhAPVKiallCqtqjRSjwKmGGPyXLY1M8ZEA9cDr4tIq5InGWM+MMZEG2OiIyMjT/jFdS4mpZQqzZMJYg/QxOV5lLPNnVGUqF4yxuxxfu8A5lO8feKU0tlclVKqNE8miGVAaxFpISI1sEmgVG8kEWkH1AEWu2yrIyIBzuMIoB+woeS5p4qPaAlCKaVK8lgvJmNMrojcC8wEfIGJxpj1IvIsEGOMKUgWo4BJpngrcXvgfRHJxyaxCa69n0490YFySilVgscSBIAxZgYwo8S2p0s8H+/mvEVAZ0/G5kqXHFVKqdKqSiO1V4m3A1BKqSpIEwS6YJBSSrmjCYKCyfo0QyillCtNEOhAOaWUckcTBDqbq1JKuaMJAkBLEEopVYomCGwjtWYIpZQqThMEtpurNlIrpVRxmiAAPx8hV4dSK6VUMeVKECLygIjUEutjEVkhIhd7OrjK4ucr5OZpglBKKVflLUH8nzHmKHAxdmK9vwETPBZVJfPz9SE3P9/bYSilVJVS3gRRMBvFEOALY8x6TqMZKvx9hBwtQSilVDHlTRDLRWQWNkHMFJFQ4LT5yu3n60Nu3mnzdpRS6pQo72yutwJdgR3GmHQRCQdu8VxYlcvPV8jRRmqllCqmvCWIc4DNxphkEbkReBI44rmwKpe/j5YglFKqpPImiHeBdBHpAjwEbAc+91hUlczP1y4YlK+lCKWUKlTeBJHrrPg2HHjbGPMOEOq5sCqXv6/9GHK0J5NSShUqbxtEioiMw3ZvPU9EfAB/z4VVufx8bIes3DxDgEfX2FNKqeqjvCWIkUAWdjzEfiAK+LfHoqpkfk4JQgfLKaVUkXIlCCcpfAmEichlQKYx5rRpg/D3tSUIrWJSSqki5Z1q41pgKXANcC2wRERGeDKwyuTnoyUIpZQqqbw17k8APY0xBwFEJBKYA0zxVGCVya+gBKFdXZVSqlB52yB8CpKDI7EC51Z5BVVMOqOrUkoVKW8J4lcRmQl87TwfCczwTEiVr6iKSUsQSilVoFwJwhjziIhcDfRzNn1gjPnec2FVrsJGam2DUEqpQuXu9W+M+Q74zoOxeE1hCUJ7MSmlVKFjJggRScH9as0CGGNMLY9EVcn8tAShlFKlHDNBGGNOm+k0jsXfV9sglFKqpNOmJ9LJKJxqQ3sxKaVUIU0QFE21ka0lCKWUKuTRBCEig0Vks4hsE5Gxbva/JiKrnJ8tIpLssu8mEdnq/NzkyTiD/H0ByMzO8+TLKKVUteKxuUtFxBd4BxgExAPLRGSaMWZDwTHGmDEux98HdHMehwPPANHYRvLlzrmHPRFrTWcK19SsXE9cXimlqiVPliB6AduMMTuMMdnAJOx6EmW5jqKBeJcAs40xSU5SmA0M9lSgIQG2BJGuJQillCrkyQTRGIhzeR7vbCtFRJoBLYC5FTlXREaLSIyIxCQkJJxwoCFaglBKqVKqSiP1KGCKMaZCX+GNMR8YY6KNMdGRkZEn/OIBfj74+QhpmiCUUqqQJxPEHqCJy/MoZ5s7oyiqXqrouSdNRAgJ8NMEoZRSLjyZIJYBrUWkhYjUwCaBaSUPEpF2QB1gscvmmcDFIlJHROoAFzvbPKZmgB+pWdoGoZRSBTzWi8kYkysi92Jv7L7ARGPMehF5FogxxhQki1HAJGOMcTk3SUT+hU0yAM8aY5I8FSvYhmotQSilVBGPJQgAY8wMSkwLbox5usTz8WWcOxGY6LHgSqgZ4EdKVk5lvZxSSlV5VaWR2usiagaQmJrt7TCUUqrK0AThiAwNICEly9thKKVUlaEJwhEZGkBSerauS62UUg5NEI7I0ACMgaQ0rWZSSinQBFGoce0gAGIPpXk5EqWUqho0QTjaN7SL423cd9TLkSilVNWgCcJRLzSAOsH+bD6Q6u1QlFKqStAE4RARmtYNIS4p3duhKKVUlaAJwkWTOkHEHdYEoZRSoAmimCbhwew5nEFmjs7JpJRSmiBc9G1Vl9x8w8z1+70dilJKeZ0mCBf9WkXQrG4wX/6129uhKKWU12mCMAaWfgjpSfj4CJed3ZDluw9rNZNS6oynCeLQVpj5OHx/BwCdGoWRl2948od1Xg5MKaW8SxNEZBs47yHYOgsStxPdPByAKcvjvRyYUkp5lyYIgK7Xg18Q/DqOyNAAnrqsAwA/r9nn5cCUUsp7NEEA1G4KPW+FHfMg4zAXtI0E4J6vVrDlQIqXg1NKKe/QBFHg7GshLwf+fJOWkTXp1cJWNd3w0RIvB6aUUt6hCaJAwy72Z+9KAPLy7RLZuoiQUupMpQnCVUQbSNwGwAtXdi7c/MCkld6KSCmlvEYThKuI1nAkDjIO07ZBKAseGQDAj6v26kpzSqkzjiYIVy0H2N9b5wDQrG4IL15lSxJ/bD3knZiUUspLNEG4ahwNIfVg84zCTQOcHk23fLqMycvivBWZUkpVOk0Qrnx8oPXFsH2unYIDaBgWVLj70e/W0P/leRw8mumtCJVSqtJogigpqgdkJkNy0YR939/dt/Dx7qR03pm3jaOZOd6ITimlKo0miJIadrW/t/xauKlb0zq8POLswuefLd7F2eNnkZaVW9nRKaVUpdEEUVLDrtC0L/zxOuQXzeh6bXQTYicMpVVkSOG2cVPXeiNCpZSqFJogSvLxgd53QMpe2DS91O7hXRsXPp62ei8b9x2tzOiUUqrSaIJwp91lENYUVn1date9F5zFV7f35pKO9QH4bFEs8zcf5NVZm7XxWil1WvFoghCRwSKyWUS2icjYMo65VkQ2iMh6EfnKZXueiKxyfqZ5Ms5SfP2gaW/Yv6bULh8foW+rCN7/WzRnR4UxaVkcN3+yjLfmbqPXC78xb/PBSg1VKaU8xWMJQkR8gXeAS4EOwHUi0qHEMa2BcUA/Y0xH4EGX3RnGmK7Oz+WeirNMjbrD0T2w4ccyD7n13Baltk2JiWfsd2tYt+eIJ6NTSimP82QJohewzRizwxiTDUwChpc45nbgHWPMYQBjTNX5+t3jZghtCKu+KvOQ4V0b0zIipNi2n9fuY9KyOF6dtdnDASqllGd5MkE0BlyHHsc721y1AdqIyJ8i8peIDHbZFygiMc72KzwYp3s1gqHtENi5EFL2l3nYvReeBcAzw4oVjkjOyOGxKWv49M+dTPhlEy/9uqlw367ENOIPp3smbqWUOkX8qsDrtwYGAFHAQhHpbIxJBpoZY/aISEtgroisNcZsdz1ZREYDowGaNm166qPrey+s/B/M+Sdc+a7bQ67qHsUVXRvj4yPsTc7gw9934ucjrNydzMrdycWOjagZwPltIhj4n4UALHtiIHWC/fHz1b4CSqmqx5N3pj1AE5fnUc42V/HANGNMjjFmJ7AFmzAwxuxxfu8A5gPdSr6AMeYDY0y0MSY6MjLy1L+D8JbQ6WrYNvuYh/n4CABPDO1A7ISh3Hl+KwAC/Hzo3rR24XH/mr6By9/+s/B5z+fn8Pqcrac+bqWUOgU8mSCWAa1FpIWI1ABGASV7I/2ALT0gIhHYKqcdIlJHRAJctvcDNngw1rLV7whpCZCWWO5TOjaqBUBkaABf3d6Hn+49t3BfenZesWM/XRTL3uSMYtuycvPIdxYsUkopb/FYgjDG5AL3AjOBjcBkY8x6EXlWRAp6Jc0EEkVkAzAPeMQYkwi0B2JEZLWzfYIxxjsJol47+3vn/HKf0vesCAa0jWTizT0J9Pelg5MwXDUKCwQgNSuXvhPmkuusN2GMoe2Tv/LEDzpKWynlXWLM6fFNNTo62sTExJz6C+dmw7vn2JXmhr4KPW87ocs0H/tzsedrxl/Mlv0pjHhvMQDntY7g2ugmZOfm89C3qwHY+eIQRITdienUDwsgwM/35N6LUkqVICLLjTHRbvdpgiiHtET4coTtzXTuGOj+d/APrNAlYmKTqBXkz8Wv2Qbq2AlDATiSnkOXZ2e5PeeJIe3p0qQ2176/mGFdGhHg58Pt57WkbYPQk3s/Sinl0ARxKmyfB9/fCan74ZrPoOOJ9bzdlZjG4fQcujYparwe+f5iluxMKtf5tYP9aVM/lJYRIayKS+ajm6L5z6wtPHZpO+rXCuSn1Xs5mpnDDb2bFZ5zJCOHQH8fLYEopUrRBHGqZKfBC43g/LEwYCyInJLLGmNoMW5GsW0dG9Vi/V47EWBwDd9SjdvuPDSoDa/O3gIUlVDAVm+de1YE/7utN8YY5BTFrZSq/o6VILw9DqJ6qeGMml4wAeKXwbWfQ0DNk76siDDlznNYsjMJETteIj/fMHbqWh6+uA3nt6nHsLf/oFFYICKCMYa9R0pPDFiQHABem72F0MCif94/th1i4ZYE/j5xKQAbnr2E4Bqe++fPcBJaUA0ttShVXWmCqKiOV8H6qbD9N5j1BAx745RcNrp5ONHNwwuf5+blk5OXzzXRTQj092Xt+IvxESEkwK+wxNGsbjC7Et2PyH7jt9LjKyYtK1olb1diOu0b1iIrN4+/f7yUYV0aMX3NXt66rjuRoQEATPhlE+8t2E7shKFc8tpCercM59nhnQqvkZKZw9vztjFmYBsC/YsngvNenkt6dh4bnh2MUqp60iG8FTViIoz4xD5e/qmdisMD/Hx9+Ns5zQtvvKGB/oQE2HwuIix7YiA/3tOvQtecsbZoypBvY+JZv/cI3Z6dzZKdSTz5wzr+2pHEf2ZvITcvnx9W7uG9BXbgelxSOpsPpPD54l3kOeMzlu9Kosdzc3h/wQ6mrdpLenYuz03fQHJ6NgCHUrNJz84jIzuP2ENpbNhbfN2MWev3c8lrCwu797o6mJJJZs7xq9TcMcawOi75+AcqpY5L2yBO1PLP4Kf7wS8Qnth/ytojKqqg+2zNAD9G9Iji00WxRNUJIv6wHXw39e6+fLF4F9+vLDmI/cT0bhFOn5Z13ZZQCky8OZr/+7T0v8WYgW0YER1F49pBdHt2FofTc/jfrb1pVDuQlpG2qq6gdNSrRTiT7zinwvH9uGoPD0xaxbs3dGdgh/r4+Yi2uSh1DNoG4Qk9brLdXue/AHFL7foRXvD17X3YtP8oo3o2JaiGL/+4uA2hAX4kpWVTM9CPAD9fukbVLkwQ6/95CWOnrmXTvqNsPZha4ddbsjPpuD2u3CUHgNfmbOG1OVvY/Nxgp0dVDjd+vASA/93am8jQAHYn2SqzpeXs1eUqP9+waX8KADG7DnPXlysYP6wDN/crPS17SS//uomQAD/uueCs4x4bE5tEvdBA6tUK4LNFsdzSrwU1/LQwrk4/WoI4GVkp8FonyEyG/o/AhU9W7utXwIcLd7AqLpl3buheuC0uKZ16tQI4nJbDBa/Mp2HtQJ4Z1pGbnIbsk+XaE+tEPDSoDZm5eayOO0LDsEA27U+hf5sIxgxsw5KdSdzw0RKu792UUT2bFM5xdXmXRkxbvZeB7eszZ+MB2jUI5dcH+xe+34e+Xc0713cnPTuX1KxcOjYK4+25W3llVuneXwDZufl8tWQXw7o04nB6DnuTMwob+h+5pC3/nrmZfw3vSOM6QfRqUZeaThtRXr45bSZhvOjV+dQNCWDyneUr0b0zbxuXdKzPWfV0vE51oN1cPWneC7DgpaLn3W6Ey9/2WpXTicrIzkMEAv19WbH7MHuTM7j3q5XFjmnXIJR/j+hCSlYO7y/YwXW9mvLh7ztoU78md51/Fkczc4g/nMGd/1vOTec044GBbej+LzvR4dlRYayJPzWLKN134VnM2XiwcD3w0AA/UrJyS8VaUJqYeHM0vVvU5bXZW/joj51c0bURP6zaC8CEqzozdmrRtCarn76YIxk5LI1N4ou/dtG/dQRvzd1Gz+Z1WBWXTE5e0f+Xm/s259NFsYzoEcWU5fFc3KE+L17Vmf/7dBlZufnUqxVIkL8P/r4+PHRxWyJDA7j3qxWkZ+e5rT6buiKei9rXJyzIv3Dbgi0JNAoLpHV9e7OdtX4//1uym9dHdiU8pAa7EtNoEBbI0YxcZm84wPW97azG8YfTqRNco7Dd6nimr9mLIAw9uyHr9hwhMyevsNNEQTVm7IShpGXlkmcMtQJtjFsPpPDBwh28cFVn/H19OJKRQ5d/zio8/njmbDjAjkOpZObkc9+FZx2zOvDXdfuoE1yD3i3rlus9ne6MMfxr+kau7NaYzlFhJ3wdTRCelJcD676D7+8o2hbZHm6eDgG14NAWaNCp7POrsN+3JnA4PYfYQ2n8Z/YWfn/0ApqEBx/3vOW7DtO2QSghNXy59+uVDGpfnz+2HWLK8vhixz19WTIIODEAACAASURBVAc6NqrF7Z/HkJdvSHO6xraMDGFHQhoArSJD2O48PhkiUJ4/9fNaR/D71kMn/Xolnd8mkpjYpML3+MM9/Zj4x05u6G2rBv/clshLv27C31dY8vhAPv5jB0t2JBGz6zAAvz96AbWC/Hlg0krmb07g8SHtGNmzKV3+OYvrejVld1Iaf25LZP7DA2hcJ4jWT/wC2CnlfX2E1fHJXNC2HgA/rd5Ll6jaGAxvz93G81d2ps2T9vjYCUMLE8Jjg9txc9/mtH/6VwAWPnIBT/64joVbEvj2znPo2TycNk/8QnZePrPG9KdN/VBiD6Ux4JX5hdcqsD0hlUB/XxrXDir2ubhOQTPnH/05q14ouxPTqR3iX5iESh474arODOxQn4iaAeX+/DfvT2HrwRQuO7tRuc8pYIxh35FMGpWIvaTs3HxEIPZQGlF1gj3exftwWjbd/jWb2sH+rHr64hO+jiaIyvBWDztfU4GonuAfDDsXwKM7ITi87HOrOGMMCalZ1Aut2PQirlKzcpm/+SBNw4PZeiCVxLQsbu5bvO6+oKrnjv4taRkZwvq9R7n9vJac9/K8YtdqERHCzkNpvHBlZ95bsL2w3eKTW3pyyyfLjhtLDT8fsnNL957q0zKcv3ZUvO0D7OSLBWNT3JVoKiKiZg0OpWaX+/jGtYOo4efDzkNpfHJzT+rWrFFsWvkCU+/uS9v6oXR8Zmax7T/dey7D3v4DgDb1a7LlQPnaps5vE8mCLQkAfHVbb9o0COWNOVv54q9dAHx5W2/6tqqLiBQrhexISEVEaBERUixBfHfXObSpH0rn8bMY0DaSns3D+WDhDt66rhv7jmTw2HdFJb0L2kbyyS29ADh4NJM8YwgPqcHjU9dxzwWtCjs9bN6fwqNTVrPaKb1+fFM0DcIC6dio+DfuH1buIS/fcHWPqGLbXUtEc/5xPgF+PuQbQ7O6dkzUn9sOEVzDl25N69Bvwlx8fYTdSekMPbsh71xvq3PnbT5I7xbhxxx3tGn/URZvT+SWcrSXFdiRkMqFry6gZoAf6/55SbnPK0kbqSvDHb9DXja85ExxEe9yo1r3HTTsAk16eSe2kyQiJ5UcwPayKvj2dnZUbbfHdG1SB4BeLcK5qH19wI4HiagZwPW9m1In2J+oOsF0aFSLiX/sZGjnhrw+x7YdfHxTNBe0rcecf/Tn/QU7+HZ5PGfVq0lyeja39GvBv2faJWCn3HkOK3Yf5oUZmxjWpRGDOzbgzd+2svVgCl/c2pvo5+ZwJCOnWFzN6wYTW8Z4E4Arujbi9VHdeOu3rbw6ewvPXdmJByatKnVc/zaRLHRuqMdSkeQAsMdluvhbPi07QT787Wru6N+y1PbnZxRNlFye5PD4kHa8MGNTYXIAO0gzJTOn2Pk3fLSEV6/pwpXdihaSNMbw6JQ1HErN4sJ29Ytdd+GWQzz943oA5m9OYP5me/2/u2kT2380iwVbEujfOoJeL/wGwFe39+a7FfF8t8KWVJc9MZAfV+0pTA4At35mv0R2a1qbRy5pS0JKVrF/q8u6NCQv3xBcw4+Jf+ws/PIBsGHfUe7/2la7XterKRe0jWT0F8sB2Pzc4GL/DrM3HABg3Z4j3PLJMoZ3bcSLV3UuTBL5+YbZGw/Qs3k44SE1GPHuYlKzcgs7mxR8ViJCTGwSk2PimBwTz8MXt6FZ3RAemrwaX2cdmtSsXLJy8zwylY6WIE61I/EQGAYvRpXe90xytWubqGwHjmZSv1bxZHSs6UF+XbePpTsP89Rl7cs8Jj07lw5Pz+T281rwxNAOxMQmMeK9xYXP8/MNBvD1Ea59bzFLY4uXIr6/uy9hQf5c+OoCHhrUhoycPP47fzs3923OM8M6FL5uTl4+y3cdpk/LuizckkBGTh4tI0LYfCCF3UnpXNa5Ef3/bUtDPgLPXdGZx793P61796a1WeGsSNg0PJgJV3fm+g9tj6+ezeuwLPZwmZ9h49pBNK4TdMyeYJed3ZA18UeK3QBddWhYi0l39GHysjie+3kjAC+POJtOjcLo0KgWy3cdpoavDxN+3cif2469VkpooB8pmbZEFd2sDit2H+ZULXcyun9LPli4A4DnrujEkz+sK9z3rys68ZTL84qYPaY/g14rPsbp+t5N+WrJbrfHPzm0feHnBHaxsO/u6stlb/1RuC0yNIBlTwzEGMPrc7byxm9b6da0NkczcopVoz5ySVs+XxzL4fQcnr6sA0//uO64n9cDF7VmzKA2FX+jaBWTdyx42ZYo/nzD/ga480/bHpG0A8QH6jT3aohnkuT0bEID/Qu/dc3ddIA+LeuWKvZ/vXQ345xG61aRIbw8ogs9mtmSTX6+KVw90PVxRXwbE0cNPx+i6gTRo1k4czcdKNYteOVTg5i+dh/X9WzCa3O28M687fzv1t6c2zqCX9bu464vVzDv4QHEJaUz+osYejYP5/eth6hfyy5OFVUniAA/X/LzDVNX7mHqingWbU8s1mgPdir5pLRsejw3x22cBVPNG2NYt+conRrXcpuAS84j1rh2ULFv0rUC/TiaWbHqti5RYcW+9Xtbh4a1yMs3bD6QcvyDHb4+QnhIDRJSsoptHxndhOy8/FM2LqnAjX2a8twVnU/oXE0Q3rTzd1g3xY66Pude6H4TfDAActJgzAZY9aVdY6Iat1Gcbg4czSQhJYtOjU+8Z0hFJKVlk5aVy6b9KQzqUFTtkpOXz28bD3BJxwbFSin+Lt1ntx1MZfTnMbwxqluZPVkKbvIF7Qzdm9Zm6t39yMs3tHrc3twn33EO176/mFE9m3Dn+a1oHhFS7vhf+nUT787fTmiAH3MeOp8/tx2iZWRNOjaqhY8Id3wRw5yNB7mqe2OmrnB/YwwN9KN9w1os3ZnEmIFtOJKRw8Q/dwJwbXQUk2PiaRIeRFxSUfIpaAMJ8vclo8TIe39fISfPcGmnBrxyTRc27jvKo1PWsDMxjZv7NmfbwdTCzgihgX68OaobPVuE08mlfSYsyJ/R/VtyRbfGvPzrJn50er65ahIeRFZOPgedRPDClZ3ZeSiVD3/fWa7Pzla9NmTSsrhyHV/Q2aJmgB8D29cr7I03un9LHh/SvlzXKH1NTRDeN+X/bFuEq04jbPJoMxiu/8Y7cakzxuLtiXRoWIsAf5/CKVzOfWkuw7s24pFL2p3wTL9Jadl0/9ds7ujfknFl3KQ27T9K2/qhhaWNhY9cwMGUTNKz8/j7xKVMvuMczo4K49352xndvyV/bDvEHV8sZ3T/lvxjUBue/3kjo/u3pEl4MFNXxLN0ZxLjLm1Pl2dn8dRlHVgbn8wPq/by+6MX0DAskMS0bJbFJjGkU8PCkl5Wbh7GUPje9yZn8P6C7TwxtENhZ4k/th4qHLz5ywPn0b6hXQ3yi7928dQP62hQK5Cpd/clISWLsCB/mkeEsHl/Cpe8bqujdrwwhKWxSYz64C8Axg/rwPaENL74axeDOtQnMyeP2MS0wkS35blL8fcVWoybwblnRfDQxW248r+LALi0UwN+WVc0Pc5V3Ruz9UAqa/cc4dZzWzD20nas33uUK975kxE9onjlmi4V/reDYycIjDGnxU+PHj1MlZaaYMyU24x5ppYxK78y5rkG9nHBz97V3o5QqRO2Nznd5OblH/e475bHmfHT1hXbdjQju9RxeXn55vPFsSY9K/eY18vPt6+ZlZNn1sQlVyBi9zbtO2qaPTbd/OObVaXiSU4vHacxxuTm5Ztmj0033Z+dZYwxJjs3z7zw8wazLznDGGPMyt2HTbPHppslOxILz2n22HRz3ktz3b6fZo9NN63G/WyMMeblXzead+ZtNVk5ecYYYz76fYdp9th08+xP6wvPuezN381NE5ec8HsGYkwZ91UtQVS2/Hzw8YEXm0CWyyjjC56A8x+1j/96D6Ki7Y9SqlLN23yQvq3qVqhXUFpWLmlZudSr5b63X25efrGR9XFJ6dQK9Ccs2L/UsfM2HaRp3WBaRZZeSiA3L5935m3nqu6NC8ck3fzJUhJTs/npvnPLHa8rrWKqin5+CJZ9ZMdIfHGlnfSvyyj44zVItv3IGe/SUJeXC5umQ4fhtpE76yg06uad2JVSVUZCShYB/j6lBhaW17ESxOkxWUx1dMmL8OA62zjd6kKI+wumP1iUHMA2ZhsDuVmw5D349ibbjvFW96J9SqkzWmRowAknh+PRgXLe4lcDajexj3veBhunQUikXZDo0GZbuti7Ev5ZYlBZ7O9Fj395FJqfBx0ut8/XToEd82D4O5XzHpRSpzWtYqoqjCk+iC5xuy0plEf0/8Flr8F4p5vjiInQfjj4lsj/+Xk2gbS6SAfsKaUAnWqjeih5w67bCp5OgvgYCG0A2amw6WeY93zpc2MmQurBoudT/g8u/Tc07WOrpyLbQmAt+Otdu0zqqK+h3RBIOQArv4Bz/2EbzpVSyoUmiKrMx7f4QkT1O8Ifr9tBdtd+brdN/rv9vWl68XN/ecTlOn7wt+9t1RXYGWZ3hsKfr8O2ObZd4+qP7PUrizF2Jly/GpX3mkqpCtEqpurmyB5I2ARnXWSfZ6Xa0di/PFr+a0S2h4SNpbf3vgv63AlhTWxycpWXWzRFSISbVdcykmH6GDh7JDTqaks9JeXnQ14W+AfB/Akw/0W7XKv/sadRVkp5jnZzPd3l5drGaxH4fDj0udveoPvcAwv/DUvehcwKzG3T9QbIOAy+/nDVR5C6Hxa9BUs/sPsLut8eWA/vnw93/m5nr512n91ep4VNFLmZEH0LHNhgq7RmPGKv8fRheKU1pB+Cv/8ItZtCeOlZRqusha9AvfbQ7vgL4pyRErdDrcbgf3IzAKvKoQniTJK825YASrZppCXCNzdC28Ew++nyX6/dZaWrrwLDoOUAiP0D0p2ZPAe/BL8+VvZ1rny/aFGlMRvg40Fw1GVenoKkk5NhSyl+zmIw8TFQsx7Me9Emqr99f+x4s9NtMuv3gL3G9t+g5QWlS0Rg22rCmsDA8bB1lm28L9mw705BZ4DxHp5Q7ojz+YQ1PvZxVUlOBjzfADpeCdd86u1oVDloI/WZpHZT99tD6sL/2VXD6HM3HFgH6UkQ2hA2/mSfb5wGNWraBvECJZMD2NLIhh+LbztWcoDiK+4lbi2eHACmjobWF8N3t0L9TnDDt5B2CD66CPxDbLsL2DaYvvfZ0sv0MXD5WxASYds0QuvDojdt1VVIXQgKhym3wJBXoNftcDgWfn4YetwETXoXzY315+v296B/Qb/7i2LaMA3WfAOjvizalu8yKVxeLqz/Hjpd5T4B7VkOwXVPfNbe1zrY3xVNRF9eC+Et4NKXjn1cwmY7QLNOs9L7Mo/CT/fb0mTrQeV/7SxnxtNNM459nKuC6svIE5uuWnmOJogzka9/8VHY9TsU339kD+Tn2l5TM8cVbR8x0f5u1g9ebWsfN+oGOZlFbRqP77Pf2r+50SarZDfz538+vPS2Nd/YH7DJ6j8uk77luCw5OucZWzLYsxz2xMC7Lms737/SJgew7R0H7OIzpOyD5Dh4w5nMbNvs0q8PsOvPogSRmgCT/2YfZx6BpJ22bcW1qu73V2H+C7bU0eEKMPmw+y/7vsOi4MMLwbcGPJVgq+x8/CAg1N4Mfx1nOwbk59qkExJRPBbXkn3B9CzxMbb0FtHa+Vwy7PsqeWPd6sxI6pogdi2CiLY2cRZ4x1nAavwR+28uArWcJTnXfmuT365FtoTV9frSn9ecf0LqATvupqDEmulMH5PnZtGj/Dz4+R/Q8/biy/DOeQYWvw1j1tvP7dBW+3kE1Sl9DVWpPJogRGQw8AbgC3xkjJng5phrgfGAAVYbY653tt8EPOkc9pwx5jNPxqpcFFRp9LjJ3mzOHQMItOhfdCN4eJvtDdWoG9QIhv1r7U2wRjC0H2a76IqP7WXV9JziieZk/TrW/fY3XZLegbUQb1f7YvcSSHNWPwtvBUnb3Z+/5VdbbRa3BH57tmj7BKdUNnA8zHXpZrzoLfv74CZYOtQmmAJnDbS/87LhnT7uOwVsmwPf3Qa+AfDE3qJYD++E5i7z6rxxtv23mPucfV6zPlz4JCx53ybT9sNsx4Ped9ipWgoUJJmje+CTS+0N97FYe6NOKjEddcnSSkEJL/UA/HCXPafjlfDj3bBzoZ26/o//2GPWfw/3LrM398L5xZzXTkuE1zvByC+gZgM77f3elXCHy2I82+c6xx6ybRdvR0O9jnD3otKf2fGkHICpt8GVH9jPae1kqN3MDkoNi7IJL7iu/ZKRecTuO7gBmvUt+5rb58HuxXDOPTZBnyxj4ODG0l/MCuxbbRP2zoXQ/+HiXx5KjpfyMI+1QYiIL7AFGATEA8uA64wxG1yOaQ1MBi40xhwWkXrGmIMiEg7EANHYv7TlQA9jTJnLaGkbRDWQlQqZyfC/EdDjZvtNeNr9ULelrepa8w0EhMGw1+yCSyn7bCP5V9fY8/veb9s+/neVfX7BE7aaZN2U8r3+WQPh+m9tddiayTDsDTtiPaAWbP75+Od7ko8/RLSBg06pp9fook4BJyr6Vvv57ImxHQYAxsbB19fBrqKVznjiADzvrEPx8DbYvxom31S8qrFJb+j/KHx5tfvXOv8xO57m17Gw/BO7re1QOxZn9lP23zdln90e1cuWRgtmEni7p/2y0WG4/VKx3mlnCm8FHa+Aeh1sSSwtwV5jyQdw2X/sjXvoK0W94PLz4Nnwos8vuG5RiRLgoc1FJd+AMMg6Ag062y834+Jt6c4Ypxv4QluNet0keK+frZ5sOwQufApmPWlnL2h+Hmz+xSbvgNDSn0ncUpj1FFw6wXbpjv3Dflnav8b2Ovy/WbYb+9s97RetwRPsv03cX0XXaDsUrvsKYv+0i49tnWn/jWpG2jFOidvg6F5ocf4Jdxn3SiO1iJwDjDfGXOI8HwdgjHnR5ZiXgS3GmI9KnHsdMMAYc4fz/H1gvjHm67JeTxNENWeMraIpWZdvjP0232G4reIBWDfVfvu+5Hm7xOtHA23j9ZaZtnorIMzeAMNbwtF9kOssMjPyS2h/mfvXX/0NfD/a/b6et9lEcixtLoUtv5T//XpLwQ3xRJw90ibxwNo20bsKawpH3C/HWaY7/7Rzkf3nxBa6AeDqj21pKz/PVt19Vsa/7/EMe9O2ubjrlAE22aQfY2nV7n+HFZ/D+WNtp4rtc20prSDhu9PrDluqW1CqYqW4+1fBB+cXVW8G1bElyJ8fKjqm/yN22wnwVoIYAQw2xtzmPP8b0NsYc6/LMT9gSxn9sNVQ440xv4rIw0CgMeY557ingAxjzCtlvZ4miDNYXo5tVymw4UdbteUfDHctgjnjYcMP8NguCKpd5mVYO8XeBJZ/VvQf++YZ0Lwf/Ldv6f/sHYZD42hbBdCoG/y3D9zyC2SnwZcjio677ht7I/zYTWNvj1vsjW3nAnvzHvA4TLrO7mt1oa0+ajvEjniv29pO2Aj222ZZVW3u3D4PPrzAPm53mW3ELqgiq4jgCLh/hU3Kh7bYTgLJu2136vIQH/tFwBN63g7LPvTMtW+car/d52Ud/9hTrWEXW+10LJ2vsW1aJ6Aq92LyA1oDA4AoYKGIlHthVREZDYwGaNq0jN476vTnmhzArtAH9pt/eAv7LXPIv4+dHAA6Ozf13nfYaoTIdjY5AFz9oe2Z0+0G+zw3y1abuPb1L+yqm2lfu+sNtmG5zSW23vi6b6BeO9urKW6ZbSfpcYvdl3rQfjMvqCbwC7LVawWNyv2dkfH5H9tk0ucuW0LaPMPW6/sFFlUj9X8EFv/XNp5nHoEu10Pj7lC/s33NXqNtdVZ8jP3Jz3H/efgHQ0568eqh8x6y9fB3/mmroILDYdtvZX+mt/1mB1F+ebW9iaUlwI75xzn+cPEEW2D4f207yOynbEP2zgXF97smh5KJqHEP27HhrIG2VHmsb/buND8X7l0Ki94u/joPbbE95xa/XbHrlVdwRFFy6HI9rP6qaF/LAUWfpY9nZnP1dhXTe8ASY8wnzvPfgLHAWWgVkzoZOZm23ro6zjGVlwPiW77YD22Dt3vADd/Zm/C5Y2xjena67SE16wlbb16znk0We1fa+uqChs69q2yVygVP2G1piTYBHI61yWrDj9D5WntDbdavaHyKq8wjMKGZvXn7B9s69KxUm1zGOWstJ8fZwZupByHtIHwy1F4rI8lONnlwk+1Oe94/7PG7/7L7p91nb4xR0fYm71oFOd5Ng/Gor23Jyy/AGTh6BWBs6eKbG2DAONtesuFHmzBCIoqPC7r4efuZgR3bs3uxnRftIpdjUvbbmQA6Xgktz7fbDu+yCWvafba32lmDiqoc71hoe5zFfAJrJkHvO23VaOYRO8C1bmvb9bvztbYtI2W/bRN7eKstmS39oGhBMdf3fNcie92PLrL/pjdNO/7fixveqmLyw1YfXQTswTZSX2+MWe9yzGBsw/VNIhIBrAS6UtQwXTCd6QpsI3VSWa+nCUKdsQp6thT8X/bGTL0le9fkZAKm7GlUCsaTrPkG2l8OAaVXTzuu1IP2Zvz7q7YE9fsrdgGu4HD38W34AVpfYnvaudq1yDb2dnfmNcvLtb2fzh7pfnzLscT+absKb5puS6H9H4ULnyj7+KwUG3viNjs6H2wVZdJO2xU484htb2s3zCbs3Cz7nl3jmv+S7Qo+6Fn3r3EcXhtJLSJDgNex7QsTjTHPi8iz2DVQp4ldIf1VYDCQBzxvjJnknPt/wOPOpZ4vKGWURROEUmewqjb5Y0ay7Yl3wTj3PZyqEJ1qQymllFu65KhSSqkK0wShlFLKLU0QSiml3NIEoZRSyi1NEEoppdzSBKGUUsotTRBKKaXc0gShlFLKrdNmoJyIJAC7TuISEcChUxSOp1WnWKF6xVudYoXqFW91ihWqV7wnE2szY0ykux2nTYI4WSISU9ZowqqmOsUK1Sve6hQrVK94q1OsUL3i9VSsWsWklFLKLU0QSiml3NIEUeQkFwCuVNUpVqhe8VanWKF6xVudYoXqFa9HYtU2CKWUUm5pCUIppZRbmiCUUkq5dcYnCBEZLCKbRWSbiIz1djwAIjJRRA6KyDqXbeEiMltEtjq/6zjbRUTedOJfIyLdy76yR2JtIiLzRGSDiKwXkQeqeLyBIrJURFY78f7T2d5CRJY4cX0jIjWc7QHO823O/uaVGa8Tg6+IrBSR6dUg1lgRWSsiq0QkxtlWVf8WaovIFBHZJCIbReScKhxrW+czLfg5KiIPejxeY8wZ+4NdCnU70BKoAawGOlSBuPpj1+Ne57LtZWCs83gs8JLzeAjwCyBAH2BJJcfaEOjuPA7FrkPeoQrHK0BN57E/sMSJYzIwytn+HnCX8/hu4D3n8SjgGy/8PfwD+AqY7jyvyrHGAhEltlXVv4XPgNucxzWA2lU11hJx+wL7gWaejtcrb7Cq/ADnADNdno8Dxnk7LieW5iUSxGagofO4IbDZefw+cJ2747wU94/AoOoQLxAMrAB6Y0eh+pX8uwBmAuc4j/2c46QSY4wCfgMuBKY7/+GrZKzO67pLEFXubwEIA3aW/HyqYqxuYr8Y+LMy4j3Tq5gaA3Euz+OdbVVRfWPMPufxfqC+87jKvAenSqMb9lt5lY3XqbJZBRwEZmNLkcnGmFw3MRXG6+w/AtStxHBfBx4F8p3ndam6sQIYYJaILBeR0c62qvi30AJIAD5xqu8+EpGQKhprSaOAr53HHo33TE8Q1ZKxXwmqVP9kEakJfAc8aIw56rqvqsVrjMkzxnTFfjvvBbTzckhuichlwEFjzHJvx1IB5xpjugOXAveISH/XnVXob8EPW437rjGmG5CGraIpVIViLeS0N10OfFtynyfiPdMTxB6gicvzKGdbVXRARBoCOL8POtu9/h5ExB+bHL40xkx1NlfZeAsYY5KBedhqmtoi4ucmpsJ4nf1hQGIlhdgPuFxEYoFJ2GqmN6porAAYY/Y4vw8C32MTcFX8W4gH4o0xS5znU7AJoyrG6upSYIUx5oDz3KPxnukJYhnQ2ukVUgNbdJvm5ZjKMg24yXl8E7auv2D7351eC32AIy5FTo8TEQE+BjYaY/5TDeKNFJHazuMgbHvJRmyiGFFGvAXvYwQw1/mm5nHGmHHGmChjTHPs3+ZcY8wNVTFWABEJEZHQgsfYuvJ1VMG/BWPMfiBORNo6my4CNlTFWEu4jqLqpYK4PBevNxpZqtIPtrV/C7Ye+glvx+PE9DWwD8jBftO5FVuX/BuwFZgDhDvHCvCOE/9aILqSYz0XW6xdA6xyfoZU4XjPBlY68a4Dnna2twSWAtuwxfcAZ3ug83ybs7+ll/4mBlDUi6lKxurEtdr5WV/w/6kK/y10BWKcv4UfgDpVNVYnhhBsiTDMZZtH49WpNpRSSrl1plcxKaWUKoMmCKWUUm5pglBKKeWWJgillFJuaYJQSinlliYIpaoAERkgzmytSlUVmiCUUkq5pQlCqQoQkRvFriexSkTedyb+SxWR18SuL/GbiEQ6x3YVkb+c+fi/d5mr/ywRmSN2TYoVItLKuXxNl/UJvnRGqSvlNZoglConEWkPjAT6GTvZXx5wA3aEa4wxpiOwAHjGOeVz4DFjzNnY0awF278E3jHGdAH6YkfNg50J90HsehotsXMxKeU1fsc/RCnluAjoASxzvtwHYSdHywe+cY75HzBVRMKA2saYBc72z4BvnbmKGhtjvgcwxmQCONdbaoyJd56vwq4J8ofn35ZS7mmCUKr8BPjMGDOu2EaRp0ocd6Lz12S5PM5D/38qL9MqJqXK7zdghIjUg8K1lpth/x8VzK56PfCHMeYIcFhEznO2/w1YYIxJAeJF5ArnGgEiElyp70KpctJvKEqVkzFmg4g8iV0xzQc72+492MVmejn7DmLbKcBOv/yekwB2ALc42/8GvC8izzrXuKYS34ZS5aazuSp1VE+MggAAAEFJREFUkkQk1RhT09txKHWqaRWTUkopt7QEoZRSyi0tQSillHJLE4RSSim3NEEopZRySxOEUkoptzRBKKWUcuv/ARjQbsUhiLDEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "e408e152-f204-4acc-f103-e19219b6bcce"
      },
      "source": [
        "#predictionScaler = pickle.load(open(\"scaler691.pkl\", 'rb'))\n",
        "Xnew=np.array([[1.36,3.0,39,296,0.65,0.0,0.549,0.5,1.2,0.65,0.73,1.28,85.3,0.77,0.48,1.19,7.5,1.11,0.59,0.73,1.12,68.2,0.68,0.29,1.16,2.5,1.08,0.63,0.72,1.03,72.8,0.67,0.55,1.07,5.2,1.05,0.62,0.73,0.91,71.1,0.65,0.54,1.05,5.6,1.01,0.66,0.71,0.95,73.5,0.61,0.47,0.93,9.1,0.89,0.79,0.62,1.13,70.6,0.56,0.44,0.71,4.7,0.87,0.81,0.6,0.95,70.7,0.69,0.61,0.85,4.4,0.86,0.75,0.65,0.72,66.2,0.71,0.35,0.94,1.8,0.83,0.73,0.69,0.66,65.0,0.58,0.5,0.80,1.0,0.74,0.75,0.54,0.65,69.3,0.48,0.48,0.64,6.7],\n",
        "               [2.8,1.4,206,208,0.36,0.5,0.5,0.5,0.99,0.77,0.63,1.09,79.8,0.68,0.6,0.89,2.1,0.96,0.73,0.66,0.9,73.4,0.67,0.45,0.92,3.3,0.92,0.76,0.66,1.02,67.5,0.62,0.49,0.82,3.1,0.9,0.73,0.6,0.98,69.9,0.6,0.34,0.82,2.7,0.84,0.74,0.64,0.74,62.3,0.58,0.51,0.78,1.6,1.29,0.6,0.74,1.31,87.2,0.84,0.36,1.39,4.9,1.09,0.7,0.7,1.02,81.6,0.72,0.39,1.03,3.7,1.03,0.72,0.69,0.98,78.7,0.69,0.43,0.96,2.1,1.1366666666666667,0.6733333333333332,0.71,1.1033333333333333,82.5,0.75,0.3933333333333333,1.1266666666666667,3.566666666666667,1.1366666666666667,0.6733333333333332,0.71,1.1033333333333333,82.5,0.75,0.3933333333333333,1.1266666666666667,3.566666666666667],\n",
        "               [1.5,2.4,77,112,0.4,0.47,0.5,0.5,1.34,0.67,0.74,1.54,90.3,0.89,0.32,1.33,6.6,1.07,0.6,0.73,0.91,72.6,0.69,0.47,1.16,2.6,0.97,0.69,0.7,0.86,72.5,0.59,0.38,0.86,6.6,0.91,0.63,0.66,0.77,65.3,0.54,0.47,0.86,5.0,0.86,0.65,0.62,0.79,63.1,0.56,0.52,0.87,7.0,1.03,0.64,0.71,0.94,71.4,0.65,0.47,1.01,5.3,1.02,0.69,0.7,1.03,71.9,0.64,0.44,0.93,8.7,1.01,0.68,0.72,0.92,71.9,0.64,0.49,0.93,5.7,1.0199999999999998,0.67,0.71,0.9633333333333334,71.73333333333333,0.6433333333333334,0.4666666666666666,0.9566666666666667,6.566666666666666,1.0199999999999998,0.67,0.71,0.9633333333333334,71.73333333333333,0.6433333333333334,0.4666666666666666,0.9566666666666667,6.566666666666666],\n",
        "               [1.32,3.19,30,54,0.68,0.5,0.524,0.524,1.17,0.67,0.73,1.23,84.4,0.74,0.56,1.10,6.2,1.16,0.6,0.74,1.22,72.3,0.71,0.28,1.19,5.4,1.11,0.63,0.71,1.06,79.8,0.7,0.45,1.11,7.6,1.11,0.65,0.72,1.05,79.5,0.71,0.59,1.10,5.3,0.96,0.63,0.71,0.81,62.8,0.61,0.54,0.96,4.1,1.12,0.7,0.72,1.15,82.6,0.72,0.55,1.03,4.5,1.07,0.63,0.7,1.04,71.6,0.68,0.29,1.08,3.6,0.99,0.7,0.69,1.02,69.1,0.63,0.58,0.90,2.6,0.96,0.66,0.69,0.86,66.5,0.63,0.64,0.94,2.3,0.96,0.7,0.68,0.89,70.0,0.62,0.57,0.89,2.6],\n",
        "               [2.38,1.53,78,103,0.48,0.55,0.583,0.5,1.16,0.72,0.69,1.27,87.0,0.8,0.49,1.12,4.8,1.07,0.56,0.73,0.91,66.9,0.65,0.33,1.16,2.4,1.0,0.66,0.71,0.89,70.6,0.62,0.44,0.94,3.9,0.98,0.7,0.67,1.01,72.0,0.62,0.55,0.88,3.8,1.0525,0.6599999999999999,0.7,1.02,74.125,0.6725000000000001,0.4525,1.0250000000000001,3.7249999999999996,1.18,0.66,0.73,1.22,82.6,0.77,0.5,1.17,7.6,1.14,0.66,0.72,1.23,79.5,0.7,0.52,1.06,5.0,1.13,0.6,0.76,0.98,73.3,0.71,0.24,1.19,3.8,1.04,0.62,0.71,0.9,73.8,0.65,0.59,1.04,4.5,0.91,0.72,0.66,0.98,63.7,0.6,0.43,0.83,4.6],\n",
        "               [1.28,3.35,18,46,0.6,0.58,0.506,0.543,1.14,0.67,0.69,1.28,80.7,0.75,0.51,1.12,3.1,1.12,0.57,0.7,1.05,74.2,0.71,0.27,1.25,3.7,1.11,0.65,0.7,1.13,81.1,0.71,0.49,1.09,7.3,1.07,0.64,0.73,0.96,75.5,0.68,0.42,1.06,7.1,0.95,0.64,0.68,0.82,68.1,0.61,0.46,0.96,3.2,1.23,0.55,0.77,1.14,75.9,0.77,0.24,1.40,2.9,1.18,0.64,0.77,1.16,78.3,0.73,0.38,1.14,6.9,1.07,0.65,0.71,1.02,77.3,0.67,0.45,1.03,5.0,1.06,0.67,0.73,1.1,74.0,0.62,0.53,0.93,6.8,0.94,0.65,0.72,0.77,61.1,0.55,0.43,0.84,4.9],\n",
        "               [2.25,1.57,34,45,0.55,0.4,0.46,0.5,1.2,0.63,0.74,1.15,84.4,0.79,0.53,1.25,4.8,1.16,0.6,0.72,1.17,76.6,0.73,0.33,1.21,4.3,1.05,0.73,0.69,1.14,78.8,0.67,0.58,0.93,5.9,1.03,0.63,0.74,0.87,69.3,0.66,0.46,1.04,3.2,0.84,0.7,0.65,0.76,60.2,0.54,0.43,0.77,3.9,1.02,0.68,0.68,1.03,70.7,0.65,0.55,0.96,4.0,1.13,0.67,0.67,1.29,77.0,0.78,0.3,1.16,0.9,1.01,0.65,0.68,0.96,70.9,0.66,0.56,1.01,3.2,1.0533333333333335,0.6666666666666666,0.6766666666666667,1.0933333333333335,72.86666666666666,0.6966666666666668,0.47000000000000003,1.0433333333333332,2.7000000000000006,1.0533333333333335,0.6666666666666666,0.6766666666666667,1.0933333333333335,72.86666666666666,0.6966666666666668,0.47000000000000003,1.0433333333333332,2.7000000000000006],\n",
        "               [2.45,1.47,215,109,0.38,0.5,0.5,0.5,1.21,0.67,0.67,1.38,89.9,0.81,0.45,1.20,5.3,1.05,0.58,0.76,0.85,66.9,0.61,0.55,1.05,4.5,1.01,0.73,0.61,1.22,74.4,0.7,0.31,0.97,2.8,0.91,0.73,0.67,0.89,65.3,0.58,0.62,0.80,3.4,0.87,0.72,0.65,0.88,62.7,0.55,0.46,0.76,5.2,1.03,0.72,0.71,0.9,79.8,0.7,0.55,0.97,4.0,1.05,0.64,0.73,0.99,70.1,0.67,0.47,1.04,3.0,1.03,0.69,0.64,1.12,73.1,0.62,0.56,0.91,4.4,1.03,0.68,0.68,0.92,77.6,0.69,0.34,1.02,2.5,0.94,0.74,0.66,1.0,68.5,0.63,0.54,0.85,2.1],\n",
        "               [1.33,2.93,42,66,0.46,0.47,0.45,0.49,1.12,0.63,0.71,1.1,77.5,0.72,0.53,1.14,3.0,1.07,0.64,0.7,1.09,73.5,0.67,0.56,1.05,5.6,1.06,0.62,0.7,1.05,70.0,0.67,0.3,1.08,3.0,1.01,0.7,0.69,1.02,74.7,0.62,0.45,0.88,5.4,1.0,0.63,0.72,0.87,68.0,0.61,0.47,0.98,3.7,1.17,0.67,0.72,1.17,85.0,0.78,0.54,1.16,3.1,1.12,0.67,0.71,1.2,75.4,0.73,0.32,1.10,1.8,1.12,0.68,0.69,1.21,79.8,0.74,0.48,1.09,5.8,0.96,0.7,0.68,0.86,71.5,0.63,0.52,0.90,4.8,1.0925,0.6799999999999999,0.7000000000000001,1.11,77.925,0.72,0.465,1.0625,3.875],\n",
        "               [1.73,2.06,48,158,0.33,0.0,0.5,0.5,1.04,0.77,0.65,1.23,80.6,0.71,0.61,0.92,5.0,0.86,0.73,0.64,0.81,65.8,0.58,0.53,0.80,4.8,1.09,0.64,0.7,1.1,71.8,0.71,0.24,1.11,4.3,0.97,0.68,0.68,0.82,74.6,0.62,0.52,0.90,4.4,0.85,0.72,0.65,0.73,63.2,0.58,0.59,0.81,2.9,0.93,0.72,0.67,0.95,64.9,0.62,0.36,0.87,2.7,0.92,0.72,0.62,0.88,73.8,0.61,0.46,0.85,4.6,0.84,0.77,0.6,0.89,67.8,0.6,0.43,0.77,2.3,0.78,0.74,0.6,0.78,59.9,0.55,0.54,0.74,2.5,0.78,0.73,0.64,0.58,64.3,0.52,0.58,0.72,1.2]\n",
        "               \n",
        "])\n",
        "Xnew = pd.DataFrame(Xnew, columns=CSV_COLUMN_NAMES2)\n",
        "pokus=predictionScaler.transform(Xnew)\n",
        "#model= keras.models.load_model(\"691model.h5\")\n",
        "ynew=(model.predict([pokus]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)\n",
        "\n",
        "\n",
        "\n",
        "#model= keras.models.load_model(\"686model.h5\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.15663248]\n",
            " [0.6790366 ]\n",
            " [0.45727098]\n",
            " [0.24388596]\n",
            " [0.52646476]\n",
            " [0.40898696]\n",
            " [0.5545635 ]\n",
            " [0.6552319 ]\n",
            " [0.32695588]\n",
            " [0.41491243]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-0x3EQ37uB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvOLjjtq370x"
      },
      "source": [
        "pd.options.display.max_rows = 4000\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDSZ8GXKuje"
      },
      "source": [
        "model.save('/content/save/691model.h5')\n",
        "pickle.dump(predictionScaler, open(\"/content/save/scaler691.pkl\", 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 100 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "model.layers[0].get_weights()[0][98]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLaoTNJnIRM"
      },
      "source": [
        "#print(X_val)\n",
        "pokus=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "pokus.pop('Match_link')\n",
        "pokus.pop('team_one_name')\n",
        "pokus.pop('team_two_name')\n",
        "pokus.pop('Result')\n",
        "\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(pokus)\n",
        "data=scaler.transform(pokus)\n",
        "print(data)\n"
      ]
    }
  ]
}