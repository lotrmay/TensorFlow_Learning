{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMe4g2nCpkjUXh5R3bkuUoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbSeoWpB3mO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCY-aVPMK1aO"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "a50c2ca1-1a4e-4f2f-dabd-67ccb27c9e28"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(train.shape)#vypíše nám dimenzionalitu našeho dataframu (2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "train['team_one_name']=pd.Categorical(train['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "train['team_two_name']=pd.Categorical(train['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "#https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "\n",
        "train.pop('playerAAAdr')\n",
        "train.pop('playerABAdr')\n",
        "train.pop('playerACAdr')\n",
        "train.pop('playerADAdr')\n",
        "train.pop('playerAEAdr')\n",
        "train.pop('playerBAAdr')\n",
        "train.pop('playerBBAdr')\n",
        "train.pop('playerBCAdr')\n",
        "train.pop('playerBDAdr')\n",
        "train.pop('playerBEAdr')\n",
        "\n",
        "train.pop('playerAADpr')\n",
        "train.pop('playerABDpr')\n",
        "train.pop('playerACDpr')\n",
        "train.pop('playerADDpr')\n",
        "train.pop('playerAEDpr')\n",
        "train.pop('playerBADpr')\n",
        "train.pop('playerBBDpr')\n",
        "train.pop('playerBCDpr')\n",
        "train.pop('playerBDDpr')\n",
        "train.pop('playerBEDpr')\n",
        "\n",
        "train.pop('playerAAKpr')\n",
        "train.pop('playerABKpr')\n",
        "train.pop('playerACKpr')\n",
        "train.pop('playerADKpr')\n",
        "train.pop('playerAEKpr')\n",
        "train.pop('playerBAKpr')\n",
        "train.pop('playerBBKpr')\n",
        "train.pop('playerBCKpr')\n",
        "train.pop('playerBDKpr')\n",
        "train.pop('playerBEKpr')\n",
        "\n",
        "train.pop('playerAAImpact')\n",
        "train.pop('playerABImpact')\n",
        "train.pop('playerACImpact')\n",
        "train.pop('playerADImpact')\n",
        "train.pop('playerAEImpact')\n",
        "train.pop('playerBAImpact')\n",
        "train.pop('playerBBImpact')\n",
        "train.pop('playerBCImpact')\n",
        "train.pop('playerBDImpact')\n",
        "train.pop('playerBEImpact')\n",
        "\n",
        "train.pop('playerAAHs')\n",
        "train.pop('playerABHs')\n",
        "train.pop('playerACHs')\n",
        "train.pop('playerADHs')\n",
        "train.pop('playerAEHs')\n",
        "train.pop('playerBAHs')\n",
        "train.pop('playerBBHs')\n",
        "train.pop('playerBCHs')\n",
        "train.pop('playerBDHs')\n",
        "train.pop('playerBEHs')\n",
        "\n",
        "train.pop('playerAARating')\n",
        "train.pop('playerABRating')\n",
        "train.pop('playerACRating')\n",
        "train.pop('playerADRating')\n",
        "train.pop('playerAERating')\n",
        "train.pop('playerBARating')\n",
        "train.pop('playerBBRating')\n",
        "train.pop('playerBCRating')\n",
        "train.pop('playerBDRating')\n",
        "train.pop('playerBERating')\n",
        "'''\n",
        "#predictors nám vybere všechny sloupce, které jsou využity pro predikování výsledků neboli target_column\n",
        "target_column = ['Result'] \n",
        "\n",
        "predictionScaler=StandardScaler()\n",
        "y = train['Result'].values\n",
        "train.pop('Result')\n",
        "X = train.values\n",
        "\n",
        "#predictionScaler.fit(scalerData)\n",
        "\n",
        "#n = 100 # Max number of neighbours you want to consider\n",
        "#param_grid = {'n_neighbors': np.arange(n)}\n",
        "#grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "#grid.fit(X,y)\n",
        "#print(grid.best_params_)\n",
        "\n",
        "\n",
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#15% dat \n",
        "\n",
        "lof = LocalOutlierFactor(contamination=0.15,n_neighbors=96)\n",
        "yhat = lof.fit_predict(X)\n",
        "mask = yhat != -1\n",
        "X, y= X[mask, :], y[mask]\n",
        "print(X.shape)\n",
        "\n",
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% random_state=98\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)#32 #888 887\n",
        "\n",
        "#validační set bude 15% random_state=75\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765) # 0.1765 x 0.85 = 0.15 podívat se na cross-validation\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) #součet odpovídá X.shape\n",
        "\n",
        "#vytvoříme scaler, který nám data přetransformuje na formát lepší pro model ?\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=CSV_COLUMN_NAMES2)\n",
        "X_test=pd.DataFrame(X_test, columns=CSV_COLUMN_NAMES2)\n",
        "X_val=pd.DataFrame(X_val, columns=CSV_COLUMN_NAMES2)\n",
        "\n",
        "predictionScaler.fit(X_train)\n",
        "\n",
        "X_train=predictionScaler.transform(X_train)#fit transform na training data viz:https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
        "X_test=predictionScaler.transform(X_test)\n",
        "X_val=predictionScaler.transform(X_val)\n",
        "\n",
        "#64 32\n",
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(Dense(64, activation='relu'))#input layer je už v modelu defaultně\n",
        "model.add(keras.layers.Dropout(0.5))#50% inputů dropne abz se příliš nespoléhala na vybrané inputy\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))#jelikož děláme binární klasifikaci, tak aktivační funkce bude sigmoid popř. softmax, zde by mezi těmito dvěmi neměl být výkonově rozdíl viz:https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#tady jsem skončil s vysvětlováním!!!\n",
        "#model zkompilujeme s parametry:\n",
        "#optimizer bude ? optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.5)\n",
        "#loss funkce bude BinaryCrossentropy, jelikož máme binární klasifikátor\n",
        "model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.01), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None))#metrics=['accuracy'] je to jedno accuracy se vnitřně přetransformuje na binary accuracy, kvůli binary crossentropy loss funkci\n",
        "#metrics = (\"accuracy\")\n",
        "#metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None)\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])\n",
        "#[tf.keras.metrics.BinaryAccuracy()]\n",
        "\n",
        "#Adagrad(learning_rate=0.01) kolem 100 epochs a 32 batch_size je kolem 0.67\n",
        "\n",
        "#shuffle=true?\n",
        "history = model.fit(X_train, y_train, epochs=2000,shuffle=True,batch_size=128,validation_data=(X_val, y_val))#validační data pro změny při tréninku sítě\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "pred_test= model.predict(X_test)\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "\n",
        "#plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')#'accuracy'\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18775, 102)\n",
            "(15958, 98)\n",
            "(11169, 98)\n",
            "(2394, 98)\n",
            "(2395, 98)\n",
            "Epoch 1/2000\n",
            "88/88 [==============================] - 1s 4ms/step - loss: 1.0023 - binary_accuracy: 0.5198 - val_loss: 0.7359 - val_binary_accuracy: 0.5453\n",
            "Epoch 2/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9817 - binary_accuracy: 0.5243 - val_loss: 0.7222 - val_binary_accuracy: 0.5461\n",
            "Epoch 3/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9638 - binary_accuracy: 0.5195 - val_loss: 0.7120 - val_binary_accuracy: 0.5407\n",
            "Epoch 4/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9435 - binary_accuracy: 0.5215 - val_loss: 0.7035 - val_binary_accuracy: 0.5436\n",
            "Epoch 5/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9198 - binary_accuracy: 0.5334 - val_loss: 0.6967 - val_binary_accuracy: 0.5503\n",
            "Epoch 6/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9304 - binary_accuracy: 0.5250 - val_loss: 0.6909 - val_binary_accuracy: 0.5553\n",
            "Epoch 7/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.9242 - binary_accuracy: 0.5228 - val_loss: 0.6859 - val_binary_accuracy: 0.5591\n",
            "Epoch 8/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.9021 - binary_accuracy: 0.5360 - val_loss: 0.6820 - val_binary_accuracy: 0.5637\n",
            "Epoch 9/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8985 - binary_accuracy: 0.5322 - val_loss: 0.6785 - val_binary_accuracy: 0.5662\n",
            "Epoch 10/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.9002 - binary_accuracy: 0.5231 - val_loss: 0.6752 - val_binary_accuracy: 0.5674\n",
            "Epoch 11/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8944 - binary_accuracy: 0.5261 - val_loss: 0.6724 - val_binary_accuracy: 0.5712\n",
            "Epoch 12/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8742 - binary_accuracy: 0.5351 - val_loss: 0.6702 - val_binary_accuracy: 0.5716\n",
            "Epoch 13/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8722 - binary_accuracy: 0.5328 - val_loss: 0.6682 - val_binary_accuracy: 0.5712\n",
            "Epoch 14/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8658 - binary_accuracy: 0.5299 - val_loss: 0.6664 - val_binary_accuracy: 0.5804\n",
            "Epoch 15/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8786 - binary_accuracy: 0.5284 - val_loss: 0.6647 - val_binary_accuracy: 0.5850\n",
            "Epoch 16/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.8617 - binary_accuracy: 0.5310 - val_loss: 0.6632 - val_binary_accuracy: 0.5887\n",
            "Epoch 17/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8489 - binary_accuracy: 0.5412 - val_loss: 0.6619 - val_binary_accuracy: 0.5929\n",
            "Epoch 18/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8453 - binary_accuracy: 0.5349 - val_loss: 0.6607 - val_binary_accuracy: 0.5967\n",
            "Epoch 19/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8370 - binary_accuracy: 0.5415 - val_loss: 0.6597 - val_binary_accuracy: 0.5987\n",
            "Epoch 20/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8370 - binary_accuracy: 0.5393 - val_loss: 0.6588 - val_binary_accuracy: 0.5987\n",
            "Epoch 21/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8374 - binary_accuracy: 0.5398 - val_loss: 0.6580 - val_binary_accuracy: 0.5996\n",
            "Epoch 22/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8305 - binary_accuracy: 0.5408 - val_loss: 0.6573 - val_binary_accuracy: 0.6017\n",
            "Epoch 23/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8275 - binary_accuracy: 0.5472 - val_loss: 0.6566 - val_binary_accuracy: 0.6008\n",
            "Epoch 24/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8150 - binary_accuracy: 0.5470 - val_loss: 0.6559 - val_binary_accuracy: 0.6025\n",
            "Epoch 25/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.8135 - binary_accuracy: 0.5439 - val_loss: 0.6554 - val_binary_accuracy: 0.6033\n",
            "Epoch 26/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8115 - binary_accuracy: 0.5432 - val_loss: 0.6548 - val_binary_accuracy: 0.6017\n",
            "Epoch 27/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8030 - binary_accuracy: 0.5433 - val_loss: 0.6542 - val_binary_accuracy: 0.6046\n",
            "Epoch 28/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8134 - binary_accuracy: 0.5438 - val_loss: 0.6536 - val_binary_accuracy: 0.6067\n",
            "Epoch 29/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.8111 - binary_accuracy: 0.5447 - val_loss: 0.6531 - val_binary_accuracy: 0.6050\n",
            "Epoch 30/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7940 - binary_accuracy: 0.5502 - val_loss: 0.6527 - val_binary_accuracy: 0.6050\n",
            "Epoch 31/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7992 - binary_accuracy: 0.5473 - val_loss: 0.6523 - val_binary_accuracy: 0.6071\n",
            "Epoch 32/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7956 - binary_accuracy: 0.5509 - val_loss: 0.6518 - val_binary_accuracy: 0.6079\n",
            "Epoch 33/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7958 - binary_accuracy: 0.5445 - val_loss: 0.6515 - val_binary_accuracy: 0.6092\n",
            "Epoch 34/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7917 - binary_accuracy: 0.5496 - val_loss: 0.6511 - val_binary_accuracy: 0.6117\n",
            "Epoch 35/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7855 - binary_accuracy: 0.5522 - val_loss: 0.6506 - val_binary_accuracy: 0.6121\n",
            "Epoch 36/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7871 - binary_accuracy: 0.5496 - val_loss: 0.6502 - val_binary_accuracy: 0.6150\n",
            "Epoch 37/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7837 - binary_accuracy: 0.5547 - val_loss: 0.6498 - val_binary_accuracy: 0.6159\n",
            "Epoch 38/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7754 - binary_accuracy: 0.5495 - val_loss: 0.6495 - val_binary_accuracy: 0.6163\n",
            "Epoch 39/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7816 - binary_accuracy: 0.5521 - val_loss: 0.6491 - val_binary_accuracy: 0.6154\n",
            "Epoch 40/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7737 - binary_accuracy: 0.5584 - val_loss: 0.6488 - val_binary_accuracy: 0.6163\n",
            "Epoch 41/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7720 - binary_accuracy: 0.5609 - val_loss: 0.6486 - val_binary_accuracy: 0.6163\n",
            "Epoch 42/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7769 - binary_accuracy: 0.5480 - val_loss: 0.6483 - val_binary_accuracy: 0.6159\n",
            "Epoch 43/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7769 - binary_accuracy: 0.5493 - val_loss: 0.6481 - val_binary_accuracy: 0.6154\n",
            "Epoch 44/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7669 - binary_accuracy: 0.5548 - val_loss: 0.6477 - val_binary_accuracy: 0.6159\n",
            "Epoch 45/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7660 - binary_accuracy: 0.5568 - val_loss: 0.6475 - val_binary_accuracy: 0.6154\n",
            "Epoch 46/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7612 - binary_accuracy: 0.5635 - val_loss: 0.6473 - val_binary_accuracy: 0.6159\n",
            "Epoch 47/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7607 - binary_accuracy: 0.5516 - val_loss: 0.6470 - val_binary_accuracy: 0.6163\n",
            "Epoch 48/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7574 - binary_accuracy: 0.5582 - val_loss: 0.6468 - val_binary_accuracy: 0.6154\n",
            "Epoch 49/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7486 - binary_accuracy: 0.5633 - val_loss: 0.6466 - val_binary_accuracy: 0.6150\n",
            "Epoch 50/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7577 - binary_accuracy: 0.5606 - val_loss: 0.6464 - val_binary_accuracy: 0.6150\n",
            "Epoch 51/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7506 - binary_accuracy: 0.5594 - val_loss: 0.6461 - val_binary_accuracy: 0.6146\n",
            "Epoch 52/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7491 - binary_accuracy: 0.5607 - val_loss: 0.6459 - val_binary_accuracy: 0.6167\n",
            "Epoch 53/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7490 - binary_accuracy: 0.5590 - val_loss: 0.6457 - val_binary_accuracy: 0.6171\n",
            "Epoch 54/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7444 - binary_accuracy: 0.5611 - val_loss: 0.6454 - val_binary_accuracy: 0.6180\n",
            "Epoch 55/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7498 - binary_accuracy: 0.5555 - val_loss: 0.6453 - val_binary_accuracy: 0.6184\n",
            "Epoch 56/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7425 - binary_accuracy: 0.5601 - val_loss: 0.6451 - val_binary_accuracy: 0.6180\n",
            "Epoch 57/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7476 - binary_accuracy: 0.5556 - val_loss: 0.6449 - val_binary_accuracy: 0.6184\n",
            "Epoch 58/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7427 - binary_accuracy: 0.5573 - val_loss: 0.6446 - val_binary_accuracy: 0.6192\n",
            "Epoch 59/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7419 - binary_accuracy: 0.5579 - val_loss: 0.6445 - val_binary_accuracy: 0.6196\n",
            "Epoch 60/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7390 - binary_accuracy: 0.5599 - val_loss: 0.6442 - val_binary_accuracy: 0.6205\n",
            "Epoch 61/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7336 - binary_accuracy: 0.5642 - val_loss: 0.6440 - val_binary_accuracy: 0.6205\n",
            "Epoch 62/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7297 - binary_accuracy: 0.5687 - val_loss: 0.6438 - val_binary_accuracy: 0.6217\n",
            "Epoch 63/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7274 - binary_accuracy: 0.5660 - val_loss: 0.6437 - val_binary_accuracy: 0.6221\n",
            "Epoch 64/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7339 - binary_accuracy: 0.5688 - val_loss: 0.6435 - val_binary_accuracy: 0.6217\n",
            "Epoch 65/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7403 - binary_accuracy: 0.5653 - val_loss: 0.6434 - val_binary_accuracy: 0.6205\n",
            "Epoch 66/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7336 - binary_accuracy: 0.5677 - val_loss: 0.6433 - val_binary_accuracy: 0.6221\n",
            "Epoch 67/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7277 - binary_accuracy: 0.5642 - val_loss: 0.6431 - val_binary_accuracy: 0.6230\n",
            "Epoch 68/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7202 - binary_accuracy: 0.5652 - val_loss: 0.6430 - val_binary_accuracy: 0.6246\n",
            "Epoch 69/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7324 - binary_accuracy: 0.5593 - val_loss: 0.6429 - val_binary_accuracy: 0.6246\n",
            "Epoch 70/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7246 - binary_accuracy: 0.5726 - val_loss: 0.6427 - val_binary_accuracy: 0.6251\n",
            "Epoch 71/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7227 - binary_accuracy: 0.5651 - val_loss: 0.6426 - val_binary_accuracy: 0.6242\n",
            "Epoch 72/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7280 - binary_accuracy: 0.5608 - val_loss: 0.6425 - val_binary_accuracy: 0.6251\n",
            "Epoch 73/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7179 - binary_accuracy: 0.5674 - val_loss: 0.6424 - val_binary_accuracy: 0.6251\n",
            "Epoch 74/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7233 - binary_accuracy: 0.5652 - val_loss: 0.6422 - val_binary_accuracy: 0.6246\n",
            "Epoch 75/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7203 - binary_accuracy: 0.5659 - val_loss: 0.6422 - val_binary_accuracy: 0.6251\n",
            "Epoch 76/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7192 - binary_accuracy: 0.5720 - val_loss: 0.6421 - val_binary_accuracy: 0.6246\n",
            "Epoch 77/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7219 - binary_accuracy: 0.5660 - val_loss: 0.6420 - val_binary_accuracy: 0.6246\n",
            "Epoch 78/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7197 - binary_accuracy: 0.5642 - val_loss: 0.6420 - val_binary_accuracy: 0.6246\n",
            "Epoch 79/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7157 - binary_accuracy: 0.5752 - val_loss: 0.6419 - val_binary_accuracy: 0.6246\n",
            "Epoch 80/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7212 - binary_accuracy: 0.5623 - val_loss: 0.6418 - val_binary_accuracy: 0.6246\n",
            "Epoch 81/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7138 - binary_accuracy: 0.5694 - val_loss: 0.6417 - val_binary_accuracy: 0.6251\n",
            "Epoch 82/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7136 - binary_accuracy: 0.5649 - val_loss: 0.6417 - val_binary_accuracy: 0.6267\n",
            "Epoch 83/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7129 - binary_accuracy: 0.5676 - val_loss: 0.6416 - val_binary_accuracy: 0.6284\n",
            "Epoch 84/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7083 - binary_accuracy: 0.5727 - val_loss: 0.6415 - val_binary_accuracy: 0.6288\n",
            "Epoch 85/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7074 - binary_accuracy: 0.5761 - val_loss: 0.6414 - val_binary_accuracy: 0.6284\n",
            "Epoch 86/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7104 - binary_accuracy: 0.5751 - val_loss: 0.6414 - val_binary_accuracy: 0.6301\n",
            "Epoch 87/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7166 - binary_accuracy: 0.5633 - val_loss: 0.6413 - val_binary_accuracy: 0.6301\n",
            "Epoch 88/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7010 - binary_accuracy: 0.5728 - val_loss: 0.6413 - val_binary_accuracy: 0.6305\n",
            "Epoch 89/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7100 - binary_accuracy: 0.5703 - val_loss: 0.6412 - val_binary_accuracy: 0.6305\n",
            "Epoch 90/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7061 - binary_accuracy: 0.5714 - val_loss: 0.6411 - val_binary_accuracy: 0.6309\n",
            "Epoch 91/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7005 - binary_accuracy: 0.5813 - val_loss: 0.6410 - val_binary_accuracy: 0.6326\n",
            "Epoch 92/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7004 - binary_accuracy: 0.5786 - val_loss: 0.6410 - val_binary_accuracy: 0.6334\n",
            "Epoch 93/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7032 - binary_accuracy: 0.5781 - val_loss: 0.6410 - val_binary_accuracy: 0.6330\n",
            "Epoch 94/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.7049 - binary_accuracy: 0.5772 - val_loss: 0.6410 - val_binary_accuracy: 0.6330\n",
            "Epoch 95/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6984 - binary_accuracy: 0.5777 - val_loss: 0.6408 - val_binary_accuracy: 0.6330\n",
            "Epoch 96/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6983 - binary_accuracy: 0.5796 - val_loss: 0.6408 - val_binary_accuracy: 0.6330\n",
            "Epoch 97/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6954 - binary_accuracy: 0.5845 - val_loss: 0.6407 - val_binary_accuracy: 0.6338\n",
            "Epoch 98/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6983 - binary_accuracy: 0.5744 - val_loss: 0.6406 - val_binary_accuracy: 0.6338\n",
            "Epoch 99/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6949 - binary_accuracy: 0.5808 - val_loss: 0.6406 - val_binary_accuracy: 0.6338\n",
            "Epoch 100/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6992 - binary_accuracy: 0.5717 - val_loss: 0.6405 - val_binary_accuracy: 0.6347\n",
            "Epoch 101/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6922 - binary_accuracy: 0.5857 - val_loss: 0.6405 - val_binary_accuracy: 0.6342\n",
            "Epoch 102/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6969 - binary_accuracy: 0.5795 - val_loss: 0.6405 - val_binary_accuracy: 0.6347\n",
            "Epoch 103/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.7021 - binary_accuracy: 0.5712 - val_loss: 0.6404 - val_binary_accuracy: 0.6359\n",
            "Epoch 104/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6969 - binary_accuracy: 0.5778 - val_loss: 0.6405 - val_binary_accuracy: 0.6363\n",
            "Epoch 105/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6951 - binary_accuracy: 0.5846 - val_loss: 0.6404 - val_binary_accuracy: 0.6347\n",
            "Epoch 106/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6974 - binary_accuracy: 0.5795 - val_loss: 0.6404 - val_binary_accuracy: 0.6355\n",
            "Epoch 107/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6985 - binary_accuracy: 0.5796 - val_loss: 0.6403 - val_binary_accuracy: 0.6372\n",
            "Epoch 108/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6925 - binary_accuracy: 0.5846 - val_loss: 0.6403 - val_binary_accuracy: 0.6363\n",
            "Epoch 109/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6977 - binary_accuracy: 0.5735 - val_loss: 0.6402 - val_binary_accuracy: 0.6384\n",
            "Epoch 110/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6925 - binary_accuracy: 0.5771 - val_loss: 0.6402 - val_binary_accuracy: 0.6388\n",
            "Epoch 111/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6924 - binary_accuracy: 0.5756 - val_loss: 0.6402 - val_binary_accuracy: 0.6380\n",
            "Epoch 112/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6896 - binary_accuracy: 0.5828 - val_loss: 0.6402 - val_binary_accuracy: 0.6372\n",
            "Epoch 113/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6887 - binary_accuracy: 0.5866 - val_loss: 0.6402 - val_binary_accuracy: 0.6380\n",
            "Epoch 114/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6860 - binary_accuracy: 0.5864 - val_loss: 0.6401 - val_binary_accuracy: 0.6372\n",
            "Epoch 115/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6863 - binary_accuracy: 0.5898 - val_loss: 0.6400 - val_binary_accuracy: 0.6376\n",
            "Epoch 116/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6861 - binary_accuracy: 0.5809 - val_loss: 0.6399 - val_binary_accuracy: 0.6384\n",
            "Epoch 117/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6856 - binary_accuracy: 0.5841 - val_loss: 0.6399 - val_binary_accuracy: 0.6376\n",
            "Epoch 118/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6898 - binary_accuracy: 0.5812 - val_loss: 0.6398 - val_binary_accuracy: 0.6388\n",
            "Epoch 119/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6872 - binary_accuracy: 0.5792 - val_loss: 0.6397 - val_binary_accuracy: 0.6392\n",
            "Epoch 120/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6830 - binary_accuracy: 0.5876 - val_loss: 0.6396 - val_binary_accuracy: 0.6397\n",
            "Epoch 121/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6838 - binary_accuracy: 0.5834 - val_loss: 0.6396 - val_binary_accuracy: 0.6388\n",
            "Epoch 122/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6898 - binary_accuracy: 0.5855 - val_loss: 0.6396 - val_binary_accuracy: 0.6405\n",
            "Epoch 123/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6824 - binary_accuracy: 0.5859 - val_loss: 0.6395 - val_binary_accuracy: 0.6397\n",
            "Epoch 124/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6844 - binary_accuracy: 0.5833 - val_loss: 0.6394 - val_binary_accuracy: 0.6388\n",
            "Epoch 125/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6854 - binary_accuracy: 0.5839 - val_loss: 0.6394 - val_binary_accuracy: 0.6392\n",
            "Epoch 126/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6844 - binary_accuracy: 0.5898 - val_loss: 0.6394 - val_binary_accuracy: 0.6401\n",
            "Epoch 127/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6817 - binary_accuracy: 0.5846 - val_loss: 0.6393 - val_binary_accuracy: 0.6401\n",
            "Epoch 128/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6797 - binary_accuracy: 0.5916 - val_loss: 0.6392 - val_binary_accuracy: 0.6397\n",
            "Epoch 129/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6774 - binary_accuracy: 0.5850 - val_loss: 0.6391 - val_binary_accuracy: 0.6401\n",
            "Epoch 130/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6768 - binary_accuracy: 0.5924 - val_loss: 0.6390 - val_binary_accuracy: 0.6392\n",
            "Epoch 131/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6771 - binary_accuracy: 0.5904 - val_loss: 0.6389 - val_binary_accuracy: 0.6388\n",
            "Epoch 132/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6803 - binary_accuracy: 0.5903 - val_loss: 0.6389 - val_binary_accuracy: 0.6380\n",
            "Epoch 133/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6788 - binary_accuracy: 0.5917 - val_loss: 0.6389 - val_binary_accuracy: 0.6392\n",
            "Epoch 134/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6788 - binary_accuracy: 0.5855 - val_loss: 0.6388 - val_binary_accuracy: 0.6388\n",
            "Epoch 135/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6783 - binary_accuracy: 0.5808 - val_loss: 0.6387 - val_binary_accuracy: 0.6392\n",
            "Epoch 136/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6756 - binary_accuracy: 0.5895 - val_loss: 0.6386 - val_binary_accuracy: 0.6388\n",
            "Epoch 137/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6737 - binary_accuracy: 0.5972 - val_loss: 0.6385 - val_binary_accuracy: 0.6384\n",
            "Epoch 138/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6747 - binary_accuracy: 0.5943 - val_loss: 0.6384 - val_binary_accuracy: 0.6392\n",
            "Epoch 139/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6784 - binary_accuracy: 0.5881 - val_loss: 0.6383 - val_binary_accuracy: 0.6392\n",
            "Epoch 140/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6731 - binary_accuracy: 0.5986 - val_loss: 0.6382 - val_binary_accuracy: 0.6392\n",
            "Epoch 141/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6711 - binary_accuracy: 0.5941 - val_loss: 0.6382 - val_binary_accuracy: 0.6401\n",
            "Epoch 142/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6791 - binary_accuracy: 0.5868 - val_loss: 0.6381 - val_binary_accuracy: 0.6409\n",
            "Epoch 143/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6717 - binary_accuracy: 0.5914 - val_loss: 0.6381 - val_binary_accuracy: 0.6409\n",
            "Epoch 144/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6758 - binary_accuracy: 0.5899 - val_loss: 0.6380 - val_binary_accuracy: 0.6405\n",
            "Epoch 145/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6764 - binary_accuracy: 0.5933 - val_loss: 0.6380 - val_binary_accuracy: 0.6418\n",
            "Epoch 146/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6777 - binary_accuracy: 0.5865 - val_loss: 0.6379 - val_binary_accuracy: 0.6413\n",
            "Epoch 147/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6766 - binary_accuracy: 0.5864 - val_loss: 0.6379 - val_binary_accuracy: 0.6422\n",
            "Epoch 148/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6762 - binary_accuracy: 0.5868 - val_loss: 0.6379 - val_binary_accuracy: 0.6422\n",
            "Epoch 149/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6718 - binary_accuracy: 0.5890 - val_loss: 0.6378 - val_binary_accuracy: 0.6418\n",
            "Epoch 150/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6757 - binary_accuracy: 0.5905 - val_loss: 0.6378 - val_binary_accuracy: 0.6405\n",
            "Epoch 151/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6739 - binary_accuracy: 0.5881 - val_loss: 0.6377 - val_binary_accuracy: 0.6401\n",
            "Epoch 152/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6700 - binary_accuracy: 0.5931 - val_loss: 0.6376 - val_binary_accuracy: 0.6405\n",
            "Epoch 153/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6710 - binary_accuracy: 0.5879 - val_loss: 0.6375 - val_binary_accuracy: 0.6397\n",
            "Epoch 154/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6672 - binary_accuracy: 0.5941 - val_loss: 0.6374 - val_binary_accuracy: 0.6405\n",
            "Epoch 155/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6751 - binary_accuracy: 0.5903 - val_loss: 0.6374 - val_binary_accuracy: 0.6405\n",
            "Epoch 156/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6727 - binary_accuracy: 0.5897 - val_loss: 0.6373 - val_binary_accuracy: 0.6422\n",
            "Epoch 157/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6685 - binary_accuracy: 0.5957 - val_loss: 0.6373 - val_binary_accuracy: 0.6426\n",
            "Epoch 158/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6724 - binary_accuracy: 0.5862 - val_loss: 0.6372 - val_binary_accuracy: 0.6430\n",
            "Epoch 159/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6700 - binary_accuracy: 0.5967 - val_loss: 0.6372 - val_binary_accuracy: 0.6434\n",
            "Epoch 160/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6655 - binary_accuracy: 0.6035 - val_loss: 0.6370 - val_binary_accuracy: 0.6438\n",
            "Epoch 161/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6689 - binary_accuracy: 0.5936 - val_loss: 0.6370 - val_binary_accuracy: 0.6438\n",
            "Epoch 162/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6695 - binary_accuracy: 0.6029 - val_loss: 0.6369 - val_binary_accuracy: 0.6447\n",
            "Epoch 163/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6650 - binary_accuracy: 0.6013 - val_loss: 0.6369 - val_binary_accuracy: 0.6447\n",
            "Epoch 164/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6634 - binary_accuracy: 0.6028 - val_loss: 0.6368 - val_binary_accuracy: 0.6455\n",
            "Epoch 165/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6662 - binary_accuracy: 0.6038 - val_loss: 0.6367 - val_binary_accuracy: 0.6468\n",
            "Epoch 166/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6705 - binary_accuracy: 0.5953 - val_loss: 0.6366 - val_binary_accuracy: 0.6459\n",
            "Epoch 167/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6678 - binary_accuracy: 0.5924 - val_loss: 0.6365 - val_binary_accuracy: 0.6480\n",
            "Epoch 168/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6629 - binary_accuracy: 0.5978 - val_loss: 0.6364 - val_binary_accuracy: 0.6497\n",
            "Epoch 169/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6718 - binary_accuracy: 0.5910 - val_loss: 0.6364 - val_binary_accuracy: 0.6489\n",
            "Epoch 170/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6621 - binary_accuracy: 0.6094 - val_loss: 0.6362 - val_binary_accuracy: 0.6489\n",
            "Epoch 171/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6681 - binary_accuracy: 0.5935 - val_loss: 0.6362 - val_binary_accuracy: 0.6484\n",
            "Epoch 172/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6642 - binary_accuracy: 0.5993 - val_loss: 0.6361 - val_binary_accuracy: 0.6484\n",
            "Epoch 173/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6616 - binary_accuracy: 0.6030 - val_loss: 0.6360 - val_binary_accuracy: 0.6489\n",
            "Epoch 174/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5997 - val_loss: 0.6359 - val_binary_accuracy: 0.6493\n",
            "Epoch 175/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6602 - binary_accuracy: 0.6044 - val_loss: 0.6357 - val_binary_accuracy: 0.6493\n",
            "Epoch 176/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6658 - binary_accuracy: 0.5983 - val_loss: 0.6357 - val_binary_accuracy: 0.6493\n",
            "Epoch 177/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6640 - binary_accuracy: 0.6017 - val_loss: 0.6356 - val_binary_accuracy: 0.6489\n",
            "Epoch 178/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6644 - binary_accuracy: 0.5988 - val_loss: 0.6355 - val_binary_accuracy: 0.6489\n",
            "Epoch 179/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6634 - binary_accuracy: 0.5995 - val_loss: 0.6355 - val_binary_accuracy: 0.6489\n",
            "Epoch 180/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6620 - binary_accuracy: 0.6086 - val_loss: 0.6354 - val_binary_accuracy: 0.6489\n",
            "Epoch 181/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6654 - binary_accuracy: 0.6012 - val_loss: 0.6353 - val_binary_accuracy: 0.6501\n",
            "Epoch 182/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6593 - binary_accuracy: 0.6041 - val_loss: 0.6352 - val_binary_accuracy: 0.6497\n",
            "Epoch 183/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6634 - binary_accuracy: 0.6020 - val_loss: 0.6352 - val_binary_accuracy: 0.6501\n",
            "Epoch 184/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6611 - binary_accuracy: 0.6040 - val_loss: 0.6350 - val_binary_accuracy: 0.6505\n",
            "Epoch 185/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6605 - binary_accuracy: 0.6038 - val_loss: 0.6349 - val_binary_accuracy: 0.6514\n",
            "Epoch 186/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6617 - binary_accuracy: 0.5992 - val_loss: 0.6348 - val_binary_accuracy: 0.6509\n",
            "Epoch 187/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6645 - binary_accuracy: 0.5993 - val_loss: 0.6348 - val_binary_accuracy: 0.6509\n",
            "Epoch 188/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6629 - binary_accuracy: 0.6033 - val_loss: 0.6348 - val_binary_accuracy: 0.6509\n",
            "Epoch 189/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6591 - binary_accuracy: 0.6086 - val_loss: 0.6347 - val_binary_accuracy: 0.6509\n",
            "Epoch 190/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6615 - binary_accuracy: 0.6033 - val_loss: 0.6347 - val_binary_accuracy: 0.6505\n",
            "Epoch 191/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6629 - binary_accuracy: 0.6011 - val_loss: 0.6346 - val_binary_accuracy: 0.6505\n",
            "Epoch 192/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6561 - binary_accuracy: 0.6090 - val_loss: 0.6345 - val_binary_accuracy: 0.6505\n",
            "Epoch 193/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6625 - binary_accuracy: 0.5981 - val_loss: 0.6344 - val_binary_accuracy: 0.6514\n",
            "Epoch 194/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6644 - binary_accuracy: 0.6034 - val_loss: 0.6344 - val_binary_accuracy: 0.6509\n",
            "Epoch 195/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6630 - binary_accuracy: 0.6041 - val_loss: 0.6343 - val_binary_accuracy: 0.6518\n",
            "Epoch 196/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6578 - binary_accuracy: 0.6100 - val_loss: 0.6342 - val_binary_accuracy: 0.6518\n",
            "Epoch 197/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6542 - binary_accuracy: 0.6060 - val_loss: 0.6342 - val_binary_accuracy: 0.6518\n",
            "Epoch 198/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6607 - binary_accuracy: 0.6068 - val_loss: 0.6341 - val_binary_accuracy: 0.6530\n",
            "Epoch 199/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6538 - binary_accuracy: 0.6121 - val_loss: 0.6339 - val_binary_accuracy: 0.6539\n",
            "Epoch 200/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6584 - binary_accuracy: 0.6104 - val_loss: 0.6338 - val_binary_accuracy: 0.6530\n",
            "Epoch 201/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6529 - binary_accuracy: 0.6121 - val_loss: 0.6337 - val_binary_accuracy: 0.6539\n",
            "Epoch 202/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6556 - binary_accuracy: 0.6127 - val_loss: 0.6336 - val_binary_accuracy: 0.6543\n",
            "Epoch 203/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6612 - binary_accuracy: 0.6001 - val_loss: 0.6335 - val_binary_accuracy: 0.6547\n",
            "Epoch 204/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6564 - binary_accuracy: 0.6075 - val_loss: 0.6334 - val_binary_accuracy: 0.6551\n",
            "Epoch 205/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6549 - binary_accuracy: 0.6110 - val_loss: 0.6334 - val_binary_accuracy: 0.6551\n",
            "Epoch 206/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6579 - binary_accuracy: 0.6067 - val_loss: 0.6333 - val_binary_accuracy: 0.6551\n",
            "Epoch 207/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6584 - binary_accuracy: 0.6076 - val_loss: 0.6332 - val_binary_accuracy: 0.6564\n",
            "Epoch 208/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6589 - binary_accuracy: 0.6067 - val_loss: 0.6332 - val_binary_accuracy: 0.6551\n",
            "Epoch 209/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6581 - binary_accuracy: 0.6069 - val_loss: 0.6330 - val_binary_accuracy: 0.6551\n",
            "Epoch 210/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6574 - binary_accuracy: 0.6088 - val_loss: 0.6329 - val_binary_accuracy: 0.6559\n",
            "Epoch 211/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6557 - binary_accuracy: 0.6085 - val_loss: 0.6328 - val_binary_accuracy: 0.6568\n",
            "Epoch 212/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6545 - binary_accuracy: 0.6049 - val_loss: 0.6328 - val_binary_accuracy: 0.6559\n",
            "Epoch 213/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.6095 - val_loss: 0.6327 - val_binary_accuracy: 0.6572\n",
            "Epoch 214/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6528 - binary_accuracy: 0.6110 - val_loss: 0.6326 - val_binary_accuracy: 0.6580\n",
            "Epoch 215/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6544 - binary_accuracy: 0.6112 - val_loss: 0.6325 - val_binary_accuracy: 0.6572\n",
            "Epoch 216/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6499 - binary_accuracy: 0.6190 - val_loss: 0.6324 - val_binary_accuracy: 0.6572\n",
            "Epoch 217/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.6061 - val_loss: 0.6323 - val_binary_accuracy: 0.6585\n",
            "Epoch 218/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6565 - binary_accuracy: 0.6090 - val_loss: 0.6322 - val_binary_accuracy: 0.6580\n",
            "Epoch 219/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6511 - binary_accuracy: 0.6181 - val_loss: 0.6322 - val_binary_accuracy: 0.6585\n",
            "Epoch 220/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_accuracy: 0.6093 - val_loss: 0.6320 - val_binary_accuracy: 0.6580\n",
            "Epoch 221/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6516 - binary_accuracy: 0.6110 - val_loss: 0.6320 - val_binary_accuracy: 0.6572\n",
            "Epoch 222/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6547 - binary_accuracy: 0.6102 - val_loss: 0.6319 - val_binary_accuracy: 0.6585\n",
            "Epoch 223/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6520 - binary_accuracy: 0.6112 - val_loss: 0.6318 - val_binary_accuracy: 0.6580\n",
            "Epoch 224/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6523 - binary_accuracy: 0.6095 - val_loss: 0.6317 - val_binary_accuracy: 0.6580\n",
            "Epoch 225/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6509 - binary_accuracy: 0.6108 - val_loss: 0.6315 - val_binary_accuracy: 0.6572\n",
            "Epoch 226/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6520 - binary_accuracy: 0.6155 - val_loss: 0.6314 - val_binary_accuracy: 0.6580\n",
            "Epoch 227/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6556 - binary_accuracy: 0.6084 - val_loss: 0.6314 - val_binary_accuracy: 0.6580\n",
            "Epoch 228/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6494 - binary_accuracy: 0.6139 - val_loss: 0.6313 - val_binary_accuracy: 0.6585\n",
            "Epoch 229/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6537 - binary_accuracy: 0.6132 - val_loss: 0.6312 - val_binary_accuracy: 0.6589\n",
            "Epoch 230/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6510 - binary_accuracy: 0.6069 - val_loss: 0.6311 - val_binary_accuracy: 0.6585\n",
            "Epoch 231/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6486 - binary_accuracy: 0.6178 - val_loss: 0.6309 - val_binary_accuracy: 0.6589\n",
            "Epoch 232/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6154 - val_loss: 0.6308 - val_binary_accuracy: 0.6589\n",
            "Epoch 233/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6501 - binary_accuracy: 0.6130 - val_loss: 0.6307 - val_binary_accuracy: 0.6597\n",
            "Epoch 234/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6479 - binary_accuracy: 0.6187 - val_loss: 0.6306 - val_binary_accuracy: 0.6597\n",
            "Epoch 235/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6523 - binary_accuracy: 0.6144 - val_loss: 0.6305 - val_binary_accuracy: 0.6605\n",
            "Epoch 236/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6501 - binary_accuracy: 0.6138 - val_loss: 0.6304 - val_binary_accuracy: 0.6601\n",
            "Epoch 237/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6554 - binary_accuracy: 0.6135 - val_loss: 0.6304 - val_binary_accuracy: 0.6610\n",
            "Epoch 238/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6500 - binary_accuracy: 0.6216 - val_loss: 0.6303 - val_binary_accuracy: 0.6618\n",
            "Epoch 239/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.6215 - val_loss: 0.6302 - val_binary_accuracy: 0.6622\n",
            "Epoch 240/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6175 - val_loss: 0.6302 - val_binary_accuracy: 0.6626\n",
            "Epoch 241/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.6115 - val_loss: 0.6301 - val_binary_accuracy: 0.6626\n",
            "Epoch 242/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6160 - val_loss: 0.6300 - val_binary_accuracy: 0.6635\n",
            "Epoch 243/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6499 - binary_accuracy: 0.6188 - val_loss: 0.6299 - val_binary_accuracy: 0.6635\n",
            "Epoch 244/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.6113 - val_loss: 0.6298 - val_binary_accuracy: 0.6635\n",
            "Epoch 245/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6454 - binary_accuracy: 0.6189 - val_loss: 0.6297 - val_binary_accuracy: 0.6630\n",
            "Epoch 246/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6477 - binary_accuracy: 0.6206 - val_loss: 0.6296 - val_binary_accuracy: 0.6626\n",
            "Epoch 247/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6487 - binary_accuracy: 0.6190 - val_loss: 0.6296 - val_binary_accuracy: 0.6626\n",
            "Epoch 248/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.6114 - val_loss: 0.6295 - val_binary_accuracy: 0.6622\n",
            "Epoch 249/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6497 - binary_accuracy: 0.6177 - val_loss: 0.6295 - val_binary_accuracy: 0.6622\n",
            "Epoch 250/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6474 - binary_accuracy: 0.6174 - val_loss: 0.6294 - val_binary_accuracy: 0.6635\n",
            "Epoch 251/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.6130 - val_loss: 0.6293 - val_binary_accuracy: 0.6639\n",
            "Epoch 252/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6479 - binary_accuracy: 0.6203 - val_loss: 0.6293 - val_binary_accuracy: 0.6639\n",
            "Epoch 253/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6449 - binary_accuracy: 0.6229 - val_loss: 0.6292 - val_binary_accuracy: 0.6643\n",
            "Epoch 254/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.6180 - val_loss: 0.6292 - val_binary_accuracy: 0.6656\n",
            "Epoch 255/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.6215 - val_loss: 0.6290 - val_binary_accuracy: 0.6639\n",
            "Epoch 256/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.6120 - val_loss: 0.6289 - val_binary_accuracy: 0.6630\n",
            "Epoch 257/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6485 - binary_accuracy: 0.6136 - val_loss: 0.6288 - val_binary_accuracy: 0.6639\n",
            "Epoch 258/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.6135 - val_loss: 0.6287 - val_binary_accuracy: 0.6635\n",
            "Epoch 259/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.6155 - val_loss: 0.6287 - val_binary_accuracy: 0.6635\n",
            "Epoch 260/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.6205 - val_loss: 0.6286 - val_binary_accuracy: 0.6626\n",
            "Epoch 261/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.6238 - val_loss: 0.6285 - val_binary_accuracy: 0.6630\n",
            "Epoch 262/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6476 - binary_accuracy: 0.6275 - val_loss: 0.6285 - val_binary_accuracy: 0.6630\n",
            "Epoch 263/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6198 - val_loss: 0.6284 - val_binary_accuracy: 0.6630\n",
            "Epoch 264/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6234 - val_loss: 0.6282 - val_binary_accuracy: 0.6635\n",
            "Epoch 265/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6213 - val_loss: 0.6281 - val_binary_accuracy: 0.6635\n",
            "Epoch 266/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6489 - binary_accuracy: 0.6176 - val_loss: 0.6281 - val_binary_accuracy: 0.6647\n",
            "Epoch 267/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.6215 - val_loss: 0.6280 - val_binary_accuracy: 0.6656\n",
            "Epoch 268/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6467 - binary_accuracy: 0.6171 - val_loss: 0.6279 - val_binary_accuracy: 0.6664\n",
            "Epoch 269/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6446 - binary_accuracy: 0.6220 - val_loss: 0.6278 - val_binary_accuracy: 0.6668\n",
            "Epoch 270/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6459 - binary_accuracy: 0.6193 - val_loss: 0.6278 - val_binary_accuracy: 0.6676\n",
            "Epoch 271/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6430 - binary_accuracy: 0.6199 - val_loss: 0.6277 - val_binary_accuracy: 0.6681\n",
            "Epoch 272/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6462 - binary_accuracy: 0.6204 - val_loss: 0.6276 - val_binary_accuracy: 0.6689\n",
            "Epoch 273/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6464 - binary_accuracy: 0.6202 - val_loss: 0.6275 - val_binary_accuracy: 0.6685\n",
            "Epoch 274/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6413 - binary_accuracy: 0.6234 - val_loss: 0.6274 - val_binary_accuracy: 0.6693\n",
            "Epoch 275/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.6242 - val_loss: 0.6273 - val_binary_accuracy: 0.6689\n",
            "Epoch 276/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6460 - binary_accuracy: 0.6212 - val_loss: 0.6272 - val_binary_accuracy: 0.6693\n",
            "Epoch 277/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6448 - binary_accuracy: 0.6236 - val_loss: 0.6271 - val_binary_accuracy: 0.6697\n",
            "Epoch 278/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6383 - binary_accuracy: 0.6309 - val_loss: 0.6269 - val_binary_accuracy: 0.6697\n",
            "Epoch 279/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6428 - binary_accuracy: 0.6240 - val_loss: 0.6268 - val_binary_accuracy: 0.6685\n",
            "Epoch 280/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6293 - val_loss: 0.6268 - val_binary_accuracy: 0.6697\n",
            "Epoch 281/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6449 - binary_accuracy: 0.6197 - val_loss: 0.6267 - val_binary_accuracy: 0.6701\n",
            "Epoch 282/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6439 - binary_accuracy: 0.6255 - val_loss: 0.6266 - val_binary_accuracy: 0.6693\n",
            "Epoch 283/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6465 - binary_accuracy: 0.6244 - val_loss: 0.6266 - val_binary_accuracy: 0.6697\n",
            "Epoch 284/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6271 - val_loss: 0.6265 - val_binary_accuracy: 0.6701\n",
            "Epoch 285/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.6283 - val_loss: 0.6264 - val_binary_accuracy: 0.6701\n",
            "Epoch 286/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6421 - binary_accuracy: 0.6257 - val_loss: 0.6263 - val_binary_accuracy: 0.6697\n",
            "Epoch 287/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6248 - val_loss: 0.6262 - val_binary_accuracy: 0.6701\n",
            "Epoch 288/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6230 - val_loss: 0.6261 - val_binary_accuracy: 0.6701\n",
            "Epoch 289/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6373 - binary_accuracy: 0.6373 - val_loss: 0.6260 - val_binary_accuracy: 0.6701\n",
            "Epoch 290/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6433 - binary_accuracy: 0.6249 - val_loss: 0.6259 - val_binary_accuracy: 0.6701\n",
            "Epoch 291/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6311 - val_loss: 0.6258 - val_binary_accuracy: 0.6697\n",
            "Epoch 292/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6424 - binary_accuracy: 0.6281 - val_loss: 0.6258 - val_binary_accuracy: 0.6693\n",
            "Epoch 293/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6422 - binary_accuracy: 0.6267 - val_loss: 0.6257 - val_binary_accuracy: 0.6697\n",
            "Epoch 294/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6446 - binary_accuracy: 0.6231 - val_loss: 0.6256 - val_binary_accuracy: 0.6697\n",
            "Epoch 295/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6325 - val_loss: 0.6255 - val_binary_accuracy: 0.6710\n",
            "Epoch 296/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6439 - binary_accuracy: 0.6246 - val_loss: 0.6254 - val_binary_accuracy: 0.6697\n",
            "Epoch 297/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6413 - binary_accuracy: 0.6264 - val_loss: 0.6253 - val_binary_accuracy: 0.6697\n",
            "Epoch 298/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6389 - binary_accuracy: 0.6301 - val_loss: 0.6252 - val_binary_accuracy: 0.6697\n",
            "Epoch 299/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6456 - binary_accuracy: 0.6204 - val_loss: 0.6252 - val_binary_accuracy: 0.6701\n",
            "Epoch 300/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6242 - val_loss: 0.6252 - val_binary_accuracy: 0.6693\n",
            "Epoch 301/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.6255 - val_loss: 0.6251 - val_binary_accuracy: 0.6697\n",
            "Epoch 302/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6320 - val_loss: 0.6249 - val_binary_accuracy: 0.6689\n",
            "Epoch 303/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6384 - binary_accuracy: 0.6308 - val_loss: 0.6248 - val_binary_accuracy: 0.6697\n",
            "Epoch 304/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.6303 - val_loss: 0.6247 - val_binary_accuracy: 0.6701\n",
            "Epoch 305/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6396 - binary_accuracy: 0.6227 - val_loss: 0.6246 - val_binary_accuracy: 0.6697\n",
            "Epoch 306/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6433 - binary_accuracy: 0.6220 - val_loss: 0.6245 - val_binary_accuracy: 0.6701\n",
            "Epoch 307/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6411 - binary_accuracy: 0.6300 - val_loss: 0.6244 - val_binary_accuracy: 0.6706\n",
            "Epoch 308/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6258 - val_loss: 0.6243 - val_binary_accuracy: 0.6701\n",
            "Epoch 309/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6383 - binary_accuracy: 0.6266 - val_loss: 0.6243 - val_binary_accuracy: 0.6714\n",
            "Epoch 310/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6385 - binary_accuracy: 0.6306 - val_loss: 0.6242 - val_binary_accuracy: 0.6722\n",
            "Epoch 311/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6424 - binary_accuracy: 0.6299 - val_loss: 0.6242 - val_binary_accuracy: 0.6731\n",
            "Epoch 312/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6292 - val_loss: 0.6240 - val_binary_accuracy: 0.6718\n",
            "Epoch 313/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6295 - val_loss: 0.6240 - val_binary_accuracy: 0.6731\n",
            "Epoch 314/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6367 - binary_accuracy: 0.6323 - val_loss: 0.6238 - val_binary_accuracy: 0.6735\n",
            "Epoch 315/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6423 - binary_accuracy: 0.6268 - val_loss: 0.6238 - val_binary_accuracy: 0.6735\n",
            "Epoch 316/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6401 - binary_accuracy: 0.6261 - val_loss: 0.6238 - val_binary_accuracy: 0.6735\n",
            "Epoch 317/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6376 - binary_accuracy: 0.6321 - val_loss: 0.6237 - val_binary_accuracy: 0.6739\n",
            "Epoch 318/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6364 - binary_accuracy: 0.6314 - val_loss: 0.6236 - val_binary_accuracy: 0.6743\n",
            "Epoch 319/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6323 - val_loss: 0.6235 - val_binary_accuracy: 0.6743\n",
            "Epoch 320/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6382 - binary_accuracy: 0.6320 - val_loss: 0.6235 - val_binary_accuracy: 0.6747\n",
            "Epoch 321/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6278 - val_loss: 0.6234 - val_binary_accuracy: 0.6739\n",
            "Epoch 322/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6266 - val_loss: 0.6233 - val_binary_accuracy: 0.6735\n",
            "Epoch 323/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6366 - val_loss: 0.6233 - val_binary_accuracy: 0.6731\n",
            "Epoch 324/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6319 - val_loss: 0.6232 - val_binary_accuracy: 0.6739\n",
            "Epoch 325/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6378 - binary_accuracy: 0.6360 - val_loss: 0.6231 - val_binary_accuracy: 0.6747\n",
            "Epoch 326/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.6287 - val_loss: 0.6230 - val_binary_accuracy: 0.6747\n",
            "Epoch 327/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6371 - binary_accuracy: 0.6299 - val_loss: 0.6230 - val_binary_accuracy: 0.6743\n",
            "Epoch 328/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6381 - binary_accuracy: 0.6342 - val_loss: 0.6229 - val_binary_accuracy: 0.6739\n",
            "Epoch 329/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6395 - binary_accuracy: 0.6349 - val_loss: 0.6228 - val_binary_accuracy: 0.6727\n",
            "Epoch 330/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6386 - binary_accuracy: 0.6309 - val_loss: 0.6227 - val_binary_accuracy: 0.6722\n",
            "Epoch 331/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6303 - val_loss: 0.6226 - val_binary_accuracy: 0.6714\n",
            "Epoch 332/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6349 - binary_accuracy: 0.6408 - val_loss: 0.6225 - val_binary_accuracy: 0.6710\n",
            "Epoch 333/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6354 - binary_accuracy: 0.6347 - val_loss: 0.6225 - val_binary_accuracy: 0.6710\n",
            "Epoch 334/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.6236 - val_loss: 0.6224 - val_binary_accuracy: 0.6710\n",
            "Epoch 335/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6349 - val_loss: 0.6223 - val_binary_accuracy: 0.6706\n",
            "Epoch 336/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6399 - binary_accuracy: 0.6344 - val_loss: 0.6223 - val_binary_accuracy: 0.6701\n",
            "Epoch 337/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6310 - val_loss: 0.6222 - val_binary_accuracy: 0.6701\n",
            "Epoch 338/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6336 - val_loss: 0.6221 - val_binary_accuracy: 0.6701\n",
            "Epoch 339/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6399 - binary_accuracy: 0.6323 - val_loss: 0.6221 - val_binary_accuracy: 0.6697\n",
            "Epoch 340/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6370 - binary_accuracy: 0.6339 - val_loss: 0.6220 - val_binary_accuracy: 0.6697\n",
            "Epoch 341/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6391 - binary_accuracy: 0.6325 - val_loss: 0.6220 - val_binary_accuracy: 0.6697\n",
            "Epoch 342/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6385 - val_loss: 0.6219 - val_binary_accuracy: 0.6697\n",
            "Epoch 343/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6357 - val_loss: 0.6218 - val_binary_accuracy: 0.6701\n",
            "Epoch 344/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6325 - val_loss: 0.6217 - val_binary_accuracy: 0.6697\n",
            "Epoch 345/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6349 - binary_accuracy: 0.6344 - val_loss: 0.6216 - val_binary_accuracy: 0.6706\n",
            "Epoch 346/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6343 - val_loss: 0.6216 - val_binary_accuracy: 0.6701\n",
            "Epoch 347/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6347 - binary_accuracy: 0.6355 - val_loss: 0.6215 - val_binary_accuracy: 0.6710\n",
            "Epoch 348/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6321 - val_loss: 0.6214 - val_binary_accuracy: 0.6714\n",
            "Epoch 349/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6382 - binary_accuracy: 0.6312 - val_loss: 0.6213 - val_binary_accuracy: 0.6714\n",
            "Epoch 350/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6380 - val_loss: 0.6213 - val_binary_accuracy: 0.6710\n",
            "Epoch 351/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6328 - val_loss: 0.6212 - val_binary_accuracy: 0.6710\n",
            "Epoch 352/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6410 - val_loss: 0.6211 - val_binary_accuracy: 0.6706\n",
            "Epoch 353/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6343 - binary_accuracy: 0.6316 - val_loss: 0.6211 - val_binary_accuracy: 0.6697\n",
            "Epoch 354/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6347 - binary_accuracy: 0.6332 - val_loss: 0.6210 - val_binary_accuracy: 0.6706\n",
            "Epoch 355/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6349 - binary_accuracy: 0.6385 - val_loss: 0.6209 - val_binary_accuracy: 0.6710\n",
            "Epoch 356/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6313 - val_loss: 0.6209 - val_binary_accuracy: 0.6710\n",
            "Epoch 357/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6344 - binary_accuracy: 0.6369 - val_loss: 0.6207 - val_binary_accuracy: 0.6710\n",
            "Epoch 358/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6334 - val_loss: 0.6206 - val_binary_accuracy: 0.6722\n",
            "Epoch 359/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6357 - val_loss: 0.6205 - val_binary_accuracy: 0.6718\n",
            "Epoch 360/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6336 - binary_accuracy: 0.6362 - val_loss: 0.6205 - val_binary_accuracy: 0.6722\n",
            "Epoch 361/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6367 - binary_accuracy: 0.6355 - val_loss: 0.6204 - val_binary_accuracy: 0.6727\n",
            "Epoch 362/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6346 - binary_accuracy: 0.6324 - val_loss: 0.6204 - val_binary_accuracy: 0.6722\n",
            "Epoch 363/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6314 - binary_accuracy: 0.6341 - val_loss: 0.6203 - val_binary_accuracy: 0.6727\n",
            "Epoch 364/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.6380 - val_loss: 0.6202 - val_binary_accuracy: 0.6731\n",
            "Epoch 365/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6397 - val_loss: 0.6201 - val_binary_accuracy: 0.6739\n",
            "Epoch 366/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6392 - val_loss: 0.6201 - val_binary_accuracy: 0.6735\n",
            "Epoch 367/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6322 - binary_accuracy: 0.6405 - val_loss: 0.6200 - val_binary_accuracy: 0.6743\n",
            "Epoch 368/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6357 - binary_accuracy: 0.6326 - val_loss: 0.6199 - val_binary_accuracy: 0.6743\n",
            "Epoch 369/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.6375 - val_loss: 0.6198 - val_binary_accuracy: 0.6752\n",
            "Epoch 370/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.6342 - val_loss: 0.6197 - val_binary_accuracy: 0.6747\n",
            "Epoch 371/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6346 - val_loss: 0.6196 - val_binary_accuracy: 0.6743\n",
            "Epoch 372/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6304 - binary_accuracy: 0.6388 - val_loss: 0.6195 - val_binary_accuracy: 0.6739\n",
            "Epoch 373/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_accuracy: 0.6362 - val_loss: 0.6194 - val_binary_accuracy: 0.6739\n",
            "Epoch 374/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6401 - val_loss: 0.6192 - val_binary_accuracy: 0.6739\n",
            "Epoch 375/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6328 - val_loss: 0.6191 - val_binary_accuracy: 0.6743\n",
            "Epoch 376/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6275 - binary_accuracy: 0.6441 - val_loss: 0.6190 - val_binary_accuracy: 0.6739\n",
            "Epoch 377/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6356 - binary_accuracy: 0.6334 - val_loss: 0.6190 - val_binary_accuracy: 0.6731\n",
            "Epoch 378/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6338 - val_loss: 0.6189 - val_binary_accuracy: 0.6739\n",
            "Epoch 379/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6419 - val_loss: 0.6189 - val_binary_accuracy: 0.6735\n",
            "Epoch 380/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6323 - binary_accuracy: 0.6340 - val_loss: 0.6188 - val_binary_accuracy: 0.6735\n",
            "Epoch 381/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6398 - val_loss: 0.6187 - val_binary_accuracy: 0.6727\n",
            "Epoch 382/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6270 - binary_accuracy: 0.6486 - val_loss: 0.6186 - val_binary_accuracy: 0.6722\n",
            "Epoch 383/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6352 - val_loss: 0.6186 - val_binary_accuracy: 0.6722\n",
            "Epoch 384/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6410 - val_loss: 0.6186 - val_binary_accuracy: 0.6731\n",
            "Epoch 385/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.6406 - val_loss: 0.6185 - val_binary_accuracy: 0.6735\n",
            "Epoch 386/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6308 - binary_accuracy: 0.6427 - val_loss: 0.6184 - val_binary_accuracy: 0.6739\n",
            "Epoch 387/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6391 - val_loss: 0.6183 - val_binary_accuracy: 0.6739\n",
            "Epoch 388/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6383 - val_loss: 0.6182 - val_binary_accuracy: 0.6739\n",
            "Epoch 389/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6344 - binary_accuracy: 0.6386 - val_loss: 0.6182 - val_binary_accuracy: 0.6739\n",
            "Epoch 390/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.6427 - val_loss: 0.6181 - val_binary_accuracy: 0.6739\n",
            "Epoch 391/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6355 - binary_accuracy: 0.6381 - val_loss: 0.6181 - val_binary_accuracy: 0.6739\n",
            "Epoch 392/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6301 - val_loss: 0.6181 - val_binary_accuracy: 0.6739\n",
            "Epoch 393/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6309 - binary_accuracy: 0.6420 - val_loss: 0.6180 - val_binary_accuracy: 0.6739\n",
            "Epoch 394/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6485 - val_loss: 0.6179 - val_binary_accuracy: 0.6731\n",
            "Epoch 395/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6307 - binary_accuracy: 0.6366 - val_loss: 0.6178 - val_binary_accuracy: 0.6739\n",
            "Epoch 396/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6260 - binary_accuracy: 0.6452 - val_loss: 0.6177 - val_binary_accuracy: 0.6735\n",
            "Epoch 397/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6293 - binary_accuracy: 0.6437 - val_loss: 0.6177 - val_binary_accuracy: 0.6735\n",
            "Epoch 398/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6428 - val_loss: 0.6177 - val_binary_accuracy: 0.6739\n",
            "Epoch 399/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6290 - binary_accuracy: 0.6485 - val_loss: 0.6176 - val_binary_accuracy: 0.6735\n",
            "Epoch 400/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6376 - val_loss: 0.6176 - val_binary_accuracy: 0.6735\n",
            "Epoch 401/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6304 - binary_accuracy: 0.6406 - val_loss: 0.6176 - val_binary_accuracy: 0.6743\n",
            "Epoch 402/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.6366 - val_loss: 0.6175 - val_binary_accuracy: 0.6739\n",
            "Epoch 403/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.6447 - val_loss: 0.6174 - val_binary_accuracy: 0.6747\n",
            "Epoch 404/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6446 - val_loss: 0.6174 - val_binary_accuracy: 0.6743\n",
            "Epoch 405/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.6448 - val_loss: 0.6173 - val_binary_accuracy: 0.6743\n",
            "Epoch 406/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6417 - val_loss: 0.6172 - val_binary_accuracy: 0.6743\n",
            "Epoch 407/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6388 - val_loss: 0.6172 - val_binary_accuracy: 0.6735\n",
            "Epoch 408/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6441 - val_loss: 0.6172 - val_binary_accuracy: 0.6743\n",
            "Epoch 409/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6378 - val_loss: 0.6171 - val_binary_accuracy: 0.6739\n",
            "Epoch 410/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6420 - val_loss: 0.6170 - val_binary_accuracy: 0.6752\n",
            "Epoch 411/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6264 - binary_accuracy: 0.6504 - val_loss: 0.6169 - val_binary_accuracy: 0.6743\n",
            "Epoch 412/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6290 - binary_accuracy: 0.6361 - val_loss: 0.6169 - val_binary_accuracy: 0.6739\n",
            "Epoch 413/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6307 - binary_accuracy: 0.6379 - val_loss: 0.6168 - val_binary_accuracy: 0.6739\n",
            "Epoch 414/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6305 - binary_accuracy: 0.6413 - val_loss: 0.6167 - val_binary_accuracy: 0.6735\n",
            "Epoch 415/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6399 - val_loss: 0.6167 - val_binary_accuracy: 0.6731\n",
            "Epoch 416/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6447 - val_loss: 0.6167 - val_binary_accuracy: 0.6727\n",
            "Epoch 417/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6264 - binary_accuracy: 0.6478 - val_loss: 0.6166 - val_binary_accuracy: 0.6727\n",
            "Epoch 418/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6404 - val_loss: 0.6165 - val_binary_accuracy: 0.6731\n",
            "Epoch 419/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6308 - binary_accuracy: 0.6411 - val_loss: 0.6165 - val_binary_accuracy: 0.6735\n",
            "Epoch 420/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6426 - val_loss: 0.6164 - val_binary_accuracy: 0.6739\n",
            "Epoch 421/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6423 - val_loss: 0.6163 - val_binary_accuracy: 0.6743\n",
            "Epoch 422/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6296 - binary_accuracy: 0.6432 - val_loss: 0.6163 - val_binary_accuracy: 0.6743\n",
            "Epoch 423/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6401 - val_loss: 0.6162 - val_binary_accuracy: 0.6739\n",
            "Epoch 424/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6432 - val_loss: 0.6162 - val_binary_accuracy: 0.6739\n",
            "Epoch 425/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6407 - val_loss: 0.6162 - val_binary_accuracy: 0.6743\n",
            "Epoch 426/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6317 - binary_accuracy: 0.6415 - val_loss: 0.6162 - val_binary_accuracy: 0.6735\n",
            "Epoch 427/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6364 - val_loss: 0.6162 - val_binary_accuracy: 0.6735\n",
            "Epoch 428/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6420 - val_loss: 0.6162 - val_binary_accuracy: 0.6731\n",
            "Epoch 429/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6480 - val_loss: 0.6161 - val_binary_accuracy: 0.6731\n",
            "Epoch 430/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6434 - val_loss: 0.6161 - val_binary_accuracy: 0.6735\n",
            "Epoch 431/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.6381 - val_loss: 0.6160 - val_binary_accuracy: 0.6731\n",
            "Epoch 432/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6313 - binary_accuracy: 0.6413 - val_loss: 0.6160 - val_binary_accuracy: 0.6739\n",
            "Epoch 433/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6276 - binary_accuracy: 0.6393 - val_loss: 0.6160 - val_binary_accuracy: 0.6735\n",
            "Epoch 434/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6436 - val_loss: 0.6159 - val_binary_accuracy: 0.6739\n",
            "Epoch 435/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6298 - binary_accuracy: 0.6461 - val_loss: 0.6159 - val_binary_accuracy: 0.6743\n",
            "Epoch 436/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.6425 - val_loss: 0.6158 - val_binary_accuracy: 0.6739\n",
            "Epoch 437/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6275 - binary_accuracy: 0.6446 - val_loss: 0.6158 - val_binary_accuracy: 0.6743\n",
            "Epoch 438/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6427 - val_loss: 0.6158 - val_binary_accuracy: 0.6752\n",
            "Epoch 439/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.6419 - val_loss: 0.6157 - val_binary_accuracy: 0.6747\n",
            "Epoch 440/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6262 - binary_accuracy: 0.6500 - val_loss: 0.6157 - val_binary_accuracy: 0.6752\n",
            "Epoch 441/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6281 - binary_accuracy: 0.6421 - val_loss: 0.6156 - val_binary_accuracy: 0.6747\n",
            "Epoch 442/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6253 - binary_accuracy: 0.6420 - val_loss: 0.6155 - val_binary_accuracy: 0.6752\n",
            "Epoch 443/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6266 - binary_accuracy: 0.6463 - val_loss: 0.6155 - val_binary_accuracy: 0.6752\n",
            "Epoch 444/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.6448 - val_loss: 0.6155 - val_binary_accuracy: 0.6752\n",
            "Epoch 445/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6488 - val_loss: 0.6154 - val_binary_accuracy: 0.6743\n",
            "Epoch 446/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6258 - binary_accuracy: 0.6446 - val_loss: 0.6154 - val_binary_accuracy: 0.6747\n",
            "Epoch 447/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6290 - binary_accuracy: 0.6454 - val_loss: 0.6153 - val_binary_accuracy: 0.6747\n",
            "Epoch 448/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6482 - val_loss: 0.6153 - val_binary_accuracy: 0.6756\n",
            "Epoch 449/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6273 - binary_accuracy: 0.6400 - val_loss: 0.6152 - val_binary_accuracy: 0.6752\n",
            "Epoch 450/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6371 - val_loss: 0.6152 - val_binary_accuracy: 0.6756\n",
            "Epoch 451/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6259 - binary_accuracy: 0.6480 - val_loss: 0.6151 - val_binary_accuracy: 0.6756\n",
            "Epoch 452/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6453 - val_loss: 0.6150 - val_binary_accuracy: 0.6760\n",
            "Epoch 453/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6280 - binary_accuracy: 0.6402 - val_loss: 0.6149 - val_binary_accuracy: 0.6756\n",
            "Epoch 454/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6264 - binary_accuracy: 0.6485 - val_loss: 0.6149 - val_binary_accuracy: 0.6756\n",
            "Epoch 455/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6280 - binary_accuracy: 0.6480 - val_loss: 0.6148 - val_binary_accuracy: 0.6756\n",
            "Epoch 456/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6434 - val_loss: 0.6148 - val_binary_accuracy: 0.6747\n",
            "Epoch 457/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6274 - binary_accuracy: 0.6467 - val_loss: 0.6147 - val_binary_accuracy: 0.6752\n",
            "Epoch 458/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6275 - binary_accuracy: 0.6476 - val_loss: 0.6147 - val_binary_accuracy: 0.6747\n",
            "Epoch 459/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6512 - val_loss: 0.6146 - val_binary_accuracy: 0.6743\n",
            "Epoch 460/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6436 - val_loss: 0.6145 - val_binary_accuracy: 0.6743\n",
            "Epoch 461/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6249 - binary_accuracy: 0.6500 - val_loss: 0.6144 - val_binary_accuracy: 0.6743\n",
            "Epoch 462/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6260 - binary_accuracy: 0.6431 - val_loss: 0.6144 - val_binary_accuracy: 0.6743\n",
            "Epoch 463/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6244 - binary_accuracy: 0.6467 - val_loss: 0.6144 - val_binary_accuracy: 0.6743\n",
            "Epoch 464/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_accuracy: 0.6475 - val_loss: 0.6143 - val_binary_accuracy: 0.6743\n",
            "Epoch 465/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6230 - binary_accuracy: 0.6480 - val_loss: 0.6142 - val_binary_accuracy: 0.6743\n",
            "Epoch 466/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6244 - binary_accuracy: 0.6412 - val_loss: 0.6141 - val_binary_accuracy: 0.6739\n",
            "Epoch 467/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.6530 - val_loss: 0.6140 - val_binary_accuracy: 0.6739\n",
            "Epoch 468/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6524 - val_loss: 0.6139 - val_binary_accuracy: 0.6743\n",
            "Epoch 469/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6261 - binary_accuracy: 0.6446 - val_loss: 0.6139 - val_binary_accuracy: 0.6743\n",
            "Epoch 470/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6288 - binary_accuracy: 0.6466 - val_loss: 0.6139 - val_binary_accuracy: 0.6747\n",
            "Epoch 471/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6264 - binary_accuracy: 0.6465 - val_loss: 0.6139 - val_binary_accuracy: 0.6747\n",
            "Epoch 472/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6533 - val_loss: 0.6139 - val_binary_accuracy: 0.6743\n",
            "Epoch 473/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6465 - val_loss: 0.6138 - val_binary_accuracy: 0.6743\n",
            "Epoch 474/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6292 - binary_accuracy: 0.6463 - val_loss: 0.6138 - val_binary_accuracy: 0.6743\n",
            "Epoch 475/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.6420 - val_loss: 0.6138 - val_binary_accuracy: 0.6743\n",
            "Epoch 476/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6244 - binary_accuracy: 0.6468 - val_loss: 0.6138 - val_binary_accuracy: 0.6747\n",
            "Epoch 477/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6271 - binary_accuracy: 0.6431 - val_loss: 0.6137 - val_binary_accuracy: 0.6743\n",
            "Epoch 478/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6270 - binary_accuracy: 0.6465 - val_loss: 0.6137 - val_binary_accuracy: 0.6743\n",
            "Epoch 479/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6482 - val_loss: 0.6137 - val_binary_accuracy: 0.6743\n",
            "Epoch 480/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.6493 - val_loss: 0.6137 - val_binary_accuracy: 0.6743\n",
            "Epoch 481/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6216 - binary_accuracy: 0.6540 - val_loss: 0.6136 - val_binary_accuracy: 0.6739\n",
            "Epoch 482/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6502 - val_loss: 0.6136 - val_binary_accuracy: 0.6739\n",
            "Epoch 483/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6235 - binary_accuracy: 0.6474 - val_loss: 0.6136 - val_binary_accuracy: 0.6739\n",
            "Epoch 484/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.6471 - val_loss: 0.6135 - val_binary_accuracy: 0.6735\n",
            "Epoch 485/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6249 - binary_accuracy: 0.6501 - val_loss: 0.6134 - val_binary_accuracy: 0.6731\n",
            "Epoch 486/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6214 - binary_accuracy: 0.6494 - val_loss: 0.6134 - val_binary_accuracy: 0.6735\n",
            "Epoch 487/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6476 - val_loss: 0.6133 - val_binary_accuracy: 0.6731\n",
            "Epoch 488/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6253 - binary_accuracy: 0.6413 - val_loss: 0.6133 - val_binary_accuracy: 0.6727\n",
            "Epoch 489/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6500 - val_loss: 0.6132 - val_binary_accuracy: 0.6731\n",
            "Epoch 490/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6527 - val_loss: 0.6132 - val_binary_accuracy: 0.6727\n",
            "Epoch 491/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6238 - binary_accuracy: 0.6461 - val_loss: 0.6131 - val_binary_accuracy: 0.6727\n",
            "Epoch 492/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6218 - binary_accuracy: 0.6466 - val_loss: 0.6130 - val_binary_accuracy: 0.6727\n",
            "Epoch 493/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6236 - binary_accuracy: 0.6469 - val_loss: 0.6130 - val_binary_accuracy: 0.6727\n",
            "Epoch 494/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6228 - binary_accuracy: 0.6449 - val_loss: 0.6130 - val_binary_accuracy: 0.6727\n",
            "Epoch 495/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6538 - val_loss: 0.6129 - val_binary_accuracy: 0.6727\n",
            "Epoch 496/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_accuracy: 0.6516 - val_loss: 0.6128 - val_binary_accuracy: 0.6727\n",
            "Epoch 497/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6523 - val_loss: 0.6128 - val_binary_accuracy: 0.6727\n",
            "Epoch 498/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6470 - val_loss: 0.6128 - val_binary_accuracy: 0.6727\n",
            "Epoch 499/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6542 - val_loss: 0.6127 - val_binary_accuracy: 0.6731\n",
            "Epoch 500/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6234 - binary_accuracy: 0.6486 - val_loss: 0.6127 - val_binary_accuracy: 0.6735\n",
            "Epoch 501/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6508 - val_loss: 0.6126 - val_binary_accuracy: 0.6735\n",
            "Epoch 502/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6230 - binary_accuracy: 0.6498 - val_loss: 0.6126 - val_binary_accuracy: 0.6735\n",
            "Epoch 503/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6497 - val_loss: 0.6126 - val_binary_accuracy: 0.6735\n",
            "Epoch 504/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6493 - val_loss: 0.6126 - val_binary_accuracy: 0.6735\n",
            "Epoch 505/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6512 - val_loss: 0.6125 - val_binary_accuracy: 0.6727\n",
            "Epoch 506/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6224 - binary_accuracy: 0.6525 - val_loss: 0.6125 - val_binary_accuracy: 0.6727\n",
            "Epoch 507/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6282 - binary_accuracy: 0.6414 - val_loss: 0.6125 - val_binary_accuracy: 0.6731\n",
            "Epoch 508/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6211 - binary_accuracy: 0.6551 - val_loss: 0.6124 - val_binary_accuracy: 0.6731\n",
            "Epoch 509/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6451 - val_loss: 0.6124 - val_binary_accuracy: 0.6739\n",
            "Epoch 510/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6517 - val_loss: 0.6124 - val_binary_accuracy: 0.6747\n",
            "Epoch 511/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.6515 - val_loss: 0.6124 - val_binary_accuracy: 0.6743\n",
            "Epoch 512/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6218 - binary_accuracy: 0.6556 - val_loss: 0.6124 - val_binary_accuracy: 0.6743\n",
            "Epoch 513/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6241 - binary_accuracy: 0.6541 - val_loss: 0.6123 - val_binary_accuracy: 0.6743\n",
            "Epoch 514/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6455 - val_loss: 0.6123 - val_binary_accuracy: 0.6743\n",
            "Epoch 515/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6247 - binary_accuracy: 0.6455 - val_loss: 0.6123 - val_binary_accuracy: 0.6743\n",
            "Epoch 516/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6178 - binary_accuracy: 0.6518 - val_loss: 0.6122 - val_binary_accuracy: 0.6735\n",
            "Epoch 517/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_accuracy: 0.6553 - val_loss: 0.6121 - val_binary_accuracy: 0.6735\n",
            "Epoch 518/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6517 - val_loss: 0.6121 - val_binary_accuracy: 0.6739\n",
            "Epoch 519/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6454 - val_loss: 0.6121 - val_binary_accuracy: 0.6739\n",
            "Epoch 520/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_accuracy: 0.6507 - val_loss: 0.6121 - val_binary_accuracy: 0.6739\n",
            "Epoch 521/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6535 - val_loss: 0.6120 - val_binary_accuracy: 0.6735\n",
            "Epoch 522/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6207 - binary_accuracy: 0.6534 - val_loss: 0.6120 - val_binary_accuracy: 0.6735\n",
            "Epoch 523/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6515 - val_loss: 0.6119 - val_binary_accuracy: 0.6735\n",
            "Epoch 524/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6492 - val_loss: 0.6119 - val_binary_accuracy: 0.6739\n",
            "Epoch 525/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6215 - binary_accuracy: 0.6544 - val_loss: 0.6119 - val_binary_accuracy: 0.6739\n",
            "Epoch 526/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6536 - val_loss: 0.6118 - val_binary_accuracy: 0.6743\n",
            "Epoch 527/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6524 - val_loss: 0.6118 - val_binary_accuracy: 0.6739\n",
            "Epoch 528/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6234 - binary_accuracy: 0.6488 - val_loss: 0.6118 - val_binary_accuracy: 0.6747\n",
            "Epoch 529/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6218 - binary_accuracy: 0.6488 - val_loss: 0.6118 - val_binary_accuracy: 0.6743\n",
            "Epoch 530/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6203 - binary_accuracy: 0.6555 - val_loss: 0.6117 - val_binary_accuracy: 0.6747\n",
            "Epoch 531/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6212 - binary_accuracy: 0.6541 - val_loss: 0.6117 - val_binary_accuracy: 0.6747\n",
            "Epoch 532/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6525 - val_loss: 0.6116 - val_binary_accuracy: 0.6752\n",
            "Epoch 533/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6200 - binary_accuracy: 0.6579 - val_loss: 0.6115 - val_binary_accuracy: 0.6747\n",
            "Epoch 534/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6217 - binary_accuracy: 0.6484 - val_loss: 0.6115 - val_binary_accuracy: 0.6747\n",
            "Epoch 535/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6220 - binary_accuracy: 0.6506 - val_loss: 0.6115 - val_binary_accuracy: 0.6752\n",
            "Epoch 536/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_accuracy: 0.6614 - val_loss: 0.6114 - val_binary_accuracy: 0.6752\n",
            "Epoch 537/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6216 - binary_accuracy: 0.6615 - val_loss: 0.6113 - val_binary_accuracy: 0.6747\n",
            "Epoch 538/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6545 - val_loss: 0.6113 - val_binary_accuracy: 0.6739\n",
            "Epoch 539/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6603 - val_loss: 0.6112 - val_binary_accuracy: 0.6752\n",
            "Epoch 540/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6510 - val_loss: 0.6112 - val_binary_accuracy: 0.6747\n",
            "Epoch 541/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6477 - val_loss: 0.6112 - val_binary_accuracy: 0.6747\n",
            "Epoch 542/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6213 - binary_accuracy: 0.6538 - val_loss: 0.6112 - val_binary_accuracy: 0.6743\n",
            "Epoch 543/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.6540 - val_loss: 0.6111 - val_binary_accuracy: 0.6743\n",
            "Epoch 544/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6235 - binary_accuracy: 0.6522 - val_loss: 0.6111 - val_binary_accuracy: 0.6743\n",
            "Epoch 545/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6591 - val_loss: 0.6111 - val_binary_accuracy: 0.6743\n",
            "Epoch 546/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6175 - binary_accuracy: 0.6568 - val_loss: 0.6110 - val_binary_accuracy: 0.6735\n",
            "Epoch 547/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6642 - val_loss: 0.6109 - val_binary_accuracy: 0.6735\n",
            "Epoch 548/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6553 - val_loss: 0.6108 - val_binary_accuracy: 0.6735\n",
            "Epoch 549/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6217 - binary_accuracy: 0.6537 - val_loss: 0.6108 - val_binary_accuracy: 0.6735\n",
            "Epoch 550/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6537 - val_loss: 0.6108 - val_binary_accuracy: 0.6735\n",
            "Epoch 551/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6484 - val_loss: 0.6108 - val_binary_accuracy: 0.6735\n",
            "Epoch 552/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_accuracy: 0.6492 - val_loss: 0.6108 - val_binary_accuracy: 0.6739\n",
            "Epoch 553/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6572 - val_loss: 0.6107 - val_binary_accuracy: 0.6739\n",
            "Epoch 554/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6249 - binary_accuracy: 0.6499 - val_loss: 0.6108 - val_binary_accuracy: 0.6739\n",
            "Epoch 555/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6508 - val_loss: 0.6108 - val_binary_accuracy: 0.6743\n",
            "Epoch 556/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6210 - binary_accuracy: 0.6545 - val_loss: 0.6108 - val_binary_accuracy: 0.6735\n",
            "Epoch 557/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6532 - val_loss: 0.6107 - val_binary_accuracy: 0.6747\n",
            "Epoch 558/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6557 - val_loss: 0.6107 - val_binary_accuracy: 0.6743\n",
            "Epoch 559/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6178 - binary_accuracy: 0.6583 - val_loss: 0.6106 - val_binary_accuracy: 0.6739\n",
            "Epoch 560/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6471 - val_loss: 0.6106 - val_binary_accuracy: 0.6739\n",
            "Epoch 561/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6573 - val_loss: 0.6106 - val_binary_accuracy: 0.6739\n",
            "Epoch 562/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6196 - binary_accuracy: 0.6525 - val_loss: 0.6106 - val_binary_accuracy: 0.6739\n",
            "Epoch 563/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6540 - val_loss: 0.6105 - val_binary_accuracy: 0.6739\n",
            "Epoch 564/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6537 - val_loss: 0.6105 - val_binary_accuracy: 0.6739\n",
            "Epoch 565/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6191 - binary_accuracy: 0.6558 - val_loss: 0.6105 - val_binary_accuracy: 0.6743\n",
            "Epoch 566/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6197 - binary_accuracy: 0.6531 - val_loss: 0.6105 - val_binary_accuracy: 0.6747\n",
            "Epoch 567/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6581 - val_loss: 0.6104 - val_binary_accuracy: 0.6731\n",
            "Epoch 568/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6588 - val_loss: 0.6104 - val_binary_accuracy: 0.6739\n",
            "Epoch 569/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6216 - binary_accuracy: 0.6550 - val_loss: 0.6104 - val_binary_accuracy: 0.6727\n",
            "Epoch 570/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6519 - val_loss: 0.6104 - val_binary_accuracy: 0.6722\n",
            "Epoch 571/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6175 - binary_accuracy: 0.6559 - val_loss: 0.6103 - val_binary_accuracy: 0.6731\n",
            "Epoch 572/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6543 - val_loss: 0.6103 - val_binary_accuracy: 0.6731\n",
            "Epoch 573/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6201 - binary_accuracy: 0.6559 - val_loss: 0.6103 - val_binary_accuracy: 0.6727\n",
            "Epoch 574/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.6551 - val_loss: 0.6103 - val_binary_accuracy: 0.6722\n",
            "Epoch 575/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6512 - val_loss: 0.6103 - val_binary_accuracy: 0.6731\n",
            "Epoch 576/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6523 - val_loss: 0.6103 - val_binary_accuracy: 0.6727\n",
            "Epoch 577/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6162 - binary_accuracy: 0.6579 - val_loss: 0.6102 - val_binary_accuracy: 0.6722\n",
            "Epoch 578/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6536 - val_loss: 0.6102 - val_binary_accuracy: 0.6722\n",
            "Epoch 579/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6214 - binary_accuracy: 0.6535 - val_loss: 0.6102 - val_binary_accuracy: 0.6722\n",
            "Epoch 580/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6602 - val_loss: 0.6101 - val_binary_accuracy: 0.6722\n",
            "Epoch 581/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6197 - binary_accuracy: 0.6619 - val_loss: 0.6101 - val_binary_accuracy: 0.6722\n",
            "Epoch 582/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6549 - val_loss: 0.6101 - val_binary_accuracy: 0.6718\n",
            "Epoch 583/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6552 - val_loss: 0.6101 - val_binary_accuracy: 0.6727\n",
            "Epoch 584/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6230 - binary_accuracy: 0.6538 - val_loss: 0.6102 - val_binary_accuracy: 0.6722\n",
            "Epoch 585/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6570 - val_loss: 0.6101 - val_binary_accuracy: 0.6722\n",
            "Epoch 586/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6203 - binary_accuracy: 0.6592 - val_loss: 0.6101 - val_binary_accuracy: 0.6731\n",
            "Epoch 587/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6582 - val_loss: 0.6101 - val_binary_accuracy: 0.6727\n",
            "Epoch 588/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6540 - val_loss: 0.6100 - val_binary_accuracy: 0.6731\n",
            "Epoch 589/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6540 - val_loss: 0.6100 - val_binary_accuracy: 0.6735\n",
            "Epoch 590/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6236 - binary_accuracy: 0.6616 - val_loss: 0.6100 - val_binary_accuracy: 0.6735\n",
            "Epoch 591/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6575 - val_loss: 0.6100 - val_binary_accuracy: 0.6731\n",
            "Epoch 592/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6516 - val_loss: 0.6100 - val_binary_accuracy: 0.6727\n",
            "Epoch 593/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6219 - binary_accuracy: 0.6506 - val_loss: 0.6100 - val_binary_accuracy: 0.6727\n",
            "Epoch 594/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6215 - binary_accuracy: 0.6502 - val_loss: 0.6100 - val_binary_accuracy: 0.6731\n",
            "Epoch 595/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6564 - val_loss: 0.6099 - val_binary_accuracy: 0.6731\n",
            "Epoch 596/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6565 - val_loss: 0.6098 - val_binary_accuracy: 0.6731\n",
            "Epoch 597/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6499 - val_loss: 0.6098 - val_binary_accuracy: 0.6727\n",
            "Epoch 598/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6610 - val_loss: 0.6097 - val_binary_accuracy: 0.6731\n",
            "Epoch 599/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6562 - val_loss: 0.6097 - val_binary_accuracy: 0.6731\n",
            "Epoch 600/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6596 - val_loss: 0.6096 - val_binary_accuracy: 0.6731\n",
            "Epoch 601/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6552 - val_loss: 0.6096 - val_binary_accuracy: 0.6731\n",
            "Epoch 602/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6588 - val_loss: 0.6096 - val_binary_accuracy: 0.6735\n",
            "Epoch 603/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6597 - val_loss: 0.6095 - val_binary_accuracy: 0.6735\n",
            "Epoch 604/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6556 - val_loss: 0.6095 - val_binary_accuracy: 0.6731\n",
            "Epoch 605/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6187 - binary_accuracy: 0.6595 - val_loss: 0.6095 - val_binary_accuracy: 0.6731\n",
            "Epoch 606/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6178 - binary_accuracy: 0.6594 - val_loss: 0.6095 - val_binary_accuracy: 0.6735\n",
            "Epoch 607/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.6516 - val_loss: 0.6094 - val_binary_accuracy: 0.6731\n",
            "Epoch 608/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6177 - binary_accuracy: 0.6567 - val_loss: 0.6094 - val_binary_accuracy: 0.6735\n",
            "Epoch 609/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6178 - binary_accuracy: 0.6560 - val_loss: 0.6094 - val_binary_accuracy: 0.6735\n",
            "Epoch 610/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6600 - val_loss: 0.6094 - val_binary_accuracy: 0.6739\n",
            "Epoch 611/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6539 - val_loss: 0.6094 - val_binary_accuracy: 0.6735\n",
            "Epoch 612/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6567 - val_loss: 0.6093 - val_binary_accuracy: 0.6747\n",
            "Epoch 613/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6563 - val_loss: 0.6093 - val_binary_accuracy: 0.6739\n",
            "Epoch 614/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6560 - val_loss: 0.6093 - val_binary_accuracy: 0.6743\n",
            "Epoch 615/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6162 - binary_accuracy: 0.6540 - val_loss: 0.6093 - val_binary_accuracy: 0.6735\n",
            "Epoch 616/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6567 - val_loss: 0.6092 - val_binary_accuracy: 0.6735\n",
            "Epoch 617/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6566 - val_loss: 0.6092 - val_binary_accuracy: 0.6735\n",
            "Epoch 618/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6587 - val_loss: 0.6092 - val_binary_accuracy: 0.6739\n",
            "Epoch 619/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6570 - val_loss: 0.6091 - val_binary_accuracy: 0.6735\n",
            "Epoch 620/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6594 - val_loss: 0.6091 - val_binary_accuracy: 0.6735\n",
            "Epoch 621/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6574 - val_loss: 0.6091 - val_binary_accuracy: 0.6739\n",
            "Epoch 622/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6163 - binary_accuracy: 0.6548 - val_loss: 0.6090 - val_binary_accuracy: 0.6739\n",
            "Epoch 623/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6173 - binary_accuracy: 0.6530 - val_loss: 0.6090 - val_binary_accuracy: 0.6747\n",
            "Epoch 624/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6599 - val_loss: 0.6089 - val_binary_accuracy: 0.6743\n",
            "Epoch 625/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6540 - val_loss: 0.6089 - val_binary_accuracy: 0.6747\n",
            "Epoch 626/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6211 - binary_accuracy: 0.6532 - val_loss: 0.6089 - val_binary_accuracy: 0.6739\n",
            "Epoch 627/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_accuracy: 0.6571 - val_loss: 0.6089 - val_binary_accuracy: 0.6735\n",
            "Epoch 628/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6191 - binary_accuracy: 0.6528 - val_loss: 0.6089 - val_binary_accuracy: 0.6735\n",
            "Epoch 629/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6171 - binary_accuracy: 0.6574 - val_loss: 0.6089 - val_binary_accuracy: 0.6731\n",
            "Epoch 630/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6549 - val_loss: 0.6089 - val_binary_accuracy: 0.6731\n",
            "Epoch 631/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6172 - binary_accuracy: 0.6599 - val_loss: 0.6089 - val_binary_accuracy: 0.6727\n",
            "Epoch 632/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_accuracy: 0.6597 - val_loss: 0.6090 - val_binary_accuracy: 0.6722\n",
            "Epoch 633/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6171 - binary_accuracy: 0.6539 - val_loss: 0.6090 - val_binary_accuracy: 0.6735\n",
            "Epoch 634/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6562 - val_loss: 0.6089 - val_binary_accuracy: 0.6727\n",
            "Epoch 635/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6564 - val_loss: 0.6089 - val_binary_accuracy: 0.6731\n",
            "Epoch 636/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6523 - val_loss: 0.6089 - val_binary_accuracy: 0.6731\n",
            "Epoch 637/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6607 - val_loss: 0.6089 - val_binary_accuracy: 0.6731\n",
            "Epoch 638/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6508 - val_loss: 0.6088 - val_binary_accuracy: 0.6727\n",
            "Epoch 639/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6146 - binary_accuracy: 0.6599 - val_loss: 0.6088 - val_binary_accuracy: 0.6727\n",
            "Epoch 640/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6648 - val_loss: 0.6087 - val_binary_accuracy: 0.6727\n",
            "Epoch 641/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6543 - val_loss: 0.6088 - val_binary_accuracy: 0.6727\n",
            "Epoch 642/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6616 - val_loss: 0.6087 - val_binary_accuracy: 0.6731\n",
            "Epoch 643/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6612 - val_loss: 0.6087 - val_binary_accuracy: 0.6731\n",
            "Epoch 644/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6160 - binary_accuracy: 0.6637 - val_loss: 0.6087 - val_binary_accuracy: 0.6731\n",
            "Epoch 645/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6160 - binary_accuracy: 0.6565 - val_loss: 0.6087 - val_binary_accuracy: 0.6735\n",
            "Epoch 646/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6627 - val_loss: 0.6087 - val_binary_accuracy: 0.6735\n",
            "Epoch 647/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6617 - val_loss: 0.6086 - val_binary_accuracy: 0.6735\n",
            "Epoch 648/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6195 - binary_accuracy: 0.6600 - val_loss: 0.6086 - val_binary_accuracy: 0.6735\n",
            "Epoch 649/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6573 - val_loss: 0.6086 - val_binary_accuracy: 0.6735\n",
            "Epoch 650/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6570 - val_loss: 0.6087 - val_binary_accuracy: 0.6735\n",
            "Epoch 651/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6174 - binary_accuracy: 0.6623 - val_loss: 0.6087 - val_binary_accuracy: 0.6735\n",
            "Epoch 652/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6632 - val_loss: 0.6087 - val_binary_accuracy: 0.6731\n",
            "Epoch 653/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6572 - val_loss: 0.6087 - val_binary_accuracy: 0.6735\n",
            "Epoch 654/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6673 - val_loss: 0.6087 - val_binary_accuracy: 0.6739\n",
            "Epoch 655/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6559 - val_loss: 0.6086 - val_binary_accuracy: 0.6731\n",
            "Epoch 656/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6578 - val_loss: 0.6086 - val_binary_accuracy: 0.6735\n",
            "Epoch 657/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6597 - val_loss: 0.6086 - val_binary_accuracy: 0.6735\n",
            "Epoch 658/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6497 - val_loss: 0.6086 - val_binary_accuracy: 0.6731\n",
            "Epoch 659/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6583 - val_loss: 0.6085 - val_binary_accuracy: 0.6735\n",
            "Epoch 660/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6505 - val_loss: 0.6085 - val_binary_accuracy: 0.6739\n",
            "Epoch 661/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6202 - binary_accuracy: 0.6560 - val_loss: 0.6086 - val_binary_accuracy: 0.6739\n",
            "Epoch 662/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6143 - binary_accuracy: 0.6645 - val_loss: 0.6085 - val_binary_accuracy: 0.6743\n",
            "Epoch 663/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6183 - binary_accuracy: 0.6617 - val_loss: 0.6085 - val_binary_accuracy: 0.6747\n",
            "Epoch 664/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6594 - val_loss: 0.6085 - val_binary_accuracy: 0.6743\n",
            "Epoch 665/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6598 - val_loss: 0.6085 - val_binary_accuracy: 0.6747\n",
            "Epoch 666/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6614 - val_loss: 0.6084 - val_binary_accuracy: 0.6747\n",
            "Epoch 667/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6603 - val_loss: 0.6084 - val_binary_accuracy: 0.6739\n",
            "Epoch 668/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6611 - val_loss: 0.6084 - val_binary_accuracy: 0.6743\n",
            "Epoch 669/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6143 - binary_accuracy: 0.6562 - val_loss: 0.6083 - val_binary_accuracy: 0.6743\n",
            "Epoch 670/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6606 - val_loss: 0.6083 - val_binary_accuracy: 0.6739\n",
            "Epoch 671/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6622 - val_loss: 0.6083 - val_binary_accuracy: 0.6747\n",
            "Epoch 672/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6591 - val_loss: 0.6083 - val_binary_accuracy: 0.6739\n",
            "Epoch 673/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6573 - val_loss: 0.6083 - val_binary_accuracy: 0.6739\n",
            "Epoch 674/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6561 - val_loss: 0.6083 - val_binary_accuracy: 0.6739\n",
            "Epoch 675/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6588 - val_loss: 0.6083 - val_binary_accuracy: 0.6752\n",
            "Epoch 676/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6653 - val_loss: 0.6082 - val_binary_accuracy: 0.6747\n",
            "Epoch 677/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6604 - val_loss: 0.6082 - val_binary_accuracy: 0.6747\n",
            "Epoch 678/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6606 - val_loss: 0.6082 - val_binary_accuracy: 0.6747\n",
            "Epoch 679/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.6573 - val_loss: 0.6081 - val_binary_accuracy: 0.6752\n",
            "Epoch 680/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6615 - val_loss: 0.6081 - val_binary_accuracy: 0.6752\n",
            "Epoch 681/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6155 - binary_accuracy: 0.6556 - val_loss: 0.6081 - val_binary_accuracy: 0.6756\n",
            "Epoch 682/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6626 - val_loss: 0.6080 - val_binary_accuracy: 0.6756\n",
            "Epoch 683/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6653 - val_loss: 0.6079 - val_binary_accuracy: 0.6760\n",
            "Epoch 684/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6146 - binary_accuracy: 0.6647 - val_loss: 0.6079 - val_binary_accuracy: 0.6760\n",
            "Epoch 685/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6163 - binary_accuracy: 0.6616 - val_loss: 0.6080 - val_binary_accuracy: 0.6756\n",
            "Epoch 686/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6580 - val_loss: 0.6080 - val_binary_accuracy: 0.6747\n",
            "Epoch 687/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6588 - val_loss: 0.6080 - val_binary_accuracy: 0.6739\n",
            "Epoch 688/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6698 - val_loss: 0.6079 - val_binary_accuracy: 0.6756\n",
            "Epoch 689/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6598 - val_loss: 0.6078 - val_binary_accuracy: 0.6743\n",
            "Epoch 690/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6531 - val_loss: 0.6078 - val_binary_accuracy: 0.6752\n",
            "Epoch 691/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6564 - val_loss: 0.6078 - val_binary_accuracy: 0.6743\n",
            "Epoch 692/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6616 - val_loss: 0.6077 - val_binary_accuracy: 0.6752\n",
            "Epoch 693/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6624 - val_loss: 0.6078 - val_binary_accuracy: 0.6747\n",
            "Epoch 694/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6624 - val_loss: 0.6077 - val_binary_accuracy: 0.6760\n",
            "Epoch 695/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6640 - val_loss: 0.6077 - val_binary_accuracy: 0.6752\n",
            "Epoch 696/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6177 - binary_accuracy: 0.6567 - val_loss: 0.6077 - val_binary_accuracy: 0.6752\n",
            "Epoch 697/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6592 - val_loss: 0.6077 - val_binary_accuracy: 0.6756\n",
            "Epoch 698/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6161 - binary_accuracy: 0.6555 - val_loss: 0.6077 - val_binary_accuracy: 0.6743\n",
            "Epoch 699/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6581 - val_loss: 0.6077 - val_binary_accuracy: 0.6752\n",
            "Epoch 700/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6616 - val_loss: 0.6077 - val_binary_accuracy: 0.6752\n",
            "Epoch 701/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6613 - val_loss: 0.6076 - val_binary_accuracy: 0.6752\n",
            "Epoch 702/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6591 - val_loss: 0.6076 - val_binary_accuracy: 0.6752\n",
            "Epoch 703/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6647 - val_loss: 0.6076 - val_binary_accuracy: 0.6747\n",
            "Epoch 704/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6186 - binary_accuracy: 0.6592 - val_loss: 0.6076 - val_binary_accuracy: 0.6739\n",
            "Epoch 705/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6647 - val_loss: 0.6076 - val_binary_accuracy: 0.6739\n",
            "Epoch 706/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6587 - val_loss: 0.6076 - val_binary_accuracy: 0.6743\n",
            "Epoch 707/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6610 - val_loss: 0.6076 - val_binary_accuracy: 0.6739\n",
            "Epoch 708/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6605 - val_loss: 0.6076 - val_binary_accuracy: 0.6743\n",
            "Epoch 709/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.6599 - val_loss: 0.6076 - val_binary_accuracy: 0.6747\n",
            "Epoch 710/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6586 - val_loss: 0.6076 - val_binary_accuracy: 0.6752\n",
            "Epoch 711/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6649 - val_loss: 0.6076 - val_binary_accuracy: 0.6743\n",
            "Epoch 712/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6616 - val_loss: 0.6076 - val_binary_accuracy: 0.6752\n",
            "Epoch 713/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6653 - val_loss: 0.6076 - val_binary_accuracy: 0.6747\n",
            "Epoch 714/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6627 - val_loss: 0.6075 - val_binary_accuracy: 0.6747\n",
            "Epoch 715/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6626 - val_loss: 0.6075 - val_binary_accuracy: 0.6747\n",
            "Epoch 716/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6629 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 717/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6624 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 718/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6581 - val_loss: 0.6075 - val_binary_accuracy: 0.6739\n",
            "Epoch 719/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6165 - binary_accuracy: 0.6616 - val_loss: 0.6076 - val_binary_accuracy: 0.6739\n",
            "Epoch 720/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6622 - val_loss: 0.6075 - val_binary_accuracy: 0.6735\n",
            "Epoch 721/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6660 - val_loss: 0.6075 - val_binary_accuracy: 0.6739\n",
            "Epoch 722/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6608 - val_loss: 0.6075 - val_binary_accuracy: 0.6739\n",
            "Epoch 723/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6638 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 724/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6600 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 725/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6577 - val_loss: 0.6075 - val_binary_accuracy: 0.6739\n",
            "Epoch 726/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6612 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 727/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6569 - val_loss: 0.6075 - val_binary_accuracy: 0.6743\n",
            "Epoch 728/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6617 - val_loss: 0.6075 - val_binary_accuracy: 0.6739\n",
            "Epoch 729/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6647 - val_loss: 0.6074 - val_binary_accuracy: 0.6743\n",
            "Epoch 730/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6631 - val_loss: 0.6074 - val_binary_accuracy: 0.6739\n",
            "Epoch 731/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6617 - val_loss: 0.6074 - val_binary_accuracy: 0.6743\n",
            "Epoch 732/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6630 - val_loss: 0.6073 - val_binary_accuracy: 0.6739\n",
            "Epoch 733/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6640 - val_loss: 0.6073 - val_binary_accuracy: 0.6747\n",
            "Epoch 734/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6616 - val_loss: 0.6072 - val_binary_accuracy: 0.6743\n",
            "Epoch 735/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6607 - val_loss: 0.6073 - val_binary_accuracy: 0.6739\n",
            "Epoch 736/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6612 - val_loss: 0.6072 - val_binary_accuracy: 0.6739\n",
            "Epoch 737/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6617 - val_loss: 0.6072 - val_binary_accuracy: 0.6739\n",
            "Epoch 738/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6666 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 739/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6166 - binary_accuracy: 0.6603 - val_loss: 0.6072 - val_binary_accuracy: 0.6735\n",
            "Epoch 740/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6591 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 741/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6635 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 742/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6591 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 743/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6621 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 744/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6632 - val_loss: 0.6071 - val_binary_accuracy: 0.6731\n",
            "Epoch 745/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6660 - val_loss: 0.6071 - val_binary_accuracy: 0.6731\n",
            "Epoch 746/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6666 - val_loss: 0.6071 - val_binary_accuracy: 0.6739\n",
            "Epoch 747/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6608 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 748/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6606 - val_loss: 0.6071 - val_binary_accuracy: 0.6735\n",
            "Epoch 749/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6615 - val_loss: 0.6071 - val_binary_accuracy: 0.6739\n",
            "Epoch 750/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6651 - val_loss: 0.6071 - val_binary_accuracy: 0.6743\n",
            "Epoch 751/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6649 - val_loss: 0.6070 - val_binary_accuracy: 0.6743\n",
            "Epoch 752/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6604 - val_loss: 0.6070 - val_binary_accuracy: 0.6743\n",
            "Epoch 753/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6616 - val_loss: 0.6070 - val_binary_accuracy: 0.6735\n",
            "Epoch 754/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6625 - val_loss: 0.6070 - val_binary_accuracy: 0.6735\n",
            "Epoch 755/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6656 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 756/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6618 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 757/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6604 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 758/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6592 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 759/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6163 - binary_accuracy: 0.6561 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 760/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6638 - val_loss: 0.6070 - val_binary_accuracy: 0.6739\n",
            "Epoch 761/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6682 - val_loss: 0.6069 - val_binary_accuracy: 0.6735\n",
            "Epoch 762/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6650 - val_loss: 0.6069 - val_binary_accuracy: 0.6735\n",
            "Epoch 763/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6146 - binary_accuracy: 0.6565 - val_loss: 0.6069 - val_binary_accuracy: 0.6735\n",
            "Epoch 764/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6652 - val_loss: 0.6068 - val_binary_accuracy: 0.6735\n",
            "Epoch 765/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6651 - val_loss: 0.6068 - val_binary_accuracy: 0.6735\n",
            "Epoch 766/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6656 - val_loss: 0.6068 - val_binary_accuracy: 0.6735\n",
            "Epoch 767/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6658 - val_loss: 0.6068 - val_binary_accuracy: 0.6735\n",
            "Epoch 768/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6596 - val_loss: 0.6068 - val_binary_accuracy: 0.6735\n",
            "Epoch 769/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6588 - val_loss: 0.6067 - val_binary_accuracy: 0.6735\n",
            "Epoch 770/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6595 - val_loss: 0.6067 - val_binary_accuracy: 0.6735\n",
            "Epoch 771/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6642 - val_loss: 0.6067 - val_binary_accuracy: 0.6739\n",
            "Epoch 772/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6620 - val_loss: 0.6067 - val_binary_accuracy: 0.6739\n",
            "Epoch 773/2000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6657 - val_loss: 0.6066 - val_binary_accuracy: 0.6739\n",
            "Epoch 774/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6698 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 775/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6626 - val_loss: 0.6066 - val_binary_accuracy: 0.6739\n",
            "Epoch 776/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6652 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 777/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.6703 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 778/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6651 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 779/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6622 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 780/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6669 - val_loss: 0.6065 - val_binary_accuracy: 0.6743\n",
            "Epoch 781/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6603 - val_loss: 0.6065 - val_binary_accuracy: 0.6743\n",
            "Epoch 782/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6608 - val_loss: 0.6065 - val_binary_accuracy: 0.6743\n",
            "Epoch 783/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6608 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 784/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6622 - val_loss: 0.6066 - val_binary_accuracy: 0.6739\n",
            "Epoch 785/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6656 - val_loss: 0.6066 - val_binary_accuracy: 0.6747\n",
            "Epoch 786/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6643 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 787/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6647 - val_loss: 0.6066 - val_binary_accuracy: 0.6752\n",
            "Epoch 788/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6664 - val_loss: 0.6066 - val_binary_accuracy: 0.6747\n",
            "Epoch 789/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6643 - val_loss: 0.6066 - val_binary_accuracy: 0.6752\n",
            "Epoch 790/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6631 - val_loss: 0.6066 - val_binary_accuracy: 0.6752\n",
            "Epoch 791/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6655 - val_loss: 0.6066 - val_binary_accuracy: 0.6752\n",
            "Epoch 792/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6582 - val_loss: 0.6066 - val_binary_accuracy: 0.6752\n",
            "Epoch 793/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6624 - val_loss: 0.6066 - val_binary_accuracy: 0.6747\n",
            "Epoch 794/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6626 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 795/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6643 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 796/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6651 - val_loss: 0.6066 - val_binary_accuracy: 0.6743\n",
            "Epoch 797/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6662 - val_loss: 0.6065 - val_binary_accuracy: 0.6743\n",
            "Epoch 798/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6620 - val_loss: 0.6065 - val_binary_accuracy: 0.6743\n",
            "Epoch 799/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6719 - val_loss: 0.6065 - val_binary_accuracy: 0.6739\n",
            "Epoch 800/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6603 - val_loss: 0.6064 - val_binary_accuracy: 0.6743\n",
            "Epoch 801/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6621 - val_loss: 0.6064 - val_binary_accuracy: 0.6739\n",
            "Epoch 802/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6642 - val_loss: 0.6063 - val_binary_accuracy: 0.6743\n",
            "Epoch 803/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6625 - val_loss: 0.6063 - val_binary_accuracy: 0.6739\n",
            "Epoch 804/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6674 - val_loss: 0.6063 - val_binary_accuracy: 0.6739\n",
            "Epoch 805/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6632 - val_loss: 0.6063 - val_binary_accuracy: 0.6739\n",
            "Epoch 806/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6654 - val_loss: 0.6063 - val_binary_accuracy: 0.6747\n",
            "Epoch 807/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6642 - val_loss: 0.6063 - val_binary_accuracy: 0.6743\n",
            "Epoch 808/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6635 - val_loss: 0.6062 - val_binary_accuracy: 0.6747\n",
            "Epoch 809/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6622 - val_loss: 0.6062 - val_binary_accuracy: 0.6752\n",
            "Epoch 810/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6665 - val_loss: 0.6062 - val_binary_accuracy: 0.6752\n",
            "Epoch 811/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6675 - val_loss: 0.6062 - val_binary_accuracy: 0.6752\n",
            "Epoch 812/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6660 - val_loss: 0.6062 - val_binary_accuracy: 0.6752\n",
            "Epoch 813/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6112 - binary_accuracy: 0.6627 - val_loss: 0.6062 - val_binary_accuracy: 0.6747\n",
            "Epoch 814/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6631 - val_loss: 0.6062 - val_binary_accuracy: 0.6743\n",
            "Epoch 815/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6694 - val_loss: 0.6061 - val_binary_accuracy: 0.6739\n",
            "Epoch 816/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6612 - val_loss: 0.6062 - val_binary_accuracy: 0.6747\n",
            "Epoch 817/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6667 - val_loss: 0.6062 - val_binary_accuracy: 0.6739\n",
            "Epoch 818/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6652 - val_loss: 0.6062 - val_binary_accuracy: 0.6747\n",
            "Epoch 819/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6698 - val_loss: 0.6062 - val_binary_accuracy: 0.6743\n",
            "Epoch 820/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6699 - val_loss: 0.6062 - val_binary_accuracy: 0.6747\n",
            "Epoch 821/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6649 - val_loss: 0.6061 - val_binary_accuracy: 0.6747\n",
            "Epoch 822/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6634 - val_loss: 0.6061 - val_binary_accuracy: 0.6743\n",
            "Epoch 823/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6680 - val_loss: 0.6061 - val_binary_accuracy: 0.6747\n",
            "Epoch 824/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6666 - val_loss: 0.6061 - val_binary_accuracy: 0.6756\n",
            "Epoch 825/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6648 - val_loss: 0.6061 - val_binary_accuracy: 0.6756\n",
            "Epoch 826/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6629 - val_loss: 0.6061 - val_binary_accuracy: 0.6756\n",
            "Epoch 827/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6649 - val_loss: 0.6061 - val_binary_accuracy: 0.6756\n",
            "Epoch 828/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6699 - val_loss: 0.6061 - val_binary_accuracy: 0.6752\n",
            "Epoch 829/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6662 - val_loss: 0.6060 - val_binary_accuracy: 0.6760\n",
            "Epoch 830/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6711 - val_loss: 0.6060 - val_binary_accuracy: 0.6756\n",
            "Epoch 831/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6655 - val_loss: 0.6060 - val_binary_accuracy: 0.6760\n",
            "Epoch 832/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6625 - val_loss: 0.6060 - val_binary_accuracy: 0.6760\n",
            "Epoch 833/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6640 - val_loss: 0.6060 - val_binary_accuracy: 0.6764\n",
            "Epoch 834/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6665 - val_loss: 0.6060 - val_binary_accuracy: 0.6756\n",
            "Epoch 835/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6664 - val_loss: 0.6060 - val_binary_accuracy: 0.6752\n",
            "Epoch 836/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6719 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 837/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6628 - val_loss: 0.6059 - val_binary_accuracy: 0.6752\n",
            "Epoch 838/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6671 - val_loss: 0.6060 - val_binary_accuracy: 0.6752\n",
            "Epoch 839/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6629 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 840/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6658 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 841/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6677 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 842/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6656 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 843/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6737 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 844/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6592 - val_loss: 0.6059 - val_binary_accuracy: 0.6760\n",
            "Epoch 845/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6667 - val_loss: 0.6059 - val_binary_accuracy: 0.6760\n",
            "Epoch 846/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6691 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 847/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6685 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 848/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6651 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 849/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6661 - val_loss: 0.6059 - val_binary_accuracy: 0.6752\n",
            "Epoch 850/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6614 - val_loss: 0.6059 - val_binary_accuracy: 0.6752\n",
            "Epoch 851/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6629 - val_loss: 0.6059 - val_binary_accuracy: 0.6747\n",
            "Epoch 852/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6645 - val_loss: 0.6059 - val_binary_accuracy: 0.6747\n",
            "Epoch 853/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6640 - val_loss: 0.6058 - val_binary_accuracy: 0.6752\n",
            "Epoch 854/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6651 - val_loss: 0.6058 - val_binary_accuracy: 0.6752\n",
            "Epoch 855/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6694 - val_loss: 0.6057 - val_binary_accuracy: 0.6747\n",
            "Epoch 856/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6686 - val_loss: 0.6057 - val_binary_accuracy: 0.6743\n",
            "Epoch 857/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6663 - val_loss: 0.6057 - val_binary_accuracy: 0.6735\n",
            "Epoch 858/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6650 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 859/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6690 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 860/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6658 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 861/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6636 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 862/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6673 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 863/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6612 - val_loss: 0.6058 - val_binary_accuracy: 0.6731\n",
            "Epoch 864/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6678 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 865/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6668 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 866/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6625 - val_loss: 0.6058 - val_binary_accuracy: 0.6731\n",
            "Epoch 867/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6683 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 868/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6676 - val_loss: 0.6058 - val_binary_accuracy: 0.6735\n",
            "Epoch 869/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6656 - val_loss: 0.6058 - val_binary_accuracy: 0.6739\n",
            "Epoch 870/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6644 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 871/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6650 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 872/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6668 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 873/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6699 - val_loss: 0.6057 - val_binary_accuracy: 0.6739\n",
            "Epoch 874/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6672 - val_loss: 0.6056 - val_binary_accuracy: 0.6731\n",
            "Epoch 875/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6651 - val_loss: 0.6056 - val_binary_accuracy: 0.6731\n",
            "Epoch 876/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6633 - val_loss: 0.6056 - val_binary_accuracy: 0.6731\n",
            "Epoch 877/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6618 - val_loss: 0.6056 - val_binary_accuracy: 0.6731\n",
            "Epoch 878/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6663 - val_loss: 0.6056 - val_binary_accuracy: 0.6739\n",
            "Epoch 879/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6684 - val_loss: 0.6056 - val_binary_accuracy: 0.6735\n",
            "Epoch 880/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6731 - val_loss: 0.6056 - val_binary_accuracy: 0.6739\n",
            "Epoch 881/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6679 - val_loss: 0.6055 - val_binary_accuracy: 0.6739\n",
            "Epoch 882/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6671 - val_loss: 0.6055 - val_binary_accuracy: 0.6735\n",
            "Epoch 883/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6677 - val_loss: 0.6055 - val_binary_accuracy: 0.6747\n",
            "Epoch 884/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6617 - val_loss: 0.6055 - val_binary_accuracy: 0.6743\n",
            "Epoch 885/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6736 - val_loss: 0.6055 - val_binary_accuracy: 0.6747\n",
            "Epoch 886/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6630 - val_loss: 0.6055 - val_binary_accuracy: 0.6739\n",
            "Epoch 887/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6678 - val_loss: 0.6055 - val_binary_accuracy: 0.6743\n",
            "Epoch 888/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6661 - val_loss: 0.6055 - val_binary_accuracy: 0.6743\n",
            "Epoch 889/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6636 - val_loss: 0.6055 - val_binary_accuracy: 0.6747\n",
            "Epoch 890/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6673 - val_loss: 0.6055 - val_binary_accuracy: 0.6756\n",
            "Epoch 891/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6694 - val_loss: 0.6054 - val_binary_accuracy: 0.6752\n",
            "Epoch 892/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6638 - val_loss: 0.6054 - val_binary_accuracy: 0.6752\n",
            "Epoch 893/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6676 - val_loss: 0.6054 - val_binary_accuracy: 0.6752\n",
            "Epoch 894/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6681 - val_loss: 0.6054 - val_binary_accuracy: 0.6752\n",
            "Epoch 895/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6667 - val_loss: 0.6053 - val_binary_accuracy: 0.6756\n",
            "Epoch 896/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6677 - val_loss: 0.6054 - val_binary_accuracy: 0.6756\n",
            "Epoch 897/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6682 - val_loss: 0.6054 - val_binary_accuracy: 0.6752\n",
            "Epoch 898/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6664 - val_loss: 0.6054 - val_binary_accuracy: 0.6760\n",
            "Epoch 899/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6583 - val_loss: 0.6055 - val_binary_accuracy: 0.6760\n",
            "Epoch 900/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6707 - val_loss: 0.6054 - val_binary_accuracy: 0.6760\n",
            "Epoch 901/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6685 - val_loss: 0.6054 - val_binary_accuracy: 0.6756\n",
            "Epoch 902/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6600 - val_loss: 0.6054 - val_binary_accuracy: 0.6760\n",
            "Epoch 903/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6682 - val_loss: 0.6054 - val_binary_accuracy: 0.6756\n",
            "Epoch 904/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6654 - val_loss: 0.6054 - val_binary_accuracy: 0.6760\n",
            "Epoch 905/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6661 - val_loss: 0.6054 - val_binary_accuracy: 0.6760\n",
            "Epoch 906/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6638 - val_loss: 0.6054 - val_binary_accuracy: 0.6756\n",
            "Epoch 907/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6697 - val_loss: 0.6053 - val_binary_accuracy: 0.6756\n",
            "Epoch 908/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6697 - val_loss: 0.6053 - val_binary_accuracy: 0.6756\n",
            "Epoch 909/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6688 - val_loss: 0.6052 - val_binary_accuracy: 0.6756\n",
            "Epoch 910/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6700 - val_loss: 0.6052 - val_binary_accuracy: 0.6756\n",
            "Epoch 911/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6688 - val_loss: 0.6053 - val_binary_accuracy: 0.6752\n",
            "Epoch 912/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6711 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 913/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6648 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 914/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6670 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 915/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6659 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 916/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6655 - val_loss: 0.6052 - val_binary_accuracy: 0.6756\n",
            "Epoch 917/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6688 - val_loss: 0.6052 - val_binary_accuracy: 0.6756\n",
            "Epoch 918/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6698 - val_loss: 0.6052 - val_binary_accuracy: 0.6747\n",
            "Epoch 919/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6654 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 920/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6677 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 921/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6719 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 922/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6677 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 923/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6669 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 924/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6712 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 925/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6667 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 926/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6652 - val_loss: 0.6052 - val_binary_accuracy: 0.6747\n",
            "Epoch 927/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6689 - val_loss: 0.6052 - val_binary_accuracy: 0.6747\n",
            "Epoch 928/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6673 - val_loss: 0.6051 - val_binary_accuracy: 0.6747\n",
            "Epoch 929/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6672 - val_loss: 0.6051 - val_binary_accuracy: 0.6747\n",
            "Epoch 930/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6661 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 931/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6668 - val_loss: 0.6052 - val_binary_accuracy: 0.6747\n",
            "Epoch 932/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6706 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 933/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6725 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 934/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6631 - val_loss: 0.6052 - val_binary_accuracy: 0.6752\n",
            "Epoch 935/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6665 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 936/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6666 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 937/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6752 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 938/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6688 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 939/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6739 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 940/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6687 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 941/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6681 - val_loss: 0.6051 - val_binary_accuracy: 0.6756\n",
            "Epoch 942/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6681 - val_loss: 0.6051 - val_binary_accuracy: 0.6756\n",
            "Epoch 943/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6642 - val_loss: 0.6051 - val_binary_accuracy: 0.6760\n",
            "Epoch 944/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6699 - val_loss: 0.6051 - val_binary_accuracy: 0.6756\n",
            "Epoch 945/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6647 - val_loss: 0.6051 - val_binary_accuracy: 0.6756\n",
            "Epoch 946/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6731 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 947/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6668 - val_loss: 0.6051 - val_binary_accuracy: 0.6752\n",
            "Epoch 948/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6681 - val_loss: 0.6050 - val_binary_accuracy: 0.6760\n",
            "Epoch 949/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6694 - val_loss: 0.6050 - val_binary_accuracy: 0.6747\n",
            "Epoch 950/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6665 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 951/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6664 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 952/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6726 - val_loss: 0.6050 - val_binary_accuracy: 0.6747\n",
            "Epoch 953/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6697 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 954/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6677 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 955/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6649 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 956/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6660 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 957/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6745 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 958/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6719 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 959/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6704 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 960/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6689 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 961/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6739 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 962/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6644 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 963/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6661 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 964/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6671 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 965/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6768 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 966/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6677 - val_loss: 0.6050 - val_binary_accuracy: 0.6739\n",
            "Epoch 967/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6715 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 968/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6719 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 969/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6683 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 970/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6740 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 971/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6713 - val_loss: 0.6050 - val_binary_accuracy: 0.6743\n",
            "Epoch 972/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6713 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 973/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6724 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 974/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6711 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 975/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6685 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 976/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6701 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 977/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6708 - val_loss: 0.6049 - val_binary_accuracy: 0.6743\n",
            "Epoch 978/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6740 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 979/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6674 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 980/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6723 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 981/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6710 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 982/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6642 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 983/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6728 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 984/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6751 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 985/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6695 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 986/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6702 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 987/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6696 - val_loss: 0.6047 - val_binary_accuracy: 0.6739\n",
            "Epoch 988/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6709 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 989/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6728 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 990/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6690 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 991/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6728 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 992/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6638 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 993/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6650 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 994/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6709 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 995/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6646 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 996/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6714 - val_loss: 0.6048 - val_binary_accuracy: 0.6743\n",
            "Epoch 997/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6677 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 998/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6650 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 999/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6708 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 1000/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6738 - val_loss: 0.6048 - val_binary_accuracy: 0.6739\n",
            "Epoch 1001/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6737 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 1002/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6657 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 1003/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6679 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 1004/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6722 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 1005/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6668 - val_loss: 0.6048 - val_binary_accuracy: 0.6735\n",
            "Epoch 1006/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6703 - val_loss: 0.6049 - val_binary_accuracy: 0.6735\n",
            "Epoch 1007/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6711 - val_loss: 0.6049 - val_binary_accuracy: 0.6731\n",
            "Epoch 1008/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6712 - val_loss: 0.6049 - val_binary_accuracy: 0.6731\n",
            "Epoch 1009/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6663 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1010/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6758 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1011/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6706 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1012/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6077 - binary_accuracy: 0.6719 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1013/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6682 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1014/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6702 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1015/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6741 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1016/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6695 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1017/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6678 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1018/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6728 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1019/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6668 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1020/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6740 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1021/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6711 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1022/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6734 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1023/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6671 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1024/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6737 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1025/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6694 - val_loss: 0.6048 - val_binary_accuracy: 0.6727\n",
            "Epoch 1026/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6723 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1027/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6679 - val_loss: 0.6048 - val_binary_accuracy: 0.6731\n",
            "Epoch 1028/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6726 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1029/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6672 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1030/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6668 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1031/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6701 - val_loss: 0.6048 - val_binary_accuracy: 0.6727\n",
            "Epoch 1032/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6714 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1033/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6719 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1034/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6666 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1035/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6676 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1036/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6699 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1037/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6698 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1038/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6711 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1039/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6793 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1040/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6730 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1041/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6745 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1042/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6651 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1043/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6714 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1044/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6717 - val_loss: 0.6047 - val_binary_accuracy: 0.6722\n",
            "Epoch 1045/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6687 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1046/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6696 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1047/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6722 - val_loss: 0.6047 - val_binary_accuracy: 0.6722\n",
            "Epoch 1048/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6680 - val_loss: 0.6047 - val_binary_accuracy: 0.6722\n",
            "Epoch 1049/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6716 - val_loss: 0.6047 - val_binary_accuracy: 0.6727\n",
            "Epoch 1050/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6721 - val_loss: 0.6046 - val_binary_accuracy: 0.6722\n",
            "Epoch 1051/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6749 - val_loss: 0.6046 - val_binary_accuracy: 0.6727\n",
            "Epoch 1052/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6714 - val_loss: 0.6046 - val_binary_accuracy: 0.6727\n",
            "Epoch 1053/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6715 - val_loss: 0.6046 - val_binary_accuracy: 0.6722\n",
            "Epoch 1054/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6725 - val_loss: 0.6047 - val_binary_accuracy: 0.6731\n",
            "Epoch 1055/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6668 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1056/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6663 - val_loss: 0.6047 - val_binary_accuracy: 0.6739\n",
            "Epoch 1057/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6717 - val_loss: 0.6047 - val_binary_accuracy: 0.6739\n",
            "Epoch 1058/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6735 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1059/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6744 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1060/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6697 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1061/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6732 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1062/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6749 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1063/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6711 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1064/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6763 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1065/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6710 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1066/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6712 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1067/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6039 - binary_accuracy: 0.6735 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1068/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6714 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1069/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6698 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1070/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6722 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1071/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6619 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1072/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6678 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1073/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6728 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1074/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6684 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1075/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6042 - binary_accuracy: 0.6744 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1076/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6687 - val_loss: 0.6047 - val_binary_accuracy: 0.6735\n",
            "Epoch 1077/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6765 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1078/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6717 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1079/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6731 - val_loss: 0.6046 - val_binary_accuracy: 0.6735\n",
            "Epoch 1080/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6759 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1081/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6691 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1082/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6688 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1083/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6695 - val_loss: 0.6046 - val_binary_accuracy: 0.6739\n",
            "Epoch 1084/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6680 - val_loss: 0.6045 - val_binary_accuracy: 0.6739\n",
            "Epoch 1085/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6743 - val_loss: 0.6045 - val_binary_accuracy: 0.6739\n",
            "Epoch 1086/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6711 - val_loss: 0.6045 - val_binary_accuracy: 0.6739\n",
            "Epoch 1087/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6734 - val_loss: 0.6045 - val_binary_accuracy: 0.6735\n",
            "Epoch 1088/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6698 - val_loss: 0.6045 - val_binary_accuracy: 0.6735\n",
            "Epoch 1089/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6713 - val_loss: 0.6045 - val_binary_accuracy: 0.6735\n",
            "Epoch 1090/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6665 - val_loss: 0.6045 - val_binary_accuracy: 0.6743\n",
            "Epoch 1091/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6764 - val_loss: 0.6045 - val_binary_accuracy: 0.6735\n",
            "Epoch 1092/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6744 - val_loss: 0.6044 - val_binary_accuracy: 0.6743\n",
            "Epoch 1093/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6693 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1094/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6715 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1095/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6735 - val_loss: 0.6044 - val_binary_accuracy: 0.6735\n",
            "Epoch 1096/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6707 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1097/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6734 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1098/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6712 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1099/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6729 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1100/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6713 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1101/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6704 - val_loss: 0.6044 - val_binary_accuracy: 0.6743\n",
            "Epoch 1102/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6717 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1103/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6743 - val_loss: 0.6044 - val_binary_accuracy: 0.6743\n",
            "Epoch 1104/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6712 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1105/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6723 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1106/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6719 - val_loss: 0.6044 - val_binary_accuracy: 0.6739\n",
            "Epoch 1107/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6744 - val_loss: 0.6044 - val_binary_accuracy: 0.6735\n",
            "Epoch 1108/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6041 - binary_accuracy: 0.6707 - val_loss: 0.6044 - val_binary_accuracy: 0.6735\n",
            "Epoch 1109/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6752 - val_loss: 0.6044 - val_binary_accuracy: 0.6731\n",
            "Epoch 1110/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6831 - val_loss: 0.6043 - val_binary_accuracy: 0.6735\n",
            "Epoch 1111/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6745 - val_loss: 0.6043 - val_binary_accuracy: 0.6735\n",
            "Epoch 1112/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6749 - val_loss: 0.6043 - val_binary_accuracy: 0.6731\n",
            "Epoch 1113/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6718 - val_loss: 0.6042 - val_binary_accuracy: 0.6735\n",
            "Epoch 1114/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6794 - val_loss: 0.6042 - val_binary_accuracy: 0.6743\n",
            "Epoch 1115/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6686 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1116/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6671 - val_loss: 0.6042 - val_binary_accuracy: 0.6739\n",
            "Epoch 1117/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6740 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1118/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6699 - val_loss: 0.6042 - val_binary_accuracy: 0.6752\n",
            "Epoch 1119/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6734 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1120/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6693 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1121/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6693 - val_loss: 0.6042 - val_binary_accuracy: 0.6739\n",
            "Epoch 1122/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6060 - binary_accuracy: 0.6709 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1123/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6763 - val_loss: 0.6042 - val_binary_accuracy: 0.6739\n",
            "Epoch 1124/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6744 - val_loss: 0.6042 - val_binary_accuracy: 0.6743\n",
            "Epoch 1125/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6711 - val_loss: 0.6042 - val_binary_accuracy: 0.6739\n",
            "Epoch 1126/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6033 - binary_accuracy: 0.6773 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1127/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6700 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1128/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6716 - val_loss: 0.6042 - val_binary_accuracy: 0.6747\n",
            "Epoch 1129/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6785 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1130/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6702 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1131/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6757 - val_loss: 0.6041 - val_binary_accuracy: 0.6743\n",
            "Epoch 1132/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6770 - val_loss: 0.6041 - val_binary_accuracy: 0.6743\n",
            "Epoch 1133/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6737 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1134/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6717 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1135/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6738 - val_loss: 0.6041 - val_binary_accuracy: 0.6743\n",
            "Epoch 1136/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6764 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1137/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6721 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1138/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6741 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1139/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6737 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1140/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6697 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1141/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6747 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1142/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6737 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1143/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6784 - val_loss: 0.6041 - val_binary_accuracy: 0.6764\n",
            "Epoch 1144/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6697 - val_loss: 0.6041 - val_binary_accuracy: 0.6764\n",
            "Epoch 1145/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6715 - val_loss: 0.6041 - val_binary_accuracy: 0.6760\n",
            "Epoch 1146/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6719 - val_loss: 0.6041 - val_binary_accuracy: 0.6760\n",
            "Epoch 1147/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6783 - val_loss: 0.6041 - val_binary_accuracy: 0.6760\n",
            "Epoch 1148/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6714 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1149/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6679 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1150/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6775 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1151/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6741 - val_loss: 0.6041 - val_binary_accuracy: 0.6764\n",
            "Epoch 1152/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6709 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1153/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6742 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1154/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6712 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1155/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6718 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 1156/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6017 - binary_accuracy: 0.6732 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1157/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6719 - val_loss: 0.6041 - val_binary_accuracy: 0.6743\n",
            "Epoch 1158/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6703 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1159/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6788 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1160/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6771 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1161/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6754 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1162/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6739 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 1163/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6745 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1164/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6728 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1165/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6704 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1166/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6715 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1167/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6727 - val_loss: 0.6041 - val_binary_accuracy: 0.6747\n",
            "Epoch 1168/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6761 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1169/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6720 - val_loss: 0.6040 - val_binary_accuracy: 0.6747\n",
            "Epoch 1170/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6764 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1171/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6719 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1172/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6768 - val_loss: 0.6040 - val_binary_accuracy: 0.6747\n",
            "Epoch 1173/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6764 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1174/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6683 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1175/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6765 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1176/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6728 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1177/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6729 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1178/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6762 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1179/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6771 - val_loss: 0.6040 - val_binary_accuracy: 0.6743\n",
            "Epoch 1180/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6768 - val_loss: 0.6040 - val_binary_accuracy: 0.6743\n",
            "Epoch 1181/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6708 - val_loss: 0.6040 - val_binary_accuracy: 0.6743\n",
            "Epoch 1182/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6785 - val_loss: 0.6040 - val_binary_accuracy: 0.6739\n",
            "Epoch 1183/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6756 - val_loss: 0.6040 - val_binary_accuracy: 0.6735\n",
            "Epoch 1184/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6788 - val_loss: 0.6040 - val_binary_accuracy: 0.6739\n",
            "Epoch 1185/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6706 - val_loss: 0.6040 - val_binary_accuracy: 0.6735\n",
            "Epoch 1186/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6728 - val_loss: 0.6039 - val_binary_accuracy: 0.6739\n",
            "Epoch 1187/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6738 - val_loss: 0.6039 - val_binary_accuracy: 0.6739\n",
            "Epoch 1188/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6766 - val_loss: 0.6040 - val_binary_accuracy: 0.6735\n",
            "Epoch 1189/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6759 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1190/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6712 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1191/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6747 - val_loss: 0.6039 - val_binary_accuracy: 0.6743\n",
            "Epoch 1192/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6730 - val_loss: 0.6040 - val_binary_accuracy: 0.6743\n",
            "Epoch 1193/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6741 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 1194/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6765 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 1195/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6737 - val_loss: 0.6039 - val_binary_accuracy: 0.6756\n",
            "Epoch 1196/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6773 - val_loss: 0.6039 - val_binary_accuracy: 0.6752\n",
            "Epoch 1197/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6754 - val_loss: 0.6039 - val_binary_accuracy: 0.6756\n",
            "Epoch 1198/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6752 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 1199/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6752 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 1200/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6754 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1201/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6762 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 1202/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6733 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 1203/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6747 - val_loss: 0.6038 - val_binary_accuracy: 0.6764\n",
            "Epoch 1204/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6746 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1205/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6785 - val_loss: 0.6038 - val_binary_accuracy: 0.6764\n",
            "Epoch 1206/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6678 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1207/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6766 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1208/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6726 - val_loss: 0.6038 - val_binary_accuracy: 0.6764\n",
            "Epoch 1209/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6721 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1210/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6732 - val_loss: 0.6038 - val_binary_accuracy: 0.6764\n",
            "Epoch 1211/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6699 - val_loss: 0.6038 - val_binary_accuracy: 0.6764\n",
            "Epoch 1212/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6771 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1213/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6023 - binary_accuracy: 0.6803 - val_loss: 0.6038 - val_binary_accuracy: 0.6768\n",
            "Epoch 1214/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6737 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1215/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6751 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1216/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6745 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1217/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6796 - val_loss: 0.6038 - val_binary_accuracy: 0.6752\n",
            "Epoch 1218/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6761 - val_loss: 0.6038 - val_binary_accuracy: 0.6752\n",
            "Epoch 1219/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6745 - val_loss: 0.6037 - val_binary_accuracy: 0.6747\n",
            "Epoch 1220/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6738 - val_loss: 0.6037 - val_binary_accuracy: 0.6747\n",
            "Epoch 1221/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6740 - val_loss: 0.6037 - val_binary_accuracy: 0.6747\n",
            "Epoch 1222/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6759 - val_loss: 0.6037 - val_binary_accuracy: 0.6747\n",
            "Epoch 1223/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6738 - val_loss: 0.6037 - val_binary_accuracy: 0.6752\n",
            "Epoch 1224/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6708 - val_loss: 0.6037 - val_binary_accuracy: 0.6752\n",
            "Epoch 1225/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6755 - val_loss: 0.6037 - val_binary_accuracy: 0.6756\n",
            "Epoch 1226/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6765 - val_loss: 0.6037 - val_binary_accuracy: 0.6756\n",
            "Epoch 1227/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6752 - val_loss: 0.6036 - val_binary_accuracy: 0.6756\n",
            "Epoch 1228/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6723 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1229/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6706 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1230/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6735 - val_loss: 0.6038 - val_binary_accuracy: 0.6760\n",
            "Epoch 1231/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6705 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1232/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6737 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1233/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6716 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1234/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6729 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1235/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6760 - val_loss: 0.6037 - val_binary_accuracy: 0.6772\n",
            "Epoch 1236/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6755 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1237/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6765 - val_loss: 0.6037 - val_binary_accuracy: 0.6760\n",
            "Epoch 1238/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6711 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1239/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6028 - binary_accuracy: 0.6717 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1240/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6766 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1241/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6804 - val_loss: 0.6038 - val_binary_accuracy: 0.6768\n",
            "Epoch 1242/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6733 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1243/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6740 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1244/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6730 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1245/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6788 - val_loss: 0.6037 - val_binary_accuracy: 0.6772\n",
            "Epoch 1246/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6777 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1247/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6742 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1248/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6754 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1249/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6740 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1250/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6703 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1251/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6742 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1252/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6762 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1253/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6023 - binary_accuracy: 0.6760 - val_loss: 0.6037 - val_binary_accuracy: 0.6772\n",
            "Epoch 1254/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6720 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1255/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6732 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1256/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6703 - val_loss: 0.6037 - val_binary_accuracy: 0.6772\n",
            "Epoch 1257/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6044 - binary_accuracy: 0.6742 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1258/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6757 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1259/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6726 - val_loss: 0.6037 - val_binary_accuracy: 0.6764\n",
            "Epoch 1260/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6737 - val_loss: 0.6037 - val_binary_accuracy: 0.6768\n",
            "Epoch 1261/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6746 - val_loss: 0.6036 - val_binary_accuracy: 0.6768\n",
            "Epoch 1262/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6677 - val_loss: 0.6036 - val_binary_accuracy: 0.6760\n",
            "Epoch 1263/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6718 - val_loss: 0.6036 - val_binary_accuracy: 0.6760\n",
            "Epoch 1264/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6761 - val_loss: 0.6036 - val_binary_accuracy: 0.6768\n",
            "Epoch 1265/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6739 - val_loss: 0.6036 - val_binary_accuracy: 0.6768\n",
            "Epoch 1266/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6757 - val_loss: 0.6036 - val_binary_accuracy: 0.6764\n",
            "Epoch 1267/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6727 - val_loss: 0.6035 - val_binary_accuracy: 0.6764\n",
            "Epoch 1268/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6765 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1269/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6755 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1270/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6745 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1271/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6759 - val_loss: 0.6035 - val_binary_accuracy: 0.6768\n",
            "Epoch 1272/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6774 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1273/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6780 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1274/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5987 - binary_accuracy: 0.6797 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1275/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6712 - val_loss: 0.6034 - val_binary_accuracy: 0.6772\n",
            "Epoch 1276/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6763 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1277/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6776 - val_loss: 0.6034 - val_binary_accuracy: 0.6772\n",
            "Epoch 1278/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6759 - val_loss: 0.6034 - val_binary_accuracy: 0.6772\n",
            "Epoch 1279/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6710 - val_loss: 0.6034 - val_binary_accuracy: 0.6772\n",
            "Epoch 1280/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6739 - val_loss: 0.6035 - val_binary_accuracy: 0.6764\n",
            "Epoch 1281/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6706 - val_loss: 0.6035 - val_binary_accuracy: 0.6768\n",
            "Epoch 1282/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6755 - val_loss: 0.6035 - val_binary_accuracy: 0.6772\n",
            "Epoch 1283/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6711 - val_loss: 0.6035 - val_binary_accuracy: 0.6764\n",
            "Epoch 1284/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6722 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1285/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6728 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1286/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6787 - val_loss: 0.6035 - val_binary_accuracy: 0.6756\n",
            "Epoch 1287/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6728 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1288/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6735 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1289/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6762 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1290/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6752 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1291/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6723 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1292/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6736 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1293/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6739 - val_loss: 0.6035 - val_binary_accuracy: 0.6764\n",
            "Epoch 1294/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6792 - val_loss: 0.6035 - val_binary_accuracy: 0.6768\n",
            "Epoch 1295/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6778 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1296/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6781 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1297/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6732 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1298/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6782 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1299/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6762 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1300/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6750 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1301/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6745 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1302/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6767 - val_loss: 0.6033 - val_binary_accuracy: 0.6768\n",
            "Epoch 1303/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6795 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1304/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6761 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1305/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6727 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1306/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6773 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1307/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6754 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1308/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6737 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1309/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6725 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1310/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6762 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1311/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6739 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1312/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6748 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1313/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6783 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1314/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6723 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1315/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6782 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1316/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6737 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1317/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6759 - val_loss: 0.6035 - val_binary_accuracy: 0.6760\n",
            "Epoch 1318/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6728 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1319/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6731 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1320/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6724 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1321/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6780 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1322/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6770 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1323/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6743 - val_loss: 0.6035 - val_binary_accuracy: 0.6764\n",
            "Epoch 1324/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6002 - binary_accuracy: 0.6724 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1325/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6735 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1326/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6798 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1327/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6750 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1328/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6742 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1329/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6735 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1330/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6775 - val_loss: 0.6035 - val_binary_accuracy: 0.6768\n",
            "Epoch 1331/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6760 - val_loss: 0.6034 - val_binary_accuracy: 0.6772\n",
            "Epoch 1332/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5988 - binary_accuracy: 0.6752 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1333/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6788 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1334/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6742 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1335/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6761 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1336/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6788 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1337/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6755 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1338/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6754 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1339/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6722 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1340/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6756 - val_loss: 0.6034 - val_binary_accuracy: 0.6760\n",
            "Epoch 1341/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6784 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1342/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6748 - val_loss: 0.6034 - val_binary_accuracy: 0.6768\n",
            "Epoch 1343/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6754 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1344/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6768 - val_loss: 0.6034 - val_binary_accuracy: 0.6764\n",
            "Epoch 1345/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6755 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1346/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6018 - binary_accuracy: 0.6788 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1347/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6760 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1348/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6004 - binary_accuracy: 0.6784 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1349/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6756 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1350/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6751 - val_loss: 0.6033 - val_binary_accuracy: 0.6764\n",
            "Epoch 1351/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6754 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1352/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6717 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1353/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6822 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1354/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6707 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1355/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5981 - binary_accuracy: 0.6810 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1356/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6767 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 1357/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6752 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1358/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6775 - val_loss: 0.6033 - val_binary_accuracy: 0.6768\n",
            "Epoch 1359/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6790 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1360/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6770 - val_loss: 0.6033 - val_binary_accuracy: 0.6768\n",
            "Epoch 1361/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6754 - val_loss: 0.6033 - val_binary_accuracy: 0.6768\n",
            "Epoch 1362/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6756 - val_loss: 0.6033 - val_binary_accuracy: 0.6760\n",
            "Epoch 1363/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6769 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1364/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6812 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1365/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6739 - val_loss: 0.6032 - val_binary_accuracy: 0.6772\n",
            "Epoch 1366/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6793 - val_loss: 0.6032 - val_binary_accuracy: 0.6777\n",
            "Epoch 1367/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6745 - val_loss: 0.6032 - val_binary_accuracy: 0.6777\n",
            "Epoch 1368/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6802 - val_loss: 0.6032 - val_binary_accuracy: 0.6777\n",
            "Epoch 1369/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6762 - val_loss: 0.6032 - val_binary_accuracy: 0.6772\n",
            "Epoch 1370/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6710 - val_loss: 0.6032 - val_binary_accuracy: 0.6777\n",
            "Epoch 1371/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6775 - val_loss: 0.6032 - val_binary_accuracy: 0.6764\n",
            "Epoch 1372/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6807 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1373/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6816 - val_loss: 0.6032 - val_binary_accuracy: 0.6772\n",
            "Epoch 1374/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5971 - binary_accuracy: 0.6814 - val_loss: 0.6032 - val_binary_accuracy: 0.6764\n",
            "Epoch 1375/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6784 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1376/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6771 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1377/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6766 - val_loss: 0.6032 - val_binary_accuracy: 0.6764\n",
            "Epoch 1378/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6851 - val_loss: 0.6032 - val_binary_accuracy: 0.6768\n",
            "Epoch 1379/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6752 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1380/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6745 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1381/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6771 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1382/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6009 - binary_accuracy: 0.6756 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1383/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6751 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1384/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6781 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1385/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6819 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1386/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6753 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1387/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6761 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1388/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6770 - val_loss: 0.6031 - val_binary_accuracy: 0.6756\n",
            "Epoch 1389/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6020 - binary_accuracy: 0.6722 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1390/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6788 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1391/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6775 - val_loss: 0.6031 - val_binary_accuracy: 0.6756\n",
            "Epoch 1392/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6801 - val_loss: 0.6031 - val_binary_accuracy: 0.6756\n",
            "Epoch 1393/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6725 - val_loss: 0.6031 - val_binary_accuracy: 0.6756\n",
            "Epoch 1394/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6750 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1395/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6711 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1396/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6774 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1397/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6747 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1398/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6827 - val_loss: 0.6031 - val_binary_accuracy: 0.6760\n",
            "Epoch 1399/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6784 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1400/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6765 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1401/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6797 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1402/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6797 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1403/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6764 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1404/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6760 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1405/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6754 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1406/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6817 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1407/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6758 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1408/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6758 - val_loss: 0.6031 - val_binary_accuracy: 0.6772\n",
            "Epoch 1409/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6754 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1410/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6749 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1411/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6829 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1412/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6723 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1413/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6838 - val_loss: 0.6031 - val_binary_accuracy: 0.6768\n",
            "Epoch 1414/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6756 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1415/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6771 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1416/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6771 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1417/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6846 - val_loss: 0.6031 - val_binary_accuracy: 0.6764\n",
            "Epoch 1418/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5986 - binary_accuracy: 0.6754 - val_loss: 0.6030 - val_binary_accuracy: 0.6768\n",
            "Epoch 1419/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5955 - binary_accuracy: 0.6763 - val_loss: 0.6030 - val_binary_accuracy: 0.6772\n",
            "Epoch 1420/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6772 - val_loss: 0.6030 - val_binary_accuracy: 0.6772\n",
            "Epoch 1421/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6759 - val_loss: 0.6030 - val_binary_accuracy: 0.6772\n",
            "Epoch 1422/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6017 - binary_accuracy: 0.6771 - val_loss: 0.6030 - val_binary_accuracy: 0.6772\n",
            "Epoch 1423/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6790 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1424/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6842 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1425/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6005 - binary_accuracy: 0.6780 - val_loss: 0.6030 - val_binary_accuracy: 0.6768\n",
            "Epoch 1426/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6747 - val_loss: 0.6030 - val_binary_accuracy: 0.6772\n",
            "Epoch 1427/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6764 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1428/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6775 - val_loss: 0.6029 - val_binary_accuracy: 0.6772\n",
            "Epoch 1429/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6777 - val_loss: 0.6029 - val_binary_accuracy: 0.6777\n",
            "Epoch 1430/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6801 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1431/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6792 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1432/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6765 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1433/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6810 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1434/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6747 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1435/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6766 - val_loss: 0.6030 - val_binary_accuracy: 0.6768\n",
            "Epoch 1436/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6762 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1437/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6800 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1438/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6797 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1439/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6815 - val_loss: 0.6030 - val_binary_accuracy: 0.6777\n",
            "Epoch 1440/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6824 - val_loss: 0.6029 - val_binary_accuracy: 0.6772\n",
            "Epoch 1441/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6786 - val_loss: 0.6029 - val_binary_accuracy: 0.6777\n",
            "Epoch 1442/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6779 - val_loss: 0.6029 - val_binary_accuracy: 0.6777\n",
            "Epoch 1443/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6024 - binary_accuracy: 0.6728 - val_loss: 0.6029 - val_binary_accuracy: 0.6777\n",
            "Epoch 1444/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6736 - val_loss: 0.6029 - val_binary_accuracy: 0.6777\n",
            "Epoch 1445/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6763 - val_loss: 0.6029 - val_binary_accuracy: 0.6772\n",
            "Epoch 1446/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6731 - val_loss: 0.6029 - val_binary_accuracy: 0.6772\n",
            "Epoch 1447/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6777 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1448/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6819 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1449/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6788 - val_loss: 0.6029 - val_binary_accuracy: 0.6772\n",
            "Epoch 1450/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6745 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1451/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5998 - binary_accuracy: 0.6798 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1452/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6803 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1453/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6752 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1454/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6776 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1455/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6750 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1456/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6782 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1457/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6809 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1458/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6741 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1459/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6798 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1460/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5966 - binary_accuracy: 0.6794 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1461/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6793 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1462/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6777 - val_loss: 0.6028 - val_binary_accuracy: 0.6764\n",
            "Epoch 1463/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5968 - binary_accuracy: 0.6803 - val_loss: 0.6028 - val_binary_accuracy: 0.6760\n",
            "Epoch 1464/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6723 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1465/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5991 - binary_accuracy: 0.6784 - val_loss: 0.6028 - val_binary_accuracy: 0.6760\n",
            "Epoch 1466/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6792 - val_loss: 0.6028 - val_binary_accuracy: 0.6760\n",
            "Epoch 1467/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6800 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1468/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6762 - val_loss: 0.6029 - val_binary_accuracy: 0.6760\n",
            "Epoch 1469/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6759 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1470/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6765 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1471/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6742 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1472/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6773 - val_loss: 0.6028 - val_binary_accuracy: 0.6764\n",
            "Epoch 1473/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6741 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1474/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6754 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1475/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6784 - val_loss: 0.6029 - val_binary_accuracy: 0.6768\n",
            "Epoch 1476/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6021 - binary_accuracy: 0.6780 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1477/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6838 - val_loss: 0.6029 - val_binary_accuracy: 0.6764\n",
            "Epoch 1478/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6833 - val_loss: 0.6028 - val_binary_accuracy: 0.6768\n",
            "Epoch 1479/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6809 - val_loss: 0.6028 - val_binary_accuracy: 0.6768\n",
            "Epoch 1480/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6776 - val_loss: 0.6028 - val_binary_accuracy: 0.6768\n",
            "Epoch 1481/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6789 - val_loss: 0.6028 - val_binary_accuracy: 0.6768\n",
            "Epoch 1482/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6033 - binary_accuracy: 0.6691 - val_loss: 0.6028 - val_binary_accuracy: 0.6768\n",
            "Epoch 1483/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6799 - val_loss: 0.6028 - val_binary_accuracy: 0.6764\n",
            "Epoch 1484/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6804 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1485/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6805 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1486/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6739 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1487/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6785 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1488/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6818 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1489/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6786 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1490/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6796 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1491/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6765 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1492/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6798 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 1493/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6788 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1494/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6778 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1495/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6750 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1496/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6771 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1497/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5965 - binary_accuracy: 0.6805 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1498/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6762 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1499/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5993 - binary_accuracy: 0.6781 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1500/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5966 - binary_accuracy: 0.6819 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1501/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6756 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1502/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6027 - binary_accuracy: 0.6785 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1503/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5997 - binary_accuracy: 0.6770 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1504/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6758 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1505/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5989 - binary_accuracy: 0.6815 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1506/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6823 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1507/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6791 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1508/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6774 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1509/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6000 - binary_accuracy: 0.6788 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1510/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6754 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1511/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6782 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1512/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5998 - binary_accuracy: 0.6754 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 1513/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6014 - binary_accuracy: 0.6745 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 1514/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6843 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 1515/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6772 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1516/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6779 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1517/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6014 - binary_accuracy: 0.6783 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1518/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6800 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1519/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6842 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1520/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5961 - binary_accuracy: 0.6832 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1521/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6779 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1522/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5975 - binary_accuracy: 0.6791 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1523/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6798 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1524/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6751 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1525/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5972 - binary_accuracy: 0.6813 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 1526/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6799 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 1527/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5975 - binary_accuracy: 0.6748 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 1528/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6796 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1529/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5975 - binary_accuracy: 0.6801 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 1530/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5984 - binary_accuracy: 0.6775 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1531/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5994 - binary_accuracy: 0.6771 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1532/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6711 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1533/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5977 - binary_accuracy: 0.6778 - val_loss: 0.6027 - val_binary_accuracy: 0.6760\n",
            "Epoch 1534/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6805 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1535/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6827 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1536/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5947 - binary_accuracy: 0.6784 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1537/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6784 - val_loss: 0.6027 - val_binary_accuracy: 0.6764\n",
            "Epoch 1538/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6785 - val_loss: 0.6027 - val_binary_accuracy: 0.6768\n",
            "Epoch 1539/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6805 - val_loss: 0.6027 - val_binary_accuracy: 0.6768\n",
            "Epoch 1540/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5991 - binary_accuracy: 0.6768 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1541/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5969 - binary_accuracy: 0.6803 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1542/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6009 - binary_accuracy: 0.6742 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1543/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6802 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1544/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5994 - binary_accuracy: 0.6818 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1545/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6830 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1546/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6776 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1547/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6765 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1548/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5965 - binary_accuracy: 0.6823 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1549/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6822 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1550/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6754 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1551/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5950 - binary_accuracy: 0.6766 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1552/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6749 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1553/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6817 - val_loss: 0.6026 - val_binary_accuracy: 0.6760\n",
            "Epoch 1554/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6814 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1555/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5963 - binary_accuracy: 0.6752 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1556/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6785 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1557/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5967 - binary_accuracy: 0.6843 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1558/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6803 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1559/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5995 - binary_accuracy: 0.6835 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1560/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6814 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1561/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6800 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1562/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6788 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1563/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6818 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1564/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6802 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1565/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6835 - val_loss: 0.6025 - val_binary_accuracy: 0.6760\n",
            "Epoch 1566/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6773 - val_loss: 0.6025 - val_binary_accuracy: 0.6760\n",
            "Epoch 1567/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6774 - val_loss: 0.6025 - val_binary_accuracy: 0.6760\n",
            "Epoch 1568/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6762 - val_loss: 0.6025 - val_binary_accuracy: 0.6760\n",
            "Epoch 1569/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6799 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1570/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5973 - binary_accuracy: 0.6792 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1571/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6777 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1572/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6749 - val_loss: 0.6026 - val_binary_accuracy: 0.6777\n",
            "Epoch 1573/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6789 - val_loss: 0.6026 - val_binary_accuracy: 0.6777\n",
            "Epoch 1574/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5969 - binary_accuracy: 0.6809 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1575/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6010 - binary_accuracy: 0.6778 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1576/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6799 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1577/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5985 - binary_accuracy: 0.6778 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1578/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6728 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1579/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6770 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1580/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6806 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1581/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6797 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1582/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6779 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1583/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6001 - binary_accuracy: 0.6737 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1584/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6778 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1585/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5991 - binary_accuracy: 0.6730 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1586/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5977 - binary_accuracy: 0.6778 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1587/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5966 - binary_accuracy: 0.6775 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1588/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6832 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1589/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6766 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1590/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5982 - binary_accuracy: 0.6882 - val_loss: 0.6027 - val_binary_accuracy: 0.6768\n",
            "Epoch 1591/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6807 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1592/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5989 - binary_accuracy: 0.6797 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1593/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6772 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1594/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5954 - binary_accuracy: 0.6816 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1595/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6803 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1596/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5984 - binary_accuracy: 0.6826 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1597/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6792 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1598/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5954 - binary_accuracy: 0.6793 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1599/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6826 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1600/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5986 - binary_accuracy: 0.6717 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1601/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6791 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1602/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6816 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1603/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5956 - binary_accuracy: 0.6831 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1604/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6796 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1605/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6814 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1606/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5962 - binary_accuracy: 0.6811 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1607/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6740 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1608/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6789 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1609/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6766 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1610/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6770 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1611/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6743 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1612/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6777 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1613/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6757 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1614/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6837 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1615/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6838 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1616/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6792 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1617/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6809 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1618/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5984 - binary_accuracy: 0.6784 - val_loss: 0.6026 - val_binary_accuracy: 0.6764\n",
            "Epoch 1619/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6805 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1620/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6824 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1621/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6818 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1622/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6831 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1623/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6767 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1624/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5994 - binary_accuracy: 0.6796 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1625/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6769 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1626/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6801 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1627/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6803 - val_loss: 0.6026 - val_binary_accuracy: 0.6768\n",
            "Epoch 1628/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5995 - binary_accuracy: 0.6806 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1629/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6785 - val_loss: 0.6026 - val_binary_accuracy: 0.6772\n",
            "Epoch 1630/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6805 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1631/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6812 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1632/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6786 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1633/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6822 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1634/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6754 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1635/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5918 - binary_accuracy: 0.6814 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1636/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5943 - binary_accuracy: 0.6777 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1637/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6808 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1638/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6800 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1639/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6791 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1640/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5962 - binary_accuracy: 0.6779 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1641/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6808 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1642/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5967 - binary_accuracy: 0.6831 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1643/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5987 - binary_accuracy: 0.6785 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1644/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6794 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1645/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6751 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1646/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6822 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1647/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6790 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1648/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5962 - binary_accuracy: 0.6806 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1649/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5942 - binary_accuracy: 0.6793 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1650/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6817 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1651/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6818 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1652/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6805 - val_loss: 0.6025 - val_binary_accuracy: 0.6768\n",
            "Epoch 1653/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6818 - val_loss: 0.6025 - val_binary_accuracy: 0.6764\n",
            "Epoch 1654/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6797 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1655/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6865 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1656/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5985 - binary_accuracy: 0.6798 - val_loss: 0.6025 - val_binary_accuracy: 0.6777\n",
            "Epoch 1657/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6820 - val_loss: 0.6025 - val_binary_accuracy: 0.6777\n",
            "Epoch 1658/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6775 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1659/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6771 - val_loss: 0.6025 - val_binary_accuracy: 0.6777\n",
            "Epoch 1660/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6822 - val_loss: 0.6025 - val_binary_accuracy: 0.6777\n",
            "Epoch 1661/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5945 - binary_accuracy: 0.6820 - val_loss: 0.6025 - val_binary_accuracy: 0.6772\n",
            "Epoch 1662/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6796 - val_loss: 0.6025 - val_binary_accuracy: 0.6777\n",
            "Epoch 1663/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6820 - val_loss: 0.6024 - val_binary_accuracy: 0.6768\n",
            "Epoch 1664/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5974 - binary_accuracy: 0.6827 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1665/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6792 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1666/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6795 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1667/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6815 - val_loss: 0.6024 - val_binary_accuracy: 0.6772\n",
            "Epoch 1668/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5963 - binary_accuracy: 0.6850 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1669/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6780 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1670/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5969 - binary_accuracy: 0.6816 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1671/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6843 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1672/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6857 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1673/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6816 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1674/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6808 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1675/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6796 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1676/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6795 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1677/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5924 - binary_accuracy: 0.6829 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1678/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6802 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1679/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5949 - binary_accuracy: 0.6825 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1680/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5977 - binary_accuracy: 0.6793 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1681/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6791 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1682/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6805 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1683/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5961 - binary_accuracy: 0.6824 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1684/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6803 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1685/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5990 - binary_accuracy: 0.6760 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1686/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5954 - binary_accuracy: 0.6790 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1687/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6789 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1688/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5963 - binary_accuracy: 0.6828 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1689/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5946 - binary_accuracy: 0.6840 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1690/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6794 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1691/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6831 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1692/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6812 - val_loss: 0.6023 - val_binary_accuracy: 0.6772\n",
            "Epoch 1693/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5930 - binary_accuracy: 0.6849 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1694/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5961 - binary_accuracy: 0.6846 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1695/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6795 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1696/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6742 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1697/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6796 - val_loss: 0.6023 - val_binary_accuracy: 0.6785\n",
            "Epoch 1698/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5904 - binary_accuracy: 0.6814 - val_loss: 0.6023 - val_binary_accuracy: 0.6772\n",
            "Epoch 1699/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6794 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1700/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5952 - binary_accuracy: 0.6822 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1701/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6831 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1702/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6779 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1703/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6839 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1704/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6830 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1705/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5927 - binary_accuracy: 0.6860 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1706/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5915 - binary_accuracy: 0.6869 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1707/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6818 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1708/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6788 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1709/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6795 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1710/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6866 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1711/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6814 - val_loss: 0.6023 - val_binary_accuracy: 0.6789\n",
            "Epoch 1712/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5973 - binary_accuracy: 0.6794 - val_loss: 0.6023 - val_binary_accuracy: 0.6789\n",
            "Epoch 1713/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6787 - val_loss: 0.6023 - val_binary_accuracy: 0.6789\n",
            "Epoch 1714/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5941 - binary_accuracy: 0.6820 - val_loss: 0.6023 - val_binary_accuracy: 0.6789\n",
            "Epoch 1715/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6819 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1716/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6795 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 1717/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5952 - binary_accuracy: 0.6795 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 1718/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6861 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 1719/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5990 - binary_accuracy: 0.6777 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 1720/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6788 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1721/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5952 - binary_accuracy: 0.6833 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1722/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5945 - binary_accuracy: 0.6844 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1723/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6852 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1724/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5985 - binary_accuracy: 0.6827 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1725/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6792 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1726/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5973 - binary_accuracy: 0.6821 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1727/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5941 - binary_accuracy: 0.6811 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1728/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.6841 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1729/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6788 - val_loss: 0.6023 - val_binary_accuracy: 0.6785\n",
            "Epoch 1730/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6853 - val_loss: 0.6023 - val_binary_accuracy: 0.6785\n",
            "Epoch 1731/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5954 - binary_accuracy: 0.6809 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1732/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6789 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1733/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6778 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1734/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6816 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1735/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6800 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1736/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5927 - binary_accuracy: 0.6802 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1737/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6813 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1738/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6842 - val_loss: 0.6023 - val_binary_accuracy: 0.6781\n",
            "Epoch 1739/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5967 - binary_accuracy: 0.6821 - val_loss: 0.6023 - val_binary_accuracy: 0.6777\n",
            "Epoch 1740/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6796 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1741/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6780 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1742/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6786 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1743/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5963 - binary_accuracy: 0.6821 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1744/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6849 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1745/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6815 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1746/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6841 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1747/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6828 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1748/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6802 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1749/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6810 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1750/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6787 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1751/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5938 - binary_accuracy: 0.6820 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1752/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5951 - binary_accuracy: 0.6829 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1753/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5938 - binary_accuracy: 0.6829 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1754/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6816 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1755/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.6019 - binary_accuracy: 0.6811 - val_loss: 0.6022 - val_binary_accuracy: 0.6772\n",
            "Epoch 1756/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5910 - binary_accuracy: 0.6859 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1757/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5929 - binary_accuracy: 0.6860 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1758/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5919 - binary_accuracy: 0.6840 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1759/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6780 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1760/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6814 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1761/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5934 - binary_accuracy: 0.6810 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1762/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5929 - binary_accuracy: 0.6853 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1763/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6819 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1764/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5931 - binary_accuracy: 0.6810 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1765/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6814 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1766/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5952 - binary_accuracy: 0.6795 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1767/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6812 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1768/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5943 - binary_accuracy: 0.6806 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1769/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5934 - binary_accuracy: 0.6861 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1770/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5911 - binary_accuracy: 0.6820 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1771/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6845 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1772/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5956 - binary_accuracy: 0.6789 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1773/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5945 - binary_accuracy: 0.6836 - val_loss: 0.6022 - val_binary_accuracy: 0.6768\n",
            "Epoch 1774/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5933 - binary_accuracy: 0.6847 - val_loss: 0.6021 - val_binary_accuracy: 0.6768\n",
            "Epoch 1775/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5935 - binary_accuracy: 0.6838 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1776/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5932 - binary_accuracy: 0.6802 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1777/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6783 - val_loss: 0.6021 - val_binary_accuracy: 0.6768\n",
            "Epoch 1778/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5944 - binary_accuracy: 0.6796 - val_loss: 0.6021 - val_binary_accuracy: 0.6768\n",
            "Epoch 1779/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5948 - binary_accuracy: 0.6819 - val_loss: 0.6021 - val_binary_accuracy: 0.6768\n",
            "Epoch 1780/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5966 - binary_accuracy: 0.6808 - val_loss: 0.6022 - val_binary_accuracy: 0.6760\n",
            "Epoch 1781/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5925 - binary_accuracy: 0.6792 - val_loss: 0.6022 - val_binary_accuracy: 0.6768\n",
            "Epoch 1782/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5978 - binary_accuracy: 0.6835 - val_loss: 0.6022 - val_binary_accuracy: 0.6760\n",
            "Epoch 1783/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5927 - binary_accuracy: 0.6844 - val_loss: 0.6022 - val_binary_accuracy: 0.6764\n",
            "Epoch 1784/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5966 - binary_accuracy: 0.6818 - val_loss: 0.6022 - val_binary_accuracy: 0.6760\n",
            "Epoch 1785/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5923 - binary_accuracy: 0.6820 - val_loss: 0.6021 - val_binary_accuracy: 0.6764\n",
            "Epoch 1786/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6805 - val_loss: 0.6021 - val_binary_accuracy: 0.6764\n",
            "Epoch 1787/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6781 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1788/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6848 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1789/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5999 - binary_accuracy: 0.6821 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1790/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5988 - binary_accuracy: 0.6820 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1791/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5939 - binary_accuracy: 0.6837 - val_loss: 0.6022 - val_binary_accuracy: 0.6777\n",
            "Epoch 1792/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5950 - binary_accuracy: 0.6827 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1793/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5975 - binary_accuracy: 0.6785 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1794/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6848 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1795/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5936 - binary_accuracy: 0.6821 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1796/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5945 - binary_accuracy: 0.6795 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1797/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6836 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1798/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6779 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1799/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5948 - binary_accuracy: 0.6850 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1800/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5920 - binary_accuracy: 0.6831 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1801/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6832 - val_loss: 0.6021 - val_binary_accuracy: 0.6777\n",
            "Epoch 1802/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.6800 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1803/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6814 - val_loss: 0.6021 - val_binary_accuracy: 0.6772\n",
            "Epoch 1804/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5945 - binary_accuracy: 0.6864 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1805/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6814 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1806/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6826 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1807/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5912 - binary_accuracy: 0.6836 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1808/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6853 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1809/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5967 - binary_accuracy: 0.6832 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1810/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5976 - binary_accuracy: 0.6803 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1811/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5935 - binary_accuracy: 0.6811 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1812/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5980 - binary_accuracy: 0.6799 - val_loss: 0.6021 - val_binary_accuracy: 0.6785\n",
            "Epoch 1813/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6856 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1814/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5974 - binary_accuracy: 0.6856 - val_loss: 0.6021 - val_binary_accuracy: 0.6781\n",
            "Epoch 1815/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6854 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1816/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5945 - binary_accuracy: 0.6796 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1817/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6807 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1818/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5950 - binary_accuracy: 0.6837 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1819/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6845 - val_loss: 0.6022 - val_binary_accuracy: 0.6781\n",
            "Epoch 1820/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5930 - binary_accuracy: 0.6812 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1821/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5920 - binary_accuracy: 0.6822 - val_loss: 0.6022 - val_binary_accuracy: 0.6785\n",
            "Epoch 1822/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5933 - binary_accuracy: 0.6819 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1823/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5967 - binary_accuracy: 0.6784 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1824/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5960 - binary_accuracy: 0.6837 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1825/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6819 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1826/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5915 - binary_accuracy: 0.6831 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1827/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5924 - binary_accuracy: 0.6847 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1828/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5936 - binary_accuracy: 0.6798 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1829/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6827 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1830/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6820 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1831/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6833 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1832/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6851 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1833/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5962 - binary_accuracy: 0.6779 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 1834/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5922 - binary_accuracy: 0.6839 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1835/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6792 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1836/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5942 - binary_accuracy: 0.6823 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1837/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6811 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1838/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6799 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1839/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6792 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1840/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6834 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1841/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5948 - binary_accuracy: 0.6845 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1842/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5952 - binary_accuracy: 0.6826 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1843/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5943 - binary_accuracy: 0.6845 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1844/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6837 - val_loss: 0.6021 - val_binary_accuracy: 0.6793\n",
            "Epoch 1845/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6793 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 1846/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6819 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1847/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6834 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1848/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6847 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1849/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5949 - binary_accuracy: 0.6789 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1850/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5938 - binary_accuracy: 0.6816 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1851/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6839 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1852/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6803 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1853/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6813 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1854/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5966 - binary_accuracy: 0.6774 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1855/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6798 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1856/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6848 - val_loss: 0.6022 - val_binary_accuracy: 0.6797\n",
            "Epoch 1857/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6791 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1858/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5936 - binary_accuracy: 0.6831 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1859/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6822 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1860/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5929 - binary_accuracy: 0.6801 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1861/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6800 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1862/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5948 - binary_accuracy: 0.6865 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1863/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6822 - val_loss: 0.6022 - val_binary_accuracy: 0.6793\n",
            "Epoch 1864/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5913 - binary_accuracy: 0.6845 - val_loss: 0.6022 - val_binary_accuracy: 0.6797\n",
            "Epoch 1865/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5945 - binary_accuracy: 0.6832 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1866/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5980 - binary_accuracy: 0.6796 - val_loss: 0.6022 - val_binary_accuracy: 0.6797\n",
            "Epoch 1867/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6876 - val_loss: 0.6022 - val_binary_accuracy: 0.6797\n",
            "Epoch 1868/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6823 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1869/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6840 - val_loss: 0.6022 - val_binary_accuracy: 0.6806\n",
            "Epoch 1870/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6782 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1871/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5938 - binary_accuracy: 0.6788 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1872/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5936 - binary_accuracy: 0.6850 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1873/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5966 - binary_accuracy: 0.6834 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1874/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5918 - binary_accuracy: 0.6831 - val_loss: 0.6022 - val_binary_accuracy: 0.6806\n",
            "Epoch 1875/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6809 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1876/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5939 - binary_accuracy: 0.6769 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1877/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5910 - binary_accuracy: 0.6854 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1878/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5975 - binary_accuracy: 0.6848 - val_loss: 0.6022 - val_binary_accuracy: 0.6806\n",
            "Epoch 1879/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6814 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1880/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5941 - binary_accuracy: 0.6856 - val_loss: 0.6022 - val_binary_accuracy: 0.6802\n",
            "Epoch 1881/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6878 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1882/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6809 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1883/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6790 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1884/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6856 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1885/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6811 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1886/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6853 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1887/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5895 - binary_accuracy: 0.6889 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1888/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6882 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1889/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6835 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1890/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6889 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1891/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6805 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1892/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6838 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1893/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6817 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1894/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5923 - binary_accuracy: 0.6811 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1895/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6872 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1896/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5929 - binary_accuracy: 0.6835 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1897/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5947 - binary_accuracy: 0.6810 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1898/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5928 - binary_accuracy: 0.6847 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1899/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5941 - binary_accuracy: 0.6845 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1900/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5965 - binary_accuracy: 0.6822 - val_loss: 0.6020 - val_binary_accuracy: 0.6793\n",
            "Epoch 1901/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6848 - val_loss: 0.6020 - val_binary_accuracy: 0.6793\n",
            "Epoch 1902/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6849 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1903/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5919 - binary_accuracy: 0.6837 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1904/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6801 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1905/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6824 - val_loss: 0.6020 - val_binary_accuracy: 0.6797\n",
            "Epoch 1906/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5942 - binary_accuracy: 0.6807 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1907/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5934 - binary_accuracy: 0.6838 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1908/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6862 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1909/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5929 - binary_accuracy: 0.6888 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1910/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6803 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1911/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5912 - binary_accuracy: 0.6856 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1912/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5917 - binary_accuracy: 0.6822 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1913/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5969 - binary_accuracy: 0.6849 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1914/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5970 - binary_accuracy: 0.6822 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1915/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5933 - binary_accuracy: 0.6862 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1916/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5949 - binary_accuracy: 0.6814 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1917/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5914 - binary_accuracy: 0.6874 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1918/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5917 - binary_accuracy: 0.6834 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1919/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5961 - binary_accuracy: 0.6856 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1920/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5898 - binary_accuracy: 0.6890 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1921/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5947 - binary_accuracy: 0.6814 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1922/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5905 - binary_accuracy: 0.6825 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1923/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6817 - val_loss: 0.6020 - val_binary_accuracy: 0.6802\n",
            "Epoch 1924/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5938 - binary_accuracy: 0.6837 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1925/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5952 - binary_accuracy: 0.6795 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1926/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5915 - binary_accuracy: 0.6831 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1927/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5916 - binary_accuracy: 0.6873 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1928/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5917 - binary_accuracy: 0.6851 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1929/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5948 - binary_accuracy: 0.6852 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1930/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5982 - binary_accuracy: 0.6830 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1931/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5929 - binary_accuracy: 0.6853 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1932/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5894 - binary_accuracy: 0.6857 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1933/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5915 - binary_accuracy: 0.6839 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1934/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5901 - binary_accuracy: 0.6882 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1935/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5939 - binary_accuracy: 0.6834 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1936/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6829 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1937/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6786 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1938/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5896 - binary_accuracy: 0.6891 - val_loss: 0.6020 - val_binary_accuracy: 0.6823\n",
            "Epoch 1939/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5946 - binary_accuracy: 0.6811 - val_loss: 0.6020 - val_binary_accuracy: 0.6818\n",
            "Epoch 1940/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6837 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1941/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5936 - binary_accuracy: 0.6869 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1942/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5913 - binary_accuracy: 0.6828 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1943/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5921 - binary_accuracy: 0.6850 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1944/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5911 - binary_accuracy: 0.6861 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1945/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5925 - binary_accuracy: 0.6841 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1946/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6821 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1947/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6745 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1948/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5943 - binary_accuracy: 0.6807 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1949/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5921 - binary_accuracy: 0.6813 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1950/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5944 - binary_accuracy: 0.6831 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1951/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5946 - binary_accuracy: 0.6824 - val_loss: 0.6020 - val_binary_accuracy: 0.6814\n",
            "Epoch 1952/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6853 - val_loss: 0.6020 - val_binary_accuracy: 0.6814\n",
            "Epoch 1953/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5917 - binary_accuracy: 0.6853 - val_loss: 0.6020 - val_binary_accuracy: 0.6823\n",
            "Epoch 1954/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5932 - binary_accuracy: 0.6805 - val_loss: 0.6020 - val_binary_accuracy: 0.6818\n",
            "Epoch 1955/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5900 - binary_accuracy: 0.6876 - val_loss: 0.6020 - val_binary_accuracy: 0.6818\n",
            "Epoch 1956/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6855 - val_loss: 0.6020 - val_binary_accuracy: 0.6818\n",
            "Epoch 1957/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5938 - binary_accuracy: 0.6831 - val_loss: 0.6020 - val_binary_accuracy: 0.6827\n",
            "Epoch 1958/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5918 - binary_accuracy: 0.6840 - val_loss: 0.6020 - val_binary_accuracy: 0.6818\n",
            "Epoch 1959/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5946 - binary_accuracy: 0.6848 - val_loss: 0.6020 - val_binary_accuracy: 0.6827\n",
            "Epoch 1960/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5929 - binary_accuracy: 0.6892 - val_loss: 0.6020 - val_binary_accuracy: 0.6827\n",
            "Epoch 1961/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5914 - binary_accuracy: 0.6826 - val_loss: 0.6020 - val_binary_accuracy: 0.6827\n",
            "Epoch 1962/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5923 - binary_accuracy: 0.6832 - val_loss: 0.6020 - val_binary_accuracy: 0.6823\n",
            "Epoch 1963/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5921 - binary_accuracy: 0.6860 - val_loss: 0.6020 - val_binary_accuracy: 0.6823\n",
            "Epoch 1964/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5937 - binary_accuracy: 0.6839 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1965/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6883 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1966/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5938 - binary_accuracy: 0.6785 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1967/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6785 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1968/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5944 - binary_accuracy: 0.6848 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1969/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6825 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1970/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5928 - binary_accuracy: 0.6838 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1971/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5924 - binary_accuracy: 0.6824 - val_loss: 0.6021 - val_binary_accuracy: 0.6823\n",
            "Epoch 1972/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5917 - binary_accuracy: 0.6845 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1973/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5931 - binary_accuracy: 0.6828 - val_loss: 0.6021 - val_binary_accuracy: 0.6818\n",
            "Epoch 1974/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5901 - binary_accuracy: 0.6858 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1975/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5920 - binary_accuracy: 0.6811 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1976/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6837 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1977/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5958 - binary_accuracy: 0.6856 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1978/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6834 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1979/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5938 - binary_accuracy: 0.6879 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1980/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5927 - binary_accuracy: 0.6822 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1981/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6861 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1982/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5942 - binary_accuracy: 0.6832 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1983/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5918 - binary_accuracy: 0.6798 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1984/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5928 - binary_accuracy: 0.6846 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1985/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5947 - binary_accuracy: 0.6811 - val_loss: 0.6021 - val_binary_accuracy: 0.6797\n",
            "Epoch 1986/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5903 - binary_accuracy: 0.6865 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1987/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5917 - binary_accuracy: 0.6892 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1988/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5921 - binary_accuracy: 0.6848 - val_loss: 0.6021 - val_binary_accuracy: 0.6814\n",
            "Epoch 1989/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6841 - val_loss: 0.6021 - val_binary_accuracy: 0.6810\n",
            "Epoch 1990/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5940 - binary_accuracy: 0.6806 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1991/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5947 - binary_accuracy: 0.6836 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1992/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6799 - val_loss: 0.6021 - val_binary_accuracy: 0.6802\n",
            "Epoch 1993/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5924 - binary_accuracy: 0.6830 - val_loss: 0.6021 - val_binary_accuracy: 0.6806\n",
            "Epoch 1994/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5913 - binary_accuracy: 0.6857 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1995/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6779 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1996/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5903 - binary_accuracy: 0.6814 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1997/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5898 - binary_accuracy: 0.6831 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Epoch 1998/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5944 - binary_accuracy: 0.6856 - val_loss: 0.6020 - val_binary_accuracy: 0.6806\n",
            "Epoch 1999/2000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.5957 - binary_accuracy: 0.6867 - val_loss: 0.6020 - val_binary_accuracy: 0.6814\n",
            "Epoch 2000/2000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6813 - val_loss: 0.6020 - val_binary_accuracy: 0.6810\n",
            "Accuracy on training data: 0.6996150016784668% \n",
            " Error on training data: 0.3003849983215332\n",
            "Accuracy on test data: 0.6604009866714478% \n",
            " Error on test data: 0.33959901332855225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "d3bd5420-7fa8-4215-af3d-5e046c29dfbf"
      },
      "source": [
        "Xnew=np.array([[2.23,1.63,36,30,0.7,0.71,0.549,0.532,1.32,0.55,0.78,1.23,85.2,0.85,0.39,1.54,2.6,1.1,0.67,0.72,1.14,76.1,0.68,0.58,1.03,4.1,1.1,0.66,0.72,1.01,80.7,0.69,0.46,1.05,3.8,1.09,0.71,0.69,1.15,81.2,0.72,0.59,1.01,4.0,0.96,0.62,0.71,0.81,63.1,0.61,0.58,0.97,2.1,1.16,0.59,0.73,1.12,75.1,0.73,0.31,1.24,3.4,1.15,0.67,0.71,1.17,83.3,0.74,0.61,1.10,5.5,1.14,0.62,0.73,1.11,74.9,0.72,0.59,1.17,2.9,1.11,0.64,0.71,1.12,77.4,0.72,0.54,1.12,3.6,0.91,0.67,0.68,0.87,63.7,0.55,0.51,0.83,6.2],\n",
        "               [1.47,2.6,22,47,0.64,0.53,0.525,0.529,1.16,0.6,0.72,1.2,74.3,0.75,0.27,1.25,2.1,1.11,0.6,0.73,1.01,77.1,0.68,0.44,1.15,5.1,1.1,0.68,0.7,1.12,80.4,0.72,0.53,1.06,4.2,1.01,0.68,0.7,0.99,73.1,0.63,0.54,0.93,7.1,1.095,0.64,0.7124999999999999,1.08,76.225,0.6950000000000001,0.445,1.0975,4.625,1.15,0.7,0.7,1.25,85.3,0.75,0.52,1.07,4.5,1.1,0.64,0.7,1.06,76.4,0.73,0.36,1.14,3.4,0.99,0.64,0.7,0.89,69.1,0.6,0.55,0.93,5.1,0.99,0.67,0.69,0.94,70.3,0.63,0.49,0.94,4.4,0.99,0.66,0.69,0.92,69.1,0.64,0.56,0.97,3.4],\n",
        "               [1.57,2.25,27,23,0.62,0.61,0.473,0.515,1.19,0.58,0.74,1.18,75.1,0.75,0.31,1.30,2.9,1.15,0.76,0.72,1.26,86.4,0.78,0.67,1.03,6.2,1.08,0.64,0.71,1.06,74.9,0.68,0.45,1.06,3.1,1.08,0.65,0.74,0.96,76.8,0.68,0.44,1.04,6.6,0.94,0.66,0.72,0.83,66.0,0.56,0.52,0.85,8.7,1.17,0.63,0.72,1.12,83.4,0.74,0.48,1.17,8.0,1.15,0.63,0.71,1.16,75.4,0.76,0.27,1.20,1.5,1.05,0.69,0.7,1.07,76.3,0.68,0.57,0.99,4.5,1.02,0.64,0.72,0.92,69.3,0.64,0.52,1.00,4.0,0.91,0.68,0.67,0.86,66.0,0.57,0.53,0.83,6.1],\n",
        "               [1.45,2.55,41,108,0.45,0.48,0.462,0.417,1.11,0.63,0.72,1.07,73.6,0.72,0.32,1.14,1.8,1.04,0.71,0.69,1.03,77.1,0.69,0.48,0.97,3.9,1.02,0.72,0.69,1.03,77.1,0.65,0.55,0.90,5.1,1.1,0.67,0.68,1.17,78.6,0.74,0.6,1.11,3.1,0.97,0.68,0.71,0.88,68.9,0.6,0.52,0.88,4.7,1.08,0.66,0.71,1.06,75.6,0.72,0.49,1.09,4.8,1.03,0.65,0.7,0.98,74.9,0.66,0.51,1.02,4.8,1.02,0.68,0.69,1.03,70.3,0.68,0.32,1.00,1.8,1.0433333333333334,0.6633333333333334,0.6999999999999998,1.0233333333333334,73.60000000000001,0.6866666666666666,0.44,1.0366666666666668,3.8000000000000003,1.0433333333333334,0.6633333333333334,0.6999999999999998,1.0233333333333334,73.60000000000001,0.6866666666666666,0.44,1.0366666666666668,3.8000000000000003],\n",
        "               [2.44,1.5,69,57,0.6,0.68,0.621,0.5,1.19,0.61,0.71,1.28,78.9,0.78,0.26,1.29,4.3,1.1,0.7,0.7,1.16,82.6,0.71,0.5,1.01,8.2,1.09,0.62,0.75,0.98,72.0,0.68,0.5,1.09,5.1,1.1,0.66,0.72,1.1,77.7,0.69,0.46,1.04,6.3,0.99,0.64,0.69,0.9,68.7,0.63,0.47,0.98,5.4,1.2,0.67,0.75,1.18,84.7,0.8,0.59,1.20,4.5,1.19,0.63,0.72,1.27,77.2,0.78,0.33,1.24,2.7,1.12,0.67,0.73,1.11,79.6,0.72,0.5,1.09,4.4,1.0,0.67,0.71,0.93,71.2,0.62,0.57,0.93,5.7,0.86,0.7,0.66,0.8,62.4,0.54,0.39,0.78,5.4],\n",
        "               [1.45,2.55,12,23,0.33,0.63,0.5,0.515,1.09,0.64,0.72,1.12,70.7,0.7,0.41,1.10,3.2,1.05,0.67,0.7,1.03,77.2,0.66,0.51,0.99,5.0,1.04,0.68,0.7,1.07,69.3,0.64,0.62,0.93,3.5,0.97,0.64,0.69,0.81,71.8,0.58,0.54,0.91,6.0,0.82,0.69,0.68,0.64,57.4,0.51,0.57,0.73,2.9,1.18,0.63,0.73,1.14,83.9,0.75,0.48,1.20,8.0,1.15,0.63,0.72,1.15,75.1,0.76,0.27,1.20,1.5,1.07,0.69,0.7,1.09,77.3,0.69,0.57,1.00,4.6,1.02,0.63,0.72,0.91,69.2,0.63,0.52,1.00,4.0,0.92,0.68,0.68,0.86,66.5,0.57,0.53,0.84,6.2]])\n",
        "Xnew = pd.DataFrame(Xnew, columns=CSV_COLUMN_NAMES2)\n",
        "pokus=predictionScaler.transform(Xnew)\n",
        "model= keras.models.load_model(\"686model.h5\")\n",
        "ynew=(model.predict([pokus]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)\n",
        "\n",
        "\n",
        "\n",
        "#model= keras.models.load_model(\"686model.h5\")\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.52328163]\n",
            " [0.44754353]\n",
            " [0.40692347]\n",
            " [0.42446122]\n",
            " [0.5000446 ]\n",
            " [0.43324134]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-0x3EQ37uB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvOLjjtq370x"
      },
      "source": [
        "pd.options.display.max_rows = 4000\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDSZ8GXKuje"
      },
      "source": [
        "model.save('/content/save/683model.h5')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 100 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "model.layers[0].get_weights()[0][98]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSBrO3pcCHlQ",
        "outputId": "61f3a2f7-e06a-4b0a-b5cb-95f6f4bb5ef3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6683375104427736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGzpVUzOYhY"
      },
      "source": [
        "import shap\n",
        "import xgboost\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','team_one_name','team_two_name']\n",
        "shap.initjs()\n",
        "#explainer = shap.Explainer(model.predict, X_train)\n",
        "#shap_values = explainer.shap_values(np.array([[1.8,1.9,26,23,0.63,0.64,0.509,0.591,1.16,0.68,0.7,1.26,84.3,0.75,0.5,1.11,7.4,1.13,0.64,0.72,1.11,78.0,0.72,0.57,1.13,3.2,1.0,0.67,0.69,0.95,69.3,0.64,0.58,0.95,4.2,0.99,0.65,0.69,0.95,67.7,0.62,0.58,0.94,3.3,1.07,0.66,0.7,1.0675000000000001,74.825,0.6825,0.5575,1.0325000000000002,4.525,1.23,0.6,0.75,1.26,79.4,0.77,0.31,1.29,3.4,1.24,0.61,0.77,1.15,82.8,0.82,0.52,1.35,3.4,1.14,0.62,0.73,1.11,76.1,0.72,0.5,1.16,5.2,1.0,0.68,0.7,0.98,70.2,0.61,0.51,0.90,3.9,0.98,0.69,0.69,0.96,71.7,0.6,0.48,0.87,5.3]])\n",
        "\n",
        "keras_explainer = shap.DeepExplainer(model, shap.sample(X_train, 10))\n",
        "keras_shap_values = keras_explainer.shap_values(X_test)\n",
        "\n",
        "values = keras_shap_values[0]\n",
        "base_values = [keras_explainer.expected_value[0]]*len(keras_shap_values[0])\n",
        "\n",
        "tmp = shap.Explanation(values = np.array(values, dtype=np.float32),\n",
        "                       base_values = np.array(base_values, dtype=np.float32),\n",
        "                       data=np.array(X_train),\n",
        "                       feature_names=CSV_COLUMN_NAMES2)\n",
        "\n",
        "#shap.plots.waterfall(tmp[5])\n",
        "#shap.plots.bar(tmp,max_display=98)\n",
        "shap.summary_plot(tmp, X_test,max_display=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLaoTNJnIRM"
      },
      "source": [
        "#print(X_val)\n",
        "pokus=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "pokus.pop('Match_link')\n",
        "pokus.pop('team_one_name')\n",
        "pokus.pop('team_two_name')\n",
        "pokus.pop('Result')\n",
        "\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(pokus)\n",
        "data=scaler.transform(pokus)\n",
        "print(data)\n"
      ]
    }
  ]
}