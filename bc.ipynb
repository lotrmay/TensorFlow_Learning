{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtfBKtq7I4meXSK2sh7YP7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbSeoWpB3mO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCY-aVPMK1aO"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "9b5b4005-b1df-4bdc-fd54-587c418206ca"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(train.shape)#vypíše nám dimenzionalitu našeho dataframu (2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "train['team_one_name']=pd.Categorical(train['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "train['team_two_name']=pd.Categorical(train['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "#https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "#frac=1 znamená, vrať všechny řádky\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "\n",
        "train.pop('playerAAAdr')\n",
        "train.pop('playerABAdr')\n",
        "train.pop('playerACAdr')\n",
        "train.pop('playerADAdr')\n",
        "train.pop('playerAEAdr')\n",
        "train.pop('playerBAAdr')\n",
        "train.pop('playerBBAdr')\n",
        "train.pop('playerBCAdr')\n",
        "train.pop('playerBDAdr')\n",
        "train.pop('playerBEAdr')\n",
        "\n",
        "train.pop('playerAADpr')\n",
        "train.pop('playerABDpr')\n",
        "train.pop('playerACDpr')\n",
        "train.pop('playerADDpr')\n",
        "train.pop('playerAEDpr')\n",
        "train.pop('playerBADpr')\n",
        "train.pop('playerBBDpr')\n",
        "train.pop('playerBCDpr')\n",
        "train.pop('playerBDDpr')\n",
        "train.pop('playerBEDpr')\n",
        "\n",
        "train.pop('playerAAKpr')\n",
        "train.pop('playerABKpr')\n",
        "train.pop('playerACKpr')\n",
        "train.pop('playerADKpr')\n",
        "train.pop('playerAEKpr')\n",
        "train.pop('playerBAKpr')\n",
        "train.pop('playerBBKpr')\n",
        "train.pop('playerBCKpr')\n",
        "train.pop('playerBDKpr')\n",
        "train.pop('playerBEKpr')\n",
        "\n",
        "train.pop('playerAAImpact')\n",
        "train.pop('playerABImpact')\n",
        "train.pop('playerACImpact')\n",
        "train.pop('playerADImpact')\n",
        "train.pop('playerAEImpact')\n",
        "train.pop('playerBAImpact')\n",
        "train.pop('playerBBImpact')\n",
        "train.pop('playerBCImpact')\n",
        "train.pop('playerBDImpact')\n",
        "train.pop('playerBEImpact')\n",
        "\n",
        "train.pop('playerAAHs')\n",
        "train.pop('playerABHs')\n",
        "train.pop('playerACHs')\n",
        "train.pop('playerADHs')\n",
        "train.pop('playerAEHs')\n",
        "train.pop('playerBAHs')\n",
        "train.pop('playerBBHs')\n",
        "train.pop('playerBCHs')\n",
        "train.pop('playerBDHs')\n",
        "train.pop('playerBEHs')\n",
        "\n",
        "train.pop('playerAARating')\n",
        "train.pop('playerABRating')\n",
        "train.pop('playerACRating')\n",
        "train.pop('playerADRating')\n",
        "train.pop('playerAERating')\n",
        "train.pop('playerBARating')\n",
        "train.pop('playerBBRating')\n",
        "train.pop('playerBCRating')\n",
        "train.pop('playerBDRating')\n",
        "train.pop('playerBERating')\n",
        "'''\n",
        "#predictors nám vybere všechny sloupce, které jsou využity pro predikování výsledků neboli target_column\n",
        "target_column = ['Result'] \n",
        "\n",
        "predictionScaler=StandardScaler()\n",
        "y = train['Result'].values\n",
        "train.pop('Result')\n",
        "X = train.values\n",
        "\n",
        "#predictionScaler.fit(scalerData)\n",
        "\n",
        "#n = 100 # Max number of neighbours you want to consider\n",
        "#param_grid = {'n_neighbors': np.arange(n)}\n",
        "#grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "#grid.fit(X,y)\n",
        "#print(grid.best_params_)\n",
        "\n",
        "\n",
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#5% dat \n",
        "\n",
        "lof = LocalOutlierFactor(contamination=0.1,n_neighbors=96)\n",
        "yhat = lof.fit_predict(X)\n",
        "mask = yhat != -1\n",
        "X, y= X[mask, :], y[mask]\n",
        "print(X.shape)\n",
        "\n",
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% random_state=98\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)#32 #888 887\n",
        "\n",
        "#validační set bude 15% random_state=75\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1666) # 0.1666 x 0.9 = 0.1 podívat se na cross-validation\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) #součet odpovídá X.shape\n",
        "\n",
        "#vytvoříme scaler, který nám data přetransformuje na formát lepší pro model ?\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=CSV_COLUMN_NAMES2)\n",
        "X_test=pd.DataFrame(X_test, columns=CSV_COLUMN_NAMES2)\n",
        "X_val=pd.DataFrame(X_val, columns=CSV_COLUMN_NAMES2)\n",
        "\n",
        "predictionScaler.fit(X_train)\n",
        "\n",
        "X_train=predictionScaler.transform(X_train)#fit transform na training data viz:https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
        "X_test=predictionScaler.transform(X_test)\n",
        "X_val=predictionScaler.transform(X_val)\n",
        "\n",
        "#64 32\n",
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(Dense(64, activation='relu', kernel_initializer=tf.initializers.lecun_uniform,bias_initializer=tf.initializers.random_uniform))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_initializer=tf.initializers.lecun_uniform,bias_initializer=tf.initializers.random_uniform))\n",
        "model.add(keras.layers.Dropout(0.5))#50% inputů dropne abz se příliš nespoléhala na vybrané inputy\n",
        "#jelikož děláme binární klasifikaci, tak aktivační funkce bude sigmoid popř. softmax, zde by mezi těmito dvěmi neměl být výkonově rozdíl viz:https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#tady jsem skončil s vysvětlováním!!!\n",
        "#model zkompilujeme s parametry:\n",
        "#Common values of [momentum] used in practice include .5, .9, and .99.\n",
        "#optimizer bude ? optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.5)\n",
        "#loss funkce bude BinaryCrossentropy, jelikož máme binární klasifikátor\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=['binary_accuracy'])#metrics=['accuracy'] je to jedno accuracy se vnitřně přetransformuje na binary accuracy, kvůli binary crossentropy loss funkci\n",
        "#metrics = (\"accuracy\")\n",
        "#metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None)\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])\n",
        "#[tf.keras.metrics.BinaryAccuracy()]\n",
        "#optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#Adagrad(learning_rate=0.01) kolem 100 epochs a 32 batch_size je kolem 0.67\n",
        "\n",
        "#shuffle=true?\n",
        "history = model.fit(X_train, y_train, epochs=500,shuffle=True,batch_size=64,validation_data=(X_val, y_val))#validační data pro změny při tréninku sítě\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "pred_test= model.predict(X_test)\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "\n",
        "#plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')#'accuracy'\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky!!\n",
        "#optimální batch_size je 128 zjištěno zkoušením\n",
        "#zatím nejlepší model měl 64 16 4 \n",
        "#dense layers používají defaultně tf.initializers.glorot_uniform,ale pro můj model je přesnější glorot_normal\n",
        "#he_uniform>he_normal\n",
        "\n",
        "#kernel inity\n",
        "#lecun normal vypadá zatím nejlíp, prozkoumat\n",
        "#lecun uniform>normal asi\n",
        "#orthogonal je taky hodně gut\n",
        "#variance scaling taky gut\n",
        "\n",
        "#bias inity\n",
        "#zatím je nejlepší he_normal (dal 69.1%)\n",
        "#lecun_normal (taky 69.1%)\n",
        "#randomnormal zatim nej\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/initializers"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18930, 102)\n",
            "(17037, 98)\n",
            "(12778, 98)\n",
            "(1704, 98)\n",
            "(2555, 98)\n",
            "Epoch 1/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.7636 - binary_accuracy: 0.5308 - val_loss: 0.6649 - val_binary_accuracy: 0.5926\n",
            "Epoch 2/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6996 - binary_accuracy: 0.5581 - val_loss: 0.6602 - val_binary_accuracy: 0.6074\n",
            "Epoch 3/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6800 - binary_accuracy: 0.5696 - val_loss: 0.6567 - val_binary_accuracy: 0.6133\n",
            "Epoch 4/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6749 - binary_accuracy: 0.5774 - val_loss: 0.6552 - val_binary_accuracy: 0.6211\n",
            "Epoch 5/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6643 - binary_accuracy: 0.5925 - val_loss: 0.6528 - val_binary_accuracy: 0.6227\n",
            "Epoch 6/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6674 - binary_accuracy: 0.5876 - val_loss: 0.6514 - val_binary_accuracy: 0.6254\n",
            "Epoch 7/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6655 - binary_accuracy: 0.5920 - val_loss: 0.6504 - val_binary_accuracy: 0.6290\n",
            "Epoch 8/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6606 - binary_accuracy: 0.5979 - val_loss: 0.6480 - val_binary_accuracy: 0.6309\n",
            "Epoch 9/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6579 - binary_accuracy: 0.6000 - val_loss: 0.6465 - val_binary_accuracy: 0.6325\n",
            "Epoch 10/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6577 - binary_accuracy: 0.6028 - val_loss: 0.6453 - val_binary_accuracy: 0.6356\n",
            "Epoch 11/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6538 - binary_accuracy: 0.6158 - val_loss: 0.6436 - val_binary_accuracy: 0.6344\n",
            "Epoch 12/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6518 - binary_accuracy: 0.6170 - val_loss: 0.6417 - val_binary_accuracy: 0.6329\n",
            "Epoch 13/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6524 - binary_accuracy: 0.6180 - val_loss: 0.6406 - val_binary_accuracy: 0.6384\n",
            "Epoch 14/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6175 - val_loss: 0.6392 - val_binary_accuracy: 0.6341\n",
            "Epoch 15/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6494 - binary_accuracy: 0.6215 - val_loss: 0.6382 - val_binary_accuracy: 0.6368\n",
            "Epoch 16/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6468 - binary_accuracy: 0.6194 - val_loss: 0.6372 - val_binary_accuracy: 0.6395\n",
            "Epoch 17/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6453 - binary_accuracy: 0.6224 - val_loss: 0.6357 - val_binary_accuracy: 0.6380\n",
            "Epoch 18/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6464 - binary_accuracy: 0.6186 - val_loss: 0.6348 - val_binary_accuracy: 0.6415\n",
            "Epoch 19/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6453 - binary_accuracy: 0.6255 - val_loss: 0.6340 - val_binary_accuracy: 0.6427\n",
            "Epoch 20/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6436 - binary_accuracy: 0.6237 - val_loss: 0.6328 - val_binary_accuracy: 0.6391\n",
            "Epoch 21/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6426 - binary_accuracy: 0.6252 - val_loss: 0.6320 - val_binary_accuracy: 0.6431\n",
            "Epoch 22/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6392 - binary_accuracy: 0.6285 - val_loss: 0.6299 - val_binary_accuracy: 0.6403\n",
            "Epoch 23/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6395 - binary_accuracy: 0.6345 - val_loss: 0.6293 - val_binary_accuracy: 0.6434\n",
            "Epoch 24/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6388 - binary_accuracy: 0.6298 - val_loss: 0.6285 - val_binary_accuracy: 0.6415\n",
            "Epoch 25/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6395 - binary_accuracy: 0.6289 - val_loss: 0.6273 - val_binary_accuracy: 0.6446\n",
            "Epoch 26/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6330 - val_loss: 0.6266 - val_binary_accuracy: 0.6431\n",
            "Epoch 27/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6337 - val_loss: 0.6255 - val_binary_accuracy: 0.6434\n",
            "Epoch 28/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6310 - val_loss: 0.6249 - val_binary_accuracy: 0.6458\n",
            "Epoch 29/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6386 - val_loss: 0.6237 - val_binary_accuracy: 0.6458\n",
            "Epoch 30/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6358 - val_loss: 0.6236 - val_binary_accuracy: 0.6458\n",
            "Epoch 31/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6344 - val_loss: 0.6228 - val_binary_accuracy: 0.6458\n",
            "Epoch 32/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6404 - val_loss: 0.6218 - val_binary_accuracy: 0.6470\n",
            "Epoch 33/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6324 - binary_accuracy: 0.6394 - val_loss: 0.6212 - val_binary_accuracy: 0.6485\n",
            "Epoch 34/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6432 - val_loss: 0.6201 - val_binary_accuracy: 0.6481\n",
            "Epoch 35/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6410 - val_loss: 0.6192 - val_binary_accuracy: 0.6501\n",
            "Epoch 36/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6443 - val_loss: 0.6195 - val_binary_accuracy: 0.6513\n",
            "Epoch 37/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6455 - val_loss: 0.6176 - val_binary_accuracy: 0.6524\n",
            "Epoch 38/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6470 - val_loss: 0.6175 - val_binary_accuracy: 0.6532\n",
            "Epoch 39/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6427 - val_loss: 0.6171 - val_binary_accuracy: 0.6532\n",
            "Epoch 40/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6490 - val_loss: 0.6168 - val_binary_accuracy: 0.6528\n",
            "Epoch 41/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6418 - val_loss: 0.6167 - val_binary_accuracy: 0.6513\n",
            "Epoch 42/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6496 - val_loss: 0.6160 - val_binary_accuracy: 0.6509\n",
            "Epoch 43/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6449 - val_loss: 0.6151 - val_binary_accuracy: 0.6532\n",
            "Epoch 44/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6544 - val_loss: 0.6145 - val_binary_accuracy: 0.6517\n",
            "Epoch 45/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6503 - val_loss: 0.6141 - val_binary_accuracy: 0.6513\n",
            "Epoch 46/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6527 - val_loss: 0.6137 - val_binary_accuracy: 0.6524\n",
            "Epoch 47/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6569 - val_loss: 0.6129 - val_binary_accuracy: 0.6513\n",
            "Epoch 48/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6502 - val_loss: 0.6128 - val_binary_accuracy: 0.6517\n",
            "Epoch 49/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6512 - val_loss: 0.6122 - val_binary_accuracy: 0.6528\n",
            "Epoch 50/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6553 - val_loss: 0.6119 - val_binary_accuracy: 0.6532\n",
            "Epoch 51/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6494 - val_loss: 0.6120 - val_binary_accuracy: 0.6528\n",
            "Epoch 52/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6543 - val_loss: 0.6117 - val_binary_accuracy: 0.6524\n",
            "Epoch 53/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6477 - val_loss: 0.6117 - val_binary_accuracy: 0.6532\n",
            "Epoch 54/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6511 - val_loss: 0.6123 - val_binary_accuracy: 0.6544\n",
            "Epoch 55/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6578 - val_loss: 0.6109 - val_binary_accuracy: 0.6552\n",
            "Epoch 56/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6536 - val_loss: 0.6108 - val_binary_accuracy: 0.6556\n",
            "Epoch 57/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6567 - val_loss: 0.6108 - val_binary_accuracy: 0.6548\n",
            "Epoch 58/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6576 - val_loss: 0.6102 - val_binary_accuracy: 0.6571\n",
            "Epoch 59/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6514 - val_loss: 0.6105 - val_binary_accuracy: 0.6568\n",
            "Epoch 60/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6571 - val_loss: 0.6106 - val_binary_accuracy: 0.6579\n",
            "Epoch 61/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6577 - val_loss: 0.6099 - val_binary_accuracy: 0.6556\n",
            "Epoch 62/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6636 - val_loss: 0.6094 - val_binary_accuracy: 0.6564\n",
            "Epoch 63/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6568 - val_loss: 0.6093 - val_binary_accuracy: 0.6564\n",
            "Epoch 64/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6596 - val_loss: 0.6092 - val_binary_accuracy: 0.6560\n",
            "Epoch 65/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6550 - val_loss: 0.6090 - val_binary_accuracy: 0.6552\n",
            "Epoch 66/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6656 - val_loss: 0.6082 - val_binary_accuracy: 0.6556\n",
            "Epoch 67/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6632 - val_loss: 0.6084 - val_binary_accuracy: 0.6579\n",
            "Epoch 68/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6640 - val_loss: 0.6083 - val_binary_accuracy: 0.6552\n",
            "Epoch 69/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6598 - val_loss: 0.6079 - val_binary_accuracy: 0.6583\n",
            "Epoch 70/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6636 - val_loss: 0.6079 - val_binary_accuracy: 0.6575\n",
            "Epoch 71/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6601 - val_loss: 0.6081 - val_binary_accuracy: 0.6571\n",
            "Epoch 72/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6625 - val_loss: 0.6071 - val_binary_accuracy: 0.6571\n",
            "Epoch 73/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6658 - val_loss: 0.6072 - val_binary_accuracy: 0.6587\n",
            "Epoch 74/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6607 - val_loss: 0.6070 - val_binary_accuracy: 0.6583\n",
            "Epoch 75/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6632 - val_loss: 0.6080 - val_binary_accuracy: 0.6583\n",
            "Epoch 76/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6668 - val_loss: 0.6075 - val_binary_accuracy: 0.6575\n",
            "Epoch 77/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6615 - val_loss: 0.6074 - val_binary_accuracy: 0.6564\n",
            "Epoch 78/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6654 - val_loss: 0.6075 - val_binary_accuracy: 0.6579\n",
            "Epoch 79/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6619 - val_loss: 0.6074 - val_binary_accuracy: 0.6587\n",
            "Epoch 80/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6652 - val_loss: 0.6069 - val_binary_accuracy: 0.6575\n",
            "Epoch 81/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6645 - val_loss: 0.6065 - val_binary_accuracy: 0.6579\n",
            "Epoch 82/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6686 - val_loss: 0.6065 - val_binary_accuracy: 0.6571\n",
            "Epoch 83/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6714 - val_loss: 0.6064 - val_binary_accuracy: 0.6579\n",
            "Epoch 84/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6715 - val_loss: 0.6066 - val_binary_accuracy: 0.6595\n",
            "Epoch 85/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6693 - val_loss: 0.6062 - val_binary_accuracy: 0.6583\n",
            "Epoch 86/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6679 - val_loss: 0.6059 - val_binary_accuracy: 0.6571\n",
            "Epoch 87/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6676 - val_loss: 0.6058 - val_binary_accuracy: 0.6591\n",
            "Epoch 88/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6663 - val_loss: 0.6060 - val_binary_accuracy: 0.6591\n",
            "Epoch 89/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6701 - val_loss: 0.6055 - val_binary_accuracy: 0.6603\n",
            "Epoch 90/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6650 - val_loss: 0.6056 - val_binary_accuracy: 0.6591\n",
            "Epoch 91/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6684 - val_loss: 0.6061 - val_binary_accuracy: 0.6603\n",
            "Epoch 92/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6627 - val_loss: 0.6056 - val_binary_accuracy: 0.6599\n",
            "Epoch 93/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6672 - val_loss: 0.6056 - val_binary_accuracy: 0.6595\n",
            "Epoch 94/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6684 - val_loss: 0.6055 - val_binary_accuracy: 0.6607\n",
            "Epoch 95/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6710 - val_loss: 0.6058 - val_binary_accuracy: 0.6622\n",
            "Epoch 96/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6661 - val_loss: 0.6057 - val_binary_accuracy: 0.6622\n",
            "Epoch 97/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6664 - val_loss: 0.6053 - val_binary_accuracy: 0.6614\n",
            "Epoch 98/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6697 - val_loss: 0.6052 - val_binary_accuracy: 0.6634\n",
            "Epoch 99/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6708 - val_loss: 0.6053 - val_binary_accuracy: 0.6642\n",
            "Epoch 100/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6657 - val_loss: 0.6054 - val_binary_accuracy: 0.6638\n",
            "Epoch 101/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6701 - val_loss: 0.6051 - val_binary_accuracy: 0.6642\n",
            "Epoch 102/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6703 - val_loss: 0.6051 - val_binary_accuracy: 0.6618\n",
            "Epoch 103/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6740 - val_loss: 0.6050 - val_binary_accuracy: 0.6599\n",
            "Epoch 104/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6732 - val_loss: 0.6051 - val_binary_accuracy: 0.6622\n",
            "Epoch 105/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6681 - val_loss: 0.6052 - val_binary_accuracy: 0.6650\n",
            "Epoch 106/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6717 - val_loss: 0.6048 - val_binary_accuracy: 0.6634\n",
            "Epoch 107/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6707 - val_loss: 0.6047 - val_binary_accuracy: 0.6638\n",
            "Epoch 108/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6713 - val_loss: 0.6047 - val_binary_accuracy: 0.6669\n",
            "Epoch 109/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6676 - val_loss: 0.6048 - val_binary_accuracy: 0.6658\n",
            "Epoch 110/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6676 - val_loss: 0.6051 - val_binary_accuracy: 0.6677\n",
            "Epoch 111/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6686 - val_loss: 0.6049 - val_binary_accuracy: 0.6661\n",
            "Epoch 112/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6706 - val_loss: 0.6050 - val_binary_accuracy: 0.6669\n",
            "Epoch 113/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6729 - val_loss: 0.6050 - val_binary_accuracy: 0.6654\n",
            "Epoch 114/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6768 - val_loss: 0.6048 - val_binary_accuracy: 0.6665\n",
            "Epoch 115/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6689 - val_loss: 0.6049 - val_binary_accuracy: 0.6646\n",
            "Epoch 116/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6731 - val_loss: 0.6046 - val_binary_accuracy: 0.6673\n",
            "Epoch 117/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6726 - val_loss: 0.6046 - val_binary_accuracy: 0.6669\n",
            "Epoch 118/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6751 - val_loss: 0.6047 - val_binary_accuracy: 0.6669\n",
            "Epoch 119/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6768 - val_loss: 0.6043 - val_binary_accuracy: 0.6665\n",
            "Epoch 120/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6744 - val_loss: 0.6044 - val_binary_accuracy: 0.6673\n",
            "Epoch 121/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6759 - val_loss: 0.6044 - val_binary_accuracy: 0.6654\n",
            "Epoch 122/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6749 - val_loss: 0.6043 - val_binary_accuracy: 0.6665\n",
            "Epoch 123/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6727 - val_loss: 0.6046 - val_binary_accuracy: 0.6665\n",
            "Epoch 124/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6728 - val_loss: 0.6041 - val_binary_accuracy: 0.6669\n",
            "Epoch 125/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6752 - val_loss: 0.6038 - val_binary_accuracy: 0.6646\n",
            "Epoch 126/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6715 - val_loss: 0.6038 - val_binary_accuracy: 0.6669\n",
            "Epoch 127/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6733 - val_loss: 0.6036 - val_binary_accuracy: 0.6697\n",
            "Epoch 128/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6745 - val_loss: 0.6038 - val_binary_accuracy: 0.6654\n",
            "Epoch 129/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6776 - val_loss: 0.6036 - val_binary_accuracy: 0.6658\n",
            "Epoch 130/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6752 - val_loss: 0.6042 - val_binary_accuracy: 0.6669\n",
            "Epoch 131/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6762 - val_loss: 0.6036 - val_binary_accuracy: 0.6673\n",
            "Epoch 132/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6742 - val_loss: 0.6037 - val_binary_accuracy: 0.6685\n",
            "Epoch 133/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6776 - val_loss: 0.6037 - val_binary_accuracy: 0.6665\n",
            "Epoch 134/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6746 - val_loss: 0.6039 - val_binary_accuracy: 0.6665\n",
            "Epoch 135/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6736 - val_loss: 0.6036 - val_binary_accuracy: 0.6677\n",
            "Epoch 136/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6776 - val_loss: 0.6035 - val_binary_accuracy: 0.6661\n",
            "Epoch 137/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6736 - val_loss: 0.6034 - val_binary_accuracy: 0.6673\n",
            "Epoch 138/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6762 - val_loss: 0.6033 - val_binary_accuracy: 0.6673\n",
            "Epoch 139/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6806 - val_loss: 0.6031 - val_binary_accuracy: 0.6654\n",
            "Epoch 140/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6769 - val_loss: 0.6030 - val_binary_accuracy: 0.6673\n",
            "Epoch 141/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6755 - val_loss: 0.6030 - val_binary_accuracy: 0.6661\n",
            "Epoch 142/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6778 - val_loss: 0.6032 - val_binary_accuracy: 0.6661\n",
            "Epoch 143/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6770 - val_loss: 0.6034 - val_binary_accuracy: 0.6622\n",
            "Epoch 144/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6740 - val_loss: 0.6031 - val_binary_accuracy: 0.6638\n",
            "Epoch 145/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6729 - val_loss: 0.6034 - val_binary_accuracy: 0.6665\n",
            "Epoch 146/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6717 - val_loss: 0.6038 - val_binary_accuracy: 0.6646\n",
            "Epoch 147/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6780 - val_loss: 0.6035 - val_binary_accuracy: 0.6650\n",
            "Epoch 148/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6748 - val_loss: 0.6032 - val_binary_accuracy: 0.6642\n",
            "Epoch 149/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6760 - val_loss: 0.6031 - val_binary_accuracy: 0.6642\n",
            "Epoch 150/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6756 - val_loss: 0.6031 - val_binary_accuracy: 0.6646\n",
            "Epoch 151/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6768 - val_loss: 0.6032 - val_binary_accuracy: 0.6646\n",
            "Epoch 152/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6787 - val_loss: 0.6033 - val_binary_accuracy: 0.6650\n",
            "Epoch 153/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6789 - val_loss: 0.6029 - val_binary_accuracy: 0.6658\n",
            "Epoch 154/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6798 - val_loss: 0.6029 - val_binary_accuracy: 0.6646\n",
            "Epoch 155/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6789 - val_loss: 0.6028 - val_binary_accuracy: 0.6661\n",
            "Epoch 156/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6811 - val_loss: 0.6031 - val_binary_accuracy: 0.6677\n",
            "Epoch 157/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6805 - val_loss: 0.6028 - val_binary_accuracy: 0.6658\n",
            "Epoch 158/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6764 - val_loss: 0.6028 - val_binary_accuracy: 0.6654\n",
            "Epoch 159/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6794 - val_loss: 0.6028 - val_binary_accuracy: 0.6658\n",
            "Epoch 160/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6776 - val_loss: 0.6027 - val_binary_accuracy: 0.6646\n",
            "Epoch 161/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6772 - val_loss: 0.6031 - val_binary_accuracy: 0.6654\n",
            "Epoch 162/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6780 - val_loss: 0.6028 - val_binary_accuracy: 0.6665\n",
            "Epoch 163/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6790 - val_loss: 0.6028 - val_binary_accuracy: 0.6669\n",
            "Epoch 164/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6818 - val_loss: 0.6028 - val_binary_accuracy: 0.6681\n",
            "Epoch 165/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6809 - val_loss: 0.6029 - val_binary_accuracy: 0.6658\n",
            "Epoch 166/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6776 - val_loss: 0.6029 - val_binary_accuracy: 0.6658\n",
            "Epoch 167/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6781 - val_loss: 0.6026 - val_binary_accuracy: 0.6658\n",
            "Epoch 168/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6788 - val_loss: 0.6025 - val_binary_accuracy: 0.6665\n",
            "Epoch 169/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6773 - val_loss: 0.6024 - val_binary_accuracy: 0.6658\n",
            "Epoch 170/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6776 - val_loss: 0.6025 - val_binary_accuracy: 0.6642\n",
            "Epoch 171/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6820 - val_loss: 0.6023 - val_binary_accuracy: 0.6646\n",
            "Epoch 172/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6798 - val_loss: 0.6026 - val_binary_accuracy: 0.6677\n",
            "Epoch 173/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6806 - val_loss: 0.6024 - val_binary_accuracy: 0.6661\n",
            "Epoch 174/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6772 - val_loss: 0.6026 - val_binary_accuracy: 0.6654\n",
            "Epoch 175/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6792 - val_loss: 0.6027 - val_binary_accuracy: 0.6642\n",
            "Epoch 176/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6821 - val_loss: 0.6024 - val_binary_accuracy: 0.6646\n",
            "Epoch 177/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6799 - val_loss: 0.6026 - val_binary_accuracy: 0.6677\n",
            "Epoch 178/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6828 - val_loss: 0.6028 - val_binary_accuracy: 0.6661\n",
            "Epoch 179/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6800 - val_loss: 0.6030 - val_binary_accuracy: 0.6634\n",
            "Epoch 180/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6802 - val_loss: 0.6028 - val_binary_accuracy: 0.6622\n",
            "Epoch 181/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6788 - val_loss: 0.6023 - val_binary_accuracy: 0.6630\n",
            "Epoch 182/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6775 - val_loss: 0.6026 - val_binary_accuracy: 0.6642\n",
            "Epoch 183/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6820 - val_loss: 0.6024 - val_binary_accuracy: 0.6626\n",
            "Epoch 184/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6845 - val_loss: 0.6026 - val_binary_accuracy: 0.6650\n",
            "Epoch 185/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6812 - val_loss: 0.6023 - val_binary_accuracy: 0.6650\n",
            "Epoch 186/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6768 - val_loss: 0.6022 - val_binary_accuracy: 0.6642\n",
            "Epoch 187/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6808 - val_loss: 0.6023 - val_binary_accuracy: 0.6622\n",
            "Epoch 188/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6818 - val_loss: 0.6023 - val_binary_accuracy: 0.6630\n",
            "Epoch 189/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6792 - val_loss: 0.6024 - val_binary_accuracy: 0.6654\n",
            "Epoch 190/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6802 - val_loss: 0.6023 - val_binary_accuracy: 0.6650\n",
            "Epoch 191/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6787 - val_loss: 0.6023 - val_binary_accuracy: 0.6622\n",
            "Epoch 192/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6810 - val_loss: 0.6024 - val_binary_accuracy: 0.6630\n",
            "Epoch 193/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6821 - val_loss: 0.6024 - val_binary_accuracy: 0.6626\n",
            "Epoch 194/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6836 - val_loss: 0.6024 - val_binary_accuracy: 0.6626\n",
            "Epoch 195/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6794 - val_loss: 0.6023 - val_binary_accuracy: 0.6630\n",
            "Epoch 196/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6799 - val_loss: 0.6021 - val_binary_accuracy: 0.6622\n",
            "Epoch 197/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6834 - val_loss: 0.6021 - val_binary_accuracy: 0.6622\n",
            "Epoch 198/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6829 - val_loss: 0.6021 - val_binary_accuracy: 0.6669\n",
            "Epoch 199/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6848 - val_loss: 0.6021 - val_binary_accuracy: 0.6614\n",
            "Epoch 200/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6834 - val_loss: 0.6023 - val_binary_accuracy: 0.6607\n",
            "Epoch 201/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6784 - val_loss: 0.6021 - val_binary_accuracy: 0.6634\n",
            "Epoch 202/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6823 - val_loss: 0.6023 - val_binary_accuracy: 0.6626\n",
            "Epoch 203/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6841 - val_loss: 0.6024 - val_binary_accuracy: 0.6630\n",
            "Epoch 204/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6804 - val_loss: 0.6024 - val_binary_accuracy: 0.6638\n",
            "Epoch 205/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6796 - val_loss: 0.6024 - val_binary_accuracy: 0.6626\n",
            "Epoch 206/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6816 - val_loss: 0.6021 - val_binary_accuracy: 0.6622\n",
            "Epoch 207/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6810 - val_loss: 0.6020 - val_binary_accuracy: 0.6630\n",
            "Epoch 208/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6823 - val_loss: 0.6019 - val_binary_accuracy: 0.6611\n",
            "Epoch 209/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6830 - val_loss: 0.6019 - val_binary_accuracy: 0.6654\n",
            "Epoch 210/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6809 - val_loss: 0.6020 - val_binary_accuracy: 0.6618\n",
            "Epoch 211/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5943 - binary_accuracy: 0.6904 - val_loss: 0.6015 - val_binary_accuracy: 0.6607\n",
            "Epoch 212/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6820 - val_loss: 0.6015 - val_binary_accuracy: 0.6614\n",
            "Epoch 213/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6809 - val_loss: 0.6016 - val_binary_accuracy: 0.6642\n",
            "Epoch 214/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6842 - val_loss: 0.6016 - val_binary_accuracy: 0.6614\n",
            "Epoch 215/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6827 - val_loss: 0.6016 - val_binary_accuracy: 0.6622\n",
            "Epoch 216/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6839 - val_loss: 0.6015 - val_binary_accuracy: 0.6634\n",
            "Epoch 217/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6801 - val_loss: 0.6017 - val_binary_accuracy: 0.6626\n",
            "Epoch 218/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6826 - val_loss: 0.6018 - val_binary_accuracy: 0.6618\n",
            "Epoch 219/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6865 - val_loss: 0.6017 - val_binary_accuracy: 0.6618\n",
            "Epoch 220/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5940 - binary_accuracy: 0.6845 - val_loss: 0.6015 - val_binary_accuracy: 0.6618\n",
            "Epoch 221/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6881 - val_loss: 0.6017 - val_binary_accuracy: 0.6642\n",
            "Epoch 222/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6844 - val_loss: 0.6017 - val_binary_accuracy: 0.6638\n",
            "Epoch 223/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5952 - binary_accuracy: 0.6829 - val_loss: 0.6019 - val_binary_accuracy: 0.6614\n",
            "Epoch 224/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6808 - val_loss: 0.6016 - val_binary_accuracy: 0.6665\n",
            "Epoch 225/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6794 - val_loss: 0.6017 - val_binary_accuracy: 0.6669\n",
            "Epoch 226/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6823 - val_loss: 0.6020 - val_binary_accuracy: 0.6614\n",
            "Epoch 227/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.6854 - val_loss: 0.6017 - val_binary_accuracy: 0.6650\n",
            "Epoch 228/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6820 - val_loss: 0.6019 - val_binary_accuracy: 0.6658\n",
            "Epoch 229/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6885 - val_loss: 0.6017 - val_binary_accuracy: 0.6642\n",
            "Epoch 230/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6850 - val_loss: 0.6017 - val_binary_accuracy: 0.6630\n",
            "Epoch 231/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6811 - val_loss: 0.6015 - val_binary_accuracy: 0.6618\n",
            "Epoch 232/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6854 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 233/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6848 - val_loss: 0.6019 - val_binary_accuracy: 0.6661\n",
            "Epoch 234/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5944 - binary_accuracy: 0.6823 - val_loss: 0.6018 - val_binary_accuracy: 0.6638\n",
            "Epoch 235/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5952 - binary_accuracy: 0.6807 - val_loss: 0.6016 - val_binary_accuracy: 0.6646\n",
            "Epoch 236/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6881 - val_loss: 0.6017 - val_binary_accuracy: 0.6630\n",
            "Epoch 237/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5942 - binary_accuracy: 0.6831 - val_loss: 0.6015 - val_binary_accuracy: 0.6658\n",
            "Epoch 238/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.6856 - val_loss: 0.6017 - val_binary_accuracy: 0.6665\n",
            "Epoch 239/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6846 - val_loss: 0.6014 - val_binary_accuracy: 0.6622\n",
            "Epoch 240/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6839 - val_loss: 0.6013 - val_binary_accuracy: 0.6654\n",
            "Epoch 241/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5926 - binary_accuracy: 0.6848 - val_loss: 0.6015 - val_binary_accuracy: 0.6611\n",
            "Epoch 242/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6866 - val_loss: 0.6016 - val_binary_accuracy: 0.6626\n",
            "Epoch 243/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6817 - val_loss: 0.6015 - val_binary_accuracy: 0.6622\n",
            "Epoch 244/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5944 - binary_accuracy: 0.6899 - val_loss: 0.6014 - val_binary_accuracy: 0.6638\n",
            "Epoch 245/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5938 - binary_accuracy: 0.6905 - val_loss: 0.6014 - val_binary_accuracy: 0.6622\n",
            "Epoch 246/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5957 - binary_accuracy: 0.6847 - val_loss: 0.6014 - val_binary_accuracy: 0.6658\n",
            "Epoch 247/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6868 - val_loss: 0.6014 - val_binary_accuracy: 0.6658\n",
            "Epoch 248/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5902 - binary_accuracy: 0.6910 - val_loss: 0.6016 - val_binary_accuracy: 0.6630\n",
            "Epoch 249/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6808 - val_loss: 0.6016 - val_binary_accuracy: 0.6626\n",
            "Epoch 250/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.6838 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 251/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5937 - binary_accuracy: 0.6848 - val_loss: 0.6015 - val_binary_accuracy: 0.6642\n",
            "Epoch 252/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.6855 - val_loss: 0.6013 - val_binary_accuracy: 0.6661\n",
            "Epoch 253/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5940 - binary_accuracy: 0.6859 - val_loss: 0.6013 - val_binary_accuracy: 0.6650\n",
            "Epoch 254/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5922 - binary_accuracy: 0.6863 - val_loss: 0.6015 - val_binary_accuracy: 0.6634\n",
            "Epoch 255/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5943 - binary_accuracy: 0.6848 - val_loss: 0.6015 - val_binary_accuracy: 0.6642\n",
            "Epoch 256/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6867 - val_loss: 0.6016 - val_binary_accuracy: 0.6638\n",
            "Epoch 257/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5907 - binary_accuracy: 0.6878 - val_loss: 0.6015 - val_binary_accuracy: 0.6626\n",
            "Epoch 258/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5944 - binary_accuracy: 0.6845 - val_loss: 0.6013 - val_binary_accuracy: 0.6630\n",
            "Epoch 259/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6857 - val_loss: 0.6013 - val_binary_accuracy: 0.6658\n",
            "Epoch 260/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6808 - val_loss: 0.6015 - val_binary_accuracy: 0.6658\n",
            "Epoch 261/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.6859 - val_loss: 0.6012 - val_binary_accuracy: 0.6626\n",
            "Epoch 262/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5928 - binary_accuracy: 0.6879 - val_loss: 0.6015 - val_binary_accuracy: 0.6646\n",
            "Epoch 263/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6873 - val_loss: 0.6014 - val_binary_accuracy: 0.6626\n",
            "Epoch 264/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6895 - val_loss: 0.6014 - val_binary_accuracy: 0.6614\n",
            "Epoch 265/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5927 - binary_accuracy: 0.6877 - val_loss: 0.6013 - val_binary_accuracy: 0.6603\n",
            "Epoch 266/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5920 - binary_accuracy: 0.6898 - val_loss: 0.6015 - val_binary_accuracy: 0.6611\n",
            "Epoch 267/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.6866 - val_loss: 0.6015 - val_binary_accuracy: 0.6642\n",
            "Epoch 268/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5911 - binary_accuracy: 0.6921 - val_loss: 0.6015 - val_binary_accuracy: 0.6611\n",
            "Epoch 269/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5917 - binary_accuracy: 0.6873 - val_loss: 0.6014 - val_binary_accuracy: 0.6614\n",
            "Epoch 270/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6843 - val_loss: 0.6014 - val_binary_accuracy: 0.6614\n",
            "Epoch 271/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6890 - val_loss: 0.6015 - val_binary_accuracy: 0.6661\n",
            "Epoch 272/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5933 - binary_accuracy: 0.6875 - val_loss: 0.6016 - val_binary_accuracy: 0.6638\n",
            "Epoch 273/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5887 - binary_accuracy: 0.6938 - val_loss: 0.6017 - val_binary_accuracy: 0.6607\n",
            "Epoch 274/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5942 - binary_accuracy: 0.6888 - val_loss: 0.6016 - val_binary_accuracy: 0.6611\n",
            "Epoch 275/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5923 - binary_accuracy: 0.6874 - val_loss: 0.6013 - val_binary_accuracy: 0.6661\n",
            "Epoch 276/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.6863 - val_loss: 0.6012 - val_binary_accuracy: 0.6654\n",
            "Epoch 277/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5909 - binary_accuracy: 0.6916 - val_loss: 0.6013 - val_binary_accuracy: 0.6642\n",
            "Epoch 278/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6789 - val_loss: 0.6014 - val_binary_accuracy: 0.6642\n",
            "Epoch 279/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5905 - binary_accuracy: 0.6869 - val_loss: 0.6014 - val_binary_accuracy: 0.6622\n",
            "Epoch 280/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5938 - binary_accuracy: 0.6873 - val_loss: 0.6012 - val_binary_accuracy: 0.6607\n",
            "Epoch 281/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5917 - binary_accuracy: 0.6879 - val_loss: 0.6013 - val_binary_accuracy: 0.6650\n",
            "Epoch 282/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.6888 - val_loss: 0.6012 - val_binary_accuracy: 0.6614\n",
            "Epoch 283/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6861 - val_loss: 0.6014 - val_binary_accuracy: 0.6650\n",
            "Epoch 284/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5913 - binary_accuracy: 0.6849 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 285/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.6875 - val_loss: 0.6015 - val_binary_accuracy: 0.6646\n",
            "Epoch 286/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5919 - binary_accuracy: 0.6854 - val_loss: 0.6013 - val_binary_accuracy: 0.6630\n",
            "Epoch 287/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5928 - binary_accuracy: 0.6876 - val_loss: 0.6013 - val_binary_accuracy: 0.6618\n",
            "Epoch 288/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6915 - val_loss: 0.6013 - val_binary_accuracy: 0.6638\n",
            "Epoch 289/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5914 - binary_accuracy: 0.6876 - val_loss: 0.6014 - val_binary_accuracy: 0.6622\n",
            "Epoch 290/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5899 - binary_accuracy: 0.6910 - val_loss: 0.6015 - val_binary_accuracy: 0.6622\n",
            "Epoch 291/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6874 - val_loss: 0.6015 - val_binary_accuracy: 0.6607\n",
            "Epoch 292/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5894 - binary_accuracy: 0.6909 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 293/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5933 - binary_accuracy: 0.6857 - val_loss: 0.6013 - val_binary_accuracy: 0.6614\n",
            "Epoch 294/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5916 - binary_accuracy: 0.6904 - val_loss: 0.6014 - val_binary_accuracy: 0.6611\n",
            "Epoch 295/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5921 - binary_accuracy: 0.6848 - val_loss: 0.6017 - val_binary_accuracy: 0.6587\n",
            "Epoch 296/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5908 - binary_accuracy: 0.6892 - val_loss: 0.6014 - val_binary_accuracy: 0.6603\n",
            "Epoch 297/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5903 - binary_accuracy: 0.6873 - val_loss: 0.6016 - val_binary_accuracy: 0.6599\n",
            "Epoch 298/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5916 - binary_accuracy: 0.6861 - val_loss: 0.6016 - val_binary_accuracy: 0.6607\n",
            "Epoch 299/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5922 - binary_accuracy: 0.6915 - val_loss: 0.6017 - val_binary_accuracy: 0.6614\n",
            "Epoch 300/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.6921 - val_loss: 0.6014 - val_binary_accuracy: 0.6599\n",
            "Epoch 301/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5913 - binary_accuracy: 0.6859 - val_loss: 0.6015 - val_binary_accuracy: 0.6614\n",
            "Epoch 302/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5934 - binary_accuracy: 0.6904 - val_loss: 0.6013 - val_binary_accuracy: 0.6599\n",
            "Epoch 303/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5907 - binary_accuracy: 0.6895 - val_loss: 0.6015 - val_binary_accuracy: 0.6599\n",
            "Epoch 304/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.6881 - val_loss: 0.6016 - val_binary_accuracy: 0.6599\n",
            "Epoch 305/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5909 - binary_accuracy: 0.6902 - val_loss: 0.6016 - val_binary_accuracy: 0.6611\n",
            "Epoch 306/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6896 - val_loss: 0.6018 - val_binary_accuracy: 0.6595\n",
            "Epoch 307/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6854 - val_loss: 0.6017 - val_binary_accuracy: 0.6611\n",
            "Epoch 308/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5922 - binary_accuracy: 0.6906 - val_loss: 0.6017 - val_binary_accuracy: 0.6591\n",
            "Epoch 309/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6899 - val_loss: 0.6015 - val_binary_accuracy: 0.6607\n",
            "Epoch 310/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5906 - binary_accuracy: 0.6906 - val_loss: 0.6016 - val_binary_accuracy: 0.6614\n",
            "Epoch 311/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5897 - binary_accuracy: 0.6902 - val_loss: 0.6014 - val_binary_accuracy: 0.6614\n",
            "Epoch 312/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5917 - binary_accuracy: 0.6855 - val_loss: 0.6016 - val_binary_accuracy: 0.6618\n",
            "Epoch 313/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5895 - binary_accuracy: 0.6895 - val_loss: 0.6015 - val_binary_accuracy: 0.6599\n",
            "Epoch 314/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5894 - binary_accuracy: 0.6868 - val_loss: 0.6016 - val_binary_accuracy: 0.6618\n",
            "Epoch 315/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5921 - binary_accuracy: 0.6862 - val_loss: 0.6015 - val_binary_accuracy: 0.6611\n",
            "Epoch 316/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5915 - binary_accuracy: 0.6893 - val_loss: 0.6013 - val_binary_accuracy: 0.6614\n",
            "Epoch 317/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5911 - binary_accuracy: 0.6877 - val_loss: 0.6012 - val_binary_accuracy: 0.6622\n",
            "Epoch 318/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.6922 - val_loss: 0.6013 - val_binary_accuracy: 0.6614\n",
            "Epoch 319/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5891 - binary_accuracy: 0.6857 - val_loss: 0.6016 - val_binary_accuracy: 0.6618\n",
            "Epoch 320/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5918 - binary_accuracy: 0.6930 - val_loss: 0.6012 - val_binary_accuracy: 0.6611\n",
            "Epoch 321/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.6942 - val_loss: 0.6012 - val_binary_accuracy: 0.6614\n",
            "Epoch 322/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5886 - binary_accuracy: 0.6919 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 323/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5893 - binary_accuracy: 0.6904 - val_loss: 0.6012 - val_binary_accuracy: 0.6614\n",
            "Epoch 324/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6890 - val_loss: 0.6011 - val_binary_accuracy: 0.6630\n",
            "Epoch 325/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5890 - binary_accuracy: 0.6863 - val_loss: 0.6016 - val_binary_accuracy: 0.6638\n",
            "Epoch 326/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5891 - binary_accuracy: 0.6906 - val_loss: 0.6013 - val_binary_accuracy: 0.6618\n",
            "Epoch 327/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5890 - binary_accuracy: 0.6895 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 328/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5897 - binary_accuracy: 0.6884 - val_loss: 0.6014 - val_binary_accuracy: 0.6618\n",
            "Epoch 329/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5887 - binary_accuracy: 0.6895 - val_loss: 0.6012 - val_binary_accuracy: 0.6622\n",
            "Epoch 330/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5917 - binary_accuracy: 0.6870 - val_loss: 0.6010 - val_binary_accuracy: 0.6638\n",
            "Epoch 331/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5895 - binary_accuracy: 0.6941 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 332/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5884 - binary_accuracy: 0.6910 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 333/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5898 - binary_accuracy: 0.6917 - val_loss: 0.6012 - val_binary_accuracy: 0.6626\n",
            "Epoch 334/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5886 - binary_accuracy: 0.6902 - val_loss: 0.6011 - val_binary_accuracy: 0.6630\n",
            "Epoch 335/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5897 - binary_accuracy: 0.6894 - val_loss: 0.6011 - val_binary_accuracy: 0.6618\n",
            "Epoch 336/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5856 - binary_accuracy: 0.6917 - val_loss: 0.6012 - val_binary_accuracy: 0.6614\n",
            "Epoch 337/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.6895 - val_loss: 0.6009 - val_binary_accuracy: 0.6622\n",
            "Epoch 338/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5881 - binary_accuracy: 0.6928 - val_loss: 0.6012 - val_binary_accuracy: 0.6622\n",
            "Epoch 339/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5886 - binary_accuracy: 0.6952 - val_loss: 0.6011 - val_binary_accuracy: 0.6611\n",
            "Epoch 340/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5889 - binary_accuracy: 0.6884 - val_loss: 0.6009 - val_binary_accuracy: 0.6622\n",
            "Epoch 341/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5889 - binary_accuracy: 0.6921 - val_loss: 0.6008 - val_binary_accuracy: 0.6614\n",
            "Epoch 342/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5910 - binary_accuracy: 0.6888 - val_loss: 0.6009 - val_binary_accuracy: 0.6634\n",
            "Epoch 343/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5905 - binary_accuracy: 0.6894 - val_loss: 0.6010 - val_binary_accuracy: 0.6630\n",
            "Epoch 344/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5891 - binary_accuracy: 0.6897 - val_loss: 0.6011 - val_binary_accuracy: 0.6630\n",
            "Epoch 345/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5897 - binary_accuracy: 0.6899 - val_loss: 0.6010 - val_binary_accuracy: 0.6646\n",
            "Epoch 346/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5858 - binary_accuracy: 0.6912 - val_loss: 0.6010 - val_binary_accuracy: 0.6630\n",
            "Epoch 347/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6895 - val_loss: 0.6010 - val_binary_accuracy: 0.6626\n",
            "Epoch 348/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5880 - binary_accuracy: 0.6884 - val_loss: 0.6011 - val_binary_accuracy: 0.6626\n",
            "Epoch 349/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5874 - binary_accuracy: 0.6889 - val_loss: 0.6012 - val_binary_accuracy: 0.6630\n",
            "Epoch 350/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5874 - binary_accuracy: 0.6917 - val_loss: 0.6012 - val_binary_accuracy: 0.6626\n",
            "Epoch 351/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5878 - binary_accuracy: 0.6881 - val_loss: 0.6012 - val_binary_accuracy: 0.6630\n",
            "Epoch 352/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6909 - val_loss: 0.6011 - val_binary_accuracy: 0.6638\n",
            "Epoch 353/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5889 - binary_accuracy: 0.6913 - val_loss: 0.6011 - val_binary_accuracy: 0.6638\n",
            "Epoch 354/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.6860 - val_loss: 0.6012 - val_binary_accuracy: 0.6630\n",
            "Epoch 355/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.6903 - val_loss: 0.6012 - val_binary_accuracy: 0.6626\n",
            "Epoch 356/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5879 - binary_accuracy: 0.6912 - val_loss: 0.6013 - val_binary_accuracy: 0.6607\n",
            "Epoch 357/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.6920 - val_loss: 0.6013 - val_binary_accuracy: 0.6622\n",
            "Epoch 358/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5874 - binary_accuracy: 0.6941 - val_loss: 0.6013 - val_binary_accuracy: 0.6630\n",
            "Epoch 359/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5880 - binary_accuracy: 0.6951 - val_loss: 0.6014 - val_binary_accuracy: 0.6634\n",
            "Epoch 360/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5882 - binary_accuracy: 0.6938 - val_loss: 0.6012 - val_binary_accuracy: 0.6618\n",
            "Epoch 361/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5873 - binary_accuracy: 0.6936 - val_loss: 0.6011 - val_binary_accuracy: 0.6630\n",
            "Epoch 362/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6883 - val_loss: 0.6011 - val_binary_accuracy: 0.6622\n",
            "Epoch 363/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5856 - binary_accuracy: 0.6946 - val_loss: 0.6011 - val_binary_accuracy: 0.6614\n",
            "Epoch 364/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5907 - binary_accuracy: 0.6890 - val_loss: 0.6012 - val_binary_accuracy: 0.6642\n",
            "Epoch 365/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6899 - val_loss: 0.6013 - val_binary_accuracy: 0.6630\n",
            "Epoch 366/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5878 - binary_accuracy: 0.6911 - val_loss: 0.6013 - val_binary_accuracy: 0.6626\n",
            "Epoch 367/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5855 - binary_accuracy: 0.6918 - val_loss: 0.6017 - val_binary_accuracy: 0.6622\n",
            "Epoch 368/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5847 - binary_accuracy: 0.6953 - val_loss: 0.6018 - val_binary_accuracy: 0.6646\n",
            "Epoch 369/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5862 - binary_accuracy: 0.6953 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 370/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.6906 - val_loss: 0.6014 - val_binary_accuracy: 0.6638\n",
            "Epoch 371/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5856 - binary_accuracy: 0.6931 - val_loss: 0.6017 - val_binary_accuracy: 0.6626\n",
            "Epoch 372/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5875 - binary_accuracy: 0.6957 - val_loss: 0.6016 - val_binary_accuracy: 0.6618\n",
            "Epoch 373/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.6915 - val_loss: 0.6016 - val_binary_accuracy: 0.6622\n",
            "Epoch 374/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5864 - binary_accuracy: 0.6900 - val_loss: 0.6016 - val_binary_accuracy: 0.6634\n",
            "Epoch 375/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5855 - binary_accuracy: 0.6926 - val_loss: 0.6016 - val_binary_accuracy: 0.6626\n",
            "Epoch 376/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5848 - binary_accuracy: 0.6928 - val_loss: 0.6016 - val_binary_accuracy: 0.6630\n",
            "Epoch 377/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5865 - binary_accuracy: 0.6919 - val_loss: 0.6014 - val_binary_accuracy: 0.6634\n",
            "Epoch 378/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5882 - binary_accuracy: 0.6931 - val_loss: 0.6015 - val_binary_accuracy: 0.6646\n",
            "Epoch 379/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5875 - binary_accuracy: 0.6910 - val_loss: 0.6014 - val_binary_accuracy: 0.6646\n",
            "Epoch 380/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5888 - binary_accuracy: 0.6904 - val_loss: 0.6015 - val_binary_accuracy: 0.6634\n",
            "Epoch 381/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5861 - binary_accuracy: 0.6949 - val_loss: 0.6013 - val_binary_accuracy: 0.6646\n",
            "Epoch 382/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5844 - binary_accuracy: 0.6945 - val_loss: 0.6015 - val_binary_accuracy: 0.6646\n",
            "Epoch 383/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5840 - binary_accuracy: 0.6938 - val_loss: 0.6012 - val_binary_accuracy: 0.6634\n",
            "Epoch 384/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.6950 - val_loss: 0.6012 - val_binary_accuracy: 0.6634\n",
            "Epoch 385/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5858 - binary_accuracy: 0.6898 - val_loss: 0.6017 - val_binary_accuracy: 0.6638\n",
            "Epoch 386/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5866 - binary_accuracy: 0.6964 - val_loss: 0.6014 - val_binary_accuracy: 0.6638\n",
            "Epoch 387/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5880 - binary_accuracy: 0.6946 - val_loss: 0.6012 - val_binary_accuracy: 0.6646\n",
            "Epoch 388/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.6894 - val_loss: 0.6014 - val_binary_accuracy: 0.6642\n",
            "Epoch 389/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5849 - binary_accuracy: 0.6921 - val_loss: 0.6014 - val_binary_accuracy: 0.6642\n",
            "Epoch 390/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.6919 - val_loss: 0.6017 - val_binary_accuracy: 0.6638\n",
            "Epoch 391/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.6900 - val_loss: 0.6016 - val_binary_accuracy: 0.6634\n",
            "Epoch 392/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5867 - binary_accuracy: 0.6920 - val_loss: 0.6017 - val_binary_accuracy: 0.6614\n",
            "Epoch 393/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5842 - binary_accuracy: 0.6917 - val_loss: 0.6015 - val_binary_accuracy: 0.6630\n",
            "Epoch 394/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5853 - binary_accuracy: 0.6946 - val_loss: 0.6016 - val_binary_accuracy: 0.6626\n",
            "Epoch 395/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5842 - binary_accuracy: 0.6946 - val_loss: 0.6016 - val_binary_accuracy: 0.6642\n",
            "Epoch 396/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.6902 - val_loss: 0.6015 - val_binary_accuracy: 0.6626\n",
            "Epoch 397/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5850 - binary_accuracy: 0.6929 - val_loss: 0.6016 - val_binary_accuracy: 0.6650\n",
            "Epoch 398/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5858 - binary_accuracy: 0.6921 - val_loss: 0.6016 - val_binary_accuracy: 0.6630\n",
            "Epoch 399/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5845 - binary_accuracy: 0.6956 - val_loss: 0.6021 - val_binary_accuracy: 0.6630\n",
            "Epoch 400/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5871 - binary_accuracy: 0.6911 - val_loss: 0.6019 - val_binary_accuracy: 0.6634\n",
            "Epoch 401/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5860 - binary_accuracy: 0.6905 - val_loss: 0.6019 - val_binary_accuracy: 0.6614\n",
            "Epoch 402/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5866 - binary_accuracy: 0.6927 - val_loss: 0.6019 - val_binary_accuracy: 0.6626\n",
            "Epoch 403/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5864 - binary_accuracy: 0.6946 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 404/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5872 - binary_accuracy: 0.6874 - val_loss: 0.6016 - val_binary_accuracy: 0.6630\n",
            "Epoch 405/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5864 - binary_accuracy: 0.6934 - val_loss: 0.6016 - val_binary_accuracy: 0.6642\n",
            "Epoch 406/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5829 - binary_accuracy: 0.6944 - val_loss: 0.6018 - val_binary_accuracy: 0.6634\n",
            "Epoch 407/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5819 - binary_accuracy: 0.6959 - val_loss: 0.6020 - val_binary_accuracy: 0.6634\n",
            "Epoch 408/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5855 - binary_accuracy: 0.6908 - val_loss: 0.6019 - val_binary_accuracy: 0.6642\n",
            "Epoch 409/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5843 - binary_accuracy: 0.6938 - val_loss: 0.6017 - val_binary_accuracy: 0.6634\n",
            "Epoch 410/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5849 - binary_accuracy: 0.6953 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 411/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5846 - binary_accuracy: 0.6894 - val_loss: 0.6017 - val_binary_accuracy: 0.6622\n",
            "Epoch 412/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5853 - binary_accuracy: 0.6930 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 413/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5856 - binary_accuracy: 0.6955 - val_loss: 0.6017 - val_binary_accuracy: 0.6626\n",
            "Epoch 414/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5866 - binary_accuracy: 0.6902 - val_loss: 0.6017 - val_binary_accuracy: 0.6622\n",
            "Epoch 415/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5867 - binary_accuracy: 0.6935 - val_loss: 0.6015 - val_binary_accuracy: 0.6622\n",
            "Epoch 416/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5836 - binary_accuracy: 0.6962 - val_loss: 0.6020 - val_binary_accuracy: 0.6611\n",
            "Epoch 417/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5852 - binary_accuracy: 0.6914 - val_loss: 0.6018 - val_binary_accuracy: 0.6622\n",
            "Epoch 418/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5860 - binary_accuracy: 0.6946 - val_loss: 0.6017 - val_binary_accuracy: 0.6626\n",
            "Epoch 419/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5834 - binary_accuracy: 0.6885 - val_loss: 0.6019 - val_binary_accuracy: 0.6646\n",
            "Epoch 420/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.6913 - val_loss: 0.6018 - val_binary_accuracy: 0.6638\n",
            "Epoch 421/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5837 - binary_accuracy: 0.6946 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 422/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5858 - binary_accuracy: 0.6909 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 423/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5849 - binary_accuracy: 0.6925 - val_loss: 0.6019 - val_binary_accuracy: 0.6650\n",
            "Epoch 424/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5838 - binary_accuracy: 0.6985 - val_loss: 0.6017 - val_binary_accuracy: 0.6650\n",
            "Epoch 425/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5814 - binary_accuracy: 0.6947 - val_loss: 0.6017 - val_binary_accuracy: 0.6618\n",
            "Epoch 426/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5861 - binary_accuracy: 0.6927 - val_loss: 0.6017 - val_binary_accuracy: 0.6642\n",
            "Epoch 427/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5852 - binary_accuracy: 0.6956 - val_loss: 0.6017 - val_binary_accuracy: 0.6646\n",
            "Epoch 428/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5859 - binary_accuracy: 0.6940 - val_loss: 0.6017 - val_binary_accuracy: 0.6642\n",
            "Epoch 429/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5870 - binary_accuracy: 0.6915 - val_loss: 0.6015 - val_binary_accuracy: 0.6646\n",
            "Epoch 430/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5835 - binary_accuracy: 0.6971 - val_loss: 0.6019 - val_binary_accuracy: 0.6642\n",
            "Epoch 431/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5832 - binary_accuracy: 0.6975 - val_loss: 0.6019 - val_binary_accuracy: 0.6638\n",
            "Epoch 432/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5845 - binary_accuracy: 0.6941 - val_loss: 0.6019 - val_binary_accuracy: 0.6658\n",
            "Epoch 433/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5823 - binary_accuracy: 0.6931 - val_loss: 0.6023 - val_binary_accuracy: 0.6630\n",
            "Epoch 434/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5849 - binary_accuracy: 0.6961 - val_loss: 0.6019 - val_binary_accuracy: 0.6634\n",
            "Epoch 435/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5848 - binary_accuracy: 0.6938 - val_loss: 0.6018 - val_binary_accuracy: 0.6642\n",
            "Epoch 436/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5859 - binary_accuracy: 0.6935 - val_loss: 0.6019 - val_binary_accuracy: 0.6622\n",
            "Epoch 437/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5826 - binary_accuracy: 0.6934 - val_loss: 0.6019 - val_binary_accuracy: 0.6626\n",
            "Epoch 438/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5847 - binary_accuracy: 0.6949 - val_loss: 0.6019 - val_binary_accuracy: 0.6630\n",
            "Epoch 439/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5853 - binary_accuracy: 0.6974 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 440/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5847 - binary_accuracy: 0.6924 - val_loss: 0.6019 - val_binary_accuracy: 0.6646\n",
            "Epoch 441/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5854 - binary_accuracy: 0.6913 - val_loss: 0.6019 - val_binary_accuracy: 0.6618\n",
            "Epoch 442/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5816 - binary_accuracy: 0.6973 - val_loss: 0.6020 - val_binary_accuracy: 0.6626\n",
            "Epoch 443/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5828 - binary_accuracy: 0.6964 - val_loss: 0.6016 - val_binary_accuracy: 0.6630\n",
            "Epoch 444/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5831 - binary_accuracy: 0.6983 - val_loss: 0.6018 - val_binary_accuracy: 0.6634\n",
            "Epoch 445/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5823 - binary_accuracy: 0.6956 - val_loss: 0.6018 - val_binary_accuracy: 0.6630\n",
            "Epoch 446/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5826 - binary_accuracy: 0.6945 - val_loss: 0.6019 - val_binary_accuracy: 0.6642\n",
            "Epoch 447/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5841 - binary_accuracy: 0.6931 - val_loss: 0.6018 - val_binary_accuracy: 0.6646\n",
            "Epoch 448/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5827 - binary_accuracy: 0.6958 - val_loss: 0.6018 - val_binary_accuracy: 0.6650\n",
            "Epoch 449/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5820 - binary_accuracy: 0.6946 - val_loss: 0.6015 - val_binary_accuracy: 0.6654\n",
            "Epoch 450/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5829 - binary_accuracy: 0.6973 - val_loss: 0.6015 - val_binary_accuracy: 0.6650\n",
            "Epoch 451/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5806 - binary_accuracy: 0.6952 - val_loss: 0.6015 - val_binary_accuracy: 0.6661\n",
            "Epoch 452/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5838 - binary_accuracy: 0.6959 - val_loss: 0.6016 - val_binary_accuracy: 0.6646\n",
            "Epoch 453/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5847 - binary_accuracy: 0.6948 - val_loss: 0.6017 - val_binary_accuracy: 0.6638\n",
            "Epoch 454/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5821 - binary_accuracy: 0.6960 - val_loss: 0.6016 - val_binary_accuracy: 0.6646\n",
            "Epoch 455/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5854 - binary_accuracy: 0.6948 - val_loss: 0.6016 - val_binary_accuracy: 0.6646\n",
            "Epoch 456/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.6929 - val_loss: 0.6014 - val_binary_accuracy: 0.6654\n",
            "Epoch 457/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5802 - binary_accuracy: 0.6992 - val_loss: 0.6014 - val_binary_accuracy: 0.6642\n",
            "Epoch 458/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5820 - binary_accuracy: 0.6971 - val_loss: 0.6019 - val_binary_accuracy: 0.6658\n",
            "Epoch 459/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.6967 - val_loss: 0.6018 - val_binary_accuracy: 0.6642\n",
            "Epoch 460/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5819 - binary_accuracy: 0.6931 - val_loss: 0.6018 - val_binary_accuracy: 0.6622\n",
            "Epoch 461/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.6945 - val_loss: 0.6018 - val_binary_accuracy: 0.6661\n",
            "Epoch 462/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.6968 - val_loss: 0.6020 - val_binary_accuracy: 0.6654\n",
            "Epoch 463/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5797 - binary_accuracy: 0.6956 - val_loss: 0.6023 - val_binary_accuracy: 0.6646\n",
            "Epoch 464/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5806 - binary_accuracy: 0.6977 - val_loss: 0.6024 - val_binary_accuracy: 0.6638\n",
            "Epoch 465/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.6972 - val_loss: 0.6025 - val_binary_accuracy: 0.6634\n",
            "Epoch 466/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5817 - binary_accuracy: 0.7004 - val_loss: 0.6018 - val_binary_accuracy: 0.6638\n",
            "Epoch 467/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5828 - binary_accuracy: 0.6949 - val_loss: 0.6021 - val_binary_accuracy: 0.6642\n",
            "Epoch 468/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5808 - binary_accuracy: 0.6961 - val_loss: 0.6024 - val_binary_accuracy: 0.6634\n",
            "Epoch 469/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5818 - binary_accuracy: 0.6974 - val_loss: 0.6021 - val_binary_accuracy: 0.6661\n",
            "Epoch 470/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5815 - binary_accuracy: 0.6948 - val_loss: 0.6023 - val_binary_accuracy: 0.6661\n",
            "Epoch 471/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.6906 - val_loss: 0.6020 - val_binary_accuracy: 0.6665\n",
            "Epoch 472/500\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.5797 - binary_accuracy: 0.6970 - val_loss: 0.6025 - val_binary_accuracy: 0.6646\n",
            "Epoch 473/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5833 - binary_accuracy: 0.6916 - val_loss: 0.6023 - val_binary_accuracy: 0.6646\n",
            "Epoch 474/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5829 - binary_accuracy: 0.6982 - val_loss: 0.6021 - val_binary_accuracy: 0.6654\n",
            "Epoch 475/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5811 - binary_accuracy: 0.6934 - val_loss: 0.6025 - val_binary_accuracy: 0.6642\n",
            "Epoch 476/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5821 - binary_accuracy: 0.6948 - val_loss: 0.6029 - val_binary_accuracy: 0.6626\n",
            "Epoch 477/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5818 - binary_accuracy: 0.6942 - val_loss: 0.6027 - val_binary_accuracy: 0.6638\n",
            "Epoch 478/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5785 - binary_accuracy: 0.6989 - val_loss: 0.6027 - val_binary_accuracy: 0.6618\n",
            "Epoch 479/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5776 - binary_accuracy: 0.7002 - val_loss: 0.6028 - val_binary_accuracy: 0.6626\n",
            "Epoch 480/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5832 - binary_accuracy: 0.6978 - val_loss: 0.6026 - val_binary_accuracy: 0.6603\n",
            "Epoch 481/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5815 - binary_accuracy: 0.6961 - val_loss: 0.6026 - val_binary_accuracy: 0.6634\n",
            "Epoch 482/500\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.5826 - binary_accuracy: 0.6927 - val_loss: 0.6028 - val_binary_accuracy: 0.6638\n",
            "Epoch 483/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5836 - binary_accuracy: 0.6950 - val_loss: 0.6029 - val_binary_accuracy: 0.6630\n",
            "Epoch 484/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5796 - binary_accuracy: 0.7023 - val_loss: 0.6028 - val_binary_accuracy: 0.6634\n",
            "Epoch 485/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5791 - binary_accuracy: 0.7009 - val_loss: 0.6027 - val_binary_accuracy: 0.6642\n",
            "Epoch 486/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5846 - binary_accuracy: 0.6946 - val_loss: 0.6027 - val_binary_accuracy: 0.6634\n",
            "Epoch 487/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5792 - binary_accuracy: 0.6992 - val_loss: 0.6028 - val_binary_accuracy: 0.6634\n",
            "Epoch 488/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5818 - binary_accuracy: 0.6978 - val_loss: 0.6025 - val_binary_accuracy: 0.6638\n",
            "Epoch 489/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5838 - binary_accuracy: 0.6992 - val_loss: 0.6027 - val_binary_accuracy: 0.6634\n",
            "Epoch 490/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5800 - binary_accuracy: 0.7000 - val_loss: 0.6024 - val_binary_accuracy: 0.6642\n",
            "Epoch 491/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5788 - binary_accuracy: 0.6996 - val_loss: 0.6028 - val_binary_accuracy: 0.6642\n",
            "Epoch 492/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5796 - binary_accuracy: 0.6971 - val_loss: 0.6027 - val_binary_accuracy: 0.6638\n",
            "Epoch 493/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5803 - binary_accuracy: 0.6991 - val_loss: 0.6028 - val_binary_accuracy: 0.6642\n",
            "Epoch 494/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5795 - binary_accuracy: 0.6973 - val_loss: 0.6025 - val_binary_accuracy: 0.6642\n",
            "Epoch 495/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5836 - binary_accuracy: 0.6962 - val_loss: 0.6027 - val_binary_accuracy: 0.6646\n",
            "Epoch 496/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.6989 - val_loss: 0.6028 - val_binary_accuracy: 0.6642\n",
            "Epoch 497/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5802 - binary_accuracy: 0.6942 - val_loss: 0.6026 - val_binary_accuracy: 0.6634\n",
            "Epoch 498/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5790 - binary_accuracy: 0.7014 - val_loss: 0.6024 - val_binary_accuracy: 0.6665\n",
            "Epoch 499/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5787 - binary_accuracy: 0.6974 - val_loss: 0.6029 - val_binary_accuracy: 0.6661\n",
            "Epoch 500/500\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.5793 - binary_accuracy: 0.6983 - val_loss: 0.6025 - val_binary_accuracy: 0.6677\n",
            "Accuracy on training data: 0.7163093090057373% \n",
            " Error on training data: 0.2836906909942627\n",
            "Accuracy on test data: 0.6555164456367493% \n",
            " Error on test data: 0.34448355436325073\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "cc84ba14-4c52-4477-e1fe-f3dc4d8636e8"
      },
      "source": [
        "predictionScaler = pickle.load(open(\"scaler691.pkl\", 'rb'))\n",
        "Xnew=np.array([[1.56,2.33,132,170,0.4,0.56,0.5,0.5,1.19,0.71,0.71,1.28,88.3,0.8,0.56,1.13,5.7,1.04,0.62,0.72,1.08,63.3,0.62,0.4,1.00,3.1,1.01,0.71,0.67,1.12,71.4,0.66,0.58,0.94,3.3,0.98,0.73,0.7,0.98,72.1,0.63,0.65,0.86,3.7,0.94,0.69,0.67,0.84,68.1,0.65,0.62,0.93,3.1,1.17,0.65,0.7,1.27,79.1,0.75,0.45,1.16,1.7,1.12,0.64,0.74,1.14,75.7,0.71,0.45,1.10,3.5,1.02,0.7,0.71,1.01,75.1,0.65,0.59,0.93,3.1,1.0,0.67,0.72,0.92,68.7,0.63,0.5,0.94,3.1,1.0,0.68,0.71,0.89,75.3,0.64,0.46,0.94,6.0],\n",
        "               [3.2,1.3,171,35,0.43,0.57,0.5,0.5,1.14,0.61,0.7,1.22,76.9,0.7,0.31,1.15,3.0,1.07,0.64,0.66,1.1,74.5,0.7,0.48,1.10,6.1,1.07,0.69,0.68,1.05,81.3,0.71,0.64,1.03,4.9,1.04,0.66,0.71,0.95,72.5,0.65,0.54,0.98,4.0,0.91,0.78,0.66,0.98,69.6,0.62,0.49,0.79,4.0,1.21,0.67,0.74,1.23,87.4,0.78,0.47,1.18,6.0,1.1,0.68,0.76,1.04,76.5,0.67,0.4,0.99,3.0,1.06,0.69,0.72,1.01,76.9,0.68,0.58,0.98,3.9,1.04,0.6,0.71,0.99,65.1,0.67,0.3,1.11,3.5,0.95,0.69,0.7,0.84,68.4,0.61,0.45,0.89,3.8],\n",
        "               [1.25,3.84,1,20,0.8,0.67,0.55,0.523,1.33,0.63,0.77,1.45,86.6,0.9,0.43,1.43,2.2,1.13,0.54,0.78,1.0,69.4,0.63,0.46,1.17,6.1,1.09,0.66,0.74,1.07,75.3,0.67,0.41,1.02,3.1,1.04,0.62,0.7,0.92,72.0,0.67,0.73,1.08,3.8,1.03,0.65,0.73,0.97,72.7,0.58,0.33,0.90,6.6,1.19,0.58,0.75,1.11,75.3,0.76,0.3,1.31,2.6,1.19,0.61,0.74,1.12,82.8,0.76,0.53,1.24,4.1,1.16,0.69,0.72,1.29,83.4,0.72,0.6,1.04,5.1,1.06,0.66,0.72,1.05,73.2,0.67,0.49,1.01,6.4,1.02,0.65,0.72,0.92,72.1,0.63,0.56,0.96,4.0],\n",
        "               [1.6,2.2,91,139,0.43,0.33,0.5,0.5,1.1,0.69,0.71,1.14,79.7,0.72,0.57,1.05,4.8,1.0,0.64,0.68,0.93,68.8,0.64,0.3,1.00,4.8,0.97,0.69,0.65,1.03,71.9,0.65,0.54,0.94,3.9,0.96,0.61,0.73,0.67,66.5,0.6,0.55,0.98,3.5,0.95,0.74,0.64,1.03,73.3,0.63,0.57,0.84,5.6,1.0,0.69,0.6,1.2,71.7,0.69,0.55,1.00,8.4,0.98,0.6,0.69,0.69,69.9,0.62,0.62,1.02,3.0,0.91,0.66,0.65,0.94,60.0,0.59,0.35,0.89,0.8,0.88,0.74,0.68,0.8,69.8,0.57,0.61,0.78,4.9,0.9425,0.6725000000000001,0.655,0.9075,67.85000000000001,0.6174999999999999,0.5325,0.9225000000000001,4.275],\n",
        "               [1.9,1.83,80,85,0.5,0.0,0.5,0.5,1.2,0.62,0.71,1.32,78.9,0.79,0.38,1.27,1.4,1.1,0.65,0.72,1.07,78.5,0.71,0.53,1.08,3.6,1.04,0.69,0.69,1.0,74.8,0.7,0.62,1.01,2.7,1.01,0.66,0.7,0.96,71.7,0.63,0.56,0.95,4.4,0.92,0.7,0.67,0.85,67.8,0.58,0.54,0.83,5.4,1.41,0.61,0.7,1.39,100.2,1.04,0.29,1.71,2.3,0.98,0.83,0.7,0.94,91.3,0.65,0.8,0.79,3.3,0.71,0.74,0.52,0.77,61.9,0.48,0.55,0.65,3.0,1.1,0.72,0.69,1.11,81.9,0.77,0.52,1.07,1.6,0.64,0.78,0.61,0.36,48.4,0.48,0.46,0.61,3.0],\n",
        "               [1.51,2.45,103,112,0.6,0.5,0.5,0.5,1.17,0.66,0.73,1.19,81.2,0.76,0.5,1.14,6.7,1.16,0.66,0.73,1.24,80.8,0.72,0.54,1.09,5.0,1.15,0.58,0.77,0.99,73.3,0.72,0.23,1.25,3.2,1.07,0.62,0.71,0.94,75.5,0.67,0.6,1.08,5.0,0.94,0.72,0.67,1.02,65.1,0.6,0.42,0.84,4.8,1.03,0.63,0.71,0.94,72.0,0.65,0.46,1.03,5.6,1.02,0.68,0.71,1.03,71.9,0.64,0.44,0.94,9.4,1.0,0.68,0.71,0.91,72.3,0.64,0.52,0.93,6.2,1.0166666666666666,0.6633333333333334,0.71,0.96,72.06666666666666,0.6433333333333334,0.47333333333333333,0.9666666666666667,7.066666666666666,1.0166666666666666,0.6633333333333334,0.71,0.96,72.06666666666666,0.6433333333333334,0.47333333333333333,0.9666666666666667,7.066666666666666],\n",
        "               [1.72,2.00,7,13,0.83,0.79,0.5,0.5,1.27,0.66,0.75,1.36,91.4,0.8,0.4,1.21,7.5,1.23,0.57,0.73,1.18,81.5,0.79,0.52,1.38,4.5,1.2,0.61,0.76,1.18,79.6,0.71,0.59,1.17,6.5,1.11,0.55,0.77,0.96,68.9,0.64,0.55,1.15,5.1,1.09,0.57,0.73,1.01,67.5,0.64,0.25,1.13,6.2,1.17,0.56,0.73,1.07,79.9,0.72,0.42,1.27,6.8,1.15,0.63,0.69,1.21,83.1,0.73,0.56,1.14,4.3,1.09,0.57,0.72,1.05,66.1,0.65,0.23,1.15,4.0,1.09,0.63,0.7,1.06,75.2,0.71,0.47,1.12,3.5,0.97,0.64,0.7,0.83,67.7,0.61,0.45,0.95,4.5],\n",
        "               [1.27,3.54,44,160,0.48,0.36,0.556,0.5,1.15,0.64,0.73,1.23,76.0,0.73,0.34,1.15,6.3,1.1,0.66,0.74,1.05,77.1,0.71,0.55,1.08,5.4,1.03,0.67,0.72,0.94,73.8,0.65,0.49,0.97,5.7,0.99,0.69,0.68,1.0,70.0,0.64,0.57,0.93,3.8,0.93,0.69,0.65,0.94,69.7,0.59,0.49,0.85,6.1,1.11,0.64,0.77,0.88,75.6,0.73,0.56,1.14,4.9,1.08,0.71,0.71,1.12,78.1,0.7,0.5,0.99,5.4,0.94,0.67,0.69,0.9,68.1,0.57,0.53,0.85,7.0,0.93,0.66,0.65,0.87,65.7,0.62,0.42,0.94,3.6,0.88,0.74,0.66,0.89,66.2,0.56,0.67,0.76,6.0],\n",
        "               [1.4,2.36,73,113,0.88,0.6,0.478,0.5,1.25,0.58,0.75,1.18,80.7,0.81,0.27,1.39,3.5,1.2,0.63,0.75,1.22,80.1,0.73,0.55,1.16,5.1,1.2,0.69,0.71,1.43,81.0,0.77,0.39,1.13,4.1,1.19,0.6,0.77,1.09,80.1,0.71,0.52,1.18,6.3,1.09,0.59,0.77,0.84,71.5,0.64,0.59,1.10,5.6,1.2,0.65,0.72,1.22,85.6,0.78,0.56,1.20,5.5,1.17,0.67,0.72,1.23,81.9,0.77,0.43,1.15,3.6,1.11,0.62,0.7,1.08,73.5,0.73,0.26,1.19,3.5,0.99,0.69,0.7,0.97,71.0,0.61,0.46,0.89,4.2,0.92,0.68,0.67,0.85,64.1,0.56,0.54,0.82,4.9],\n",
        "               [1.83,1.91,140,126,0.55,0.48,0.5,0.434,1.14,0.69,0.69,1.22,82.7,0.76,0.58,1.10,4.7,1.08,0.65,0.72,0.99,76.3,0.7,0.48,1.07,3.1,1.03,0.65,0.7,0.94,69.9,0.65,0.31,1.00,3.0,1.02,0.69,0.7,0.97,74.9,0.66,0.47,0.96,4.7,1.0675,0.6699999999999999,0.7024999999999999,1.03,75.95,0.6925,0.46,1.0325,3.875,1.06,0.73,0.65,1.12,85.2,0.72,0.47,0.99,3.6,1.05,0.74,0.68,1.11,80.1,0.73,0.49,0.99,3.4,0.98,0.7,0.68,0.97,72.8,0.65,0.54,0.93,5.0,0.97,0.72,0.7,0.94,68.5,0.64,0.48,0.89,2.2,0.92,0.63,0.69,0.83,58.7,0.58,0.28,0.92,0.6],\n",
        "               [2.73,1.42,150,85,0.67,0.0,0.5,0.5,1.2,0.7,0.66,1.41,87.5,0.79,0.55,1.14,4.4,1.15,0.64,0.77,1.13,77.0,0.71,0.46,1.11,2.7,1.09,0.68,0.63,1.17,78.2,0.77,0.36,1.12,5.5,0.97,0.68,0.73,0.77,68.2,0.64,0.55,0.94,6.3,0.86,0.71,0.59,0.81,66.6,0.53,0.59,0.75,2.8,1.41,0.61,0.7,1.39,100.2,1.04,0.29,1.71,2.3,0.98,0.83,0.7,0.94,91.3,0.65,0.8,0.79,3.3,0.71,0.74,0.52,0.77,61.9,0.48,0.55,0.65,3.0,1.1,0.72,0.69,1.11,81.9,0.77,0.52,1.07,1.6,0.64,0.78,0.61,0.36,48.4,0.48,0.46,0.61,3.0]])\n",
        "Xnew = pd.DataFrame(Xnew, columns=CSV_COLUMN_NAMES2)\n",
        "pokus=predictionScaler.transform(Xnew)\n",
        "model= keras.models.load_model(\"691model.h5\")\n",
        "ynew=(model.predict([pokus]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)\n",
        "\n",
        "\n",
        "\n",
        "#model= keras.models.load_model(\"686model.h5\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.39036605]\n",
            " [0.7086521 ]\n",
            " [0.3340835 ]\n",
            " [0.4286273 ]\n",
            " [0.40556884]\n",
            " [0.41955107]\n",
            " [0.39172646]\n",
            " [0.27470365]\n",
            " [0.34163332]\n",
            " [0.40461916]\n",
            " [0.5113183 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-0x3EQ37uB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvOLjjtq370x"
      },
      "source": [
        "pd.options.display.max_rows = 4000\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDSZ8GXKuje"
      },
      "source": [
        "model.save('/content/save/691model.h5')\n",
        "pickle.dump(predictionScaler, open(\"/content/save/scaler691.pkl\", 'wb'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 100 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "model.layers[0].get_weights()[0][98]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSBrO3pcCHlQ",
        "outputId": "61f3a2f7-e06a-4b0a-b5cb-95f6f4bb5ef3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6683375104427736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGzpVUzOYhY"
      },
      "source": [
        "import shap\n",
        "import xgboost\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','team_one_name','team_two_name']\n",
        "shap.initjs()\n",
        "#explainer = shap.Explainer(model.predict, X_train)\n",
        "#shap_values = explainer.shap_values(np.array([[1.8,1.9,26,23,0.63,0.64,0.509,0.591,1.16,0.68,0.7,1.26,84.3,0.75,0.5,1.11,7.4,1.13,0.64,0.72,1.11,78.0,0.72,0.57,1.13,3.2,1.0,0.67,0.69,0.95,69.3,0.64,0.58,0.95,4.2,0.99,0.65,0.69,0.95,67.7,0.62,0.58,0.94,3.3,1.07,0.66,0.7,1.0675000000000001,74.825,0.6825,0.5575,1.0325000000000002,4.525,1.23,0.6,0.75,1.26,79.4,0.77,0.31,1.29,3.4,1.24,0.61,0.77,1.15,82.8,0.82,0.52,1.35,3.4,1.14,0.62,0.73,1.11,76.1,0.72,0.5,1.16,5.2,1.0,0.68,0.7,0.98,70.2,0.61,0.51,0.90,3.9,0.98,0.69,0.69,0.96,71.7,0.6,0.48,0.87,5.3]])\n",
        "\n",
        "keras_explainer = shap.DeepExplainer(model, shap.sample(X_train, 10))\n",
        "keras_shap_values = keras_explainer.shap_values(X_test)\n",
        "\n",
        "values = keras_shap_values[0]\n",
        "base_values = [keras_explainer.expected_value[0]]*len(keras_shap_values[0])\n",
        "\n",
        "tmp = shap.Explanation(values = np.array(values, dtype=np.float32),\n",
        "                       base_values = np.array(base_values, dtype=np.float32),\n",
        "                       data=np.array(X_train),\n",
        "                       feature_names=CSV_COLUMN_NAMES2)\n",
        "\n",
        "#shap.plots.waterfall(tmp[5])\n",
        "#shap.plots.bar(tmp,max_display=98)\n",
        "shap.summary_plot(tmp, X_test,max_display=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLaoTNJnIRM"
      },
      "source": [
        "#print(X_val)\n",
        "pokus=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "pokus.pop('Match_link')\n",
        "pokus.pop('team_one_name')\n",
        "pokus.pop('team_two_name')\n",
        "pokus.pop('Result')\n",
        "\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(pokus)\n",
        "data=scaler.transform(pokus)\n",
        "print(data)\n"
      ]
    }
  ]
}