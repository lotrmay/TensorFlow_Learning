{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOH0JNgH8xjJR1ztoMssYQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbSeoWpB3mO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCY-aVPMK1aO"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "3db0c7aa-2a98-449b-934f-b70670fa74e7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(train.shape)#vypíše nám dimenzionalitu našeho dataframu (2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "train['team_one_name']=pd.Categorical(train['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "train['team_two_name']=pd.Categorical(train['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "\n",
        "train.pop('playerAAAdr')\n",
        "train.pop('playerABAdr')\n",
        "train.pop('playerACAdr')\n",
        "train.pop('playerADAdr')\n",
        "train.pop('playerAEAdr')\n",
        "train.pop('playerBAAdr')\n",
        "train.pop('playerBBAdr')\n",
        "train.pop('playerBCAdr')\n",
        "train.pop('playerBDAdr')\n",
        "train.pop('playerBEAdr')\n",
        "\n",
        "train.pop('playerAADpr')\n",
        "train.pop('playerABDpr')\n",
        "train.pop('playerACDpr')\n",
        "train.pop('playerADDpr')\n",
        "train.pop('playerAEDpr')\n",
        "train.pop('playerBADpr')\n",
        "train.pop('playerBBDpr')\n",
        "train.pop('playerBCDpr')\n",
        "train.pop('playerBDDpr')\n",
        "train.pop('playerBEDpr')\n",
        "\n",
        "train.pop('playerAAKpr')\n",
        "train.pop('playerABKpr')\n",
        "train.pop('playerACKpr')\n",
        "train.pop('playerADKpr')\n",
        "train.pop('playerAEKpr')\n",
        "train.pop('playerBAKpr')\n",
        "train.pop('playerBBKpr')\n",
        "train.pop('playerBCKpr')\n",
        "train.pop('playerBDKpr')\n",
        "train.pop('playerBEKpr')\n",
        "\n",
        "train.pop('playerAAImpact')\n",
        "train.pop('playerABImpact')\n",
        "train.pop('playerACImpact')\n",
        "train.pop('playerADImpact')\n",
        "train.pop('playerAEImpact')\n",
        "train.pop('playerBAImpact')\n",
        "train.pop('playerBBImpact')\n",
        "train.pop('playerBCImpact')\n",
        "train.pop('playerBDImpact')\n",
        "train.pop('playerBEImpact')\n",
        "\n",
        "train.pop('playerAAHs')\n",
        "train.pop('playerABHs')\n",
        "train.pop('playerACHs')\n",
        "train.pop('playerADHs')\n",
        "train.pop('playerAEHs')\n",
        "train.pop('playerBAHs')\n",
        "train.pop('playerBBHs')\n",
        "train.pop('playerBCHs')\n",
        "train.pop('playerBDHs')\n",
        "train.pop('playerBEHs')\n",
        "\n",
        "train.pop('playerAARating')\n",
        "train.pop('playerABRating')\n",
        "train.pop('playerACRating')\n",
        "train.pop('playerADRating')\n",
        "train.pop('playerAERating')\n",
        "train.pop('playerBARating')\n",
        "train.pop('playerBBRating')\n",
        "train.pop('playerBCRating')\n",
        "train.pop('playerBDRating')\n",
        "train.pop('playerBERating')\n",
        "'''\n",
        "#predictors nám vybere všechny sloupce, které jsou využity pro predikování výsledků neboli target_column\n",
        "target_column = ['Result'] \n",
        "predictors = list(set(list(train.columns))-set(target_column))\n",
        "\n",
        "scalerData=train.copy()\n",
        "scalerData.pop('Result')\n",
        "\n",
        "predictionScaler=MinMaxScaler(feature_range=(0,2))\n",
        "X = train[predictors].values\n",
        "y = train[target_column].values\n",
        "predictionScaler.fit(scalerData)\n",
        "\n",
        "#n = 100 # Max number of neighbours you want to consider\n",
        "#param_grid = {'n_neighbors': np.arange(n)}\n",
        "#grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "#grid.fit(X,y)\n",
        "#print(grid.best_params_)\n",
        "\n",
        "\n",
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#15% dat \n",
        "lof = LocalOutlierFactor(contamination=0.15,n_neighbors=96)\n",
        "yhat = lof.fit_predict(X)\n",
        "mask = yhat != -1\n",
        "X, y= X[mask, :], y[mask]\n",
        "print(X.shape)\n",
        "\n",
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% random_state=98\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,random_state=3332)#32 #888 887\n",
        "\n",
        "#validační set bude 15% random_state=75\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765,random_state=7215) # 0.1765 x 0.85 = 0.15 podívat se na cross-validation\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) #součet odpovídá X.shape\n",
        "\n",
        "#vytvoříme scaler, který nám data přetransformuje na formát lepší pro model ?\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=CSV_COLUMN_NAMES2)\n",
        "X_test=pd.DataFrame(X_test, columns=CSV_COLUMN_NAMES2)\n",
        "X_val=pd.DataFrame(X_val, columns=CSV_COLUMN_NAMES2)\n",
        "\n",
        "X_train=predictionScaler.transform(X_train)\n",
        "X_test=predictionScaler.transform(X_test)\n",
        "X_val=predictionScaler.transform(X_val)\n",
        "\n",
        "\n",
        "#64 32\n",
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(Dense(64, activation='relu'))#input layer je už v modelu defaultně\n",
        "model.add(keras.layers.Dropout(0.5))#50% inputů dropne abz se příliš nespoléhala na vybrané inputy\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))#jelikož děláme binární klasifikaci, tak aktivační funkce bude sigmoid popř. softmax, zde by mezi těmito dvěmi neměl být výkonově rozdíl viz:https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#tady jsem skončil s vysvětlováním!!!\n",
        "#model zkompilujeme s parametry:\n",
        "#optimizer bude ? optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9\n",
        "#loss funkce bude BinaryCrossentropy, jelikož máme binární klasifikátor\n",
        "model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.07), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None))#metrics=['accuracy'] je to jedno accuracy se vnitřně přetransformuje na binary accuracy, kvůli binary crossentropy loss funkci\n",
        "\n",
        "#[tf.keras.metrics.BinaryAccuracy()]\n",
        "\n",
        "#Adagrad(learning_rate=0.01) kolem 100 epochs a 32 batch_size je kolem 0.67\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1500,batch_size=32,validation_data=(X_val, y_val))#validační data pro změny při tréninku sítě\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "pred_test= model.predict(X_test)\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18775, 102)\n",
            "(15958, 98)\n",
            "(11169, 98)\n",
            "(2394, 98)\n",
            "(2395, 98)\n",
            "Epoch 1/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 12.4795 - binary_accuracy: 0.5035 - val_loss: 1.5466 - val_binary_accuracy: 0.5478\n",
            "Epoch 2/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 6.3481 - binary_accuracy: 0.5229 - val_loss: 1.0755 - val_binary_accuracy: 0.5916\n",
            "Epoch 3/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 3.7747 - binary_accuracy: 0.5155 - val_loss: 0.8796 - val_binary_accuracy: 0.5374\n",
            "Epoch 4/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 2.3224 - binary_accuracy: 0.5086 - val_loss: 0.7697 - val_binary_accuracy: 0.5165\n",
            "Epoch 5/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.5839 - binary_accuracy: 0.5149 - val_loss: 0.7111 - val_binary_accuracy: 0.5353\n",
            "Epoch 6/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.1759 - binary_accuracy: 0.5313 - val_loss: 0.6820 - val_binary_accuracy: 0.5641\n",
            "Epoch 7/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.9534 - binary_accuracy: 0.5385 - val_loss: 0.6675 - val_binary_accuracy: 0.6021\n",
            "Epoch 8/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.8748 - binary_accuracy: 0.5464 - val_loss: 0.6655 - val_binary_accuracy: 0.5954\n",
            "Epoch 9/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.8113 - binary_accuracy: 0.5423 - val_loss: 0.6678 - val_binary_accuracy: 0.6063\n",
            "Epoch 10/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7687 - binary_accuracy: 0.5428 - val_loss: 0.6673 - val_binary_accuracy: 0.6125\n",
            "Epoch 11/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7456 - binary_accuracy: 0.5525 - val_loss: 0.6668 - val_binary_accuracy: 0.6167\n",
            "Epoch 12/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7269 - binary_accuracy: 0.5529 - val_loss: 0.6680 - val_binary_accuracy: 0.6200\n",
            "Epoch 13/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7191 - binary_accuracy: 0.5429 - val_loss: 0.6663 - val_binary_accuracy: 0.6159\n",
            "Epoch 14/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7091 - binary_accuracy: 0.5434 - val_loss: 0.6662 - val_binary_accuracy: 0.6188\n",
            "Epoch 15/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7085 - binary_accuracy: 0.5465 - val_loss: 0.6646 - val_binary_accuracy: 0.6129\n",
            "Epoch 16/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6924 - binary_accuracy: 0.5628 - val_loss: 0.6637 - val_binary_accuracy: 0.6154\n",
            "Epoch 17/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6921 - binary_accuracy: 0.5569 - val_loss: 0.6626 - val_binary_accuracy: 0.6142\n",
            "Epoch 18/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6893 - binary_accuracy: 0.5662 - val_loss: 0.6624 - val_binary_accuracy: 0.6175\n",
            "Epoch 19/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6878 - binary_accuracy: 0.5648 - val_loss: 0.6641 - val_binary_accuracy: 0.6217\n",
            "Epoch 20/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6876 - binary_accuracy: 0.5575 - val_loss: 0.6652 - val_binary_accuracy: 0.6129\n",
            "Epoch 21/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6812 - binary_accuracy: 0.5652 - val_loss: 0.6653 - val_binary_accuracy: 0.6188\n",
            "Epoch 22/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6814 - binary_accuracy: 0.5665 - val_loss: 0.6589 - val_binary_accuracy: 0.6255\n",
            "Epoch 23/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6768 - binary_accuracy: 0.5711 - val_loss: 0.6604 - val_binary_accuracy: 0.6205\n",
            "Epoch 24/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6837 - binary_accuracy: 0.5645 - val_loss: 0.6625 - val_binary_accuracy: 0.6205\n",
            "Epoch 25/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6799 - binary_accuracy: 0.5711 - val_loss: 0.6657 - val_binary_accuracy: 0.6238\n",
            "Epoch 26/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6761 - binary_accuracy: 0.5737 - val_loss: 0.6629 - val_binary_accuracy: 0.6284\n",
            "Epoch 27/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6771 - binary_accuracy: 0.5804 - val_loss: 0.6593 - val_binary_accuracy: 0.6284\n",
            "Epoch 28/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6741 - binary_accuracy: 0.5750 - val_loss: 0.6584 - val_binary_accuracy: 0.6317\n",
            "Epoch 29/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6765 - binary_accuracy: 0.5765 - val_loss: 0.6612 - val_binary_accuracy: 0.6292\n",
            "Epoch 30/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6742 - binary_accuracy: 0.5771 - val_loss: 0.6623 - val_binary_accuracy: 0.6284\n",
            "Epoch 31/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6772 - binary_accuracy: 0.5785 - val_loss: 0.6584 - val_binary_accuracy: 0.6267\n",
            "Epoch 32/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6724 - binary_accuracy: 0.5849 - val_loss: 0.6585 - val_binary_accuracy: 0.6313\n",
            "Epoch 33/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6695 - binary_accuracy: 0.5771 - val_loss: 0.6540 - val_binary_accuracy: 0.6309\n",
            "Epoch 34/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6713 - binary_accuracy: 0.5792 - val_loss: 0.6576 - val_binary_accuracy: 0.6271\n",
            "Epoch 35/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6712 - binary_accuracy: 0.5774 - val_loss: 0.6571 - val_binary_accuracy: 0.6292\n",
            "Epoch 36/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6678 - binary_accuracy: 0.5846 - val_loss: 0.6577 - val_binary_accuracy: 0.6301\n",
            "Epoch 37/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6709 - binary_accuracy: 0.5825 - val_loss: 0.6570 - val_binary_accuracy: 0.6271\n",
            "Epoch 38/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6695 - binary_accuracy: 0.5849 - val_loss: 0.6558 - val_binary_accuracy: 0.6338\n",
            "Epoch 39/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6686 - binary_accuracy: 0.5936 - val_loss: 0.6553 - val_binary_accuracy: 0.6251\n",
            "Epoch 40/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6717 - binary_accuracy: 0.5856 - val_loss: 0.6597 - val_binary_accuracy: 0.6251\n",
            "Epoch 41/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6647 - binary_accuracy: 0.5905 - val_loss: 0.6569 - val_binary_accuracy: 0.6263\n",
            "Epoch 42/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6681 - binary_accuracy: 0.5860 - val_loss: 0.6572 - val_binary_accuracy: 0.6263\n",
            "Epoch 43/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6670 - binary_accuracy: 0.5970 - val_loss: 0.6531 - val_binary_accuracy: 0.6301\n",
            "Epoch 44/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6661 - binary_accuracy: 0.5885 - val_loss: 0.6539 - val_binary_accuracy: 0.6263\n",
            "Epoch 45/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6684 - binary_accuracy: 0.5854 - val_loss: 0.6539 - val_binary_accuracy: 0.6309\n",
            "Epoch 46/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6649 - binary_accuracy: 0.5887 - val_loss: 0.6538 - val_binary_accuracy: 0.6305\n",
            "Epoch 47/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6601 - binary_accuracy: 0.5932 - val_loss: 0.6542 - val_binary_accuracy: 0.6276\n",
            "Epoch 48/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6636 - binary_accuracy: 0.5903 - val_loss: 0.6529 - val_binary_accuracy: 0.6296\n",
            "Epoch 49/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6656 - binary_accuracy: 0.5953 - val_loss: 0.6527 - val_binary_accuracy: 0.6322\n",
            "Epoch 50/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6662 - binary_accuracy: 0.5902 - val_loss: 0.6556 - val_binary_accuracy: 0.6296\n",
            "Epoch 51/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6638 - binary_accuracy: 0.5854 - val_loss: 0.6551 - val_binary_accuracy: 0.6292\n",
            "Epoch 52/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6632 - binary_accuracy: 0.5856 - val_loss: 0.6529 - val_binary_accuracy: 0.6305\n",
            "Epoch 53/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6644 - binary_accuracy: 0.5971 - val_loss: 0.6501 - val_binary_accuracy: 0.6305\n",
            "Epoch 54/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6653 - binary_accuracy: 0.5956 - val_loss: 0.6515 - val_binary_accuracy: 0.6288\n",
            "Epoch 55/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6634 - binary_accuracy: 0.5905 - val_loss: 0.6545 - val_binary_accuracy: 0.6296\n",
            "Epoch 56/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6647 - binary_accuracy: 0.5912 - val_loss: 0.6507 - val_binary_accuracy: 0.6292\n",
            "Epoch 57/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6634 - binary_accuracy: 0.5895 - val_loss: 0.6502 - val_binary_accuracy: 0.6313\n",
            "Epoch 58/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6627 - binary_accuracy: 0.5911 - val_loss: 0.6524 - val_binary_accuracy: 0.6309\n",
            "Epoch 59/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6612 - binary_accuracy: 0.5872 - val_loss: 0.6511 - val_binary_accuracy: 0.6271\n",
            "Epoch 60/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6643 - binary_accuracy: 0.5881 - val_loss: 0.6497 - val_binary_accuracy: 0.6305\n",
            "Epoch 61/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6588 - binary_accuracy: 0.5939 - val_loss: 0.6500 - val_binary_accuracy: 0.6284\n",
            "Epoch 62/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6604 - binary_accuracy: 0.5894 - val_loss: 0.6524 - val_binary_accuracy: 0.6309\n",
            "Epoch 63/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6619 - binary_accuracy: 0.5932 - val_loss: 0.6509 - val_binary_accuracy: 0.6288\n",
            "Epoch 64/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6588 - binary_accuracy: 0.5992 - val_loss: 0.6468 - val_binary_accuracy: 0.6288\n",
            "Epoch 65/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6584 - binary_accuracy: 0.6034 - val_loss: 0.6488 - val_binary_accuracy: 0.6317\n",
            "Epoch 66/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6577 - binary_accuracy: 0.6069 - val_loss: 0.6500 - val_binary_accuracy: 0.6309\n",
            "Epoch 67/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6582 - binary_accuracy: 0.6108 - val_loss: 0.6488 - val_binary_accuracy: 0.6292\n",
            "Epoch 68/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6577 - binary_accuracy: 0.6124 - val_loss: 0.6506 - val_binary_accuracy: 0.6388\n",
            "Epoch 69/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6573 - binary_accuracy: 0.6061 - val_loss: 0.6504 - val_binary_accuracy: 0.6351\n",
            "Epoch 70/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6590 - binary_accuracy: 0.6119 - val_loss: 0.6503 - val_binary_accuracy: 0.6392\n",
            "Epoch 71/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6567 - binary_accuracy: 0.6138 - val_loss: 0.6483 - val_binary_accuracy: 0.6363\n",
            "Epoch 72/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6567 - binary_accuracy: 0.6108 - val_loss: 0.6486 - val_binary_accuracy: 0.6338\n",
            "Epoch 73/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6516 - binary_accuracy: 0.6150 - val_loss: 0.6478 - val_binary_accuracy: 0.6330\n",
            "Epoch 74/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6563 - binary_accuracy: 0.6129 - val_loss: 0.6477 - val_binary_accuracy: 0.6367\n",
            "Epoch 75/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6570 - binary_accuracy: 0.6143 - val_loss: 0.6490 - val_binary_accuracy: 0.6334\n",
            "Epoch 76/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6553 - binary_accuracy: 0.6170 - val_loss: 0.6488 - val_binary_accuracy: 0.6342\n",
            "Epoch 77/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6584 - binary_accuracy: 0.6088 - val_loss: 0.6502 - val_binary_accuracy: 0.6338\n",
            "Epoch 78/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6588 - binary_accuracy: 0.6178 - val_loss: 0.6484 - val_binary_accuracy: 0.6359\n",
            "Epoch 79/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6543 - binary_accuracy: 0.6106 - val_loss: 0.6492 - val_binary_accuracy: 0.6347\n",
            "Epoch 80/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6575 - binary_accuracy: 0.6106 - val_loss: 0.6501 - val_binary_accuracy: 0.6347\n",
            "Epoch 81/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6554 - binary_accuracy: 0.6188 - val_loss: 0.6481 - val_binary_accuracy: 0.6359\n",
            "Epoch 82/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6571 - binary_accuracy: 0.6123 - val_loss: 0.6494 - val_binary_accuracy: 0.6409\n",
            "Epoch 83/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6517 - binary_accuracy: 0.6189 - val_loss: 0.6447 - val_binary_accuracy: 0.6422\n",
            "Epoch 84/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6532 - binary_accuracy: 0.6195 - val_loss: 0.6459 - val_binary_accuracy: 0.6342\n",
            "Epoch 85/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6549 - binary_accuracy: 0.6090 - val_loss: 0.6485 - val_binary_accuracy: 0.6363\n",
            "Epoch 86/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6533 - binary_accuracy: 0.6148 - val_loss: 0.6461 - val_binary_accuracy: 0.6405\n",
            "Epoch 87/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6537 - binary_accuracy: 0.6122 - val_loss: 0.6455 - val_binary_accuracy: 0.6347\n",
            "Epoch 88/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6527 - binary_accuracy: 0.6176 - val_loss: 0.6469 - val_binary_accuracy: 0.6409\n",
            "Epoch 89/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6561 - binary_accuracy: 0.6097 - val_loss: 0.6469 - val_binary_accuracy: 0.6397\n",
            "Epoch 90/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6534 - binary_accuracy: 0.6163 - val_loss: 0.6454 - val_binary_accuracy: 0.6372\n",
            "Epoch 91/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6544 - binary_accuracy: 0.6187 - val_loss: 0.6445 - val_binary_accuracy: 0.6355\n",
            "Epoch 92/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6531 - binary_accuracy: 0.6140 - val_loss: 0.6462 - val_binary_accuracy: 0.6418\n",
            "Epoch 93/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6507 - binary_accuracy: 0.6176 - val_loss: 0.6425 - val_binary_accuracy: 0.6405\n",
            "Epoch 94/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6540 - binary_accuracy: 0.6189 - val_loss: 0.6460 - val_binary_accuracy: 0.6372\n",
            "Epoch 95/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6530 - binary_accuracy: 0.6159 - val_loss: 0.6457 - val_binary_accuracy: 0.6355\n",
            "Epoch 96/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6547 - binary_accuracy: 0.6118 - val_loss: 0.6466 - val_binary_accuracy: 0.6355\n",
            "Epoch 97/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6512 - binary_accuracy: 0.6138 - val_loss: 0.6442 - val_binary_accuracy: 0.6367\n",
            "Epoch 98/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6548 - binary_accuracy: 0.6129 - val_loss: 0.6453 - val_binary_accuracy: 0.6359\n",
            "Epoch 99/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6534 - binary_accuracy: 0.6203 - val_loss: 0.6440 - val_binary_accuracy: 0.6413\n",
            "Epoch 100/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6544 - binary_accuracy: 0.6115 - val_loss: 0.6471 - val_binary_accuracy: 0.6401\n",
            "Epoch 101/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6523 - binary_accuracy: 0.6157 - val_loss: 0.6449 - val_binary_accuracy: 0.6468\n",
            "Epoch 102/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6518 - binary_accuracy: 0.6275 - val_loss: 0.6439 - val_binary_accuracy: 0.6430\n",
            "Epoch 103/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6532 - binary_accuracy: 0.6195 - val_loss: 0.6437 - val_binary_accuracy: 0.6363\n",
            "Epoch 104/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6496 - binary_accuracy: 0.6167 - val_loss: 0.6421 - val_binary_accuracy: 0.6367\n",
            "Epoch 105/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6499 - binary_accuracy: 0.6180 - val_loss: 0.6426 - val_binary_accuracy: 0.6430\n",
            "Epoch 106/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6508 - binary_accuracy: 0.6160 - val_loss: 0.6441 - val_binary_accuracy: 0.6480\n",
            "Epoch 107/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6488 - binary_accuracy: 0.6213 - val_loss: 0.6432 - val_binary_accuracy: 0.6418\n",
            "Epoch 108/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6486 - binary_accuracy: 0.6154 - val_loss: 0.6417 - val_binary_accuracy: 0.6451\n",
            "Epoch 109/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6483 - binary_accuracy: 0.6186 - val_loss: 0.6428 - val_binary_accuracy: 0.6434\n",
            "Epoch 110/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6209 - val_loss: 0.6423 - val_binary_accuracy: 0.6459\n",
            "Epoch 111/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6507 - binary_accuracy: 0.6171 - val_loss: 0.6435 - val_binary_accuracy: 0.6443\n",
            "Epoch 112/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6501 - binary_accuracy: 0.6155 - val_loss: 0.6421 - val_binary_accuracy: 0.6430\n",
            "Epoch 113/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6492 - binary_accuracy: 0.6189 - val_loss: 0.6424 - val_binary_accuracy: 0.6438\n",
            "Epoch 114/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6223 - val_loss: 0.6409 - val_binary_accuracy: 0.6489\n",
            "Epoch 115/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6194 - val_loss: 0.6412 - val_binary_accuracy: 0.6476\n",
            "Epoch 116/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6466 - binary_accuracy: 0.6253 - val_loss: 0.6423 - val_binary_accuracy: 0.6451\n",
            "Epoch 117/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6491 - binary_accuracy: 0.6223 - val_loss: 0.6415 - val_binary_accuracy: 0.6480\n",
            "Epoch 118/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6156 - val_loss: 0.6424 - val_binary_accuracy: 0.6489\n",
            "Epoch 119/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6463 - binary_accuracy: 0.6225 - val_loss: 0.6416 - val_binary_accuracy: 0.6409\n",
            "Epoch 120/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6179 - val_loss: 0.6408 - val_binary_accuracy: 0.6522\n",
            "Epoch 121/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6478 - binary_accuracy: 0.6226 - val_loss: 0.6408 - val_binary_accuracy: 0.6459\n",
            "Epoch 122/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6533 - binary_accuracy: 0.6163 - val_loss: 0.6415 - val_binary_accuracy: 0.6413\n",
            "Epoch 123/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6502 - binary_accuracy: 0.6150 - val_loss: 0.6413 - val_binary_accuracy: 0.6472\n",
            "Epoch 124/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6473 - binary_accuracy: 0.6220 - val_loss: 0.6420 - val_binary_accuracy: 0.6497\n",
            "Epoch 125/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6460 - binary_accuracy: 0.6184 - val_loss: 0.6402 - val_binary_accuracy: 0.6468\n",
            "Epoch 126/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6520 - binary_accuracy: 0.6180 - val_loss: 0.6418 - val_binary_accuracy: 0.6430\n",
            "Epoch 127/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6495 - binary_accuracy: 0.6136 - val_loss: 0.6412 - val_binary_accuracy: 0.6459\n",
            "Epoch 128/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6460 - binary_accuracy: 0.6225 - val_loss: 0.6397 - val_binary_accuracy: 0.6484\n",
            "Epoch 129/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6468 - binary_accuracy: 0.6182 - val_loss: 0.6396 - val_binary_accuracy: 0.6501\n",
            "Epoch 130/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6198 - val_loss: 0.6397 - val_binary_accuracy: 0.6489\n",
            "Epoch 131/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6471 - binary_accuracy: 0.6223 - val_loss: 0.6423 - val_binary_accuracy: 0.6480\n",
            "Epoch 132/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6462 - binary_accuracy: 0.6226 - val_loss: 0.6408 - val_binary_accuracy: 0.6522\n",
            "Epoch 133/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6474 - binary_accuracy: 0.6237 - val_loss: 0.6415 - val_binary_accuracy: 0.6480\n",
            "Epoch 134/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6467 - binary_accuracy: 0.6283 - val_loss: 0.6415 - val_binary_accuracy: 0.6468\n",
            "Epoch 135/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6469 - binary_accuracy: 0.6201 - val_loss: 0.6418 - val_binary_accuracy: 0.6472\n",
            "Epoch 136/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6208 - val_loss: 0.6406 - val_binary_accuracy: 0.6476\n",
            "Epoch 137/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6444 - binary_accuracy: 0.6222 - val_loss: 0.6387 - val_binary_accuracy: 0.6497\n",
            "Epoch 138/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6473 - binary_accuracy: 0.6204 - val_loss: 0.6397 - val_binary_accuracy: 0.6539\n",
            "Epoch 139/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6430 - binary_accuracy: 0.6257 - val_loss: 0.6369 - val_binary_accuracy: 0.6493\n",
            "Epoch 140/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6447 - binary_accuracy: 0.6240 - val_loss: 0.6389 - val_binary_accuracy: 0.6455\n",
            "Epoch 141/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6433 - binary_accuracy: 0.6232 - val_loss: 0.6401 - val_binary_accuracy: 0.6518\n",
            "Epoch 142/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6483 - binary_accuracy: 0.6208 - val_loss: 0.6407 - val_binary_accuracy: 0.6526\n",
            "Epoch 143/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6450 - binary_accuracy: 0.6231 - val_loss: 0.6420 - val_binary_accuracy: 0.6447\n",
            "Epoch 144/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6470 - binary_accuracy: 0.6242 - val_loss: 0.6401 - val_binary_accuracy: 0.6447\n",
            "Epoch 145/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6435 - binary_accuracy: 0.6242 - val_loss: 0.6380 - val_binary_accuracy: 0.6518\n",
            "Epoch 146/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6221 - val_loss: 0.6412 - val_binary_accuracy: 0.6526\n",
            "Epoch 147/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6414 - binary_accuracy: 0.6289 - val_loss: 0.6397 - val_binary_accuracy: 0.6514\n",
            "Epoch 148/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6231 - val_loss: 0.6407 - val_binary_accuracy: 0.6447\n",
            "Epoch 149/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6438 - binary_accuracy: 0.6257 - val_loss: 0.6384 - val_binary_accuracy: 0.6476\n",
            "Epoch 150/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6220 - val_loss: 0.6399 - val_binary_accuracy: 0.6447\n",
            "Epoch 151/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6188 - val_loss: 0.6410 - val_binary_accuracy: 0.6489\n",
            "Epoch 152/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6443 - binary_accuracy: 0.6221 - val_loss: 0.6400 - val_binary_accuracy: 0.6484\n",
            "Epoch 153/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6428 - binary_accuracy: 0.6271 - val_loss: 0.6392 - val_binary_accuracy: 0.6480\n",
            "Epoch 154/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6227 - val_loss: 0.6404 - val_binary_accuracy: 0.6451\n",
            "Epoch 155/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6230 - val_loss: 0.6370 - val_binary_accuracy: 0.6501\n",
            "Epoch 156/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6437 - binary_accuracy: 0.6224 - val_loss: 0.6368 - val_binary_accuracy: 0.6509\n",
            "Epoch 157/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6448 - binary_accuracy: 0.6252 - val_loss: 0.6372 - val_binary_accuracy: 0.6505\n",
            "Epoch 158/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6288 - val_loss: 0.6370 - val_binary_accuracy: 0.6501\n",
            "Epoch 159/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6252 - val_loss: 0.6385 - val_binary_accuracy: 0.6497\n",
            "Epoch 160/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6337 - val_loss: 0.6381 - val_binary_accuracy: 0.6551\n",
            "Epoch 161/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6437 - binary_accuracy: 0.6217 - val_loss: 0.6394 - val_binary_accuracy: 0.6530\n",
            "Epoch 162/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6447 - binary_accuracy: 0.6280 - val_loss: 0.6377 - val_binary_accuracy: 0.6434\n",
            "Epoch 163/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6409 - binary_accuracy: 0.6248 - val_loss: 0.6394 - val_binary_accuracy: 0.6514\n",
            "Epoch 164/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6248 - val_loss: 0.6379 - val_binary_accuracy: 0.6530\n",
            "Epoch 165/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6290 - val_loss: 0.6380 - val_binary_accuracy: 0.6493\n",
            "Epoch 166/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6433 - binary_accuracy: 0.6250 - val_loss: 0.6378 - val_binary_accuracy: 0.6505\n",
            "Epoch 167/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6457 - binary_accuracy: 0.6197 - val_loss: 0.6394 - val_binary_accuracy: 0.6555\n",
            "Epoch 168/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6280 - val_loss: 0.6371 - val_binary_accuracy: 0.6539\n",
            "Epoch 169/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6256 - val_loss: 0.6349 - val_binary_accuracy: 0.6472\n",
            "Epoch 170/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6429 - binary_accuracy: 0.6243 - val_loss: 0.6366 - val_binary_accuracy: 0.6547\n",
            "Epoch 171/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6279 - val_loss: 0.6372 - val_binary_accuracy: 0.6547\n",
            "Epoch 172/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6411 - binary_accuracy: 0.6270 - val_loss: 0.6355 - val_binary_accuracy: 0.6539\n",
            "Epoch 173/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6426 - binary_accuracy: 0.6270 - val_loss: 0.6394 - val_binary_accuracy: 0.6530\n",
            "Epoch 174/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6431 - binary_accuracy: 0.6264 - val_loss: 0.6361 - val_binary_accuracy: 0.6522\n",
            "Epoch 175/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6403 - binary_accuracy: 0.6291 - val_loss: 0.6383 - val_binary_accuracy: 0.6551\n",
            "Epoch 176/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6282 - val_loss: 0.6381 - val_binary_accuracy: 0.6547\n",
            "Epoch 177/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6452 - binary_accuracy: 0.6241 - val_loss: 0.6380 - val_binary_accuracy: 0.6555\n",
            "Epoch 178/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6452 - binary_accuracy: 0.6256 - val_loss: 0.6398 - val_binary_accuracy: 0.6497\n",
            "Epoch 179/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6280 - val_loss: 0.6363 - val_binary_accuracy: 0.6559\n",
            "Epoch 180/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6250 - val_loss: 0.6352 - val_binary_accuracy: 0.6518\n",
            "Epoch 181/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6393 - binary_accuracy: 0.6306 - val_loss: 0.6363 - val_binary_accuracy: 0.6572\n",
            "Epoch 182/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6394 - binary_accuracy: 0.6308 - val_loss: 0.6349 - val_binary_accuracy: 0.6501\n",
            "Epoch 183/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6433 - binary_accuracy: 0.6326 - val_loss: 0.6354 - val_binary_accuracy: 0.6539\n",
            "Epoch 184/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6428 - binary_accuracy: 0.6249 - val_loss: 0.6375 - val_binary_accuracy: 0.6568\n",
            "Epoch 185/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6428 - binary_accuracy: 0.6262 - val_loss: 0.6363 - val_binary_accuracy: 0.6539\n",
            "Epoch 186/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6305 - val_loss: 0.6384 - val_binary_accuracy: 0.6526\n",
            "Epoch 187/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6288 - val_loss: 0.6374 - val_binary_accuracy: 0.6418\n",
            "Epoch 188/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6401 - binary_accuracy: 0.6274 - val_loss: 0.6344 - val_binary_accuracy: 0.6476\n",
            "Epoch 189/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6408 - binary_accuracy: 0.6262 - val_loss: 0.6373 - val_binary_accuracy: 0.6576\n",
            "Epoch 190/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6420 - binary_accuracy: 0.6276 - val_loss: 0.6387 - val_binary_accuracy: 0.6514\n",
            "Epoch 191/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6394 - binary_accuracy: 0.6315 - val_loss: 0.6384 - val_binary_accuracy: 0.6501\n",
            "Epoch 192/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6348 - val_loss: 0.6354 - val_binary_accuracy: 0.6505\n",
            "Epoch 193/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6428 - binary_accuracy: 0.6255 - val_loss: 0.6360 - val_binary_accuracy: 0.6518\n",
            "Epoch 194/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6260 - val_loss: 0.6362 - val_binary_accuracy: 0.6605\n",
            "Epoch 195/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6288 - val_loss: 0.6364 - val_binary_accuracy: 0.6484\n",
            "Epoch 196/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6424 - binary_accuracy: 0.6310 - val_loss: 0.6365 - val_binary_accuracy: 0.6551\n",
            "Epoch 197/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6298 - val_loss: 0.6370 - val_binary_accuracy: 0.6580\n",
            "Epoch 198/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6280 - val_loss: 0.6371 - val_binary_accuracy: 0.6480\n",
            "Epoch 199/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6393 - binary_accuracy: 0.6300 - val_loss: 0.6361 - val_binary_accuracy: 0.6530\n",
            "Epoch 200/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6313 - val_loss: 0.6347 - val_binary_accuracy: 0.6559\n",
            "Epoch 201/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6271 - val_loss: 0.6343 - val_binary_accuracy: 0.6580\n",
            "Epoch 202/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6294 - val_loss: 0.6339 - val_binary_accuracy: 0.6543\n",
            "Epoch 203/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6403 - binary_accuracy: 0.6239 - val_loss: 0.6378 - val_binary_accuracy: 0.6572\n",
            "Epoch 204/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6294 - val_loss: 0.6347 - val_binary_accuracy: 0.6514\n",
            "Epoch 205/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6392 - binary_accuracy: 0.6327 - val_loss: 0.6344 - val_binary_accuracy: 0.6522\n",
            "Epoch 206/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6374 - binary_accuracy: 0.6328 - val_loss: 0.6338 - val_binary_accuracy: 0.6489\n",
            "Epoch 207/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6314 - val_loss: 0.6350 - val_binary_accuracy: 0.6497\n",
            "Epoch 208/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6296 - val_loss: 0.6355 - val_binary_accuracy: 0.6576\n",
            "Epoch 209/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6394 - binary_accuracy: 0.6302 - val_loss: 0.6339 - val_binary_accuracy: 0.6580\n",
            "Epoch 210/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6327 - val_loss: 0.6361 - val_binary_accuracy: 0.6564\n",
            "Epoch 211/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6316 - val_loss: 0.6338 - val_binary_accuracy: 0.6593\n",
            "Epoch 212/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6397 - binary_accuracy: 0.6266 - val_loss: 0.6323 - val_binary_accuracy: 0.6593\n",
            "Epoch 213/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6397 - binary_accuracy: 0.6311 - val_loss: 0.6320 - val_binary_accuracy: 0.6601\n",
            "Epoch 214/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6303 - val_loss: 0.6333 - val_binary_accuracy: 0.6501\n",
            "Epoch 215/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6375 - binary_accuracy: 0.6300 - val_loss: 0.6319 - val_binary_accuracy: 0.6534\n",
            "Epoch 216/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6308 - val_loss: 0.6325 - val_binary_accuracy: 0.6610\n",
            "Epoch 217/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6401 - binary_accuracy: 0.6319 - val_loss: 0.6329 - val_binary_accuracy: 0.6539\n",
            "Epoch 218/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6409 - binary_accuracy: 0.6328 - val_loss: 0.6326 - val_binary_accuracy: 0.6539\n",
            "Epoch 219/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6391 - binary_accuracy: 0.6325 - val_loss: 0.6344 - val_binary_accuracy: 0.6580\n",
            "Epoch 220/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6376 - binary_accuracy: 0.6334 - val_loss: 0.6331 - val_binary_accuracy: 0.6551\n",
            "Epoch 221/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6336 - val_loss: 0.6357 - val_binary_accuracy: 0.6530\n",
            "Epoch 222/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6325 - val_loss: 0.6338 - val_binary_accuracy: 0.6589\n",
            "Epoch 223/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6376 - binary_accuracy: 0.6318 - val_loss: 0.6355 - val_binary_accuracy: 0.6559\n",
            "Epoch 224/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6373 - binary_accuracy: 0.6326 - val_loss: 0.6347 - val_binary_accuracy: 0.6589\n",
            "Epoch 225/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6369 - binary_accuracy: 0.6329 - val_loss: 0.6342 - val_binary_accuracy: 0.6585\n",
            "Epoch 226/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6329 - val_loss: 0.6357 - val_binary_accuracy: 0.6526\n",
            "Epoch 227/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6380 - val_loss: 0.6326 - val_binary_accuracy: 0.6526\n",
            "Epoch 228/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6296 - val_loss: 0.6328 - val_binary_accuracy: 0.6539\n",
            "Epoch 229/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6403 - binary_accuracy: 0.6296 - val_loss: 0.6330 - val_binary_accuracy: 0.6555\n",
            "Epoch 230/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6360 - val_loss: 0.6336 - val_binary_accuracy: 0.6534\n",
            "Epoch 231/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6355 - val_loss: 0.6352 - val_binary_accuracy: 0.6589\n",
            "Epoch 232/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6350 - val_loss: 0.6333 - val_binary_accuracy: 0.6539\n",
            "Epoch 233/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6263 - val_loss: 0.6325 - val_binary_accuracy: 0.6585\n",
            "Epoch 234/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6345 - val_loss: 0.6337 - val_binary_accuracy: 0.6593\n",
            "Epoch 235/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6321 - val_loss: 0.6323 - val_binary_accuracy: 0.6576\n",
            "Epoch 236/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6353 - binary_accuracy: 0.6379 - val_loss: 0.6354 - val_binary_accuracy: 0.6543\n",
            "Epoch 237/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6360 - binary_accuracy: 0.6325 - val_loss: 0.6313 - val_binary_accuracy: 0.6601\n",
            "Epoch 238/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6330 - val_loss: 0.6312 - val_binary_accuracy: 0.6576\n",
            "Epoch 239/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6375 - binary_accuracy: 0.6362 - val_loss: 0.6324 - val_binary_accuracy: 0.6589\n",
            "Epoch 240/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6359 - val_loss: 0.6352 - val_binary_accuracy: 0.6585\n",
            "Epoch 241/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6288 - val_loss: 0.6337 - val_binary_accuracy: 0.6605\n",
            "Epoch 242/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6371 - val_loss: 0.6331 - val_binary_accuracy: 0.6514\n",
            "Epoch 243/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6311 - val_loss: 0.6323 - val_binary_accuracy: 0.6585\n",
            "Epoch 244/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6341 - val_loss: 0.6341 - val_binary_accuracy: 0.6501\n",
            "Epoch 245/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6281 - val_loss: 0.6345 - val_binary_accuracy: 0.6555\n",
            "Epoch 246/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6274 - val_loss: 0.6335 - val_binary_accuracy: 0.6534\n",
            "Epoch 247/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6294 - val_loss: 0.6326 - val_binary_accuracy: 0.6551\n",
            "Epoch 248/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6320 - val_loss: 0.6333 - val_binary_accuracy: 0.6559\n",
            "Epoch 249/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6274 - val_loss: 0.6352 - val_binary_accuracy: 0.6589\n",
            "Epoch 250/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6309 - val_loss: 0.6329 - val_binary_accuracy: 0.6539\n",
            "Epoch 251/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6360 - val_loss: 0.6345 - val_binary_accuracy: 0.6585\n",
            "Epoch 252/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6303 - val_loss: 0.6346 - val_binary_accuracy: 0.6580\n",
            "Epoch 253/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6344 - binary_accuracy: 0.6336 - val_loss: 0.6318 - val_binary_accuracy: 0.6564\n",
            "Epoch 254/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6332 - val_loss: 0.6316 - val_binary_accuracy: 0.6505\n",
            "Epoch 255/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6359 - binary_accuracy: 0.6301 - val_loss: 0.6308 - val_binary_accuracy: 0.6601\n",
            "Epoch 256/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6343 - binary_accuracy: 0.6331 - val_loss: 0.6313 - val_binary_accuracy: 0.6543\n",
            "Epoch 257/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6367 - binary_accuracy: 0.6356 - val_loss: 0.6331 - val_binary_accuracy: 0.6564\n",
            "Epoch 258/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6359 - binary_accuracy: 0.6336 - val_loss: 0.6317 - val_binary_accuracy: 0.6551\n",
            "Epoch 259/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6308 - val_loss: 0.6338 - val_binary_accuracy: 0.6534\n",
            "Epoch 260/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6303 - val_loss: 0.6338 - val_binary_accuracy: 0.6547\n",
            "Epoch 261/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6354 - binary_accuracy: 0.6375 - val_loss: 0.6325 - val_binary_accuracy: 0.6555\n",
            "Epoch 262/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6403 - val_loss: 0.6319 - val_binary_accuracy: 0.6505\n",
            "Epoch 263/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6423 - val_loss: 0.6316 - val_binary_accuracy: 0.6589\n",
            "Epoch 264/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6320 - val_loss: 0.6305 - val_binary_accuracy: 0.6576\n",
            "Epoch 265/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6351 - binary_accuracy: 0.6336 - val_loss: 0.6325 - val_binary_accuracy: 0.6564\n",
            "Epoch 266/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6378 - val_loss: 0.6322 - val_binary_accuracy: 0.6534\n",
            "Epoch 267/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6343 - binary_accuracy: 0.6383 - val_loss: 0.6313 - val_binary_accuracy: 0.6530\n",
            "Epoch 268/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6360 - val_loss: 0.6306 - val_binary_accuracy: 0.6580\n",
            "Epoch 269/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6373 - val_loss: 0.6330 - val_binary_accuracy: 0.6568\n",
            "Epoch 270/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6337 - binary_accuracy: 0.6349 - val_loss: 0.6320 - val_binary_accuracy: 0.6589\n",
            "Epoch 271/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6412 - val_loss: 0.6292 - val_binary_accuracy: 0.6580\n",
            "Epoch 272/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6361 - val_loss: 0.6341 - val_binary_accuracy: 0.6572\n",
            "Epoch 273/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6342 - val_loss: 0.6305 - val_binary_accuracy: 0.6568\n",
            "Epoch 274/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6361 - binary_accuracy: 0.6364 - val_loss: 0.6331 - val_binary_accuracy: 0.6564\n",
            "Epoch 275/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6353 - binary_accuracy: 0.6325 - val_loss: 0.6332 - val_binary_accuracy: 0.6568\n",
            "Epoch 276/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6310 - binary_accuracy: 0.6363 - val_loss: 0.6288 - val_binary_accuracy: 0.6580\n",
            "Epoch 277/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6321 - binary_accuracy: 0.6379 - val_loss: 0.6326 - val_binary_accuracy: 0.6564\n",
            "Epoch 278/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6378 - val_loss: 0.6304 - val_binary_accuracy: 0.6597\n",
            "Epoch 279/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6394 - val_loss: 0.6331 - val_binary_accuracy: 0.6580\n",
            "Epoch 280/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6353 - val_loss: 0.6341 - val_binary_accuracy: 0.6526\n",
            "Epoch 281/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6328 - binary_accuracy: 0.6369 - val_loss: 0.6314 - val_binary_accuracy: 0.6585\n",
            "Epoch 282/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6302 - val_loss: 0.6301 - val_binary_accuracy: 0.6568\n",
            "Epoch 283/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6366 - val_loss: 0.6292 - val_binary_accuracy: 0.6618\n",
            "Epoch 284/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6351 - val_loss: 0.6313 - val_binary_accuracy: 0.6585\n",
            "Epoch 285/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6429 - val_loss: 0.6307 - val_binary_accuracy: 0.6589\n",
            "Epoch 286/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6352 - binary_accuracy: 0.6352 - val_loss: 0.6302 - val_binary_accuracy: 0.6589\n",
            "Epoch 287/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6326 - binary_accuracy: 0.6400 - val_loss: 0.6312 - val_binary_accuracy: 0.6585\n",
            "Epoch 288/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6354 - binary_accuracy: 0.6355 - val_loss: 0.6324 - val_binary_accuracy: 0.6605\n",
            "Epoch 289/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6370 - val_loss: 0.6287 - val_binary_accuracy: 0.6605\n",
            "Epoch 290/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6320 - val_loss: 0.6303 - val_binary_accuracy: 0.6597\n",
            "Epoch 291/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6305 - val_loss: 0.6286 - val_binary_accuracy: 0.6626\n",
            "Epoch 292/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6364 - val_loss: 0.6291 - val_binary_accuracy: 0.6589\n",
            "Epoch 293/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6381 - val_loss: 0.6279 - val_binary_accuracy: 0.6597\n",
            "Epoch 294/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6361 - val_loss: 0.6315 - val_binary_accuracy: 0.6593\n",
            "Epoch 295/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6417 - val_loss: 0.6285 - val_binary_accuracy: 0.6622\n",
            "Epoch 296/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6364 - binary_accuracy: 0.6339 - val_loss: 0.6322 - val_binary_accuracy: 0.6589\n",
            "Epoch 297/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6317 - val_loss: 0.6304 - val_binary_accuracy: 0.6610\n",
            "Epoch 298/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6367 - binary_accuracy: 0.6345 - val_loss: 0.6313 - val_binary_accuracy: 0.6610\n",
            "Epoch 299/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6414 - val_loss: 0.6306 - val_binary_accuracy: 0.6593\n",
            "Epoch 300/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6346 - val_loss: 0.6323 - val_binary_accuracy: 0.6576\n",
            "Epoch 301/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6317 - val_loss: 0.6310 - val_binary_accuracy: 0.6593\n",
            "Epoch 302/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6388 - val_loss: 0.6302 - val_binary_accuracy: 0.6585\n",
            "Epoch 303/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6372 - val_loss: 0.6281 - val_binary_accuracy: 0.6585\n",
            "Epoch 304/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6361 - val_loss: 0.6287 - val_binary_accuracy: 0.6585\n",
            "Epoch 305/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6379 - val_loss: 0.6303 - val_binary_accuracy: 0.6593\n",
            "Epoch 306/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6352 - binary_accuracy: 0.6339 - val_loss: 0.6321 - val_binary_accuracy: 0.6589\n",
            "Epoch 307/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6344 - binary_accuracy: 0.6352 - val_loss: 0.6316 - val_binary_accuracy: 0.6597\n",
            "Epoch 308/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6369 - val_loss: 0.6302 - val_binary_accuracy: 0.6614\n",
            "Epoch 309/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6333 - binary_accuracy: 0.6346 - val_loss: 0.6322 - val_binary_accuracy: 0.6559\n",
            "Epoch 310/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6351 - val_loss: 0.6328 - val_binary_accuracy: 0.6593\n",
            "Epoch 311/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6383 - val_loss: 0.6321 - val_binary_accuracy: 0.6593\n",
            "Epoch 312/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6376 - val_loss: 0.6303 - val_binary_accuracy: 0.6551\n",
            "Epoch 313/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6378 - val_loss: 0.6327 - val_binary_accuracy: 0.6564\n",
            "Epoch 314/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6352 - val_loss: 0.6307 - val_binary_accuracy: 0.6530\n",
            "Epoch 315/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6368 - val_loss: 0.6304 - val_binary_accuracy: 0.6555\n",
            "Epoch 316/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6425 - val_loss: 0.6298 - val_binary_accuracy: 0.6593\n",
            "Epoch 317/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6411 - val_loss: 0.6287 - val_binary_accuracy: 0.6618\n",
            "Epoch 318/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6370 - val_loss: 0.6308 - val_binary_accuracy: 0.6547\n",
            "Epoch 319/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6401 - val_loss: 0.6286 - val_binary_accuracy: 0.6605\n",
            "Epoch 320/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6420 - val_loss: 0.6298 - val_binary_accuracy: 0.6614\n",
            "Epoch 321/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6387 - val_loss: 0.6284 - val_binary_accuracy: 0.6610\n",
            "Epoch 322/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6380 - val_loss: 0.6314 - val_binary_accuracy: 0.6626\n",
            "Epoch 323/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6369 - val_loss: 0.6286 - val_binary_accuracy: 0.6618\n",
            "Epoch 324/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6317 - val_loss: 0.6304 - val_binary_accuracy: 0.6630\n",
            "Epoch 325/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6347 - val_loss: 0.6285 - val_binary_accuracy: 0.6534\n",
            "Epoch 326/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6294 - binary_accuracy: 0.6355 - val_loss: 0.6294 - val_binary_accuracy: 0.6626\n",
            "Epoch 327/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6376 - val_loss: 0.6293 - val_binary_accuracy: 0.6572\n",
            "Epoch 328/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6310 - binary_accuracy: 0.6386 - val_loss: 0.6263 - val_binary_accuracy: 0.6626\n",
            "Epoch 329/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6348 - val_loss: 0.6286 - val_binary_accuracy: 0.6635\n",
            "Epoch 330/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6386 - val_loss: 0.6304 - val_binary_accuracy: 0.6568\n",
            "Epoch 331/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6414 - val_loss: 0.6290 - val_binary_accuracy: 0.6622\n",
            "Epoch 332/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6332 - val_loss: 0.6298 - val_binary_accuracy: 0.6626\n",
            "Epoch 333/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6421 - val_loss: 0.6276 - val_binary_accuracy: 0.6593\n",
            "Epoch 334/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6411 - val_loss: 0.6296 - val_binary_accuracy: 0.6597\n",
            "Epoch 335/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6482 - val_loss: 0.6286 - val_binary_accuracy: 0.6610\n",
            "Epoch 336/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6387 - val_loss: 0.6282 - val_binary_accuracy: 0.6539\n",
            "Epoch 337/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6415 - val_loss: 0.6290 - val_binary_accuracy: 0.6564\n",
            "Epoch 338/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6295 - val_loss: 0.6285 - val_binary_accuracy: 0.6593\n",
            "Epoch 339/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6381 - val_loss: 0.6286 - val_binary_accuracy: 0.6664\n",
            "Epoch 340/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6415 - val_loss: 0.6302 - val_binary_accuracy: 0.6597\n",
            "Epoch 341/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6326 - val_loss: 0.6313 - val_binary_accuracy: 0.6626\n",
            "Epoch 342/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6338 - val_loss: 0.6307 - val_binary_accuracy: 0.6630\n",
            "Epoch 343/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6421 - val_loss: 0.6288 - val_binary_accuracy: 0.6622\n",
            "Epoch 344/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6362 - val_loss: 0.6287 - val_binary_accuracy: 0.6597\n",
            "Epoch 345/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6373 - val_loss: 0.6294 - val_binary_accuracy: 0.6635\n",
            "Epoch 346/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6350 - val_loss: 0.6282 - val_binary_accuracy: 0.6601\n",
            "Epoch 347/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6333 - binary_accuracy: 0.6349 - val_loss: 0.6301 - val_binary_accuracy: 0.6610\n",
            "Epoch 348/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6382 - val_loss: 0.6287 - val_binary_accuracy: 0.6635\n",
            "Epoch 349/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6370 - val_loss: 0.6286 - val_binary_accuracy: 0.6643\n",
            "Epoch 350/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6428 - val_loss: 0.6286 - val_binary_accuracy: 0.6543\n",
            "Epoch 351/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6357 - val_loss: 0.6286 - val_binary_accuracy: 0.6610\n",
            "Epoch 352/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6380 - val_loss: 0.6285 - val_binary_accuracy: 0.6664\n",
            "Epoch 353/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6366 - val_loss: 0.6287 - val_binary_accuracy: 0.6614\n",
            "Epoch 354/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6398 - val_loss: 0.6289 - val_binary_accuracy: 0.6572\n",
            "Epoch 355/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6294 - binary_accuracy: 0.6352 - val_loss: 0.6294 - val_binary_accuracy: 0.6618\n",
            "Epoch 356/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6375 - val_loss: 0.6303 - val_binary_accuracy: 0.6589\n",
            "Epoch 357/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6358 - val_loss: 0.6282 - val_binary_accuracy: 0.6601\n",
            "Epoch 358/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6394 - val_loss: 0.6266 - val_binary_accuracy: 0.6605\n",
            "Epoch 359/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6294 - binary_accuracy: 0.6406 - val_loss: 0.6263 - val_binary_accuracy: 0.6635\n",
            "Epoch 360/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6414 - val_loss: 0.6260 - val_binary_accuracy: 0.6635\n",
            "Epoch 361/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6374 - val_loss: 0.6290 - val_binary_accuracy: 0.6622\n",
            "Epoch 362/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6358 - val_loss: 0.6288 - val_binary_accuracy: 0.6605\n",
            "Epoch 363/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6397 - val_loss: 0.6280 - val_binary_accuracy: 0.6651\n",
            "Epoch 364/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6359 - val_loss: 0.6273 - val_binary_accuracy: 0.6668\n",
            "Epoch 365/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6411 - val_loss: 0.6287 - val_binary_accuracy: 0.6610\n",
            "Epoch 366/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6331 - binary_accuracy: 0.6438 - val_loss: 0.6261 - val_binary_accuracy: 0.6635\n",
            "Epoch 367/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6403 - val_loss: 0.6287 - val_binary_accuracy: 0.6618\n",
            "Epoch 368/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6408 - val_loss: 0.6268 - val_binary_accuracy: 0.6597\n",
            "Epoch 369/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6408 - val_loss: 0.6296 - val_binary_accuracy: 0.6580\n",
            "Epoch 370/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6314 - val_loss: 0.6280 - val_binary_accuracy: 0.6622\n",
            "Epoch 371/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6397 - val_loss: 0.6267 - val_binary_accuracy: 0.6664\n",
            "Epoch 372/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6361 - val_loss: 0.6274 - val_binary_accuracy: 0.6626\n",
            "Epoch 373/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6415 - val_loss: 0.6291 - val_binary_accuracy: 0.6668\n",
            "Epoch 374/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6313 - val_loss: 0.6276 - val_binary_accuracy: 0.6630\n",
            "Epoch 375/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6385 - val_loss: 0.6290 - val_binary_accuracy: 0.6626\n",
            "Epoch 376/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6369 - val_loss: 0.6249 - val_binary_accuracy: 0.6630\n",
            "Epoch 377/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6427 - val_loss: 0.6265 - val_binary_accuracy: 0.6622\n",
            "Epoch 378/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6312 - binary_accuracy: 0.6397 - val_loss: 0.6267 - val_binary_accuracy: 0.6639\n",
            "Epoch 379/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6413 - val_loss: 0.6281 - val_binary_accuracy: 0.6630\n",
            "Epoch 380/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6333 - val_loss: 0.6265 - val_binary_accuracy: 0.6610\n",
            "Epoch 381/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6294 - binary_accuracy: 0.6374 - val_loss: 0.6278 - val_binary_accuracy: 0.6622\n",
            "Epoch 382/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6330 - binary_accuracy: 0.6361 - val_loss: 0.6279 - val_binary_accuracy: 0.6639\n",
            "Epoch 383/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6407 - val_loss: 0.6252 - val_binary_accuracy: 0.6668\n",
            "Epoch 384/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6342 - val_loss: 0.6295 - val_binary_accuracy: 0.6630\n",
            "Epoch 385/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6388 - val_loss: 0.6286 - val_binary_accuracy: 0.6576\n",
            "Epoch 386/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6373 - val_loss: 0.6280 - val_binary_accuracy: 0.6601\n",
            "Epoch 387/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6395 - val_loss: 0.6255 - val_binary_accuracy: 0.6630\n",
            "Epoch 388/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6361 - val_loss: 0.6248 - val_binary_accuracy: 0.6626\n",
            "Epoch 389/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6375 - val_loss: 0.6280 - val_binary_accuracy: 0.6647\n",
            "Epoch 390/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6473 - val_loss: 0.6246 - val_binary_accuracy: 0.6643\n",
            "Epoch 391/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6390 - val_loss: 0.6280 - val_binary_accuracy: 0.6605\n",
            "Epoch 392/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6395 - val_loss: 0.6283 - val_binary_accuracy: 0.6593\n",
            "Epoch 393/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6412 - val_loss: 0.6277 - val_binary_accuracy: 0.6605\n",
            "Epoch 394/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6423 - val_loss: 0.6277 - val_binary_accuracy: 0.6622\n",
            "Epoch 395/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6359 - val_loss: 0.6269 - val_binary_accuracy: 0.6668\n",
            "Epoch 396/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6408 - val_loss: 0.6256 - val_binary_accuracy: 0.6622\n",
            "Epoch 397/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6361 - val_loss: 0.6283 - val_binary_accuracy: 0.6597\n",
            "Epoch 398/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6370 - val_loss: 0.6281 - val_binary_accuracy: 0.6580\n",
            "Epoch 399/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6433 - val_loss: 0.6276 - val_binary_accuracy: 0.6626\n",
            "Epoch 400/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6411 - val_loss: 0.6263 - val_binary_accuracy: 0.6626\n",
            "Epoch 401/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6356 - val_loss: 0.6256 - val_binary_accuracy: 0.6635\n",
            "Epoch 402/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6411 - val_loss: 0.6265 - val_binary_accuracy: 0.6614\n",
            "Epoch 403/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6379 - val_loss: 0.6283 - val_binary_accuracy: 0.6639\n",
            "Epoch 404/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6362 - val_loss: 0.6274 - val_binary_accuracy: 0.6643\n",
            "Epoch 405/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6402 - val_loss: 0.6262 - val_binary_accuracy: 0.6647\n",
            "Epoch 406/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6424 - val_loss: 0.6275 - val_binary_accuracy: 0.6614\n",
            "Epoch 407/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6389 - val_loss: 0.6244 - val_binary_accuracy: 0.6626\n",
            "Epoch 408/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6394 - val_loss: 0.6272 - val_binary_accuracy: 0.6622\n",
            "Epoch 409/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6349 - val_loss: 0.6257 - val_binary_accuracy: 0.6622\n",
            "Epoch 410/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6366 - val_loss: 0.6255 - val_binary_accuracy: 0.6585\n",
            "Epoch 411/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6360 - val_loss: 0.6293 - val_binary_accuracy: 0.6597\n",
            "Epoch 412/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6383 - val_loss: 0.6246 - val_binary_accuracy: 0.6618\n",
            "Epoch 413/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6411 - val_loss: 0.6259 - val_binary_accuracy: 0.6597\n",
            "Epoch 414/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6360 - val_loss: 0.6276 - val_binary_accuracy: 0.6601\n",
            "Epoch 415/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6403 - val_loss: 0.6277 - val_binary_accuracy: 0.6526\n",
            "Epoch 416/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6434 - val_loss: 0.6263 - val_binary_accuracy: 0.6656\n",
            "Epoch 417/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6421 - val_loss: 0.6242 - val_binary_accuracy: 0.6610\n",
            "Epoch 418/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6424 - val_loss: 0.6230 - val_binary_accuracy: 0.6601\n",
            "Epoch 419/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6367 - val_loss: 0.6254 - val_binary_accuracy: 0.6622\n",
            "Epoch 420/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6378 - val_loss: 0.6267 - val_binary_accuracy: 0.6639\n",
            "Epoch 421/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6375 - val_loss: 0.6247 - val_binary_accuracy: 0.6643\n",
            "Epoch 422/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6403 - val_loss: 0.6267 - val_binary_accuracy: 0.6605\n",
            "Epoch 423/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6446 - val_loss: 0.6269 - val_binary_accuracy: 0.6551\n",
            "Epoch 424/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6369 - val_loss: 0.6241 - val_binary_accuracy: 0.6572\n",
            "Epoch 425/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6377 - val_loss: 0.6243 - val_binary_accuracy: 0.6639\n",
            "Epoch 426/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6385 - val_loss: 0.6250 - val_binary_accuracy: 0.6639\n",
            "Epoch 427/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6401 - val_loss: 0.6265 - val_binary_accuracy: 0.6635\n",
            "Epoch 428/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6368 - val_loss: 0.6262 - val_binary_accuracy: 0.6580\n",
            "Epoch 429/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6364 - val_loss: 0.6247 - val_binary_accuracy: 0.6610\n",
            "Epoch 430/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6412 - val_loss: 0.6253 - val_binary_accuracy: 0.6551\n",
            "Epoch 431/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6377 - val_loss: 0.6238 - val_binary_accuracy: 0.6639\n",
            "Epoch 432/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6392 - val_loss: 0.6229 - val_binary_accuracy: 0.6651\n",
            "Epoch 433/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6366 - val_loss: 0.6250 - val_binary_accuracy: 0.6614\n",
            "Epoch 434/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6420 - val_loss: 0.6220 - val_binary_accuracy: 0.6656\n",
            "Epoch 435/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6356 - val_loss: 0.6272 - val_binary_accuracy: 0.6639\n",
            "Epoch 436/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6472 - val_loss: 0.6236 - val_binary_accuracy: 0.6593\n",
            "Epoch 437/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6410 - val_loss: 0.6224 - val_binary_accuracy: 0.6610\n",
            "Epoch 438/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6382 - val_loss: 0.6262 - val_binary_accuracy: 0.6618\n",
            "Epoch 439/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6341 - val_loss: 0.6252 - val_binary_accuracy: 0.6601\n",
            "Epoch 440/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6404 - val_loss: 0.6236 - val_binary_accuracy: 0.6580\n",
            "Epoch 441/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6378 - val_loss: 0.6256 - val_binary_accuracy: 0.6639\n",
            "Epoch 442/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6371 - val_loss: 0.6244 - val_binary_accuracy: 0.6589\n",
            "Epoch 443/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6386 - val_loss: 0.6259 - val_binary_accuracy: 0.6614\n",
            "Epoch 444/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6411 - val_loss: 0.6248 - val_binary_accuracy: 0.6589\n",
            "Epoch 445/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6413 - val_loss: 0.6249 - val_binary_accuracy: 0.6618\n",
            "Epoch 446/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6411 - val_loss: 0.6235 - val_binary_accuracy: 0.6614\n",
            "Epoch 447/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6380 - val_loss: 0.6262 - val_binary_accuracy: 0.6614\n",
            "Epoch 448/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6365 - val_loss: 0.6254 - val_binary_accuracy: 0.6589\n",
            "Epoch 449/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6436 - val_loss: 0.6263 - val_binary_accuracy: 0.6656\n",
            "Epoch 450/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6439 - val_loss: 0.6253 - val_binary_accuracy: 0.6689\n",
            "Epoch 451/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6409 - val_loss: 0.6258 - val_binary_accuracy: 0.6614\n",
            "Epoch 452/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6445 - val_loss: 0.6280 - val_binary_accuracy: 0.6622\n",
            "Epoch 453/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6388 - val_loss: 0.6274 - val_binary_accuracy: 0.6585\n",
            "Epoch 454/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6311 - binary_accuracy: 0.6391 - val_loss: 0.6253 - val_binary_accuracy: 0.6626\n",
            "Epoch 455/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6429 - val_loss: 0.6249 - val_binary_accuracy: 0.6643\n",
            "Epoch 456/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6417 - val_loss: 0.6239 - val_binary_accuracy: 0.6580\n",
            "Epoch 457/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6492 - val_loss: 0.6247 - val_binary_accuracy: 0.6605\n",
            "Epoch 458/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6387 - val_loss: 0.6233 - val_binary_accuracy: 0.6626\n",
            "Epoch 459/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6432 - val_loss: 0.6229 - val_binary_accuracy: 0.6635\n",
            "Epoch 460/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6428 - val_loss: 0.6227 - val_binary_accuracy: 0.6622\n",
            "Epoch 461/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6471 - val_loss: 0.6242 - val_binary_accuracy: 0.6647\n",
            "Epoch 462/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6509 - val_loss: 0.6226 - val_binary_accuracy: 0.6651\n",
            "Epoch 463/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6441 - val_loss: 0.6262 - val_binary_accuracy: 0.6647\n",
            "Epoch 464/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6456 - val_loss: 0.6249 - val_binary_accuracy: 0.6601\n",
            "Epoch 465/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6386 - val_loss: 0.6242 - val_binary_accuracy: 0.6614\n",
            "Epoch 466/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6464 - val_loss: 0.6248 - val_binary_accuracy: 0.6651\n",
            "Epoch 467/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6445 - val_loss: 0.6251 - val_binary_accuracy: 0.6572\n",
            "Epoch 468/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6429 - val_loss: 0.6238 - val_binary_accuracy: 0.6589\n",
            "Epoch 469/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6396 - val_loss: 0.6259 - val_binary_accuracy: 0.6597\n",
            "Epoch 470/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6375 - val_loss: 0.6251 - val_binary_accuracy: 0.6585\n",
            "Epoch 471/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6489 - val_loss: 0.6239 - val_binary_accuracy: 0.6597\n",
            "Epoch 472/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6460 - val_loss: 0.6231 - val_binary_accuracy: 0.6614\n",
            "Epoch 473/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6447 - val_loss: 0.6239 - val_binary_accuracy: 0.6580\n",
            "Epoch 474/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6445 - val_loss: 0.6236 - val_binary_accuracy: 0.6618\n",
            "Epoch 475/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6447 - val_loss: 0.6264 - val_binary_accuracy: 0.6626\n",
            "Epoch 476/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6376 - val_loss: 0.6269 - val_binary_accuracy: 0.6601\n",
            "Epoch 477/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6448 - val_loss: 0.6254 - val_binary_accuracy: 0.6639\n",
            "Epoch 478/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6442 - val_loss: 0.6225 - val_binary_accuracy: 0.6585\n",
            "Epoch 479/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6438 - val_loss: 0.6258 - val_binary_accuracy: 0.6580\n",
            "Epoch 480/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6399 - val_loss: 0.6243 - val_binary_accuracy: 0.6618\n",
            "Epoch 481/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6429 - val_loss: 0.6274 - val_binary_accuracy: 0.6622\n",
            "Epoch 482/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6472 - val_loss: 0.6236 - val_binary_accuracy: 0.6597\n",
            "Epoch 483/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6429 - val_loss: 0.6248 - val_binary_accuracy: 0.6618\n",
            "Epoch 484/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6489 - val_loss: 0.6248 - val_binary_accuracy: 0.6576\n",
            "Epoch 485/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6452 - val_loss: 0.6259 - val_binary_accuracy: 0.6597\n",
            "Epoch 486/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6445 - val_loss: 0.6275 - val_binary_accuracy: 0.6559\n",
            "Epoch 487/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6438 - val_loss: 0.6252 - val_binary_accuracy: 0.6585\n",
            "Epoch 488/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6439 - val_loss: 0.6261 - val_binary_accuracy: 0.6605\n",
            "Epoch 489/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6459 - val_loss: 0.6230 - val_binary_accuracy: 0.6610\n",
            "Epoch 490/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6485 - val_loss: 0.6213 - val_binary_accuracy: 0.6614\n",
            "Epoch 491/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6426 - val_loss: 0.6237 - val_binary_accuracy: 0.6605\n",
            "Epoch 492/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6486 - val_loss: 0.6250 - val_binary_accuracy: 0.6605\n",
            "Epoch 493/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6454 - val_loss: 0.6255 - val_binary_accuracy: 0.6576\n",
            "Epoch 494/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6396 - val_loss: 0.6269 - val_binary_accuracy: 0.6593\n",
            "Epoch 495/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6428 - val_loss: 0.6261 - val_binary_accuracy: 0.6585\n",
            "Epoch 496/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6494 - val_loss: 0.6245 - val_binary_accuracy: 0.6593\n",
            "Epoch 497/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6481 - val_loss: 0.6216 - val_binary_accuracy: 0.6597\n",
            "Epoch 498/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6454 - val_loss: 0.6251 - val_binary_accuracy: 0.6626\n",
            "Epoch 499/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6467 - val_loss: 0.6227 - val_binary_accuracy: 0.6635\n",
            "Epoch 500/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6441 - val_loss: 0.6242 - val_binary_accuracy: 0.6559\n",
            "Epoch 501/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6497 - val_loss: 0.6246 - val_binary_accuracy: 0.6564\n",
            "Epoch 502/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6462 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 503/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6435 - val_loss: 0.6257 - val_binary_accuracy: 0.6559\n",
            "Epoch 504/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6444 - val_loss: 0.6238 - val_binary_accuracy: 0.6597\n",
            "Epoch 505/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6458 - val_loss: 0.6219 - val_binary_accuracy: 0.6618\n",
            "Epoch 506/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6470 - val_loss: 0.6245 - val_binary_accuracy: 0.6614\n",
            "Epoch 507/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6432 - val_loss: 0.6227 - val_binary_accuracy: 0.6610\n",
            "Epoch 508/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6497 - val_loss: 0.6240 - val_binary_accuracy: 0.6580\n",
            "Epoch 509/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6494 - val_loss: 0.6239 - val_binary_accuracy: 0.6580\n",
            "Epoch 510/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6477 - val_loss: 0.6241 - val_binary_accuracy: 0.6614\n",
            "Epoch 511/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6457 - val_loss: 0.6234 - val_binary_accuracy: 0.6618\n",
            "Epoch 512/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6466 - val_loss: 0.6224 - val_binary_accuracy: 0.6622\n",
            "Epoch 513/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6486 - val_loss: 0.6230 - val_binary_accuracy: 0.6593\n",
            "Epoch 514/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6438 - val_loss: 0.6238 - val_binary_accuracy: 0.6597\n",
            "Epoch 515/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6436 - val_loss: 0.6232 - val_binary_accuracy: 0.6626\n",
            "Epoch 516/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6470 - val_loss: 0.6242 - val_binary_accuracy: 0.6551\n",
            "Epoch 517/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6403 - val_loss: 0.6221 - val_binary_accuracy: 0.6597\n",
            "Epoch 518/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6427 - val_loss: 0.6225 - val_binary_accuracy: 0.6559\n",
            "Epoch 519/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6483 - val_loss: 0.6223 - val_binary_accuracy: 0.6564\n",
            "Epoch 520/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6471 - val_loss: 0.6240 - val_binary_accuracy: 0.6589\n",
            "Epoch 521/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6459 - val_loss: 0.6241 - val_binary_accuracy: 0.6589\n",
            "Epoch 522/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6483 - val_loss: 0.6238 - val_binary_accuracy: 0.6630\n",
            "Epoch 523/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6493 - val_loss: 0.6248 - val_binary_accuracy: 0.6576\n",
            "Epoch 524/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6409 - val_loss: 0.6256 - val_binary_accuracy: 0.6559\n",
            "Epoch 525/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6492 - val_loss: 0.6231 - val_binary_accuracy: 0.6555\n",
            "Epoch 526/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6450 - val_loss: 0.6243 - val_binary_accuracy: 0.6601\n",
            "Epoch 527/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6484 - val_loss: 0.6230 - val_binary_accuracy: 0.6610\n",
            "Epoch 528/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6472 - val_loss: 0.6225 - val_binary_accuracy: 0.6543\n",
            "Epoch 529/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6473 - val_loss: 0.6257 - val_binary_accuracy: 0.6539\n",
            "Epoch 530/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6471 - val_loss: 0.6239 - val_binary_accuracy: 0.6576\n",
            "Epoch 531/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6458 - val_loss: 0.6257 - val_binary_accuracy: 0.6597\n",
            "Epoch 532/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6478 - val_loss: 0.6256 - val_binary_accuracy: 0.6559\n",
            "Epoch 533/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6489 - val_loss: 0.6248 - val_binary_accuracy: 0.6601\n",
            "Epoch 534/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6477 - val_loss: 0.6240 - val_binary_accuracy: 0.6580\n",
            "Epoch 535/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6474 - val_loss: 0.6241 - val_binary_accuracy: 0.6572\n",
            "Epoch 536/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6436 - val_loss: 0.6251 - val_binary_accuracy: 0.6555\n",
            "Epoch 537/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6432 - val_loss: 0.6225 - val_binary_accuracy: 0.6589\n",
            "Epoch 538/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6448 - val_loss: 0.6250 - val_binary_accuracy: 0.6572\n",
            "Epoch 539/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6476 - val_loss: 0.6223 - val_binary_accuracy: 0.6618\n",
            "Epoch 540/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6414 - val_loss: 0.6255 - val_binary_accuracy: 0.6589\n",
            "Epoch 541/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6485 - val_loss: 0.6229 - val_binary_accuracy: 0.6551\n",
            "Epoch 542/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6474 - val_loss: 0.6258 - val_binary_accuracy: 0.6597\n",
            "Epoch 543/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6501 - val_loss: 0.6213 - val_binary_accuracy: 0.6585\n",
            "Epoch 544/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6503 - val_loss: 0.6223 - val_binary_accuracy: 0.6572\n",
            "Epoch 545/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6508 - val_loss: 0.6223 - val_binary_accuracy: 0.6580\n",
            "Epoch 546/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6507 - val_loss: 0.6252 - val_binary_accuracy: 0.6564\n",
            "Epoch 547/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6466 - val_loss: 0.6237 - val_binary_accuracy: 0.6576\n",
            "Epoch 548/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6479 - val_loss: 0.6253 - val_binary_accuracy: 0.6614\n",
            "Epoch 549/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6522 - val_loss: 0.6214 - val_binary_accuracy: 0.6630\n",
            "Epoch 550/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6490 - val_loss: 0.6232 - val_binary_accuracy: 0.6643\n",
            "Epoch 551/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6464 - val_loss: 0.6252 - val_binary_accuracy: 0.6526\n",
            "Epoch 552/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6454 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 553/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6578 - val_loss: 0.6259 - val_binary_accuracy: 0.6614\n",
            "Epoch 554/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6483 - val_loss: 0.6234 - val_binary_accuracy: 0.6580\n",
            "Epoch 555/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6499 - val_loss: 0.6248 - val_binary_accuracy: 0.6564\n",
            "Epoch 556/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6507 - val_loss: 0.6228 - val_binary_accuracy: 0.6589\n",
            "Epoch 557/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6486 - val_loss: 0.6219 - val_binary_accuracy: 0.6568\n",
            "Epoch 558/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6497 - val_loss: 0.6217 - val_binary_accuracy: 0.6580\n",
            "Epoch 559/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6481 - val_loss: 0.6224 - val_binary_accuracy: 0.6589\n",
            "Epoch 560/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6489 - val_loss: 0.6225 - val_binary_accuracy: 0.6585\n",
            "Epoch 561/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6491 - val_loss: 0.6225 - val_binary_accuracy: 0.6568\n",
            "Epoch 562/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6460 - val_loss: 0.6234 - val_binary_accuracy: 0.6601\n",
            "Epoch 563/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6472 - val_loss: 0.6219 - val_binary_accuracy: 0.6618\n",
            "Epoch 564/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6420 - val_loss: 0.6250 - val_binary_accuracy: 0.6589\n",
            "Epoch 565/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6470 - val_loss: 0.6208 - val_binary_accuracy: 0.6597\n",
            "Epoch 566/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6480 - val_loss: 0.6220 - val_binary_accuracy: 0.6589\n",
            "Epoch 567/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6502 - val_loss: 0.6251 - val_binary_accuracy: 0.6589\n",
            "Epoch 568/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6459 - val_loss: 0.6254 - val_binary_accuracy: 0.6576\n",
            "Epoch 569/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6510 - val_loss: 0.6214 - val_binary_accuracy: 0.6626\n",
            "Epoch 570/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6448 - val_loss: 0.6229 - val_binary_accuracy: 0.6668\n",
            "Epoch 571/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6490 - val_loss: 0.6206 - val_binary_accuracy: 0.6605\n",
            "Epoch 572/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6506 - val_loss: 0.6244 - val_binary_accuracy: 0.6622\n",
            "Epoch 573/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6450 - val_loss: 0.6245 - val_binary_accuracy: 0.6576\n",
            "Epoch 574/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6424 - val_loss: 0.6243 - val_binary_accuracy: 0.6547\n",
            "Epoch 575/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6457 - val_loss: 0.6258 - val_binary_accuracy: 0.6539\n",
            "Epoch 576/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6514 - val_loss: 0.6231 - val_binary_accuracy: 0.6555\n",
            "Epoch 577/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6488 - val_loss: 0.6226 - val_binary_accuracy: 0.6614\n",
            "Epoch 578/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6482 - val_loss: 0.6228 - val_binary_accuracy: 0.6564\n",
            "Epoch 579/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6471 - val_loss: 0.6246 - val_binary_accuracy: 0.6568\n",
            "Epoch 580/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6526 - val_loss: 0.6239 - val_binary_accuracy: 0.6605\n",
            "Epoch 581/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6493 - val_loss: 0.6273 - val_binary_accuracy: 0.6576\n",
            "Epoch 582/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6446 - val_loss: 0.6247 - val_binary_accuracy: 0.6551\n",
            "Epoch 583/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6469 - val_loss: 0.6236 - val_binary_accuracy: 0.6580\n",
            "Epoch 584/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6497 - val_loss: 0.6209 - val_binary_accuracy: 0.6522\n",
            "Epoch 585/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6459 - val_loss: 0.6219 - val_binary_accuracy: 0.6605\n",
            "Epoch 586/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6471 - val_loss: 0.6250 - val_binary_accuracy: 0.6593\n",
            "Epoch 587/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6516 - val_loss: 0.6243 - val_binary_accuracy: 0.6585\n",
            "Epoch 588/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6529 - val_loss: 0.6229 - val_binary_accuracy: 0.6555\n",
            "Epoch 589/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6512 - val_loss: 0.6219 - val_binary_accuracy: 0.6564\n",
            "Epoch 590/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6475 - val_loss: 0.6235 - val_binary_accuracy: 0.6559\n",
            "Epoch 591/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6508 - val_loss: 0.6245 - val_binary_accuracy: 0.6605\n",
            "Epoch 592/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6478 - val_loss: 0.6238 - val_binary_accuracy: 0.6564\n",
            "Epoch 593/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6499 - val_loss: 0.6222 - val_binary_accuracy: 0.6534\n",
            "Epoch 594/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6463 - val_loss: 0.6235 - val_binary_accuracy: 0.6534\n",
            "Epoch 595/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6457 - val_loss: 0.6259 - val_binary_accuracy: 0.6551\n",
            "Epoch 596/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6486 - val_loss: 0.6230 - val_binary_accuracy: 0.6580\n",
            "Epoch 597/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6527 - val_loss: 0.6223 - val_binary_accuracy: 0.6605\n",
            "Epoch 598/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6519 - val_loss: 0.6233 - val_binary_accuracy: 0.6576\n",
            "Epoch 599/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6506 - val_loss: 0.6233 - val_binary_accuracy: 0.6597\n",
            "Epoch 600/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6463 - val_loss: 0.6255 - val_binary_accuracy: 0.6564\n",
            "Epoch 601/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6482 - val_loss: 0.6242 - val_binary_accuracy: 0.6585\n",
            "Epoch 602/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6484 - val_loss: 0.6224 - val_binary_accuracy: 0.6559\n",
            "Epoch 603/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6504 - val_loss: 0.6206 - val_binary_accuracy: 0.6564\n",
            "Epoch 604/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6542 - val_loss: 0.6220 - val_binary_accuracy: 0.6555\n",
            "Epoch 605/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6520 - val_loss: 0.6222 - val_binary_accuracy: 0.6580\n",
            "Epoch 606/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6482 - val_loss: 0.6235 - val_binary_accuracy: 0.6555\n",
            "Epoch 607/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6488 - val_loss: 0.6249 - val_binary_accuracy: 0.6585\n",
            "Epoch 608/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6480 - val_loss: 0.6231 - val_binary_accuracy: 0.6593\n",
            "Epoch 609/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6527 - val_loss: 0.6232 - val_binary_accuracy: 0.6585\n",
            "Epoch 610/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6533 - val_loss: 0.6229 - val_binary_accuracy: 0.6597\n",
            "Epoch 611/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6540 - val_loss: 0.6216 - val_binary_accuracy: 0.6593\n",
            "Epoch 612/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6558 - val_loss: 0.6244 - val_binary_accuracy: 0.6564\n",
            "Epoch 613/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6481 - val_loss: 0.6232 - val_binary_accuracy: 0.6601\n",
            "Epoch 614/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6530 - val_loss: 0.6214 - val_binary_accuracy: 0.6597\n",
            "Epoch 615/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6547 - val_loss: 0.6219 - val_binary_accuracy: 0.6635\n",
            "Epoch 616/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6494 - val_loss: 0.6243 - val_binary_accuracy: 0.6585\n",
            "Epoch 617/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6505 - val_loss: 0.6222 - val_binary_accuracy: 0.6568\n",
            "Epoch 618/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6517 - val_loss: 0.6235 - val_binary_accuracy: 0.6501\n",
            "Epoch 619/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6523 - val_loss: 0.6222 - val_binary_accuracy: 0.6568\n",
            "Epoch 620/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6486 - val_loss: 0.6241 - val_binary_accuracy: 0.6530\n",
            "Epoch 621/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6472 - val_loss: 0.6197 - val_binary_accuracy: 0.6601\n",
            "Epoch 622/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6504 - val_loss: 0.6211 - val_binary_accuracy: 0.6559\n",
            "Epoch 623/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6445 - val_loss: 0.6242 - val_binary_accuracy: 0.6522\n",
            "Epoch 624/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6493 - val_loss: 0.6234 - val_binary_accuracy: 0.6589\n",
            "Epoch 625/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6526 - val_loss: 0.6212 - val_binary_accuracy: 0.6580\n",
            "Epoch 626/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6517 - val_loss: 0.6238 - val_binary_accuracy: 0.6660\n",
            "Epoch 627/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6478 - val_loss: 0.6244 - val_binary_accuracy: 0.6589\n",
            "Epoch 628/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6497 - val_loss: 0.6231 - val_binary_accuracy: 0.6576\n",
            "Epoch 629/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6471 - val_loss: 0.6241 - val_binary_accuracy: 0.6551\n",
            "Epoch 630/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6506 - val_loss: 0.6200 - val_binary_accuracy: 0.6576\n",
            "Epoch 631/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6469 - val_loss: 0.6230 - val_binary_accuracy: 0.6551\n",
            "Epoch 632/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6528 - val_loss: 0.6234 - val_binary_accuracy: 0.6559\n",
            "Epoch 633/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6556 - val_loss: 0.6220 - val_binary_accuracy: 0.6559\n",
            "Epoch 634/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6512 - val_loss: 0.6229 - val_binary_accuracy: 0.6610\n",
            "Epoch 635/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6481 - val_loss: 0.6215 - val_binary_accuracy: 0.6639\n",
            "Epoch 636/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6505 - val_loss: 0.6210 - val_binary_accuracy: 0.6555\n",
            "Epoch 637/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6471 - val_loss: 0.6232 - val_binary_accuracy: 0.6593\n",
            "Epoch 638/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6503 - val_loss: 0.6225 - val_binary_accuracy: 0.6564\n",
            "Epoch 639/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6457 - val_loss: 0.6234 - val_binary_accuracy: 0.6559\n",
            "Epoch 640/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6515 - val_loss: 0.6211 - val_binary_accuracy: 0.6572\n",
            "Epoch 641/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6510 - val_loss: 0.6211 - val_binary_accuracy: 0.6576\n",
            "Epoch 642/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6534 - val_loss: 0.6218 - val_binary_accuracy: 0.6593\n",
            "Epoch 643/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6506 - val_loss: 0.6226 - val_binary_accuracy: 0.6593\n",
            "Epoch 644/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6496 - val_loss: 0.6227 - val_binary_accuracy: 0.6551\n",
            "Epoch 645/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6470 - val_loss: 0.6225 - val_binary_accuracy: 0.6551\n",
            "Epoch 646/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6524 - val_loss: 0.6251 - val_binary_accuracy: 0.6568\n",
            "Epoch 647/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6480 - val_loss: 0.6221 - val_binary_accuracy: 0.6614\n",
            "Epoch 648/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6520 - val_loss: 0.6247 - val_binary_accuracy: 0.6534\n",
            "Epoch 649/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6485 - val_loss: 0.6208 - val_binary_accuracy: 0.6547\n",
            "Epoch 650/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6467 - val_loss: 0.6210 - val_binary_accuracy: 0.6576\n",
            "Epoch 651/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6478 - val_loss: 0.6214 - val_binary_accuracy: 0.6543\n",
            "Epoch 652/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6468 - val_loss: 0.6207 - val_binary_accuracy: 0.6564\n",
            "Epoch 653/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6499 - val_loss: 0.6222 - val_binary_accuracy: 0.6568\n",
            "Epoch 654/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6495 - val_loss: 0.6224 - val_binary_accuracy: 0.6526\n",
            "Epoch 655/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6525 - val_loss: 0.6233 - val_binary_accuracy: 0.6568\n",
            "Epoch 656/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6475 - val_loss: 0.6233 - val_binary_accuracy: 0.6543\n",
            "Epoch 657/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6523 - val_loss: 0.6254 - val_binary_accuracy: 0.6539\n",
            "Epoch 658/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6512 - val_loss: 0.6234 - val_binary_accuracy: 0.6555\n",
            "Epoch 659/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6506 - val_loss: 0.6242 - val_binary_accuracy: 0.6534\n",
            "Epoch 660/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6517 - val_loss: 0.6202 - val_binary_accuracy: 0.6610\n",
            "Epoch 661/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6572 - val_loss: 0.6244 - val_binary_accuracy: 0.6580\n",
            "Epoch 662/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6476 - val_loss: 0.6238 - val_binary_accuracy: 0.6514\n",
            "Epoch 663/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6466 - val_loss: 0.6216 - val_binary_accuracy: 0.6630\n",
            "Epoch 664/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6494 - val_loss: 0.6190 - val_binary_accuracy: 0.6597\n",
            "Epoch 665/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6498 - val_loss: 0.6206 - val_binary_accuracy: 0.6585\n",
            "Epoch 666/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6494 - val_loss: 0.6219 - val_binary_accuracy: 0.6610\n",
            "Epoch 667/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6490 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 668/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6464 - val_loss: 0.6223 - val_binary_accuracy: 0.6543\n",
            "Epoch 669/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6463 - val_loss: 0.6237 - val_binary_accuracy: 0.6530\n",
            "Epoch 670/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6577 - val_loss: 0.6201 - val_binary_accuracy: 0.6597\n",
            "Epoch 671/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6474 - val_loss: 0.6215 - val_binary_accuracy: 0.6522\n",
            "Epoch 672/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6497 - val_loss: 0.6224 - val_binary_accuracy: 0.6572\n",
            "Epoch 673/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6446 - val_loss: 0.6209 - val_binary_accuracy: 0.6593\n",
            "Epoch 674/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6492 - val_loss: 0.6210 - val_binary_accuracy: 0.6593\n",
            "Epoch 675/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6493 - val_loss: 0.6210 - val_binary_accuracy: 0.6593\n",
            "Epoch 676/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6487 - val_loss: 0.6215 - val_binary_accuracy: 0.6530\n",
            "Epoch 677/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6498 - val_loss: 0.6231 - val_binary_accuracy: 0.6539\n",
            "Epoch 678/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6501 - val_loss: 0.6226 - val_binary_accuracy: 0.6551\n",
            "Epoch 679/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6491 - val_loss: 0.6232 - val_binary_accuracy: 0.6610\n",
            "Epoch 680/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6532 - val_loss: 0.6202 - val_binary_accuracy: 0.6547\n",
            "Epoch 681/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6520 - val_loss: 0.6197 - val_binary_accuracy: 0.6526\n",
            "Epoch 682/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6479 - val_loss: 0.6228 - val_binary_accuracy: 0.6580\n",
            "Epoch 683/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6442 - val_loss: 0.6241 - val_binary_accuracy: 0.6543\n",
            "Epoch 684/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6474 - val_loss: 0.6200 - val_binary_accuracy: 0.6622\n",
            "Epoch 685/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6515 - val_loss: 0.6211 - val_binary_accuracy: 0.6543\n",
            "Epoch 686/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6523 - val_loss: 0.6222 - val_binary_accuracy: 0.6543\n",
            "Epoch 687/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6536 - val_loss: 0.6221 - val_binary_accuracy: 0.6534\n",
            "Epoch 688/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6499 - val_loss: 0.6212 - val_binary_accuracy: 0.6555\n",
            "Epoch 689/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6488 - val_loss: 0.6226 - val_binary_accuracy: 0.6518\n",
            "Epoch 690/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6535 - val_loss: 0.6218 - val_binary_accuracy: 0.6559\n",
            "Epoch 691/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6456 - val_loss: 0.6212 - val_binary_accuracy: 0.6539\n",
            "Epoch 692/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6507 - val_loss: 0.6222 - val_binary_accuracy: 0.6539\n",
            "Epoch 693/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6470 - val_loss: 0.6194 - val_binary_accuracy: 0.6568\n",
            "Epoch 694/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6485 - val_loss: 0.6219 - val_binary_accuracy: 0.6543\n",
            "Epoch 695/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6521 - val_loss: 0.6192 - val_binary_accuracy: 0.6589\n",
            "Epoch 696/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6487 - val_loss: 0.6214 - val_binary_accuracy: 0.6597\n",
            "Epoch 697/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6481 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 698/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6501 - val_loss: 0.6215 - val_binary_accuracy: 0.6559\n",
            "Epoch 699/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6523 - val_loss: 0.6222 - val_binary_accuracy: 0.6597\n",
            "Epoch 700/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6451 - val_loss: 0.6196 - val_binary_accuracy: 0.6547\n",
            "Epoch 701/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6504 - val_loss: 0.6232 - val_binary_accuracy: 0.6526\n",
            "Epoch 702/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6476 - val_loss: 0.6213 - val_binary_accuracy: 0.6539\n",
            "Epoch 703/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6517 - val_loss: 0.6199 - val_binary_accuracy: 0.6622\n",
            "Epoch 704/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6485 - val_loss: 0.6211 - val_binary_accuracy: 0.6618\n",
            "Epoch 705/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6507 - val_loss: 0.6194 - val_binary_accuracy: 0.6605\n",
            "Epoch 706/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6503 - val_loss: 0.6193 - val_binary_accuracy: 0.6585\n",
            "Epoch 707/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6483 - val_loss: 0.6231 - val_binary_accuracy: 0.6593\n",
            "Epoch 708/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6546 - val_loss: 0.6231 - val_binary_accuracy: 0.6522\n",
            "Epoch 709/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6491 - val_loss: 0.6234 - val_binary_accuracy: 0.6539\n",
            "Epoch 710/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6473 - val_loss: 0.6226 - val_binary_accuracy: 0.6526\n",
            "Epoch 711/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6500 - val_loss: 0.6205 - val_binary_accuracy: 0.6530\n",
            "Epoch 712/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6537 - val_loss: 0.6222 - val_binary_accuracy: 0.6559\n",
            "Epoch 713/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6491 - val_loss: 0.6232 - val_binary_accuracy: 0.6534\n",
            "Epoch 714/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6482 - val_loss: 0.6232 - val_binary_accuracy: 0.6568\n",
            "Epoch 715/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6540 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 716/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6492 - val_loss: 0.6232 - val_binary_accuracy: 0.6555\n",
            "Epoch 717/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6540 - val_loss: 0.6203 - val_binary_accuracy: 0.6618\n",
            "Epoch 718/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6511 - val_loss: 0.6198 - val_binary_accuracy: 0.6601\n",
            "Epoch 719/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6550 - val_loss: 0.6219 - val_binary_accuracy: 0.6585\n",
            "Epoch 720/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6479 - val_loss: 0.6210 - val_binary_accuracy: 0.6643\n",
            "Epoch 721/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6499 - val_loss: 0.6217 - val_binary_accuracy: 0.6509\n",
            "Epoch 722/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6507 - val_loss: 0.6210 - val_binary_accuracy: 0.6539\n",
            "Epoch 723/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6549 - val_loss: 0.6211 - val_binary_accuracy: 0.6564\n",
            "Epoch 724/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6493 - val_loss: 0.6218 - val_binary_accuracy: 0.6635\n",
            "Epoch 725/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6490 - val_loss: 0.6193 - val_binary_accuracy: 0.6572\n",
            "Epoch 726/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6565 - val_loss: 0.6208 - val_binary_accuracy: 0.6597\n",
            "Epoch 727/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6513 - val_loss: 0.6229 - val_binary_accuracy: 0.6559\n",
            "Epoch 728/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6547 - val_loss: 0.6199 - val_binary_accuracy: 0.6622\n",
            "Epoch 729/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6518 - val_loss: 0.6208 - val_binary_accuracy: 0.6568\n",
            "Epoch 730/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6549 - val_loss: 0.6211 - val_binary_accuracy: 0.6551\n",
            "Epoch 731/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6518 - val_loss: 0.6222 - val_binary_accuracy: 0.6576\n",
            "Epoch 732/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6540 - val_loss: 0.6202 - val_binary_accuracy: 0.6593\n",
            "Epoch 733/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6494 - val_loss: 0.6234 - val_binary_accuracy: 0.6576\n",
            "Epoch 734/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6535 - val_loss: 0.6228 - val_binary_accuracy: 0.6530\n",
            "Epoch 735/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6490 - val_loss: 0.6226 - val_binary_accuracy: 0.6580\n",
            "Epoch 736/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6529 - val_loss: 0.6208 - val_binary_accuracy: 0.6589\n",
            "Epoch 737/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6525 - val_loss: 0.6233 - val_binary_accuracy: 0.6509\n",
            "Epoch 738/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6527 - val_loss: 0.6197 - val_binary_accuracy: 0.6559\n",
            "Epoch 739/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6474 - val_loss: 0.6219 - val_binary_accuracy: 0.6534\n",
            "Epoch 740/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6482 - val_loss: 0.6229 - val_binary_accuracy: 0.6530\n",
            "Epoch 741/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6502 - val_loss: 0.6216 - val_binary_accuracy: 0.6564\n",
            "Epoch 742/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6564 - val_loss: 0.6198 - val_binary_accuracy: 0.6576\n",
            "Epoch 743/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6557 - val_loss: 0.6197 - val_binary_accuracy: 0.6551\n",
            "Epoch 744/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6513 - val_loss: 0.6224 - val_binary_accuracy: 0.6564\n",
            "Epoch 745/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6592 - val_loss: 0.6207 - val_binary_accuracy: 0.6568\n",
            "Epoch 746/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6475 - val_loss: 0.6202 - val_binary_accuracy: 0.6605\n",
            "Epoch 747/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6518 - val_loss: 0.6187 - val_binary_accuracy: 0.6568\n",
            "Epoch 748/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6484 - val_loss: 0.6195 - val_binary_accuracy: 0.6618\n",
            "Epoch 749/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6465 - val_loss: 0.6200 - val_binary_accuracy: 0.6597\n",
            "Epoch 750/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6494 - val_loss: 0.6189 - val_binary_accuracy: 0.6580\n",
            "Epoch 751/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6526 - val_loss: 0.6235 - val_binary_accuracy: 0.6572\n",
            "Epoch 752/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6488 - val_loss: 0.6188 - val_binary_accuracy: 0.6568\n",
            "Epoch 753/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6554 - val_loss: 0.6194 - val_binary_accuracy: 0.6543\n",
            "Epoch 754/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6525 - val_loss: 0.6185 - val_binary_accuracy: 0.6605\n",
            "Epoch 755/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6535 - val_loss: 0.6217 - val_binary_accuracy: 0.6568\n",
            "Epoch 756/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6455 - val_loss: 0.6221 - val_binary_accuracy: 0.6572\n",
            "Epoch 757/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6491 - val_loss: 0.6237 - val_binary_accuracy: 0.6522\n",
            "Epoch 758/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6467 - val_loss: 0.6224 - val_binary_accuracy: 0.6564\n",
            "Epoch 759/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6551 - val_loss: 0.6199 - val_binary_accuracy: 0.6543\n",
            "Epoch 760/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6523 - val_loss: 0.6226 - val_binary_accuracy: 0.6543\n",
            "Epoch 761/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6468 - val_loss: 0.6222 - val_binary_accuracy: 0.6572\n",
            "Epoch 762/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6484 - val_loss: 0.6206 - val_binary_accuracy: 0.6614\n",
            "Epoch 763/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6473 - val_loss: 0.6186 - val_binary_accuracy: 0.6605\n",
            "Epoch 764/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6472 - val_loss: 0.6224 - val_binary_accuracy: 0.6514\n",
            "Epoch 765/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6487 - val_loss: 0.6237 - val_binary_accuracy: 0.6509\n",
            "Epoch 766/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6543 - val_loss: 0.6210 - val_binary_accuracy: 0.6589\n",
            "Epoch 767/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6505 - val_loss: 0.6204 - val_binary_accuracy: 0.6564\n",
            "Epoch 768/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6572 - val_loss: 0.6207 - val_binary_accuracy: 0.6564\n",
            "Epoch 769/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6514 - val_loss: 0.6183 - val_binary_accuracy: 0.6585\n",
            "Epoch 770/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6505 - val_loss: 0.6237 - val_binary_accuracy: 0.6530\n",
            "Epoch 771/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6477 - val_loss: 0.6213 - val_binary_accuracy: 0.6551\n",
            "Epoch 772/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6583 - val_loss: 0.6217 - val_binary_accuracy: 0.6559\n",
            "Epoch 773/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6537 - val_loss: 0.6210 - val_binary_accuracy: 0.6568\n",
            "Epoch 774/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6540 - val_loss: 0.6225 - val_binary_accuracy: 0.6597\n",
            "Epoch 775/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6529 - val_loss: 0.6220 - val_binary_accuracy: 0.6576\n",
            "Epoch 776/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6497 - val_loss: 0.6246 - val_binary_accuracy: 0.6509\n",
            "Epoch 777/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6549 - val_loss: 0.6211 - val_binary_accuracy: 0.6585\n",
            "Epoch 778/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6450 - val_loss: 0.6219 - val_binary_accuracy: 0.6555\n",
            "Epoch 779/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6494 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 780/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6496 - val_loss: 0.6214 - val_binary_accuracy: 0.6543\n",
            "Epoch 781/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6533 - val_loss: 0.6221 - val_binary_accuracy: 0.6568\n",
            "Epoch 782/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6525 - val_loss: 0.6214 - val_binary_accuracy: 0.6559\n",
            "Epoch 783/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6524 - val_loss: 0.6191 - val_binary_accuracy: 0.6534\n",
            "Epoch 784/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6518 - val_loss: 0.6214 - val_binary_accuracy: 0.6568\n",
            "Epoch 785/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6512 - val_loss: 0.6222 - val_binary_accuracy: 0.6572\n",
            "Epoch 786/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6530 - val_loss: 0.6214 - val_binary_accuracy: 0.6543\n",
            "Epoch 787/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6541 - val_loss: 0.6205 - val_binary_accuracy: 0.6589\n",
            "Epoch 788/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6445 - val_loss: 0.6220 - val_binary_accuracy: 0.6551\n",
            "Epoch 789/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6483 - val_loss: 0.6231 - val_binary_accuracy: 0.6593\n",
            "Epoch 790/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6528 - val_loss: 0.6221 - val_binary_accuracy: 0.6543\n",
            "Epoch 791/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6523 - val_loss: 0.6216 - val_binary_accuracy: 0.6597\n",
            "Epoch 792/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6462 - val_loss: 0.6204 - val_binary_accuracy: 0.6543\n",
            "Epoch 793/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6501 - val_loss: 0.6191 - val_binary_accuracy: 0.6580\n",
            "Epoch 794/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6566 - val_loss: 0.6189 - val_binary_accuracy: 0.6585\n",
            "Epoch 795/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6517 - val_loss: 0.6210 - val_binary_accuracy: 0.6580\n",
            "Epoch 796/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6525 - val_loss: 0.6210 - val_binary_accuracy: 0.6639\n",
            "Epoch 797/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6521 - val_loss: 0.6214 - val_binary_accuracy: 0.6589\n",
            "Epoch 798/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6536 - val_loss: 0.6195 - val_binary_accuracy: 0.6605\n",
            "Epoch 799/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6555 - val_loss: 0.6212 - val_binary_accuracy: 0.6526\n",
            "Epoch 800/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6471 - val_loss: 0.6233 - val_binary_accuracy: 0.6522\n",
            "Epoch 801/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6513 - val_loss: 0.6227 - val_binary_accuracy: 0.6534\n",
            "Epoch 802/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6502 - val_loss: 0.6221 - val_binary_accuracy: 0.6618\n",
            "Epoch 803/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6562 - val_loss: 0.6221 - val_binary_accuracy: 0.6534\n",
            "Epoch 804/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6500 - val_loss: 0.6217 - val_binary_accuracy: 0.6559\n",
            "Epoch 805/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6505 - val_loss: 0.6221 - val_binary_accuracy: 0.6572\n",
            "Epoch 806/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6574 - val_loss: 0.6204 - val_binary_accuracy: 0.6555\n",
            "Epoch 807/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6516 - val_loss: 0.6194 - val_binary_accuracy: 0.6580\n",
            "Epoch 808/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6521 - val_loss: 0.6217 - val_binary_accuracy: 0.6614\n",
            "Epoch 809/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6540 - val_loss: 0.6216 - val_binary_accuracy: 0.6564\n",
            "Epoch 810/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6569 - val_loss: 0.6206 - val_binary_accuracy: 0.6626\n",
            "Epoch 811/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6492 - val_loss: 0.6185 - val_binary_accuracy: 0.6576\n",
            "Epoch 812/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6548 - val_loss: 0.6213 - val_binary_accuracy: 0.6618\n",
            "Epoch 813/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6525 - val_loss: 0.6211 - val_binary_accuracy: 0.6539\n",
            "Epoch 814/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6594 - val_loss: 0.6228 - val_binary_accuracy: 0.6530\n",
            "Epoch 815/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6562 - val_loss: 0.6212 - val_binary_accuracy: 0.6543\n",
            "Epoch 816/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6526 - val_loss: 0.6237 - val_binary_accuracy: 0.6534\n",
            "Epoch 817/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6548 - val_loss: 0.6209 - val_binary_accuracy: 0.6585\n",
            "Epoch 818/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6548 - val_loss: 0.6227 - val_binary_accuracy: 0.6555\n",
            "Epoch 819/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6551 - val_loss: 0.6214 - val_binary_accuracy: 0.6551\n",
            "Epoch 820/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6509 - val_loss: 0.6212 - val_binary_accuracy: 0.6589\n",
            "Epoch 821/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6496 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 822/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6502 - val_loss: 0.6200 - val_binary_accuracy: 0.6643\n",
            "Epoch 823/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6540 - val_loss: 0.6206 - val_binary_accuracy: 0.6564\n",
            "Epoch 824/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6538 - val_loss: 0.6202 - val_binary_accuracy: 0.6626\n",
            "Epoch 825/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6525 - val_loss: 0.6193 - val_binary_accuracy: 0.6555\n",
            "Epoch 826/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6569 - val_loss: 0.6194 - val_binary_accuracy: 0.6547\n",
            "Epoch 827/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6520 - val_loss: 0.6200 - val_binary_accuracy: 0.6576\n",
            "Epoch 828/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6503 - val_loss: 0.6212 - val_binary_accuracy: 0.6547\n",
            "Epoch 829/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6478 - val_loss: 0.6205 - val_binary_accuracy: 0.6547\n",
            "Epoch 830/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6583 - val_loss: 0.6224 - val_binary_accuracy: 0.6526\n",
            "Epoch 831/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6542 - val_loss: 0.6207 - val_binary_accuracy: 0.6522\n",
            "Epoch 832/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6562 - val_loss: 0.6220 - val_binary_accuracy: 0.6580\n",
            "Epoch 833/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6518 - val_loss: 0.6230 - val_binary_accuracy: 0.6547\n",
            "Epoch 834/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6526 - val_loss: 0.6214 - val_binary_accuracy: 0.6580\n",
            "Epoch 835/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6540 - val_loss: 0.6233 - val_binary_accuracy: 0.6589\n",
            "Epoch 836/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6475 - val_loss: 0.6208 - val_binary_accuracy: 0.6622\n",
            "Epoch 837/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6523 - val_loss: 0.6219 - val_binary_accuracy: 0.6572\n",
            "Epoch 838/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6527 - val_loss: 0.6204 - val_binary_accuracy: 0.6509\n",
            "Epoch 839/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6512 - val_loss: 0.6193 - val_binary_accuracy: 0.6601\n",
            "Epoch 840/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6555 - val_loss: 0.6207 - val_binary_accuracy: 0.6559\n",
            "Epoch 841/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6515 - val_loss: 0.6219 - val_binary_accuracy: 0.6551\n",
            "Epoch 842/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6582 - val_loss: 0.6212 - val_binary_accuracy: 0.6555\n",
            "Epoch 843/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6565 - val_loss: 0.6209 - val_binary_accuracy: 0.6576\n",
            "Epoch 844/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6548 - val_loss: 0.6218 - val_binary_accuracy: 0.6514\n",
            "Epoch 845/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6571 - val_loss: 0.6186 - val_binary_accuracy: 0.6585\n",
            "Epoch 846/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6507 - val_loss: 0.6215 - val_binary_accuracy: 0.6564\n",
            "Epoch 847/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6554 - val_loss: 0.6222 - val_binary_accuracy: 0.6564\n",
            "Epoch 848/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6566 - val_loss: 0.6195 - val_binary_accuracy: 0.6530\n",
            "Epoch 849/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6501 - val_loss: 0.6193 - val_binary_accuracy: 0.6656\n",
            "Epoch 850/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6522 - val_loss: 0.6224 - val_binary_accuracy: 0.6526\n",
            "Epoch 851/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6557 - val_loss: 0.6213 - val_binary_accuracy: 0.6530\n",
            "Epoch 852/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6602 - val_loss: 0.6189 - val_binary_accuracy: 0.6614\n",
            "Epoch 853/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6547 - val_loss: 0.6199 - val_binary_accuracy: 0.6605\n",
            "Epoch 854/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6497 - val_loss: 0.6224 - val_binary_accuracy: 0.6526\n",
            "Epoch 855/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6531 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 856/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6542 - val_loss: 0.6206 - val_binary_accuracy: 0.6585\n",
            "Epoch 857/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6523 - val_loss: 0.6224 - val_binary_accuracy: 0.6530\n",
            "Epoch 858/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6619 - val_loss: 0.6234 - val_binary_accuracy: 0.6518\n",
            "Epoch 859/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6516 - val_loss: 0.6215 - val_binary_accuracy: 0.6522\n",
            "Epoch 860/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6548 - val_loss: 0.6199 - val_binary_accuracy: 0.6564\n",
            "Epoch 861/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6514 - val_loss: 0.6199 - val_binary_accuracy: 0.6585\n",
            "Epoch 862/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6513 - val_loss: 0.6184 - val_binary_accuracy: 0.6585\n",
            "Epoch 863/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6547 - val_loss: 0.6211 - val_binary_accuracy: 0.6543\n",
            "Epoch 864/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6454 - val_loss: 0.6201 - val_binary_accuracy: 0.6589\n",
            "Epoch 865/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6517 - val_loss: 0.6235 - val_binary_accuracy: 0.6555\n",
            "Epoch 866/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6548 - val_loss: 0.6204 - val_binary_accuracy: 0.6509\n",
            "Epoch 867/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6591 - val_loss: 0.6179 - val_binary_accuracy: 0.6564\n",
            "Epoch 868/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6533 - val_loss: 0.6200 - val_binary_accuracy: 0.6572\n",
            "Epoch 869/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6559 - val_loss: 0.6203 - val_binary_accuracy: 0.6610\n",
            "Epoch 870/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6548 - val_loss: 0.6178 - val_binary_accuracy: 0.6543\n",
            "Epoch 871/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6554 - val_loss: 0.6211 - val_binary_accuracy: 0.6585\n",
            "Epoch 872/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6555 - val_loss: 0.6213 - val_binary_accuracy: 0.6493\n",
            "Epoch 873/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6548 - val_loss: 0.6214 - val_binary_accuracy: 0.6489\n",
            "Epoch 874/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6597 - val_loss: 0.6198 - val_binary_accuracy: 0.6618\n",
            "Epoch 875/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6544 - val_loss: 0.6206 - val_binary_accuracy: 0.6526\n",
            "Epoch 876/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6548 - val_loss: 0.6189 - val_binary_accuracy: 0.6593\n",
            "Epoch 877/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6541 - val_loss: 0.6198 - val_binary_accuracy: 0.6580\n",
            "Epoch 878/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6554 - val_loss: 0.6207 - val_binary_accuracy: 0.6551\n",
            "Epoch 879/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6574 - val_loss: 0.6202 - val_binary_accuracy: 0.6543\n",
            "Epoch 880/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6538 - val_loss: 0.6222 - val_binary_accuracy: 0.6530\n",
            "Epoch 881/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6510 - val_loss: 0.6213 - val_binary_accuracy: 0.6610\n",
            "Epoch 882/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6473 - val_loss: 0.6241 - val_binary_accuracy: 0.6526\n",
            "Epoch 883/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6523 - val_loss: 0.6222 - val_binary_accuracy: 0.6534\n",
            "Epoch 884/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6530 - val_loss: 0.6215 - val_binary_accuracy: 0.6597\n",
            "Epoch 885/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6519 - val_loss: 0.6219 - val_binary_accuracy: 0.6576\n",
            "Epoch 886/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6576 - val_loss: 0.6208 - val_binary_accuracy: 0.6622\n",
            "Epoch 887/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6494 - val_loss: 0.6195 - val_binary_accuracy: 0.6618\n",
            "Epoch 888/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6548 - val_loss: 0.6202 - val_binary_accuracy: 0.6626\n",
            "Epoch 889/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6544 - val_loss: 0.6214 - val_binary_accuracy: 0.6559\n",
            "Epoch 890/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6546 - val_loss: 0.6219 - val_binary_accuracy: 0.6555\n",
            "Epoch 891/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6548 - val_loss: 0.6208 - val_binary_accuracy: 0.6639\n",
            "Epoch 892/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6527 - val_loss: 0.6221 - val_binary_accuracy: 0.6601\n",
            "Epoch 893/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6528 - val_loss: 0.6189 - val_binary_accuracy: 0.6585\n",
            "Epoch 894/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6544 - val_loss: 0.6220 - val_binary_accuracy: 0.6547\n",
            "Epoch 895/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6507 - val_loss: 0.6193 - val_binary_accuracy: 0.6572\n",
            "Epoch 896/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6554 - val_loss: 0.6215 - val_binary_accuracy: 0.6539\n",
            "Epoch 897/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6518 - val_loss: 0.6221 - val_binary_accuracy: 0.6559\n",
            "Epoch 898/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6537 - val_loss: 0.6225 - val_binary_accuracy: 0.6559\n",
            "Epoch 899/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6513 - val_loss: 0.6183 - val_binary_accuracy: 0.6622\n",
            "Epoch 900/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6539 - val_loss: 0.6211 - val_binary_accuracy: 0.6576\n",
            "Epoch 901/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6562 - val_loss: 0.6196 - val_binary_accuracy: 0.6539\n",
            "Epoch 902/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6518 - val_loss: 0.6199 - val_binary_accuracy: 0.6551\n",
            "Epoch 903/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6553 - val_loss: 0.6227 - val_binary_accuracy: 0.6501\n",
            "Epoch 904/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6570 - val_loss: 0.6208 - val_binary_accuracy: 0.6618\n",
            "Epoch 905/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6586 - val_loss: 0.6209 - val_binary_accuracy: 0.6509\n",
            "Epoch 906/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6561 - val_loss: 0.6208 - val_binary_accuracy: 0.6630\n",
            "Epoch 907/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6558 - val_loss: 0.6203 - val_binary_accuracy: 0.6530\n",
            "Epoch 908/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6531 - val_loss: 0.6201 - val_binary_accuracy: 0.6555\n",
            "Epoch 909/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6549 - val_loss: 0.6201 - val_binary_accuracy: 0.6630\n",
            "Epoch 910/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6517 - val_loss: 0.6211 - val_binary_accuracy: 0.6509\n",
            "Epoch 911/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6521 - val_loss: 0.6208 - val_binary_accuracy: 0.6601\n",
            "Epoch 912/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6581 - val_loss: 0.6213 - val_binary_accuracy: 0.6539\n",
            "Epoch 913/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6531 - val_loss: 0.6194 - val_binary_accuracy: 0.6522\n",
            "Epoch 914/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6509 - val_loss: 0.6182 - val_binary_accuracy: 0.6576\n",
            "Epoch 915/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6499 - val_loss: 0.6202 - val_binary_accuracy: 0.6505\n",
            "Epoch 916/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6509 - val_loss: 0.6220 - val_binary_accuracy: 0.6559\n",
            "Epoch 917/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6556 - val_loss: 0.6205 - val_binary_accuracy: 0.6572\n",
            "Epoch 918/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6527 - val_loss: 0.6189 - val_binary_accuracy: 0.6610\n",
            "Epoch 919/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6575 - val_loss: 0.6228 - val_binary_accuracy: 0.6509\n",
            "Epoch 920/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6518 - val_loss: 0.6180 - val_binary_accuracy: 0.6622\n",
            "Epoch 921/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6505 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 922/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6571 - val_loss: 0.6187 - val_binary_accuracy: 0.6614\n",
            "Epoch 923/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6537 - val_loss: 0.6206 - val_binary_accuracy: 0.6572\n",
            "Epoch 924/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6548 - val_loss: 0.6210 - val_binary_accuracy: 0.6589\n",
            "Epoch 925/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6596 - val_loss: 0.6199 - val_binary_accuracy: 0.6559\n",
            "Epoch 926/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6590 - val_loss: 0.6195 - val_binary_accuracy: 0.6593\n",
            "Epoch 927/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6544 - val_loss: 0.6225 - val_binary_accuracy: 0.6559\n",
            "Epoch 928/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6545 - val_loss: 0.6203 - val_binary_accuracy: 0.6626\n",
            "Epoch 929/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6486 - val_loss: 0.6210 - val_binary_accuracy: 0.6555\n",
            "Epoch 930/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6578 - val_loss: 0.6202 - val_binary_accuracy: 0.6618\n",
            "Epoch 931/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6509 - val_loss: 0.6239 - val_binary_accuracy: 0.6547\n",
            "Epoch 932/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6534 - val_loss: 0.6196 - val_binary_accuracy: 0.6518\n",
            "Epoch 933/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6545 - val_loss: 0.6199 - val_binary_accuracy: 0.6585\n",
            "Epoch 934/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6579 - val_loss: 0.6191 - val_binary_accuracy: 0.6639\n",
            "Epoch 935/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6554 - val_loss: 0.6217 - val_binary_accuracy: 0.6568\n",
            "Epoch 936/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6515 - val_loss: 0.6228 - val_binary_accuracy: 0.6484\n",
            "Epoch 937/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6550 - val_loss: 0.6197 - val_binary_accuracy: 0.6651\n",
            "Epoch 938/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6554 - val_loss: 0.6213 - val_binary_accuracy: 0.6530\n",
            "Epoch 939/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6569 - val_loss: 0.6202 - val_binary_accuracy: 0.6580\n",
            "Epoch 940/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6548 - val_loss: 0.6194 - val_binary_accuracy: 0.6593\n",
            "Epoch 941/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6540 - val_loss: 0.6203 - val_binary_accuracy: 0.6555\n",
            "Epoch 942/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6548 - val_loss: 0.6216 - val_binary_accuracy: 0.6547\n",
            "Epoch 943/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6501 - val_loss: 0.6214 - val_binary_accuracy: 0.6593\n",
            "Epoch 944/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6529 - val_loss: 0.6209 - val_binary_accuracy: 0.6568\n",
            "Epoch 945/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6535 - val_loss: 0.6192 - val_binary_accuracy: 0.6572\n",
            "Epoch 946/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6582 - val_loss: 0.6208 - val_binary_accuracy: 0.6555\n",
            "Epoch 947/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6561 - val_loss: 0.6222 - val_binary_accuracy: 0.6497\n",
            "Epoch 948/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6551 - val_loss: 0.6212 - val_binary_accuracy: 0.6539\n",
            "Epoch 949/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6578 - val_loss: 0.6225 - val_binary_accuracy: 0.6539\n",
            "Epoch 950/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6498 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 951/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6553 - val_loss: 0.6203 - val_binary_accuracy: 0.6564\n",
            "Epoch 952/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6553 - val_loss: 0.6207 - val_binary_accuracy: 0.6622\n",
            "Epoch 953/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6552 - val_loss: 0.6214 - val_binary_accuracy: 0.6635\n",
            "Epoch 954/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6547 - val_loss: 0.6238 - val_binary_accuracy: 0.6505\n",
            "Epoch 955/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6585 - val_loss: 0.6200 - val_binary_accuracy: 0.6576\n",
            "Epoch 956/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6571 - val_loss: 0.6203 - val_binary_accuracy: 0.6635\n",
            "Epoch 957/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6563 - val_loss: 0.6222 - val_binary_accuracy: 0.6534\n",
            "Epoch 958/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6516 - val_loss: 0.6239 - val_binary_accuracy: 0.6522\n",
            "Epoch 959/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6503 - val_loss: 0.6238 - val_binary_accuracy: 0.6559\n",
            "Epoch 960/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6572 - val_loss: 0.6215 - val_binary_accuracy: 0.6522\n",
            "Epoch 961/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6498 - val_loss: 0.6198 - val_binary_accuracy: 0.6589\n",
            "Epoch 962/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6534 - val_loss: 0.6207 - val_binary_accuracy: 0.6493\n",
            "Epoch 963/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6580 - val_loss: 0.6214 - val_binary_accuracy: 0.6505\n",
            "Epoch 964/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6538 - val_loss: 0.6215 - val_binary_accuracy: 0.6614\n",
            "Epoch 965/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6562 - val_loss: 0.6193 - val_binary_accuracy: 0.6585\n",
            "Epoch 966/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6568 - val_loss: 0.6230 - val_binary_accuracy: 0.6572\n",
            "Epoch 967/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6593 - val_loss: 0.6213 - val_binary_accuracy: 0.6572\n",
            "Epoch 968/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6560 - val_loss: 0.6204 - val_binary_accuracy: 0.6626\n",
            "Epoch 969/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6603 - val_loss: 0.6184 - val_binary_accuracy: 0.6618\n",
            "Epoch 970/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6590 - val_loss: 0.6206 - val_binary_accuracy: 0.6534\n",
            "Epoch 971/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6565 - val_loss: 0.6221 - val_binary_accuracy: 0.6530\n",
            "Epoch 972/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6572 - val_loss: 0.6185 - val_binary_accuracy: 0.6551\n",
            "Epoch 973/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6574 - val_loss: 0.6206 - val_binary_accuracy: 0.6585\n",
            "Epoch 974/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6543 - val_loss: 0.6209 - val_binary_accuracy: 0.6555\n",
            "Epoch 975/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6572 - val_loss: 0.6203 - val_binary_accuracy: 0.6555\n",
            "Epoch 976/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6543 - val_loss: 0.6243 - val_binary_accuracy: 0.6518\n",
            "Epoch 977/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6560 - val_loss: 0.6227 - val_binary_accuracy: 0.6572\n",
            "Epoch 978/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6599 - val_loss: 0.6233 - val_binary_accuracy: 0.6534\n",
            "Epoch 979/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6568 - val_loss: 0.6209 - val_binary_accuracy: 0.6559\n",
            "Epoch 980/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6549 - val_loss: 0.6219 - val_binary_accuracy: 0.6551\n",
            "Epoch 981/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6582 - val_loss: 0.6215 - val_binary_accuracy: 0.6547\n",
            "Epoch 982/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6567 - val_loss: 0.6236 - val_binary_accuracy: 0.6564\n",
            "Epoch 983/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6539 - val_loss: 0.6208 - val_binary_accuracy: 0.6622\n",
            "Epoch 984/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6540 - val_loss: 0.6198 - val_binary_accuracy: 0.6610\n",
            "Epoch 985/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6544 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 986/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6537 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 987/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6592 - val_loss: 0.6223 - val_binary_accuracy: 0.6589\n",
            "Epoch 988/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6536 - val_loss: 0.6239 - val_binary_accuracy: 0.6559\n",
            "Epoch 989/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6514 - val_loss: 0.6204 - val_binary_accuracy: 0.6576\n",
            "Epoch 990/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6580 - val_loss: 0.6232 - val_binary_accuracy: 0.6530\n",
            "Epoch 991/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6533 - val_loss: 0.6197 - val_binary_accuracy: 0.6643\n",
            "Epoch 992/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6526 - val_loss: 0.6228 - val_binary_accuracy: 0.6497\n",
            "Epoch 993/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6525 - val_loss: 0.6237 - val_binary_accuracy: 0.6605\n",
            "Epoch 994/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6568 - val_loss: 0.6215 - val_binary_accuracy: 0.6576\n",
            "Epoch 995/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6562 - val_loss: 0.6210 - val_binary_accuracy: 0.6585\n",
            "Epoch 996/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6604 - val_loss: 0.6215 - val_binary_accuracy: 0.6559\n",
            "Epoch 997/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6557 - val_loss: 0.6196 - val_binary_accuracy: 0.6614\n",
            "Epoch 998/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6567 - val_loss: 0.6193 - val_binary_accuracy: 0.6618\n",
            "Epoch 999/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6548 - val_loss: 0.6224 - val_binary_accuracy: 0.6576\n",
            "Epoch 1000/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6557 - val_loss: 0.6220 - val_binary_accuracy: 0.6555\n",
            "Epoch 1001/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6568 - val_loss: 0.6242 - val_binary_accuracy: 0.6610\n",
            "Epoch 1002/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6531 - val_loss: 0.6220 - val_binary_accuracy: 0.6576\n",
            "Epoch 1003/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6582 - val_loss: 0.6199 - val_binary_accuracy: 0.6543\n",
            "Epoch 1004/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6532 - val_loss: 0.6228 - val_binary_accuracy: 0.6593\n",
            "Epoch 1005/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6543 - val_loss: 0.6249 - val_binary_accuracy: 0.6468\n",
            "Epoch 1006/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6549 - val_loss: 0.6200 - val_binary_accuracy: 0.6610\n",
            "Epoch 1007/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6596 - val_loss: 0.6217 - val_binary_accuracy: 0.6539\n",
            "Epoch 1008/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6556 - val_loss: 0.6209 - val_binary_accuracy: 0.6580\n",
            "Epoch 1009/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6511 - val_loss: 0.6227 - val_binary_accuracy: 0.6580\n",
            "Epoch 1010/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6557 - val_loss: 0.6195 - val_binary_accuracy: 0.6601\n",
            "Epoch 1011/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6537 - val_loss: 0.6194 - val_binary_accuracy: 0.6555\n",
            "Epoch 1012/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6584 - val_loss: 0.6217 - val_binary_accuracy: 0.6539\n",
            "Epoch 1013/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6506 - val_loss: 0.6226 - val_binary_accuracy: 0.6551\n",
            "Epoch 1014/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6551 - val_loss: 0.6183 - val_binary_accuracy: 0.6630\n",
            "Epoch 1015/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6553 - val_loss: 0.6208 - val_binary_accuracy: 0.6568\n",
            "Epoch 1016/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6561 - val_loss: 0.6211 - val_binary_accuracy: 0.6605\n",
            "Epoch 1017/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6519 - val_loss: 0.6205 - val_binary_accuracy: 0.6543\n",
            "Epoch 1018/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6486 - val_loss: 0.6202 - val_binary_accuracy: 0.6539\n",
            "Epoch 1019/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6593 - val_loss: 0.6176 - val_binary_accuracy: 0.6635\n",
            "Epoch 1020/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6557 - val_loss: 0.6193 - val_binary_accuracy: 0.6559\n",
            "Epoch 1021/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6553 - val_loss: 0.6213 - val_binary_accuracy: 0.6509\n",
            "Epoch 1022/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6552 - val_loss: 0.6208 - val_binary_accuracy: 0.6568\n",
            "Epoch 1023/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6551 - val_loss: 0.6252 - val_binary_accuracy: 0.6522\n",
            "Epoch 1024/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6537 - val_loss: 0.6190 - val_binary_accuracy: 0.6593\n",
            "Epoch 1025/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6537 - val_loss: 0.6192 - val_binary_accuracy: 0.6626\n",
            "Epoch 1026/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6582 - val_loss: 0.6195 - val_binary_accuracy: 0.6559\n",
            "Epoch 1027/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6542 - val_loss: 0.6205 - val_binary_accuracy: 0.6601\n",
            "Epoch 1028/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6543 - val_loss: 0.6207 - val_binary_accuracy: 0.6630\n",
            "Epoch 1029/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6534 - val_loss: 0.6213 - val_binary_accuracy: 0.6526\n",
            "Epoch 1030/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6574 - val_loss: 0.6202 - val_binary_accuracy: 0.6580\n",
            "Epoch 1031/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6572 - val_loss: 0.6219 - val_binary_accuracy: 0.6568\n",
            "Epoch 1032/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6599 - val_loss: 0.6184 - val_binary_accuracy: 0.6630\n",
            "Epoch 1033/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6565 - val_loss: 0.6209 - val_binary_accuracy: 0.6559\n",
            "Epoch 1034/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6506 - val_loss: 0.6247 - val_binary_accuracy: 0.6509\n",
            "Epoch 1035/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6518 - val_loss: 0.6211 - val_binary_accuracy: 0.6522\n",
            "Epoch 1036/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6591 - val_loss: 0.6196 - val_binary_accuracy: 0.6505\n",
            "Epoch 1037/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6564 - val_loss: 0.6194 - val_binary_accuracy: 0.6585\n",
            "Epoch 1038/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6580 - val_loss: 0.6213 - val_binary_accuracy: 0.6543\n",
            "Epoch 1039/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6497 - val_loss: 0.6215 - val_binary_accuracy: 0.6518\n",
            "Epoch 1040/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6561 - val_loss: 0.6205 - val_binary_accuracy: 0.6551\n",
            "Epoch 1041/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6514 - val_loss: 0.6228 - val_binary_accuracy: 0.6539\n",
            "Epoch 1042/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6606 - val_loss: 0.6208 - val_binary_accuracy: 0.6497\n",
            "Epoch 1043/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6545 - val_loss: 0.6195 - val_binary_accuracy: 0.6564\n",
            "Epoch 1044/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6559 - val_loss: 0.6214 - val_binary_accuracy: 0.6559\n",
            "Epoch 1045/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6551 - val_loss: 0.6200 - val_binary_accuracy: 0.6547\n",
            "Epoch 1046/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6602 - val_loss: 0.6188 - val_binary_accuracy: 0.6639\n",
            "Epoch 1047/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6540 - val_loss: 0.6227 - val_binary_accuracy: 0.6505\n",
            "Epoch 1048/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6509 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 1049/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6543 - val_loss: 0.6199 - val_binary_accuracy: 0.6555\n",
            "Epoch 1050/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6524 - val_loss: 0.6218 - val_binary_accuracy: 0.6564\n",
            "Epoch 1051/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6588 - val_loss: 0.6205 - val_binary_accuracy: 0.6559\n",
            "Epoch 1052/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6568 - val_loss: 0.6203 - val_binary_accuracy: 0.6601\n",
            "Epoch 1053/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6522 - val_loss: 0.6228 - val_binary_accuracy: 0.6509\n",
            "Epoch 1054/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6570 - val_loss: 0.6202 - val_binary_accuracy: 0.6572\n",
            "Epoch 1055/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6539 - val_loss: 0.6204 - val_binary_accuracy: 0.6618\n",
            "Epoch 1056/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6584 - val_loss: 0.6240 - val_binary_accuracy: 0.6530\n",
            "Epoch 1057/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6560 - val_loss: 0.6229 - val_binary_accuracy: 0.6526\n",
            "Epoch 1058/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6604 - val_loss: 0.6214 - val_binary_accuracy: 0.6585\n",
            "Epoch 1059/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6571 - val_loss: 0.6225 - val_binary_accuracy: 0.6489\n",
            "Epoch 1060/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6545 - val_loss: 0.6193 - val_binary_accuracy: 0.6589\n",
            "Epoch 1061/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6539 - val_loss: 0.6197 - val_binary_accuracy: 0.6547\n",
            "Epoch 1062/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6569 - val_loss: 0.6195 - val_binary_accuracy: 0.6539\n",
            "Epoch 1063/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6567 - val_loss: 0.6219 - val_binary_accuracy: 0.6551\n",
            "Epoch 1064/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6547 - val_loss: 0.6243 - val_binary_accuracy: 0.6484\n",
            "Epoch 1065/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6596 - val_loss: 0.6216 - val_binary_accuracy: 0.6543\n",
            "Epoch 1066/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6545 - val_loss: 0.6200 - val_binary_accuracy: 0.6593\n",
            "Epoch 1067/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6545 - val_loss: 0.6202 - val_binary_accuracy: 0.6555\n",
            "Epoch 1068/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6533 - val_loss: 0.6215 - val_binary_accuracy: 0.6514\n",
            "Epoch 1069/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6582 - val_loss: 0.6198 - val_binary_accuracy: 0.6572\n",
            "Epoch 1070/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6519 - val_loss: 0.6222 - val_binary_accuracy: 0.6530\n",
            "Epoch 1071/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6531 - val_loss: 0.6206 - val_binary_accuracy: 0.6576\n",
            "Epoch 1072/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6575 - val_loss: 0.6225 - val_binary_accuracy: 0.6551\n",
            "Epoch 1073/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6539 - val_loss: 0.6226 - val_binary_accuracy: 0.6489\n",
            "Epoch 1074/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6528 - val_loss: 0.6210 - val_binary_accuracy: 0.6572\n",
            "Epoch 1075/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6552 - val_loss: 0.6229 - val_binary_accuracy: 0.6534\n",
            "Epoch 1076/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6552 - val_loss: 0.6207 - val_binary_accuracy: 0.6547\n",
            "Epoch 1077/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6593 - val_loss: 0.6211 - val_binary_accuracy: 0.6509\n",
            "Epoch 1078/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6560 - val_loss: 0.6230 - val_binary_accuracy: 0.6551\n",
            "Epoch 1079/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6537 - val_loss: 0.6218 - val_binary_accuracy: 0.6526\n",
            "Epoch 1080/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6526 - val_loss: 0.6201 - val_binary_accuracy: 0.6580\n",
            "Epoch 1081/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6517 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 1082/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6577 - val_loss: 0.6209 - val_binary_accuracy: 0.6543\n",
            "Epoch 1083/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6539 - val_loss: 0.6205 - val_binary_accuracy: 0.6576\n",
            "Epoch 1084/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6542 - val_loss: 0.6222 - val_binary_accuracy: 0.6568\n",
            "Epoch 1085/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6543 - val_loss: 0.6199 - val_binary_accuracy: 0.6530\n",
            "Epoch 1086/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6563 - val_loss: 0.6208 - val_binary_accuracy: 0.6559\n",
            "Epoch 1087/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6562 - val_loss: 0.6202 - val_binary_accuracy: 0.6526\n",
            "Epoch 1088/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6605 - val_loss: 0.6218 - val_binary_accuracy: 0.6572\n",
            "Epoch 1089/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6568 - val_loss: 0.6202 - val_binary_accuracy: 0.6622\n",
            "Epoch 1090/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6546 - val_loss: 0.6226 - val_binary_accuracy: 0.6534\n",
            "Epoch 1091/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6617 - val_loss: 0.6219 - val_binary_accuracy: 0.6564\n",
            "Epoch 1092/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6611 - val_loss: 0.6219 - val_binary_accuracy: 0.6572\n",
            "Epoch 1093/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6586 - val_loss: 0.6243 - val_binary_accuracy: 0.6514\n",
            "Epoch 1094/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6627 - val_loss: 0.6196 - val_binary_accuracy: 0.6605\n",
            "Epoch 1095/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6177 - binary_accuracy: 0.6524 - val_loss: 0.6224 - val_binary_accuracy: 0.6509\n",
            "Epoch 1096/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6519 - val_loss: 0.6220 - val_binary_accuracy: 0.6564\n",
            "Epoch 1097/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6583 - val_loss: 0.6200 - val_binary_accuracy: 0.6572\n",
            "Epoch 1098/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6565 - val_loss: 0.6230 - val_binary_accuracy: 0.6555\n",
            "Epoch 1099/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6581 - val_loss: 0.6209 - val_binary_accuracy: 0.6614\n",
            "Epoch 1100/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6543 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 1101/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6574 - val_loss: 0.6211 - val_binary_accuracy: 0.6572\n",
            "Epoch 1102/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6540 - val_loss: 0.6208 - val_binary_accuracy: 0.6630\n",
            "Epoch 1103/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6579 - val_loss: 0.6227 - val_binary_accuracy: 0.6639\n",
            "Epoch 1104/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6603 - val_loss: 0.6221 - val_binary_accuracy: 0.6610\n",
            "Epoch 1105/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6588 - val_loss: 0.6223 - val_binary_accuracy: 0.6530\n",
            "Epoch 1106/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6569 - val_loss: 0.6192 - val_binary_accuracy: 0.6576\n",
            "Epoch 1107/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6557 - val_loss: 0.6238 - val_binary_accuracy: 0.6505\n",
            "Epoch 1108/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6566 - val_loss: 0.6241 - val_binary_accuracy: 0.6576\n",
            "Epoch 1109/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6516 - val_loss: 0.6217 - val_binary_accuracy: 0.6514\n",
            "Epoch 1110/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6571 - val_loss: 0.6194 - val_binary_accuracy: 0.6651\n",
            "Epoch 1111/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6564 - val_loss: 0.6219 - val_binary_accuracy: 0.6568\n",
            "Epoch 1112/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6560 - val_loss: 0.6212 - val_binary_accuracy: 0.6618\n",
            "Epoch 1113/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6575 - val_loss: 0.6227 - val_binary_accuracy: 0.6509\n",
            "Epoch 1114/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6515 - val_loss: 0.6211 - val_binary_accuracy: 0.6539\n",
            "Epoch 1115/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6613 - val_loss: 0.6225 - val_binary_accuracy: 0.6526\n",
            "Epoch 1116/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6577 - val_loss: 0.6187 - val_binary_accuracy: 0.6668\n",
            "Epoch 1117/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6557 - val_loss: 0.6235 - val_binary_accuracy: 0.6530\n",
            "Epoch 1118/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6547 - val_loss: 0.6214 - val_binary_accuracy: 0.6559\n",
            "Epoch 1119/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6634 - val_loss: 0.6216 - val_binary_accuracy: 0.6555\n",
            "Epoch 1120/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6586 - val_loss: 0.6210 - val_binary_accuracy: 0.6543\n",
            "Epoch 1121/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6574 - val_loss: 0.6208 - val_binary_accuracy: 0.6564\n",
            "Epoch 1122/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6518 - val_loss: 0.6221 - val_binary_accuracy: 0.6509\n",
            "Epoch 1123/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6559 - val_loss: 0.6197 - val_binary_accuracy: 0.6534\n",
            "Epoch 1124/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6557 - val_loss: 0.6204 - val_binary_accuracy: 0.6593\n",
            "Epoch 1125/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6617 - val_loss: 0.6239 - val_binary_accuracy: 0.6514\n",
            "Epoch 1126/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6558 - val_loss: 0.6197 - val_binary_accuracy: 0.6547\n",
            "Epoch 1127/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6557 - val_loss: 0.6208 - val_binary_accuracy: 0.6643\n",
            "Epoch 1128/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6578 - val_loss: 0.6226 - val_binary_accuracy: 0.6505\n",
            "Epoch 1129/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6568 - val_loss: 0.6225 - val_binary_accuracy: 0.6526\n",
            "Epoch 1130/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6603 - val_loss: 0.6214 - val_binary_accuracy: 0.6576\n",
            "Epoch 1131/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6601 - val_loss: 0.6206 - val_binary_accuracy: 0.6618\n",
            "Epoch 1132/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6561 - val_loss: 0.6219 - val_binary_accuracy: 0.6547\n",
            "Epoch 1133/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6585 - val_loss: 0.6212 - val_binary_accuracy: 0.6559\n",
            "Epoch 1134/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6556 - val_loss: 0.6229 - val_binary_accuracy: 0.6559\n",
            "Epoch 1135/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6616 - val_loss: 0.6222 - val_binary_accuracy: 0.6526\n",
            "Epoch 1136/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6590 - val_loss: 0.6202 - val_binary_accuracy: 0.6585\n",
            "Epoch 1137/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6604 - val_loss: 0.6212 - val_binary_accuracy: 0.6585\n",
            "Epoch 1138/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6597 - val_loss: 0.6226 - val_binary_accuracy: 0.6505\n",
            "Epoch 1139/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6564 - val_loss: 0.6189 - val_binary_accuracy: 0.6643\n",
            "Epoch 1140/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6542 - val_loss: 0.6201 - val_binary_accuracy: 0.6526\n",
            "Epoch 1141/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6569 - val_loss: 0.6185 - val_binary_accuracy: 0.6597\n",
            "Epoch 1142/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6576 - val_loss: 0.6209 - val_binary_accuracy: 0.6589\n",
            "Epoch 1143/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6572 - val_loss: 0.6193 - val_binary_accuracy: 0.6547\n",
            "Epoch 1144/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6594 - val_loss: 0.6218 - val_binary_accuracy: 0.6543\n",
            "Epoch 1145/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6590 - val_loss: 0.6206 - val_binary_accuracy: 0.6530\n",
            "Epoch 1146/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6584 - val_loss: 0.6197 - val_binary_accuracy: 0.6555\n",
            "Epoch 1147/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6554 - val_loss: 0.6220 - val_binary_accuracy: 0.6585\n",
            "Epoch 1148/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6577 - val_loss: 0.6202 - val_binary_accuracy: 0.6601\n",
            "Epoch 1149/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6618 - val_loss: 0.6193 - val_binary_accuracy: 0.6534\n",
            "Epoch 1150/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6604 - val_loss: 0.6230 - val_binary_accuracy: 0.6497\n",
            "Epoch 1151/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6618 - val_loss: 0.6229 - val_binary_accuracy: 0.6514\n",
            "Epoch 1152/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6586 - val_loss: 0.6244 - val_binary_accuracy: 0.6505\n",
            "Epoch 1153/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6574 - val_loss: 0.6178 - val_binary_accuracy: 0.6580\n",
            "Epoch 1154/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6579 - val_loss: 0.6198 - val_binary_accuracy: 0.6543\n",
            "Epoch 1155/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6574 - val_loss: 0.6209 - val_binary_accuracy: 0.6547\n",
            "Epoch 1156/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6574 - val_loss: 0.6215 - val_binary_accuracy: 0.6509\n",
            "Epoch 1157/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6194 - binary_accuracy: 0.6583 - val_loss: 0.6199 - val_binary_accuracy: 0.6576\n",
            "Epoch 1158/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6605 - val_loss: 0.6225 - val_binary_accuracy: 0.6559\n",
            "Epoch 1159/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6599 - val_loss: 0.6203 - val_binary_accuracy: 0.6568\n",
            "Epoch 1160/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6547 - val_loss: 0.6215 - val_binary_accuracy: 0.6518\n",
            "Epoch 1161/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6548 - val_loss: 0.6214 - val_binary_accuracy: 0.6564\n",
            "Epoch 1162/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6578 - val_loss: 0.6198 - val_binary_accuracy: 0.6576\n",
            "Epoch 1163/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6555 - val_loss: 0.6201 - val_binary_accuracy: 0.6543\n",
            "Epoch 1164/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6540 - val_loss: 0.6209 - val_binary_accuracy: 0.6551\n",
            "Epoch 1165/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6566 - val_loss: 0.6187 - val_binary_accuracy: 0.6589\n",
            "Epoch 1166/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6622 - val_loss: 0.6193 - val_binary_accuracy: 0.6564\n",
            "Epoch 1167/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6608 - val_loss: 0.6185 - val_binary_accuracy: 0.6597\n",
            "Epoch 1168/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6587 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 1169/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6577 - val_loss: 0.6212 - val_binary_accuracy: 0.6526\n",
            "Epoch 1170/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6576 - val_loss: 0.6206 - val_binary_accuracy: 0.6543\n",
            "Epoch 1171/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6162 - binary_accuracy: 0.6574 - val_loss: 0.6225 - val_binary_accuracy: 0.6476\n",
            "Epoch 1172/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6562 - val_loss: 0.6201 - val_binary_accuracy: 0.6551\n",
            "Epoch 1173/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6536 - val_loss: 0.6186 - val_binary_accuracy: 0.6618\n",
            "Epoch 1174/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6603 - val_loss: 0.6203 - val_binary_accuracy: 0.6593\n",
            "Epoch 1175/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6593 - val_loss: 0.6194 - val_binary_accuracy: 0.6530\n",
            "Epoch 1176/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6578 - val_loss: 0.6218 - val_binary_accuracy: 0.6614\n",
            "Epoch 1177/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6626 - val_loss: 0.6217 - val_binary_accuracy: 0.6572\n",
            "Epoch 1178/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6578 - val_loss: 0.6195 - val_binary_accuracy: 0.6551\n",
            "Epoch 1179/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6580 - val_loss: 0.6221 - val_binary_accuracy: 0.6543\n",
            "Epoch 1180/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6600 - val_loss: 0.6176 - val_binary_accuracy: 0.6568\n",
            "Epoch 1181/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6165 - binary_accuracy: 0.6565 - val_loss: 0.6208 - val_binary_accuracy: 0.6526\n",
            "Epoch 1182/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6528 - val_loss: 0.6208 - val_binary_accuracy: 0.6526\n",
            "Epoch 1183/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6573 - val_loss: 0.6212 - val_binary_accuracy: 0.6484\n",
            "Epoch 1184/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6576 - val_loss: 0.6219 - val_binary_accuracy: 0.6539\n",
            "Epoch 1185/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6583 - val_loss: 0.6200 - val_binary_accuracy: 0.6555\n",
            "Epoch 1186/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6580 - val_loss: 0.6208 - val_binary_accuracy: 0.6585\n",
            "Epoch 1187/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6575 - val_loss: 0.6185 - val_binary_accuracy: 0.6614\n",
            "Epoch 1188/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6575 - val_loss: 0.6202 - val_binary_accuracy: 0.6539\n",
            "Epoch 1189/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6567 - val_loss: 0.6200 - val_binary_accuracy: 0.6593\n",
            "Epoch 1190/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6552 - val_loss: 0.6219 - val_binary_accuracy: 0.6564\n",
            "Epoch 1191/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6619 - val_loss: 0.6196 - val_binary_accuracy: 0.6559\n",
            "Epoch 1192/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6588 - val_loss: 0.6169 - val_binary_accuracy: 0.6618\n",
            "Epoch 1193/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6600 - val_loss: 0.6201 - val_binary_accuracy: 0.6585\n",
            "Epoch 1194/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6615 - val_loss: 0.6188 - val_binary_accuracy: 0.6559\n",
            "Epoch 1195/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6537 - val_loss: 0.6204 - val_binary_accuracy: 0.6564\n",
            "Epoch 1196/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6173 - binary_accuracy: 0.6583 - val_loss: 0.6179 - val_binary_accuracy: 0.6656\n",
            "Epoch 1197/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6600 - val_loss: 0.6202 - val_binary_accuracy: 0.6639\n",
            "Epoch 1198/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6576 - val_loss: 0.6191 - val_binary_accuracy: 0.6551\n",
            "Epoch 1199/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6631 - val_loss: 0.6216 - val_binary_accuracy: 0.6572\n",
            "Epoch 1200/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6616 - val_loss: 0.6194 - val_binary_accuracy: 0.6576\n",
            "Epoch 1201/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6540 - val_loss: 0.6218 - val_binary_accuracy: 0.6547\n",
            "Epoch 1202/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6581 - val_loss: 0.6197 - val_binary_accuracy: 0.6580\n",
            "Epoch 1203/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6598 - val_loss: 0.6191 - val_binary_accuracy: 0.6643\n",
            "Epoch 1204/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6611 - val_loss: 0.6212 - val_binary_accuracy: 0.6551\n",
            "Epoch 1205/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6596 - val_loss: 0.6183 - val_binary_accuracy: 0.6626\n",
            "Epoch 1206/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6576 - val_loss: 0.6222 - val_binary_accuracy: 0.6547\n",
            "Epoch 1207/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6616 - val_loss: 0.6215 - val_binary_accuracy: 0.6551\n",
            "Epoch 1208/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6643 - val_loss: 0.6216 - val_binary_accuracy: 0.6618\n",
            "Epoch 1209/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6565 - val_loss: 0.6215 - val_binary_accuracy: 0.6547\n",
            "Epoch 1210/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6636 - val_loss: 0.6211 - val_binary_accuracy: 0.6555\n",
            "Epoch 1211/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6590 - val_loss: 0.6187 - val_binary_accuracy: 0.6580\n",
            "Epoch 1212/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6563 - val_loss: 0.6183 - val_binary_accuracy: 0.6614\n",
            "Epoch 1213/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6561 - val_loss: 0.6193 - val_binary_accuracy: 0.6572\n",
            "Epoch 1214/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6566 - val_loss: 0.6196 - val_binary_accuracy: 0.6589\n",
            "Epoch 1215/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6590 - val_loss: 0.6196 - val_binary_accuracy: 0.6585\n",
            "Epoch 1216/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6592 - val_loss: 0.6211 - val_binary_accuracy: 0.6547\n",
            "Epoch 1217/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6605 - val_loss: 0.6184 - val_binary_accuracy: 0.6572\n",
            "Epoch 1218/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6572 - val_loss: 0.6208 - val_binary_accuracy: 0.6539\n",
            "Epoch 1219/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6584 - val_loss: 0.6215 - val_binary_accuracy: 0.6559\n",
            "Epoch 1220/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6563 - val_loss: 0.6203 - val_binary_accuracy: 0.6580\n",
            "Epoch 1221/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6593 - val_loss: 0.6187 - val_binary_accuracy: 0.6576\n",
            "Epoch 1222/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6606 - val_loss: 0.6200 - val_binary_accuracy: 0.6564\n",
            "Epoch 1223/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6589 - val_loss: 0.6211 - val_binary_accuracy: 0.6589\n",
            "Epoch 1224/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6568 - val_loss: 0.6207 - val_binary_accuracy: 0.6539\n",
            "Epoch 1225/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6563 - val_loss: 0.6230 - val_binary_accuracy: 0.6572\n",
            "Epoch 1226/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6542 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 1227/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6580 - val_loss: 0.6205 - val_binary_accuracy: 0.6543\n",
            "Epoch 1228/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6601 - val_loss: 0.6195 - val_binary_accuracy: 0.6547\n",
            "Epoch 1229/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6574 - val_loss: 0.6214 - val_binary_accuracy: 0.6530\n",
            "Epoch 1230/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6598 - val_loss: 0.6201 - val_binary_accuracy: 0.6626\n",
            "Epoch 1231/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6595 - val_loss: 0.6212 - val_binary_accuracy: 0.6555\n",
            "Epoch 1232/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6624 - val_loss: 0.6206 - val_binary_accuracy: 0.6601\n",
            "Epoch 1233/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6581 - val_loss: 0.6198 - val_binary_accuracy: 0.6605\n",
            "Epoch 1234/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6570 - val_loss: 0.6195 - val_binary_accuracy: 0.6601\n",
            "Epoch 1235/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6622 - val_loss: 0.6213 - val_binary_accuracy: 0.6526\n",
            "Epoch 1236/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6564 - val_loss: 0.6202 - val_binary_accuracy: 0.6547\n",
            "Epoch 1237/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6581 - val_loss: 0.6198 - val_binary_accuracy: 0.6564\n",
            "Epoch 1238/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6561 - val_loss: 0.6184 - val_binary_accuracy: 0.6572\n",
            "Epoch 1239/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6610 - val_loss: 0.6212 - val_binary_accuracy: 0.6568\n",
            "Epoch 1240/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6565 - val_loss: 0.6201 - val_binary_accuracy: 0.6580\n",
            "Epoch 1241/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6603 - val_loss: 0.6182 - val_binary_accuracy: 0.6630\n",
            "Epoch 1242/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6564 - val_loss: 0.6179 - val_binary_accuracy: 0.6585\n",
            "Epoch 1243/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6608 - val_loss: 0.6195 - val_binary_accuracy: 0.6605\n",
            "Epoch 1244/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6567 - val_loss: 0.6196 - val_binary_accuracy: 0.6618\n",
            "Epoch 1245/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6555 - val_loss: 0.6191 - val_binary_accuracy: 0.6564\n",
            "Epoch 1246/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6548 - val_loss: 0.6187 - val_binary_accuracy: 0.6601\n",
            "Epoch 1247/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6542 - val_loss: 0.6206 - val_binary_accuracy: 0.6564\n",
            "Epoch 1248/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6629 - val_loss: 0.6186 - val_binary_accuracy: 0.6589\n",
            "Epoch 1249/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6618 - val_loss: 0.6217 - val_binary_accuracy: 0.6589\n",
            "Epoch 1250/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6538 - val_loss: 0.6204 - val_binary_accuracy: 0.6539\n",
            "Epoch 1251/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6628 - val_loss: 0.6210 - val_binary_accuracy: 0.6576\n",
            "Epoch 1252/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6579 - val_loss: 0.6164 - val_binary_accuracy: 0.6660\n",
            "Epoch 1253/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6606 - val_loss: 0.6189 - val_binary_accuracy: 0.6585\n",
            "Epoch 1254/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6603 - val_loss: 0.6178 - val_binary_accuracy: 0.6618\n",
            "Epoch 1255/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6569 - val_loss: 0.6201 - val_binary_accuracy: 0.6543\n",
            "Epoch 1256/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6600 - val_loss: 0.6198 - val_binary_accuracy: 0.6605\n",
            "Epoch 1257/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6577 - val_loss: 0.6210 - val_binary_accuracy: 0.6555\n",
            "Epoch 1258/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6620 - val_loss: 0.6191 - val_binary_accuracy: 0.6610\n",
            "Epoch 1259/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6534 - val_loss: 0.6230 - val_binary_accuracy: 0.6568\n",
            "Epoch 1260/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6618 - val_loss: 0.6208 - val_binary_accuracy: 0.6534\n",
            "Epoch 1261/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6576 - val_loss: 0.6209 - val_binary_accuracy: 0.6585\n",
            "Epoch 1262/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6601 - val_loss: 0.6189 - val_binary_accuracy: 0.6618\n",
            "Epoch 1263/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6637 - val_loss: 0.6210 - val_binary_accuracy: 0.6576\n",
            "Epoch 1264/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6595 - val_loss: 0.6198 - val_binary_accuracy: 0.6572\n",
            "Epoch 1265/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6594 - val_loss: 0.6234 - val_binary_accuracy: 0.6505\n",
            "Epoch 1266/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6565 - val_loss: 0.6182 - val_binary_accuracy: 0.6543\n",
            "Epoch 1267/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6594 - val_loss: 0.6189 - val_binary_accuracy: 0.6555\n",
            "Epoch 1268/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6598 - val_loss: 0.6204 - val_binary_accuracy: 0.6518\n",
            "Epoch 1269/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6594 - val_loss: 0.6201 - val_binary_accuracy: 0.6559\n",
            "Epoch 1270/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6533 - val_loss: 0.6204 - val_binary_accuracy: 0.6618\n",
            "Epoch 1271/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6595 - val_loss: 0.6206 - val_binary_accuracy: 0.6559\n",
            "Epoch 1272/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6576 - val_loss: 0.6191 - val_binary_accuracy: 0.6547\n",
            "Epoch 1273/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6656 - val_loss: 0.6192 - val_binary_accuracy: 0.6576\n",
            "Epoch 1274/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6576 - val_loss: 0.6201 - val_binary_accuracy: 0.6585\n",
            "Epoch 1275/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6613 - val_loss: 0.6203 - val_binary_accuracy: 0.6580\n",
            "Epoch 1276/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6636 - val_loss: 0.6192 - val_binary_accuracy: 0.6539\n",
            "Epoch 1277/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6551 - val_loss: 0.6213 - val_binary_accuracy: 0.6539\n",
            "Epoch 1278/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6617 - val_loss: 0.6196 - val_binary_accuracy: 0.6559\n",
            "Epoch 1279/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6608 - val_loss: 0.6226 - val_binary_accuracy: 0.6468\n",
            "Epoch 1280/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6575 - val_loss: 0.6220 - val_binary_accuracy: 0.6505\n",
            "Epoch 1281/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6557 - val_loss: 0.6179 - val_binary_accuracy: 0.6568\n",
            "Epoch 1282/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6577 - val_loss: 0.6191 - val_binary_accuracy: 0.6589\n",
            "Epoch 1283/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6607 - val_loss: 0.6178 - val_binary_accuracy: 0.6597\n",
            "Epoch 1284/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6591 - val_loss: 0.6183 - val_binary_accuracy: 0.6572\n",
            "Epoch 1285/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6617 - val_loss: 0.6205 - val_binary_accuracy: 0.6601\n",
            "Epoch 1286/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6607 - val_loss: 0.6191 - val_binary_accuracy: 0.6597\n",
            "Epoch 1287/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6615 - val_loss: 0.6203 - val_binary_accuracy: 0.6572\n",
            "Epoch 1288/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6609 - val_loss: 0.6220 - val_binary_accuracy: 0.6539\n",
            "Epoch 1289/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6637 - val_loss: 0.6185 - val_binary_accuracy: 0.6568\n",
            "Epoch 1290/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6587 - val_loss: 0.6208 - val_binary_accuracy: 0.6551\n",
            "Epoch 1291/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6625 - val_loss: 0.6189 - val_binary_accuracy: 0.6580\n",
            "Epoch 1292/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6643 - val_loss: 0.6190 - val_binary_accuracy: 0.6555\n",
            "Epoch 1293/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6565 - val_loss: 0.6186 - val_binary_accuracy: 0.6585\n",
            "Epoch 1294/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6639 - val_loss: 0.6192 - val_binary_accuracy: 0.6589\n",
            "Epoch 1295/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6576 - val_loss: 0.6195 - val_binary_accuracy: 0.6601\n",
            "Epoch 1296/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6611 - val_loss: 0.6221 - val_binary_accuracy: 0.6555\n",
            "Epoch 1297/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6551 - val_loss: 0.6190 - val_binary_accuracy: 0.6593\n",
            "Epoch 1298/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6600 - val_loss: 0.6211 - val_binary_accuracy: 0.6572\n",
            "Epoch 1299/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6580 - val_loss: 0.6211 - val_binary_accuracy: 0.6564\n",
            "Epoch 1300/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6619 - val_loss: 0.6203 - val_binary_accuracy: 0.6601\n",
            "Epoch 1301/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6596 - val_loss: 0.6199 - val_binary_accuracy: 0.6593\n",
            "Epoch 1302/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6647 - val_loss: 0.6219 - val_binary_accuracy: 0.6576\n",
            "Epoch 1303/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6604 - val_loss: 0.6208 - val_binary_accuracy: 0.6610\n",
            "Epoch 1304/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6584 - val_loss: 0.6206 - val_binary_accuracy: 0.6585\n",
            "Epoch 1305/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6590 - val_loss: 0.6213 - val_binary_accuracy: 0.6589\n",
            "Epoch 1306/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6558 - val_loss: 0.6193 - val_binary_accuracy: 0.6576\n",
            "Epoch 1307/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6585 - val_loss: 0.6208 - val_binary_accuracy: 0.6522\n",
            "Epoch 1308/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6581 - val_loss: 0.6177 - val_binary_accuracy: 0.6559\n",
            "Epoch 1309/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6631 - val_loss: 0.6210 - val_binary_accuracy: 0.6580\n",
            "Epoch 1310/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6642 - val_loss: 0.6189 - val_binary_accuracy: 0.6576\n",
            "Epoch 1311/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6608 - val_loss: 0.6210 - val_binary_accuracy: 0.6518\n",
            "Epoch 1312/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6596 - val_loss: 0.6205 - val_binary_accuracy: 0.6568\n",
            "Epoch 1313/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6582 - val_loss: 0.6188 - val_binary_accuracy: 0.6568\n",
            "Epoch 1314/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6619 - val_loss: 0.6195 - val_binary_accuracy: 0.6630\n",
            "Epoch 1315/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6607 - val_loss: 0.6204 - val_binary_accuracy: 0.6564\n",
            "Epoch 1316/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6615 - val_loss: 0.6191 - val_binary_accuracy: 0.6622\n",
            "Epoch 1317/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6565 - val_loss: 0.6187 - val_binary_accuracy: 0.6601\n",
            "Epoch 1318/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6579 - val_loss: 0.6218 - val_binary_accuracy: 0.6622\n",
            "Epoch 1319/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6632 - val_loss: 0.6211 - val_binary_accuracy: 0.6568\n",
            "Epoch 1320/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6642 - val_loss: 0.6197 - val_binary_accuracy: 0.6605\n",
            "Epoch 1321/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6591 - val_loss: 0.6187 - val_binary_accuracy: 0.6605\n",
            "Epoch 1322/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6587 - val_loss: 0.6197 - val_binary_accuracy: 0.6572\n",
            "Epoch 1323/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6583 - val_loss: 0.6189 - val_binary_accuracy: 0.6530\n",
            "Epoch 1324/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6624 - val_loss: 0.6220 - val_binary_accuracy: 0.6547\n",
            "Epoch 1325/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6559 - val_loss: 0.6217 - val_binary_accuracy: 0.6526\n",
            "Epoch 1326/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6590 - val_loss: 0.6204 - val_binary_accuracy: 0.6585\n",
            "Epoch 1327/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6620 - val_loss: 0.6205 - val_binary_accuracy: 0.6564\n",
            "Epoch 1328/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6575 - val_loss: 0.6222 - val_binary_accuracy: 0.6585\n",
            "Epoch 1329/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6563 - val_loss: 0.6195 - val_binary_accuracy: 0.6605\n",
            "Epoch 1330/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6591 - val_loss: 0.6199 - val_binary_accuracy: 0.6568\n",
            "Epoch 1331/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6596 - val_loss: 0.6192 - val_binary_accuracy: 0.6576\n",
            "Epoch 1332/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6585 - val_loss: 0.6218 - val_binary_accuracy: 0.6589\n",
            "Epoch 1333/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6619 - val_loss: 0.6213 - val_binary_accuracy: 0.6564\n",
            "Epoch 1334/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6614 - val_loss: 0.6189 - val_binary_accuracy: 0.6564\n",
            "Epoch 1335/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6585 - val_loss: 0.6220 - val_binary_accuracy: 0.6568\n",
            "Epoch 1336/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6172 - binary_accuracy: 0.6584 - val_loss: 0.6183 - val_binary_accuracy: 0.6614\n",
            "Epoch 1337/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6593 - val_loss: 0.6204 - val_binary_accuracy: 0.6589\n",
            "Epoch 1338/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6608 - val_loss: 0.6184 - val_binary_accuracy: 0.6589\n",
            "Epoch 1339/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6591 - val_loss: 0.6208 - val_binary_accuracy: 0.6610\n",
            "Epoch 1340/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6650 - val_loss: 0.6185 - val_binary_accuracy: 0.6564\n",
            "Epoch 1341/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6608 - val_loss: 0.6173 - val_binary_accuracy: 0.6618\n",
            "Epoch 1342/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6576 - val_loss: 0.6179 - val_binary_accuracy: 0.6622\n",
            "Epoch 1343/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6636 - val_loss: 0.6184 - val_binary_accuracy: 0.6635\n",
            "Epoch 1344/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6575 - val_loss: 0.6196 - val_binary_accuracy: 0.6618\n",
            "Epoch 1345/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6620 - val_loss: 0.6194 - val_binary_accuracy: 0.6585\n",
            "Epoch 1346/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6601 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 1347/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6600 - val_loss: 0.6190 - val_binary_accuracy: 0.6568\n",
            "Epoch 1348/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6680 - val_loss: 0.6181 - val_binary_accuracy: 0.6626\n",
            "Epoch 1349/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6638 - val_loss: 0.6182 - val_binary_accuracy: 0.6601\n",
            "Epoch 1350/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6601 - val_loss: 0.6222 - val_binary_accuracy: 0.6564\n",
            "Epoch 1351/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6591 - val_loss: 0.6191 - val_binary_accuracy: 0.6580\n",
            "Epoch 1352/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6600 - val_loss: 0.6190 - val_binary_accuracy: 0.6605\n",
            "Epoch 1353/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6591 - val_loss: 0.6194 - val_binary_accuracy: 0.6605\n",
            "Epoch 1354/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6630 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 1355/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6610 - val_loss: 0.6195 - val_binary_accuracy: 0.6572\n",
            "Epoch 1356/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6617 - val_loss: 0.6203 - val_binary_accuracy: 0.6585\n",
            "Epoch 1357/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6606 - val_loss: 0.6188 - val_binary_accuracy: 0.6630\n",
            "Epoch 1358/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6624 - val_loss: 0.6193 - val_binary_accuracy: 0.6585\n",
            "Epoch 1359/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6602 - val_loss: 0.6199 - val_binary_accuracy: 0.6534\n",
            "Epoch 1360/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6596 - val_loss: 0.6194 - val_binary_accuracy: 0.6585\n",
            "Epoch 1361/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6600 - val_loss: 0.6211 - val_binary_accuracy: 0.6572\n",
            "Epoch 1362/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6611 - val_loss: 0.6179 - val_binary_accuracy: 0.6630\n",
            "Epoch 1363/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6612 - val_loss: 0.6213 - val_binary_accuracy: 0.6526\n",
            "Epoch 1364/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6645 - val_loss: 0.6199 - val_binary_accuracy: 0.6593\n",
            "Epoch 1365/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6666 - val_loss: 0.6212 - val_binary_accuracy: 0.6601\n",
            "Epoch 1366/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6642 - val_loss: 0.6196 - val_binary_accuracy: 0.6576\n",
            "Epoch 1367/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6576 - val_loss: 0.6193 - val_binary_accuracy: 0.6568\n",
            "Epoch 1368/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6632 - val_loss: 0.6193 - val_binary_accuracy: 0.6572\n",
            "Epoch 1369/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6579 - val_loss: 0.6216 - val_binary_accuracy: 0.6572\n",
            "Epoch 1370/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6657 - val_loss: 0.6189 - val_binary_accuracy: 0.6618\n",
            "Epoch 1371/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6618 - val_loss: 0.6201 - val_binary_accuracy: 0.6564\n",
            "Epoch 1372/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6605 - val_loss: 0.6212 - val_binary_accuracy: 0.6597\n",
            "Epoch 1373/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6627 - val_loss: 0.6180 - val_binary_accuracy: 0.6576\n",
            "Epoch 1374/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6628 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 1375/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6618 - val_loss: 0.6209 - val_binary_accuracy: 0.6568\n",
            "Epoch 1376/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6551 - val_loss: 0.6187 - val_binary_accuracy: 0.6639\n",
            "Epoch 1377/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6614 - val_loss: 0.6202 - val_binary_accuracy: 0.6580\n",
            "Epoch 1378/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6583 - val_loss: 0.6208 - val_binary_accuracy: 0.6572\n",
            "Epoch 1379/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6636 - val_loss: 0.6206 - val_binary_accuracy: 0.6605\n",
            "Epoch 1380/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6629 - val_loss: 0.6192 - val_binary_accuracy: 0.6601\n",
            "Epoch 1381/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6575 - val_loss: 0.6195 - val_binary_accuracy: 0.6585\n",
            "Epoch 1382/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6608 - val_loss: 0.6192 - val_binary_accuracy: 0.6568\n",
            "Epoch 1383/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6614 - val_loss: 0.6201 - val_binary_accuracy: 0.6572\n",
            "Epoch 1384/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6658 - val_loss: 0.6214 - val_binary_accuracy: 0.6585\n",
            "Epoch 1385/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6628 - val_loss: 0.6174 - val_binary_accuracy: 0.6610\n",
            "Epoch 1386/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6656 - val_loss: 0.6192 - val_binary_accuracy: 0.6597\n",
            "Epoch 1387/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6641 - val_loss: 0.6208 - val_binary_accuracy: 0.6559\n",
            "Epoch 1388/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6592 - val_loss: 0.6209 - val_binary_accuracy: 0.6576\n",
            "Epoch 1389/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6595 - val_loss: 0.6201 - val_binary_accuracy: 0.6568\n",
            "Epoch 1390/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6604 - val_loss: 0.6218 - val_binary_accuracy: 0.6626\n",
            "Epoch 1391/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6606 - val_loss: 0.6216 - val_binary_accuracy: 0.6547\n",
            "Epoch 1392/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6607 - val_loss: 0.6231 - val_binary_accuracy: 0.6543\n",
            "Epoch 1393/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6610 - val_loss: 0.6180 - val_binary_accuracy: 0.6630\n",
            "Epoch 1394/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6593 - val_loss: 0.6211 - val_binary_accuracy: 0.6593\n",
            "Epoch 1395/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6624 - val_loss: 0.6203 - val_binary_accuracy: 0.6605\n",
            "Epoch 1396/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6625 - val_loss: 0.6207 - val_binary_accuracy: 0.6614\n",
            "Epoch 1397/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6586 - val_loss: 0.6201 - val_binary_accuracy: 0.6605\n",
            "Epoch 1398/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6595 - val_loss: 0.6189 - val_binary_accuracy: 0.6635\n",
            "Epoch 1399/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6597 - val_loss: 0.6193 - val_binary_accuracy: 0.6572\n",
            "Epoch 1400/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6574 - val_loss: 0.6194 - val_binary_accuracy: 0.6656\n",
            "Epoch 1401/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6641 - val_loss: 0.6189 - val_binary_accuracy: 0.6601\n",
            "Epoch 1402/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6610 - val_loss: 0.6209 - val_binary_accuracy: 0.6580\n",
            "Epoch 1403/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6640 - val_loss: 0.6174 - val_binary_accuracy: 0.6643\n",
            "Epoch 1404/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6617 - val_loss: 0.6194 - val_binary_accuracy: 0.6539\n",
            "Epoch 1405/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6628 - val_loss: 0.6203 - val_binary_accuracy: 0.6589\n",
            "Epoch 1406/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6636 - val_loss: 0.6200 - val_binary_accuracy: 0.6559\n",
            "Epoch 1407/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6585 - val_loss: 0.6173 - val_binary_accuracy: 0.6576\n",
            "Epoch 1408/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6605 - val_loss: 0.6198 - val_binary_accuracy: 0.6572\n",
            "Epoch 1409/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6637 - val_loss: 0.6184 - val_binary_accuracy: 0.6589\n",
            "Epoch 1410/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6636 - val_loss: 0.6188 - val_binary_accuracy: 0.6580\n",
            "Epoch 1411/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6587 - val_loss: 0.6190 - val_binary_accuracy: 0.6568\n",
            "Epoch 1412/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6626 - val_loss: 0.6202 - val_binary_accuracy: 0.6651\n",
            "Epoch 1413/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6651 - val_loss: 0.6198 - val_binary_accuracy: 0.6580\n",
            "Epoch 1414/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6605 - val_loss: 0.6206 - val_binary_accuracy: 0.6635\n",
            "Epoch 1415/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6591 - val_loss: 0.6204 - val_binary_accuracy: 0.6539\n",
            "Epoch 1416/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6651 - val_loss: 0.6195 - val_binary_accuracy: 0.6618\n",
            "Epoch 1417/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6607 - val_loss: 0.6220 - val_binary_accuracy: 0.6564\n",
            "Epoch 1418/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6622 - val_loss: 0.6198 - val_binary_accuracy: 0.6551\n",
            "Epoch 1419/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6623 - val_loss: 0.6194 - val_binary_accuracy: 0.6618\n",
            "Epoch 1420/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6587 - val_loss: 0.6213 - val_binary_accuracy: 0.6526\n",
            "Epoch 1421/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6600 - val_loss: 0.6209 - val_binary_accuracy: 0.6555\n",
            "Epoch 1422/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6607 - val_loss: 0.6172 - val_binary_accuracy: 0.6610\n",
            "Epoch 1423/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6660 - val_loss: 0.6191 - val_binary_accuracy: 0.6585\n",
            "Epoch 1424/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6625 - val_loss: 0.6189 - val_binary_accuracy: 0.6597\n",
            "Epoch 1425/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6626 - val_loss: 0.6197 - val_binary_accuracy: 0.6605\n",
            "Epoch 1426/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6617 - val_loss: 0.6179 - val_binary_accuracy: 0.6572\n",
            "Epoch 1427/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6608 - val_loss: 0.6202 - val_binary_accuracy: 0.6601\n",
            "Epoch 1428/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6604 - val_loss: 0.6180 - val_binary_accuracy: 0.6614\n",
            "Epoch 1429/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6561 - val_loss: 0.6209 - val_binary_accuracy: 0.6589\n",
            "Epoch 1430/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6640 - val_loss: 0.6199 - val_binary_accuracy: 0.6589\n",
            "Epoch 1431/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6650 - val_loss: 0.6192 - val_binary_accuracy: 0.6630\n",
            "Epoch 1432/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6183 - binary_accuracy: 0.6600 - val_loss: 0.6198 - val_binary_accuracy: 0.6547\n",
            "Epoch 1433/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6590 - val_loss: 0.6180 - val_binary_accuracy: 0.6622\n",
            "Epoch 1434/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6593 - val_loss: 0.6194 - val_binary_accuracy: 0.6601\n",
            "Epoch 1435/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6574 - val_loss: 0.6191 - val_binary_accuracy: 0.6572\n",
            "Epoch 1436/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6617 - val_loss: 0.6194 - val_binary_accuracy: 0.6539\n",
            "Epoch 1437/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6635 - val_loss: 0.6200 - val_binary_accuracy: 0.6551\n",
            "Epoch 1438/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6669 - val_loss: 0.6181 - val_binary_accuracy: 0.6618\n",
            "Epoch 1439/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6593 - val_loss: 0.6188 - val_binary_accuracy: 0.6576\n",
            "Epoch 1440/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6624 - val_loss: 0.6196 - val_binary_accuracy: 0.6589\n",
            "Epoch 1441/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6612 - val_loss: 0.6190 - val_binary_accuracy: 0.6585\n",
            "Epoch 1442/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6637 - val_loss: 0.6192 - val_binary_accuracy: 0.6576\n",
            "Epoch 1443/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6604 - val_loss: 0.6203 - val_binary_accuracy: 0.6601\n",
            "Epoch 1444/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6166 - binary_accuracy: 0.6613 - val_loss: 0.6199 - val_binary_accuracy: 0.6626\n",
            "Epoch 1445/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6648 - val_loss: 0.6176 - val_binary_accuracy: 0.6597\n",
            "Epoch 1446/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6181 - binary_accuracy: 0.6575 - val_loss: 0.6197 - val_binary_accuracy: 0.6597\n",
            "Epoch 1447/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6606 - val_loss: 0.6201 - val_binary_accuracy: 0.6630\n",
            "Epoch 1448/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6594 - val_loss: 0.6197 - val_binary_accuracy: 0.6568\n",
            "Epoch 1449/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6615 - val_loss: 0.6165 - val_binary_accuracy: 0.6622\n",
            "Epoch 1450/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6632 - val_loss: 0.6167 - val_binary_accuracy: 0.6580\n",
            "Epoch 1451/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6625 - val_loss: 0.6191 - val_binary_accuracy: 0.6585\n",
            "Epoch 1452/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6652 - val_loss: 0.6174 - val_binary_accuracy: 0.6639\n",
            "Epoch 1453/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6645 - val_loss: 0.6183 - val_binary_accuracy: 0.6605\n",
            "Epoch 1454/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6593 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 1455/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6596 - val_loss: 0.6189 - val_binary_accuracy: 0.6572\n",
            "Epoch 1456/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6611 - val_loss: 0.6186 - val_binary_accuracy: 0.6576\n",
            "Epoch 1457/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6558 - val_loss: 0.6205 - val_binary_accuracy: 0.6580\n",
            "Epoch 1458/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6629 - val_loss: 0.6179 - val_binary_accuracy: 0.6580\n",
            "Epoch 1459/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6668 - val_loss: 0.6191 - val_binary_accuracy: 0.6601\n",
            "Epoch 1460/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6644 - val_loss: 0.6173 - val_binary_accuracy: 0.6568\n",
            "Epoch 1461/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6640 - val_loss: 0.6182 - val_binary_accuracy: 0.6618\n",
            "Epoch 1462/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6638 - val_loss: 0.6186 - val_binary_accuracy: 0.6610\n",
            "Epoch 1463/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6656 - val_loss: 0.6183 - val_binary_accuracy: 0.6564\n",
            "Epoch 1464/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6607 - val_loss: 0.6194 - val_binary_accuracy: 0.6593\n",
            "Epoch 1465/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6626 - val_loss: 0.6182 - val_binary_accuracy: 0.6564\n",
            "Epoch 1466/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6631 - val_loss: 0.6174 - val_binary_accuracy: 0.6635\n",
            "Epoch 1467/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6599 - val_loss: 0.6176 - val_binary_accuracy: 0.6618\n",
            "Epoch 1468/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6584 - val_loss: 0.6184 - val_binary_accuracy: 0.6635\n",
            "Epoch 1469/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6644 - val_loss: 0.6168 - val_binary_accuracy: 0.6630\n",
            "Epoch 1470/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6650 - val_loss: 0.6173 - val_binary_accuracy: 0.6601\n",
            "Epoch 1471/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6626 - val_loss: 0.6198 - val_binary_accuracy: 0.6622\n",
            "Epoch 1472/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6594 - val_loss: 0.6207 - val_binary_accuracy: 0.6568\n",
            "Epoch 1473/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6613 - val_loss: 0.6171 - val_binary_accuracy: 0.6647\n",
            "Epoch 1474/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6624 - val_loss: 0.6208 - val_binary_accuracy: 0.6576\n",
            "Epoch 1475/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6636 - val_loss: 0.6204 - val_binary_accuracy: 0.6576\n",
            "Epoch 1476/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6609 - val_loss: 0.6189 - val_binary_accuracy: 0.6597\n",
            "Epoch 1477/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6612 - val_loss: 0.6201 - val_binary_accuracy: 0.6580\n",
            "Epoch 1478/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6624 - val_loss: 0.6186 - val_binary_accuracy: 0.6597\n",
            "Epoch 1479/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6642 - val_loss: 0.6214 - val_binary_accuracy: 0.6526\n",
            "Epoch 1480/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6638 - val_loss: 0.6201 - val_binary_accuracy: 0.6572\n",
            "Epoch 1481/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6617 - val_loss: 0.6190 - val_binary_accuracy: 0.6601\n",
            "Epoch 1482/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6682 - val_loss: 0.6160 - val_binary_accuracy: 0.6626\n",
            "Epoch 1483/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6608 - val_loss: 0.6182 - val_binary_accuracy: 0.6601\n",
            "Epoch 1484/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6671 - val_loss: 0.6179 - val_binary_accuracy: 0.6576\n",
            "Epoch 1485/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6614 - val_loss: 0.6188 - val_binary_accuracy: 0.6585\n",
            "Epoch 1486/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6599 - val_loss: 0.6174 - val_binary_accuracy: 0.6572\n",
            "Epoch 1487/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6593 - val_loss: 0.6182 - val_binary_accuracy: 0.6589\n",
            "Epoch 1488/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6672 - val_loss: 0.6160 - val_binary_accuracy: 0.6626\n",
            "Epoch 1489/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6589 - val_loss: 0.6191 - val_binary_accuracy: 0.6564\n",
            "Epoch 1490/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6642 - val_loss: 0.6184 - val_binary_accuracy: 0.6564\n",
            "Epoch 1491/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6595 - val_loss: 0.6189 - val_binary_accuracy: 0.6601\n",
            "Epoch 1492/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6616 - val_loss: 0.6194 - val_binary_accuracy: 0.6597\n",
            "Epoch 1493/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6620 - val_loss: 0.6186 - val_binary_accuracy: 0.6605\n",
            "Epoch 1494/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6660 - val_loss: 0.6202 - val_binary_accuracy: 0.6585\n",
            "Epoch 1495/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6642 - val_loss: 0.6186 - val_binary_accuracy: 0.6585\n",
            "Epoch 1496/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6634 - val_loss: 0.6186 - val_binary_accuracy: 0.6593\n",
            "Epoch 1497/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6634 - val_loss: 0.6189 - val_binary_accuracy: 0.6593\n",
            "Epoch 1498/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6628 - val_loss: 0.6201 - val_binary_accuracy: 0.6622\n",
            "Epoch 1499/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6685 - val_loss: 0.6183 - val_binary_accuracy: 0.6597\n",
            "Epoch 1500/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6667 - val_loss: 0.6180 - val_binary_accuracy: 0.6639\n",
            "Accuracy on training data: 0.6802757382392883% \n",
            " Error on training data: 0.31972426176071167\n",
            "Accuracy on test data: 0.6716791987419128% \n",
            " Error on test data: 0.32832080125808716\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfUklEQVR4nO3de5hcdZ3n8ffnVFW6EwgQknBLwETHQS4qaHRRHPURZZCrK0hwwfW2MrPrs4DjZWGcWWf2cXZx9ZlxHC+AgjIOoshlcFwQAbmMj4gGRAl3UJCES0IkIYF0uqrOd/84py7p6oROp6urcurzep5+quqcU/X71umuT//qd079ShGBmZkNjqTXBZiZ2fRy8JuZDRgHv5nZgHHwm5kNGAe/mdmAcfCbmQ0YB7/ZVkj6lqTPTnDbRyW9fXsfx6zbHPxmZgPGwW9mNmAc/LbDy4dYPinpN5Kel3ShpD0lXStpvaQbJM1p2/54SfdIWivpZkkHtK07VNKd+f2+BwyPaetYSXfl9/2ZpFdNsuaPSHpY0h8k/UDSPvlySfoHSaskPSfpbkkH5+uOlnRvXttKSZ+Y1A6zgefgt6I4EXgH8MfAccC1wF8C88n+zs8AkPTHwKXAWfm6a4B/kzRD0gzgX4FvA7sD388fl/y+hwIXAX8GzAXOB34gaWhbCpX0NuD/ACcDewOPAd/NVx8JvDl/Hrvm26zJ110I/FlEzAYOBn6yLe2aNTj4rSj+KSKejoiVwL8Dt0fEryJiBLgKODTfbinw/yLi+oioAl8AZgJvBA4DKsAXI6IaEZcDv2xr43Tg/Ii4PSLqEXExsCm/37Y4FbgoIu6MiE3AOcAbJC0CqsBs4BWAIuK+iHgyv18VOFDSLhHxbETcuY3tmgEOfiuOp9uubxzn9s759X3IetgAREQKPA4syNetjM1nLnys7fpLgI/nwzxrJa0F9s3vty3G1rCBrFe/ICJ+AnwZ+AqwStIFknbJNz0ROBp4TNItkt6wje2aAQ5+GzxPkAU4kI2pk4X3SuBJYEG+rGG/tuuPA38XEbu1/cyKiEu3s4adyIaOVgJExJci4rXAgWRDPp/Ml/8yIk4A9iAbkrpsG9s1Axz8NnguA46RdISkCvBxsuGanwG3ATXgDEkVSe8GXt92368Dfy7pP+QHYXeSdIyk2dtYw6XAByUdkh8f+N9kQ1OPSnpd/vgV4HlgBEjzYxCnSto1H6J6Dki3Yz/YAHPw20CJiAeA04B/Ap4hOxB8XESMRsQo8G7gA8AfyI4HXNl232XAR8iGYp4FHs633dYabgD+GriC7F3Gy4BT8tW7kP2DeZZsOGgN8Pl83fuARyU9B/w52bECs20mfxGLmdlgcY/fzGzAOPjNzAaMg9/MbMA4+M3MBky51wVMxLx582LRokW9LsPMbIdyxx13PBMR88cu3yGCf9GiRSxbtqzXZZiZ7VAkPTbecg/1mJkNGAe/mdmAcfCbmQ2YHWKMfzzVapUVK1YwMjLS61K6anh4mIULF1KpVHpdipkVxA4b/CtWrGD27NksWrSIzSdTLI6IYM2aNaxYsYLFixf3uhwzK4gddqhnZGSEuXPnFjb0ASQxd+7cwr+rMbPptcMGP1Do0G8YhOdoZtNrhw7+F/Pcxiqr1ru3bGbWrtDBv36kxjPrR7vy2GvXruWrX/3qNt/v6KOPZu3atV2oyMxsYgod/JnufN/AloK/Vqtt9X7XXHMNu+22W1dqMjObiB32rJ4J6eLw+Nlnn80jjzzCIYccQqVSYXh4mDlz5nD//ffz4IMP8q53vYvHH3+ckZERzjzzTE4//XSgNf3Ehg0beOc738mb3vQmfvazn7FgwQKuvvpqZs6c2b2izcwoSPD/7b/dw71PPNexfLSWUktTZs3Y9qd54D678JnjDtri+nPPPZfly5dz1113cfPNN3PMMcewfPny5mmXF110EbvvvjsbN27kda97HSeeeCJz587d7DEeeughLr30Ur7+9a9z8sknc8UVV3Daaadtc61mZtuiEMHfD17/+tdvdq79l770Ja666ioAHn/8cR566KGO4F+8eDGHHHIIAK997Wt59NFHp61eMxtcXQt+SRcBxwKrIuLgfNnnyb7cehR4BPhgRGz3kc4t9cxXrt3I2hdGOWifXbe3iRe10047Na/ffPPN3HDDDdx2223MmjWLt771reOeiz80NNS8XiqV2LhxY9frNDPr5sHdbwFHjVl2PXBwRLwKeBA4p4vtd3OIn9mzZ7N+/fpx161bt445c+Ywa9Ys7r//fn7+8593sRIzs23TtR5/RNwqadGYZT9uu/lz4KRutd9tc+fO5fDDD+fggw9m5syZ7Lnnns11Rx11FOeddx4HHHAA+++/P4cddlgPKzUz21wvx/g/BHxvSyslnQ6cDrDffvtNV03b5Dvf+c64y4eGhrj22mvHXdcYx583bx7Lly9vLv/EJz4x5fWZmY2nJ+fxS/o0UAMu2dI2EXFBRCyJiCXz53d8c5iZmU3StPf4JX2A7KDvERHRnU9XmZnZFk1r8Es6CvgU8JaIeGFaGvW/FjOzzXRtqEfSpcBtwP6SVkj6MPBlYDZwvaS7JJ3XrfbNzGx83Tyr573jLL6wW+2ZmdnEDMAkbWZm1q7wwd8vQ/w777xzr0swMwMGIPjNzGxznqRtks4++2z23XdfPvrRjwLwN3/zN5TLZW666SaeffZZqtUqn/3sZznhhBN6XKmZ2eaKEfzXng1P3d2xeG6tzq5pwCSmZWavV8I7z93i6qVLl3LWWWc1g/+yyy7juuuu44wzzmCXXXbhmWee4bDDDuP444/39+aaWV8pRvD3wKGHHsqqVat44oknWL16NXPmzGGvvfbiYx/7GLfeeitJkrBy5Uqefvpp9tprr16Xa2bWVIzg30LP/A/rNrJmwygHL+jOtMzvec97uPzyy3nqqadYunQpl1xyCatXr+aOO+6gUqmwaNGicadjNjPrpWIEf48sXbqUj3zkIzzzzDPccsstXHbZZeyxxx5UKhVuuukmHnvssV6XaGbWwcG/HQ466CDWr1/PggUL2HvvvTn11FM57rjjeOUrX8mSJUt4xSte0esSzcw6OPi30913tw4qz5s3j9tuu23c7TZs2DBdJZmZbZXP4zczGzCFD/5++eSumVm/2KGDfxCm8x+E52hm02uHDf7h4WHWrFlT6GCMCNasWcPw8HCvSzGzAtlhD+4uXLiQFStWsHr16i1us25jlQ2bapSfmzmNlU2t4eFhFi5c2OsyzKxAdtjgr1QqLF68eKvbfO5H9/ONf1/BQ3939DRVZWbW/3bYoZ6J8Aw5ZmadCh38AAU+BGBmNimFDn5Pimlm1qnQwQ8+j9/MbKxCB788ym9m1qHQwQ/+AJSZ2ViFDn6P8ZuZdSp08IPH+M3Mxupa8Eu6SNIqScvblu0u6XpJD+WXc7rVPvg8fjOz8XSzx/8t4Kgxy84GboyIlwM35re7ykP8Zmab61rwR8StwB/GLD4BuDi/fjHwrm61D3iQ38xsHNM9xr9nRDyZX38K2HOa2zczG3g9O7gb2XmWWxyIkXS6pGWSlm1tBs6tcX/fzKzTdAf/05L2BsgvV21pw4i4ICKWRMSS+fPnb1ejPpffzKxluoP/B8D78+vvB67uZmONIX7nvplZSzdP57wUuA3YX9IKSR8GzgXeIekh4O357a7xlA1mZp269kUsEfHeLaw6olttbok7/GZmLYX+5K7P5jQz61To4G/wwV0zs5ZCB787/GZmnQod/A3u75uZtRQ6+D3Gb2bWqdDB3+AhfjOzlkIHv9zlNzPrUOjgbwiP8puZNQ1E8JuZWctABL/H+M3MWgod/B7iNzPrVOjgNzOzToUOfs/OaWbWqdDB3+AxfjOzlkIHv8f4zcw6FTr4G3wev5lZS6GD3x1+M7NOhQ7+Bo/xm5m1FDr4PcZvZtap0MHf4A6/mVlLoYPf5/GbmXUqdPA3+Dt3zcxaCh38HuM3M+tU6OBvcH/fzKxlIILfzMxaehL8kj4m6R5JyyVdKmm4m+15iN/MrGXag1/SAuAMYElEHAyUgFO61FY3HtbMbIfWq6GeMjBTUhmYBTzR1dbc4zcza5r24I+IlcAXgN8DTwLrIuLHY7eTdLqkZZKWrV69elJtub9vZtapF0M9c4ATgMXAPsBOkk4bu11EXBARSyJiyfz587erTc/OaWbW0ouhnrcDv4uI1RFRBa4E3tiNhjzEb2bWqRfB/3vgMEmzlB19PQK4r5sN+qweM7OWXozx3w5cDtwJ3J3XcEE32nKH38ysU7kXjUbEZ4DPTFt709WQmdkOoNCf3PV5/GZmnQod/A2endPMrKXQwe8Ov5lZp0IHf4P7+2ZmLYUOfnf4zcw6FTr4GzzEb2bWUuzg9yC/mVmHYgd/znP1mJm1FDr43d83M+tU6OBvcoffzKyp0MHvIX4zs06FDv4Gd/jNzFomFPySzpS0izIXSrpT0pHdLm57yaP8ZmYdJtrj/1BEPAccCcwB3gec27WqppjP4zcza5lo8De6zkcD346Ie9gBTprxGL+ZWaeJBv8dkn5MFvzXSZoNpN0ra2r5PH4zs5aJfhHLh4FDgN9GxAuSdgc+2L2ypoY7/GZmnSba438D8EBErJV0GvBXwLrulTW1PMZvZtYy0eD/GvCCpFcDHwceAf65a1VNEY/xm5l1mmjw1yL7GqsTgC9HxFeA2d0ra2q5w29m1jLRMf71ks4hO43zTyQlQKV7ZU0Nn8dvZtZpoj3+pcAmsvP5nwIWAp/vWlVTLE3d5zcza5hQ8Odhfwmwq6RjgZGI8Bi/mdkOaKJTNpwM/AJ4D3AycLukk7pZ2FRI8uT3WT1mZi0THeP/NPC6iFgFIGk+cANw+WQalbQb8A3gYLJjrx+KiNsm81hbbye7TJ38ZmZNEw3+pBH6uTVs38ye/wj8KCJOkjQDmLUdj7VFzR5/Nx7czGwHNdHg/5Gk64BL89tLgWsm06CkXYE3Ax8AiIhRYHQyj/XibWWX7vGbmbVMKPgj4pOSTgQOzxddEBFXTbLNxcBq4Jv5B8LuAM6MiOfbN5J0OnA6wH777TephuQxfjOzDhMeromIKyLiL/KfyYY+ZP9sXgN8LSIOBZ4Hzh6nvQsiYklELJk/f/6kGmqc1BNOfjOzpq32+CWtZ/whcgEREbtMos0VwIqIuD2/fTnjBP9U8Bi/mVmnrQZ/REz5tAwR8ZSkxyXtHxEPAEcA9051O+AxfjOz8Uz04O5U++/AJfkZPb+lS1M8J3nwO/fNzFp6EvwRcRewpNvtNA7uusdvZtayPefi973Wwd2elmFm1lcKHfyessHMrFOhg98Hd83MOhU6+H06p5lZp0IHP+7xm5l1KHTwe4zfzKxToYPfUzaYmXUqdPB7jN/MrFPBgz+79Hfumpm1FDr4Wwd3e1uGmVk/KXTwt4Z6nPxmZg2FDn5P2WBm1qnQwZ8kPp3TzGysQgd/o8fvD3CZmbUUO/h9OqeZWYeCB3926R6/mVlLoYO/cVaPu/xmZi2FDn6P8ZuZdSp08CfNr17scSFmZn2k0MHfHOlxj9/MrGkggt89fjOzlkIHf/Pgro/umpk1FTr43eM3M+tU6OD3N3CZmXXqWfBLKkn6laQfdq2N/NKnc5qZtfSyx38mcF83G/CUDWZmnXoS/JIWAscA3+huO9mlT+c0M2vpVY//i8CngHRLG0g6XdIySctWr149qUY8xm9m1mnag1/SscCqiLhja9tFxAURsSQilsyfP39SbSWepM3MrEMvevyHA8dLehT4LvA2Sf/SjYaEp2wwMxtr2oM/Is6JiIURsQg4BfhJRJzWjbY8xm9m1qnQ5/G3gr+3dZiZ9ZNyLxuPiJuBm7v1+M2Duz6h08ysaSB6/B7jNzNrKXTw+3ROM7NOhQ5+T9lgZtap2MHvKRvMzDoUOvgTn85pZtah0MHf6PGnPrprZtZU6OBv9vh7W4aZWV8pdPB7ygYzs07FDv782XmM38yspdjBn186983MWgod/J6ywcysU6GD31M2mJl1KnTwe8oGM7NOhQ7+Bk/ZYGbWUujgb/T4zcyspeDBn136k7tmZi2FDv7mlA3OfTOzpkIHf2vKBie/mVlDoYPfPX4zs06FDn7Iz+X3WT1mZk3FD37c4zcza1f44E8kj/GbmbUZiOCvp72uwsysfxQ++MslUXPym5k1FT74K6WEmgf5zcyapj34Je0r6SZJ90q6R9KZ3WyvUhKj7vGbmTWVe9BmDfh4RNwpaTZwh6TrI+LebjRWKSUe6jEzazPtPf6IeDIi7syvrwfuAxZ0q71ySVTrHuoxM2vo6Ri/pEXAocDt46w7XdIySctWr1496TYqSULVPX4zs6aeBb+knYErgLMi4rmx6yPigohYEhFL5s+fP+l2KiUHv5lZu54Ev6QKWehfEhFXdrOt7HROD/WYmTX04qweARcC90XE33e7vUopoerTOc3MmnrR4z8ceB/wNkl35T9Hd6uxSklUax7qMTNrmPbTOSPip2Rzp00Lj/GbmW2u2J/c/d2tvOOFaxj1GL+ZWVOxg//eqzlp3Tf9AS4zszbFDv7SEJWoeqjHzKxNwYO/QomaT+c0M2tT7OAvZz3+0Vq915WYmfWNYgd/aQYAqld7XIiZWf8YiOCnPtrbOszM+kixg788lF3WN/W2DjOzPlLs4M97/LXRESJ8gNfMDIoe/DN2AmAmI2ys+gCvmRkUPfhn7Q7AHNazYaTW42LMzPpDwYN/LgC7az1PPTfS42LMzPpDwYN/HpAF/4NPb+hxMWZm/aHgwZ/1+PcobeCux5/tcTFmZv2h2ME/YxbMmsvhu63hqjtXcu3dT/LcSJXUX8xiZgNs2ufjn3aL38Jh91zJd5Pf8fz3y9wVZarJEGlSIUpDpKUhojRElQpRmkG5lFApiUQJqRJQiVK5TFIqUU0TQgnlcgVUgqREHVGNhKFKhXK5DEkJEOWSQCUiKSMlIOX3SUAJShJQGQmSqENpCCQkoUgpkZIopV7eiVI6CkmZejKD7AvMsoeDIIkgShUERFIiSWsoSUjqVSSI0gxIZoDyL0FIEgRtj6NWfSivK0FK8kVZrUJZ7SRIAYhKIkSwqR4MlUQ9DTbVauw6XKEeQTkRJUGlLMpJwtpNoNoIVIYplYcokx1wV36qrRRZOwKRLyOQRERQqwdJUmJTHYaHZpCmKeVKhSSCUgKj9SCNoNR4bnm3RrSe61hKtPk2SQmSMqqPQlJCaa25P1D2fIk6UolISlTrwcjoKGWllJMEUPNvgPw5ZPdvtB0QKUQA0fpiCiV5wcr/Dhq/E5rbEpG3n98/KYMSUqCUCCHSeo1EQKlC1KtQHyWSCimipECRQlonoo6UEOVhojZKUqpA9XlIKvnjCurV7My4aLRZz/6G02q2rDwEaT1bntbyOrPnmKZB0nxy0fY82rTfHt6VSGuoVMkuI7L92Hiu5aGsnqSUtZX/1hp/t83L1osju29ay54TZHU2ntt4YmydE7ydlLMPiZZm5L/HcR6/cZ8Xa3tL66dY8YP/LZ+CtMaBI+tZt34Do5s2Qm0dqm+ilI5Sqo1SHh1lRlQpk03tEEBCkOB3BlNpZpcff0aXH38s5W1Od7tjJVu4rrbLsW/t29d1I2omM5SgMZfdkEbWpRCQaOpf3ymiRolS1LNO3ZgMSVGW8VLbGlEmO918ExWyf+WZQDz8tq9z4JvfPaV1Fj/49zgAln6bErD7tt43oq1H036Z9Zrq9SpRr0Gk1Os1Nm6qZttEUEvznlW9SkSQpimkKRF1IlIirWe30zohZZf1OgGEEoISKUKjG0hLQxA1VBul1esAok6QQNRISVC9SlqaAZESKmf9yXQU1avNP7KItK3j0upJEinRdr39Mhq9TALSNOuVRFBLYbSWUik3erSiWk+REpIE0oB6GtTTrAc4svF5dtl1N5J0FKojRGlGW583eyEEbR0qZS+Sxs00TamUREUp1Wo1653Xq9RChLJ3II2edufn9aLt2pZ6oJBEDaJOqgqKGvVkCEU9f1eSEoiUEiIlrVeZmaTUS0OkKuU9chBjPjMS6ZhmSm0VZfWKvDfeWLpZrzJ7fq3AKOX3rKNIqadp9gZAQsp+J4mCpFQmkhlEWqWkoJqKNESav2utp3XK9U2oVKJeqxGVWZDWSPI6ElKSqFGPhCRJeKEWlBXZO15EKaoECZtSoVKFRGI0jeydj0S9nubPrPVuK39P1/y9Z+94awzXn6dGmTStkSRlVCoRoxuJ0ozs3Uq6iVCZchKkqpBGStL2N5zk7wzV9rsNlbKWIs32H6KUtjp3+fvJZl3tl81tGnU3X3abv6uICEpRb/51JVGjFDVIStTS7PcGar3ji3r2MoqURNnrJVH2TltKqMSmxrMhEawfqXHIPn/EVCt+8G8PCUpltrSbSm3Xy8DQdNRkZradin1w18zMOjj4zcwGjIPfzGzAOPjNzAaMg9/MbMA4+M3MBoyD38xswDj4zcwGjHaErySUtBp4bJJ3nwc8M4XldEO/19jv9YFrnAr9Xh/0f439Vt9LImL+2IU7RPBvD0nLImJJr+vYmn6vsd/rA9c4Ffq9Puj/Gvu9vgYP9ZiZDRgHv5nZgBmE4L+g1wVMQL/X2O/1gWucCv1eH/R/jf1eHzAAY/xmZra5Qejxm5lZGwe/mdmAKXTwSzpK0gOSHpZ0do9q2FfSTZLulXSPpDPz5btLul7SQ/nlnHy5JH0pr/k3kl4zTXWWJP1K0g/z24sl3Z7X8T1JM/LlQ/nth/P1i6apvt0kXS7pfkn3SXpDH+7Dj+W/4+WSLpU03Ov9KOkiSaskLW9bts37TdL78+0fkvT+Ltf3+fz3/BtJV0narW3dOXl9D0j607blXXutj1dj27qPSwpJ8/Lb074PJyUiCvlD9gVZjwAvJfta1F8DB/agjr2B1+TXZwMPAgcC/xc4O19+NvC5/PrRwLVk38l3GHD7NNX5F8B3gB/mty8DTsmvnwf81/z6fwPOy6+fAnxvmuq7GPgv+fUZwG79tA+BBcDvgJlt++8Dvd6PwJuB1wDL25Zt034j+9bS3+aXc/Lrc7pY35FAOb/+ubb6Dsxfx0PA4vz1Xer2a328GvPl+wLXkX24dF6v9uGknlOvGu76E4M3ANe13T4HOKcP6roaeAfwALB3vmxv4IH8+vnAe9u2b27XxZoWAjcCbwN+mP/RPtP24mvuy/wP/Q359XK+nbpc3655qGrM8n7ahwuAx/MXdjnfj3/aD/sRWDQmWLdpvwHvBc5vW77ZdlNd35h1/xG4JL++2Wu4sQ+n47U+Xo3A5cCrgUdpBX9P9uG2/hR5qKfxQmxYkS/rmfzt/KHA7cCeEfFkvuopYM/8ei/q/iLwKaDxreBzgbURURunhmZ9+fp1+fbdtBhYDXwzH476hqSd6KN9GBErgS8AvweeJNsvd9Bf+7FhW/dbL19LHyLrQbOVOqa9PkknACsj4tdjVvVNjVtT5ODvK5J2Bq4AzoqI59rXRdYF6Ml5tZKOBVZFxB29aH+CymRvtb8WEYcCz5MNUTT1ch8C5OPkJ5D9k9oH2Ak4qlf1TFSv99vWSPo0UAMu6XUt7STNAv4S+J+9rmWyihz8K8nG4BoW5sumnaQKWehfEhFX5ouflrR3vn5vYFW+fLrrPhw4XtKjwHfJhnv+EdhNUnmcGpr15et3BdZ0sT7IekcrIuL2/PblZP8I+mUfArwd+F1ErI6IKnAl2b7tp/3YsK37bdr3p6QPAMcCp+b/nPqpvpeR/YP/df66WQjcKWmvPqpxq4oc/L8EXp6fVTGD7ADaD6a7CEkCLgTui4i/b1v1A6BxZP/9ZGP/jeX/OT874DBgXdvb8ikXEedExMKIWES2j34SEacCNwEnbaG+Rt0n5dt3tccYEU8Bj0vaP190BHAvfbIPc78HDpM0K/+dN2rsm/3YZlv323XAkZLm5O9sjsyXdYWko8iGHo+PiBfG1H1KfkbUYuDlwC+Y5td6RNwdEXtExKL8dbOC7ASOp+iTffiienVwYTp+yI6wP0h2xP/TParhTWRvpX8D3JX/HE02nnsj8BBwA7B7vr2Ar+Q13w0smcZa30rrrJ6Xkr2oHga+Dwzly4fz2w/n6186TbUdAizL9+O/kp0Z0Vf7EPhb4H5gOfBtsrNPerofgUvJjjlUyQLqw5PZb2Rj7Q/nPx/scn0Pk42HN14v57Vt/+m8vgeAd7Yt79prfbwax6x/lNbB3Wnfh5P58ZQNZmYDpshDPWZmNg4Hv5nZgHHwm5kNGAe/mdmAcfCbmQ0YB79Zl0l6q/JZT836gYPfzGzAOPjNcpJOk/QLSXdJOl/ZdxRskPQPyubZv1HS/HzbQyT9vG3O+Mac9n8k6QZJv5Z0p6SX5Q+/s1rfJ3BJ/ules55w8JsBkg4AlgKHR8QhQB04lWyytWURcRBwC/CZ/C7/DPyPiHgV2Sc0G8svAb4SEa8G3kj2iU/IZmU9i2xO+ZeSzeNj1hPlF9/EbCAcAbwW+GXeGZ9JNnlZCnwv3+ZfgCsl7QrsFhG35MsvBr4vaTawICKuAoiIEYD88X4RESvy23eRze/+0+4/LbNODn6zjICLI+KczRZKfz1mu8nOcbKp7Xodv/ashzzUY5a5EThJ0h7Q/F7al5C9Rhqza/4n4KcRsQ54VtKf5MvfB9wSEeuBFZLelT/GUD53u1lfca/DDIiIeyX9FfBjSQnZTIwfJfvSl9fn61aRHQeAbDrj8/Jg/y3wwXz5+4DzJf2v/DHeM41Pw2xCPDun2VZI2hARO/e6DrOp5KEeM7MB4x6/mdmAcY/fzGzAOPjNzAaMg9/MbMA4+M3MBoyD38xswPx/7ZcfU+c4TzsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "d810a70d-e161-4f8e-c9af-5198fd724958"
      },
      "source": [
        "Xnew=np.array([[1.7,2.05,57,43,0.69,0.5,0.5,0.5,1.2,0.62,0.71,1.31,77.8,0.78,0.33,1.26,2.6,1.2,0.67,0.74,1.17,85.5,0.79,0.62,1.18,4.6,1.09,0.67,0.71,1.04,78.3,0.73,0.51,1.08,4.4,0.99,0.69,0.71,0.9,71.7,0.61,0.55,0.89,6.0,0.86,0.7,0.66,0.82,61.8,0.54,0.38,0.77,4.6,1.1,0.68,0.71,1.13,86.8,0.68,0.58,1.00,4.4,1.2,0.65,0.71,1.35,79.1,0.81,0.31,1.26,1.0,1.02,0.69,0.68,0.99,72.9,0.66,0.56,0.95,3.7,1.05,0.63,0.69,1.0,71.2,0.67,0.59,1.07,3.9,1.0925,0.6625,0.6975,1.1175,77.5,0.7050000000000001,0.51,1.07,3.2500000000000004],\n",
        "               [1.3,3.2,20,134,0.44,0.71,0.473,0.5,1.1,0.67,0.69,1.13,82.3,0.7,0.44,1.05,8.1,1.1,0.6,0.71,1.06,71.0,0.69,0.3,1.14,4.3,1.06,0.68,0.71,0.97,76.6,0.71,0.54,1.04,3.1,0.97,0.69,0.71,0.95,65.6,0.6,0.53,0.88,3.7,0.87,0.7,0.68,0.77,62.4,0.53,0.61,0.75,3.6,1.22,0.66,0.73,1.36,85.0,0.77,0.53,1.18,5.0,1.22,0.64,0.75,1.25,83.5,0.79,0.48,1.23,6.4,1.16,0.57,0.76,1.01,75.0,0.73,0.27,1.28,3.3,1.1,0.59,0.72,1.0,74.5,0.66,0.62,1.12,4.9,0.85,0.71,0.64,0.88,60.9,0.56,0.43,0.78,4.0],\n",
        "               [2.03,1.73,74,33,0.67,0.47,0.472,0.589,1.27,0.62,0.76,1.36,87.7,0.8,0.59,1.30,3.5,1.12,0.65,0.76,1.01,75.3,0.76,0.52,1.17,4.3,1.11,0.61,0.71,1.12,70.9,0.71,0.34,1.16,7.5,1.09,0.64,0.71,1.16,75.5,0.67,0.48,1.05,5.8,0.96,0.68,0.68,0.93,71.5,0.59,0.46,0.86,4.2,1.24,0.54,0.76,1.29,73.4,0.75,0.26,1.39,2.5,1.18,0.65,0.7,1.26,83.1,0.75,0.52,1.16,5.8,0.99,0.66,0.7,0.88,70.9,0.6,0.56,0.91,5.4,0.95,0.68,0.69,0.84,69.7,0.6,0.55,0.88,8.6,0.94,0.68,0.66,0.87,69.0,0.6,0.6,0.89,3.3],\n",
        "               [2.3,1.5,25,22,0.59,0.66,0.5,0.521,1.2,0.57,0.73,1.14,78.4,0.76,0.24,1.33,3.7,1.13,0.67,0.69,1.16,82.6,0.73,0.5,1.09,5.0,1.0,0.64,0.68,0.9,71.2,0.64,0.59,0.99,4.4,0.91,0.67,0.67,0.83,67.0,0.57,0.47,0.85,5.7,1.06,0.6375,0.6925,1.0074999999999998,74.8,0.6749999999999999,0.45,1.065,4.7,1.19,0.59,0.72,1.22,75.5,0.76,0.27,1.28,2.2,1.12,0.6,0.73,1.01,76.8,0.68,0.44,1.14,5.1,1.11,0.68,0.71,1.13,81.7,0.73,0.53,1.07,4.0,1.01,0.68,0.7,0.98,73.4,0.63,0.54,0.93,6.9,1.1075,0.6375000000000001,0.7150000000000001,1.085,76.85,0.7,0.445,1.105,4.550000000000001],\n",
        "               [1.52,2.33,30,35,0.71,0.64,0.523,0.51,1.17,0.59,0.74,1.11,75.9,0.74,0.31,1.25,3.5,1.13,0.67,0.71,1.16,82.6,0.73,0.61,1.09,5.4,1.12,0.62,0.73,1.09,73.7,0.71,0.58,1.15,3.0,1.1,0.65,0.7,1.12,77.3,0.72,0.54,1.10,3.8,0.92,0.66,0.68,0.88,64.3,0.56,0.51,0.85,6.5,1.27,0.65,0.77,1.26,89.8,0.81,0.47,1.25,6.0,1.16,0.66,0.78,1.14,78.8,0.7,0.4,1.06,3.4,1.08,0.66,0.72,1.0,77.6,0.68,0.63,1.03,4.1,1.07,0.58,0.73,1.03,65.2,0.67,0.28,1.15,4.0,1.02,0.68,0.72,0.94,72.4,0.66,0.45,0.97,4.0],\n",
        "               [1.22,4.00,2,9,0.89,0.56,0.549,0.478,1.26,0.6,0.74,1.36,84.5,0.8,0.52,1.33,7.8,1.23,0.49,0.75,1.2,72.7,0.71,0.28,1.45,5.5,1.17,0.58,0.73,1.15,80.9,0.69,0.45,1.18,6.5,1.15,0.67,0.7,1.34,82.6,0.71,0.46,1.06,7.5,0.94,0.54,0.74,0.68,54.9,0.5,0.45,0.93,7.2,1.15,0.69,0.68,1.2,85.9,0.75,0.33,1.09,5.0,1.01,0.76,0.6,1.22,84.6,0.69,0.44,0.92,6.1,1.0,0.63,0.71,0.89,67.9,0.6,0.46,0.96,4.2,0.93,0.71,0.68,0.89,67.3,0.65,0.46,0.93,4.2,0.88,0.7,0.69,0.74,62.0,0.57,0.55,0.82,3.8],\n",
        "               [1.43,2.76,27,60,0.59,0.67,0.479,0.527,1.16,0.6,0.73,1.14,74.2,0.74,0.33,1.24,3.1,1.13,0.77,0.71,1.26,85.8,0.78,0.67,1.01,5.7,1.06,0.65,0.7,1.04,74.0,0.67,0.46,1.04,3.0,1.06,0.66,0.73,0.93,76.4,0.67,0.46,1.01,6.4,0.94,0.66,0.71,0.83,65.5,0.57,0.51,0.85,8.8,1.14,0.71,0.73,1.15,83.4,0.77,0.43,1.09,5.8,1.09,0.65,0.73,1.15,71.0,0.7,0.32,1.08,4.6,1.08,0.65,0.67,1.05,80.7,0.71,0.49,1.09,7.8,1.05,0.64,0.75,0.98,73.5,0.6,0.65,0.94,6.0,0.89,0.63,0.7,0.73,57.7,0.57,0.35,0.90,2.4]\n",
        "               ])\n",
        "Xnew=predictionScaler.transform(Xnew)\n",
        "#model= keras.models.load_model(\"691model.h5\")\n",
        "\n",
        "ynew=(model.predict([Xnew]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.46845505]\n",
            " [0.47569743]\n",
            " [0.5411184 ]\n",
            " [0.4769532 ]\n",
            " [0.5028554 ]\n",
            " [0.5008502 ]\n",
            " [0.49375707]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDSZ8GXKuje"
      },
      "source": [
        "model.save('/content/save/68model.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 100 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "model.layers[0].get_weights()[0][98]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSBrO3pcCHlQ",
        "outputId": "61f3a2f7-e06a-4b0a-b5cb-95f6f4bb5ef3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6683375104427736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGzpVUzOYhY"
      },
      "source": [
        "import shap\n",
        "import xgboost\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','team_one_name','team_two_name']\n",
        "shap.initjs()\n",
        "#explainer = shap.Explainer(model.predict, X_train)\n",
        "#shap_values = explainer.shap_values(np.array([[1.8,1.9,26,23,0.63,0.64,0.509,0.591,1.16,0.68,0.7,1.26,84.3,0.75,0.5,1.11,7.4,1.13,0.64,0.72,1.11,78.0,0.72,0.57,1.13,3.2,1.0,0.67,0.69,0.95,69.3,0.64,0.58,0.95,4.2,0.99,0.65,0.69,0.95,67.7,0.62,0.58,0.94,3.3,1.07,0.66,0.7,1.0675000000000001,74.825,0.6825,0.5575,1.0325000000000002,4.525,1.23,0.6,0.75,1.26,79.4,0.77,0.31,1.29,3.4,1.24,0.61,0.77,1.15,82.8,0.82,0.52,1.35,3.4,1.14,0.62,0.73,1.11,76.1,0.72,0.5,1.16,5.2,1.0,0.68,0.7,0.98,70.2,0.61,0.51,0.90,3.9,0.98,0.69,0.69,0.96,71.7,0.6,0.48,0.87,5.3]])\n",
        "\n",
        "keras_explainer = shap.DeepExplainer(model, shap.sample(X_train, 10))\n",
        "keras_shap_values = keras_explainer.shap_values(X_test)\n",
        "\n",
        "values = keras_shap_values[0]\n",
        "base_values = [keras_explainer.expected_value[0]]*len(keras_shap_values[0])\n",
        "\n",
        "tmp = shap.Explanation(values = np.array(values, dtype=np.float32),\n",
        "                       base_values = np.array(base_values, dtype=np.float32),\n",
        "                       data=np.array(X_train),\n",
        "                       feature_names=CSV_COLUMN_NAMES2)\n",
        "\n",
        "#shap.plots.waterfall(tmp[5])\n",
        "#shap.plots.bar(tmp,max_display=98)\n",
        "shap.summary_plot(tmp, X_test,max_display=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLaoTNJnIRM"
      },
      "source": [
        "#print(X_val)\n",
        "pokus=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "pokus.pop('Match_link')\n",
        "pokus.pop('team_one_name')\n",
        "pokus.pop('team_two_name')\n",
        "pokus.pop('Result')\n",
        "\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(pokus)\n",
        "data=scaler.transform(pokus)\n",
        "print(data)\n"
      ]
    }
  ]
}