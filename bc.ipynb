{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOp12AhZBe1wufCGqXd6WyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "f2825c80-b34d-464c-9b21-b850a6dbf014"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import numpy\n",
        "import keras\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "RESULTS=['0','1']\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)\n",
        "#train_y=train.pop('Result')\n",
        "#test_y=test.pop('Result')\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "'''\n",
        "\n",
        "target_column = ['Result'] \n",
        "predictors = list(set(list(train.columns))-set(target_column))\n",
        "scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "norm = StandardScaler()\n",
        "train[predictors]=norm.fit_transform(train[predictors])\n",
        "train[predictors] = scaler.fit_transform(train[predictors])\n",
        "\n",
        "\n",
        "#train[predictors] = train[predictors]/train[predictors].max()\n",
        "\n",
        "X = train[predictors].values\n",
        "y = train[target_column].values\n",
        "#print(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=9)#32 #888\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "#y_train = np_utils.to_categorical(y_train)\n",
        "#y_test = np_utils.to_categorical(y_test)#tohle nepoužívám, protože mám sigmoid a výsledky můžou být jen 1 nebo 0, takže to není nutné dělat  z toho kategorizační vektory\n",
        "count_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(98, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))#binary sigmoid     categorical softmax\n",
        "\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(learning_rate=0.017), #keras.optimizers.SGD(learning_rate=0.01)\n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "#change number of hidden layers and change the learning rate up to 0.9\n",
        "\n",
        "#adadelta-lr 0.04 78 (bez grenadedmg a kast) 20 4 1 sigmoid binary crossentropy  1000 epochs a 64 batch size a 9 rs\n",
        "#adadelta-lr 0.015 98 30 15 5 2 rs9 testsize 0.15 64batchsize  Accuracy on test data: 0.690095841884613% \n",
        "#adadelta-lr 0.02 98 35 15 2 rs17 testsize 0.15 64batchsize 0.15 test rate Accuracy on test data: 0.6890308856964111% \n",
        "#record accuracy má Adadelta(0.01), categorical_crossentropy 98,50,2 1000 epochs a 32 batch size\n",
        "#record accuracy má adadelta(0.01) 86 random state 32 batch size a 1000 epochs  test accuracy: 0.674478\n",
        "#adadelta zatím top\n",
        "#binary_crossentropy\n",
        "#categorical_crossentropy\n",
        "# categorical_hinge 0.677\n",
        "# hinge 0.667\n",
        "# MeanAbsoluteError 0.654, \n",
        "# MeanAbsolutePercentageError 0.6814 \n",
        "\n",
        "lof = LocalOutlierFactor()\n",
        "yhat = lof.fit_predict(X_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "print(X_train.shape, X_train.shape)\n",
        "history = model.fit(X_train, y_train, epochs=1000,batch_size=64,validation_data=(X_test, y_test))\n",
        "\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
        "pred_test= model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15958, 98)\n",
            "(2817, 98)\n",
            "(15800, 98) (15800, 98)\n",
            "Epoch 1/1000\n",
            "247/247 [==============================] - 2s 3ms/step - loss: 0.6946 - accuracy: 0.4780 - val_loss: 0.6899 - val_accuracy: 0.5360\n",
            "Epoch 2/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5367 - val_loss: 0.6888 - val_accuracy: 0.5364\n",
            "Epoch 3/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5383 - val_loss: 0.6879 - val_accuracy: 0.5364\n",
            "Epoch 4/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5418 - val_loss: 0.6872 - val_accuracy: 0.5364\n",
            "Epoch 5/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5401 - val_loss: 0.6864 - val_accuracy: 0.5367\n",
            "Epoch 6/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5361 - val_loss: 0.6848 - val_accuracy: 0.5367\n",
            "Epoch 7/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5358 - val_loss: 0.6833 - val_accuracy: 0.5382\n",
            "Epoch 8/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5451 - val_loss: 0.6822 - val_accuracy: 0.5428\n",
            "Epoch 9/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6793 - accuracy: 0.5541 - val_loss: 0.6809 - val_accuracy: 0.5552\n",
            "Epoch 10/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5589 - val_loss: 0.6798 - val_accuracy: 0.5619\n",
            "Epoch 11/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5610 - val_loss: 0.6788 - val_accuracy: 0.5595\n",
            "Epoch 12/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5602 - val_loss: 0.6776 - val_accuracy: 0.5637\n",
            "Epoch 13/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5695 - val_loss: 0.6766 - val_accuracy: 0.5648\n",
            "Epoch 14/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5678 - val_loss: 0.6754 - val_accuracy: 0.5758\n",
            "Epoch 15/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5779 - val_loss: 0.6743 - val_accuracy: 0.5786\n",
            "Epoch 16/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5808 - val_loss: 0.6731 - val_accuracy: 0.5811\n",
            "Epoch 17/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5843 - val_loss: 0.6720 - val_accuracy: 0.5843\n",
            "Epoch 18/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6692 - accuracy: 0.5872 - val_loss: 0.6709 - val_accuracy: 0.5861\n",
            "Epoch 19/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6688 - accuracy: 0.5865 - val_loss: 0.6697 - val_accuracy: 0.5925\n",
            "Epoch 20/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.5947 - val_loss: 0.6685 - val_accuracy: 0.5960\n",
            "Epoch 21/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.5954 - val_loss: 0.6674 - val_accuracy: 0.5957\n",
            "Epoch 22/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.5984 - val_loss: 0.6661 - val_accuracy: 0.5964\n",
            "Epoch 23/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.5952 - val_loss: 0.6650 - val_accuracy: 0.5950\n",
            "Epoch 24/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6022 - val_loss: 0.6636 - val_accuracy: 0.6045\n",
            "Epoch 25/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6106 - val_loss: 0.6624 - val_accuracy: 0.6088\n",
            "Epoch 26/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6083 - val_loss: 0.6613 - val_accuracy: 0.6124\n",
            "Epoch 27/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6080 - val_loss: 0.6602 - val_accuracy: 0.6131\n",
            "Epoch 28/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6145 - val_loss: 0.6591 - val_accuracy: 0.6138\n",
            "Epoch 29/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6123 - val_loss: 0.6580 - val_accuracy: 0.6131\n",
            "Epoch 30/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6202 - val_loss: 0.6569 - val_accuracy: 0.6124\n",
            "Epoch 31/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6546 - accuracy: 0.6202 - val_loss: 0.6562 - val_accuracy: 0.6127\n",
            "Epoch 32/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6139 - val_loss: 0.6548 - val_accuracy: 0.6170\n",
            "Epoch 33/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6253 - val_loss: 0.6537 - val_accuracy: 0.6177\n",
            "Epoch 34/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6479 - accuracy: 0.6304 - val_loss: 0.6527 - val_accuracy: 0.6195\n",
            "Epoch 35/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6254 - val_loss: 0.6517 - val_accuracy: 0.6202\n",
            "Epoch 36/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6274 - val_loss: 0.6508 - val_accuracy: 0.6244\n",
            "Epoch 37/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6309 - val_loss: 0.6498 - val_accuracy: 0.6223\n",
            "Epoch 38/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6456 - accuracy: 0.6265 - val_loss: 0.6488 - val_accuracy: 0.6248\n",
            "Epoch 39/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6360 - val_loss: 0.6479 - val_accuracy: 0.6241\n",
            "Epoch 40/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6320 - val_loss: 0.6471 - val_accuracy: 0.6269\n",
            "Epoch 41/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6409 - accuracy: 0.6336 - val_loss: 0.6467 - val_accuracy: 0.6244\n",
            "Epoch 42/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6302 - val_loss: 0.6454 - val_accuracy: 0.6248\n",
            "Epoch 43/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6419 - val_loss: 0.6447 - val_accuracy: 0.6269\n",
            "Epoch 44/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6273 - val_loss: 0.6438 - val_accuracy: 0.6305\n",
            "Epoch 45/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6414 - accuracy: 0.6353 - val_loss: 0.6430 - val_accuracy: 0.6273\n",
            "Epoch 46/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6324 - val_loss: 0.6426 - val_accuracy: 0.6290\n",
            "Epoch 47/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6397 - val_loss: 0.6414 - val_accuracy: 0.6258\n",
            "Epoch 48/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6336 - val_loss: 0.6408 - val_accuracy: 0.6294\n",
            "Epoch 49/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6403 - val_loss: 0.6400 - val_accuracy: 0.6283\n",
            "Epoch 50/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6390 - accuracy: 0.6333 - val_loss: 0.6393 - val_accuracy: 0.6308\n",
            "Epoch 51/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6404 - accuracy: 0.6311 - val_loss: 0.6385 - val_accuracy: 0.6322\n",
            "Epoch 52/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6354 - val_loss: 0.6379 - val_accuracy: 0.6319\n",
            "Epoch 53/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6346 - accuracy: 0.6401 - val_loss: 0.6372 - val_accuracy: 0.6347\n",
            "Epoch 54/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6433 - val_loss: 0.6366 - val_accuracy: 0.6397\n",
            "Epoch 55/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6426 - val_loss: 0.6359 - val_accuracy: 0.6376\n",
            "Epoch 56/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6299 - accuracy: 0.6460 - val_loss: 0.6354 - val_accuracy: 0.6397\n",
            "Epoch 57/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6441 - val_loss: 0.6348 - val_accuracy: 0.6333\n",
            "Epoch 58/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6388 - val_loss: 0.6345 - val_accuracy: 0.6322\n",
            "Epoch 59/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6325 - accuracy: 0.6351 - val_loss: 0.6338 - val_accuracy: 0.6344\n",
            "Epoch 60/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6464 - val_loss: 0.6328 - val_accuracy: 0.6404\n",
            "Epoch 61/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.6449 - val_loss: 0.6322 - val_accuracy: 0.6425\n",
            "Epoch 62/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6466 - val_loss: 0.6314 - val_accuracy: 0.6397\n",
            "Epoch 63/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6290 - accuracy: 0.6364 - val_loss: 0.6311 - val_accuracy: 0.6376\n",
            "Epoch 64/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6447 - val_loss: 0.6302 - val_accuracy: 0.6425\n",
            "Epoch 65/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6494 - val_loss: 0.6297 - val_accuracy: 0.6425\n",
            "Epoch 66/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6456 - val_loss: 0.6291 - val_accuracy: 0.6425\n",
            "Epoch 67/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6549 - val_loss: 0.6288 - val_accuracy: 0.6422\n",
            "Epoch 68/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6270 - accuracy: 0.6403 - val_loss: 0.6279 - val_accuracy: 0.6436\n",
            "Epoch 69/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6471 - val_loss: 0.6276 - val_accuracy: 0.6422\n",
            "Epoch 70/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.6511 - val_loss: 0.6270 - val_accuracy: 0.6461\n",
            "Epoch 71/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6534 - val_loss: 0.6263 - val_accuracy: 0.6443\n",
            "Epoch 72/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.6455 - val_loss: 0.6261 - val_accuracy: 0.6439\n",
            "Epoch 73/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6462 - val_loss: 0.6253 - val_accuracy: 0.6447\n",
            "Epoch 74/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.6558 - val_loss: 0.6248 - val_accuracy: 0.6482\n",
            "Epoch 75/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6184 - accuracy: 0.6556 - val_loss: 0.6242 - val_accuracy: 0.6496\n",
            "Epoch 76/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6233 - accuracy: 0.6484 - val_loss: 0.6236 - val_accuracy: 0.6489\n",
            "Epoch 77/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6480 - val_loss: 0.6231 - val_accuracy: 0.6493\n",
            "Epoch 78/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6522 - val_loss: 0.6226 - val_accuracy: 0.6493\n",
            "Epoch 79/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6216 - accuracy: 0.6507 - val_loss: 0.6222 - val_accuracy: 0.6507\n",
            "Epoch 80/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6499 - val_loss: 0.6217 - val_accuracy: 0.6539\n",
            "Epoch 81/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6201 - accuracy: 0.6492 - val_loss: 0.6213 - val_accuracy: 0.6500\n",
            "Epoch 82/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6457 - val_loss: 0.6209 - val_accuracy: 0.6489\n",
            "Epoch 83/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6572 - val_loss: 0.6203 - val_accuracy: 0.6532\n",
            "Epoch 84/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6511 - val_loss: 0.6199 - val_accuracy: 0.6550\n",
            "Epoch 85/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.6497 - val_loss: 0.6196 - val_accuracy: 0.6503\n",
            "Epoch 86/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6160 - accuracy: 0.6543 - val_loss: 0.6192 - val_accuracy: 0.6546\n",
            "Epoch 87/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.6582 - val_loss: 0.6188 - val_accuracy: 0.6514\n",
            "Epoch 88/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.6521 - val_loss: 0.6180 - val_accuracy: 0.6557\n",
            "Epoch 89/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6593 - val_loss: 0.6184 - val_accuracy: 0.6514\n",
            "Epoch 90/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6193 - accuracy: 0.6477 - val_loss: 0.6174 - val_accuracy: 0.6560\n",
            "Epoch 91/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6123 - accuracy: 0.6599 - val_loss: 0.6167 - val_accuracy: 0.6560\n",
            "Epoch 92/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.6536 - val_loss: 0.6165 - val_accuracy: 0.6550\n",
            "Epoch 93/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6540 - val_loss: 0.6164 - val_accuracy: 0.6550\n",
            "Epoch 94/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6143 - accuracy: 0.6544 - val_loss: 0.6173 - val_accuracy: 0.6546\n",
            "Epoch 95/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6123 - accuracy: 0.6634 - val_loss: 0.6152 - val_accuracy: 0.6581\n",
            "Epoch 96/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.6530 - val_loss: 0.6154 - val_accuracy: 0.6557\n",
            "Epoch 97/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6157 - accuracy: 0.6592 - val_loss: 0.6144 - val_accuracy: 0.6603\n",
            "Epoch 98/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6124 - accuracy: 0.6582 - val_loss: 0.6140 - val_accuracy: 0.6606\n",
            "Epoch 99/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6544 - val_loss: 0.6139 - val_accuracy: 0.6589\n",
            "Epoch 100/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.6505 - val_loss: 0.6133 - val_accuracy: 0.6606\n",
            "Epoch 101/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6132 - accuracy: 0.6585 - val_loss: 0.6129 - val_accuracy: 0.6610\n",
            "Epoch 102/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.6512 - val_loss: 0.6123 - val_accuracy: 0.6628\n",
            "Epoch 103/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6554 - val_loss: 0.6122 - val_accuracy: 0.6617\n",
            "Epoch 104/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6090 - accuracy: 0.6571 - val_loss: 0.6116 - val_accuracy: 0.6645\n",
            "Epoch 105/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6089 - accuracy: 0.6581 - val_loss: 0.6113 - val_accuracy: 0.6642\n",
            "Epoch 106/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6552 - val_loss: 0.6109 - val_accuracy: 0.6642\n",
            "Epoch 107/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6603 - val_loss: 0.6106 - val_accuracy: 0.6674\n",
            "Epoch 108/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6129 - accuracy: 0.6551 - val_loss: 0.6102 - val_accuracy: 0.6674\n",
            "Epoch 109/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6618 - val_loss: 0.6101 - val_accuracy: 0.6652\n",
            "Epoch 110/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6655 - val_loss: 0.6100 - val_accuracy: 0.6621\n",
            "Epoch 111/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6645 - val_loss: 0.6092 - val_accuracy: 0.6663\n",
            "Epoch 112/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6094 - accuracy: 0.6597 - val_loss: 0.6091 - val_accuracy: 0.6674\n",
            "Epoch 113/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6122 - accuracy: 0.6581 - val_loss: 0.6086 - val_accuracy: 0.6674\n",
            "Epoch 114/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6134 - accuracy: 0.6532 - val_loss: 0.6091 - val_accuracy: 0.6631\n",
            "Epoch 115/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6658 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
            "Epoch 116/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6047 - accuracy: 0.6652 - val_loss: 0.6078 - val_accuracy: 0.6692\n",
            "Epoch 117/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6661 - val_loss: 0.6074 - val_accuracy: 0.6688\n",
            "Epoch 118/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.6617 - val_loss: 0.6071 - val_accuracy: 0.6702\n",
            "Epoch 119/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6619 - val_loss: 0.6069 - val_accuracy: 0.6681\n",
            "Epoch 120/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6076 - accuracy: 0.6618 - val_loss: 0.6067 - val_accuracy: 0.6695\n",
            "Epoch 121/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6044 - accuracy: 0.6643 - val_loss: 0.6063 - val_accuracy: 0.6716\n",
            "Epoch 122/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.6634 - val_loss: 0.6060 - val_accuracy: 0.6713\n",
            "Epoch 123/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.6690 - val_loss: 0.6060 - val_accuracy: 0.6699\n",
            "Epoch 124/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6089 - accuracy: 0.6640 - val_loss: 0.6055 - val_accuracy: 0.6720\n",
            "Epoch 125/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.6600 - val_loss: 0.6052 - val_accuracy: 0.6731\n",
            "Epoch 126/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.6701 - val_loss: 0.6050 - val_accuracy: 0.6727\n",
            "Epoch 127/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6043 - accuracy: 0.6634 - val_loss: 0.6047 - val_accuracy: 0.6738\n",
            "Epoch 128/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.6661 - val_loss: 0.6045 - val_accuracy: 0.6738\n",
            "Epoch 129/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6642 - val_loss: 0.6041 - val_accuracy: 0.6731\n",
            "Epoch 130/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.6656 - val_loss: 0.6039 - val_accuracy: 0.6752\n",
            "Epoch 131/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6652 - val_loss: 0.6038 - val_accuracy: 0.6755\n",
            "Epoch 132/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.6695 - val_loss: 0.6034 - val_accuracy: 0.6731\n",
            "Epoch 133/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6647 - val_loss: 0.6032 - val_accuracy: 0.6748\n",
            "Epoch 134/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6083 - accuracy: 0.6569 - val_loss: 0.6034 - val_accuracy: 0.6731\n",
            "Epoch 135/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6010 - accuracy: 0.6695 - val_loss: 0.6027 - val_accuracy: 0.6752\n",
            "Epoch 136/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6076 - accuracy: 0.6584 - val_loss: 0.6027 - val_accuracy: 0.6763\n",
            "Epoch 137/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6065 - accuracy: 0.6614 - val_loss: 0.6022 - val_accuracy: 0.6759\n",
            "Epoch 138/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.6687 - val_loss: 0.6021 - val_accuracy: 0.6763\n",
            "Epoch 139/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6632 - val_loss: 0.6023 - val_accuracy: 0.6738\n",
            "Epoch 140/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6689 - val_loss: 0.6016 - val_accuracy: 0.6766\n",
            "Epoch 141/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6090 - accuracy: 0.6602 - val_loss: 0.6014 - val_accuracy: 0.6755\n",
            "Epoch 142/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6606 - val_loss: 0.6012 - val_accuracy: 0.6770\n",
            "Epoch 143/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6039 - accuracy: 0.6630 - val_loss: 0.6010 - val_accuracy: 0.6766\n",
            "Epoch 144/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.6704 - val_loss: 0.6009 - val_accuracy: 0.6713\n",
            "Epoch 145/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.6688 - val_loss: 0.6017 - val_accuracy: 0.6748\n",
            "Epoch 146/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6060 - accuracy: 0.6672 - val_loss: 0.6004 - val_accuracy: 0.6763\n",
            "Epoch 147/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.6691 - val_loss: 0.6003 - val_accuracy: 0.6745\n",
            "Epoch 148/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.6740 - val_loss: 0.6003 - val_accuracy: 0.6731\n",
            "Epoch 149/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6687 - val_loss: 0.6000 - val_accuracy: 0.6770\n",
            "Epoch 150/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6719 - val_loss: 0.6003 - val_accuracy: 0.6770\n",
            "Epoch 151/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6714 - val_loss: 0.5995 - val_accuracy: 0.6773\n",
            "Epoch 152/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6674 - val_loss: 0.5994 - val_accuracy: 0.6777\n",
            "Epoch 153/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.6651 - val_loss: 0.5992 - val_accuracy: 0.6770\n",
            "Epoch 154/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.6660 - val_loss: 0.5991 - val_accuracy: 0.6763\n",
            "Epoch 155/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.6607 - val_loss: 0.5992 - val_accuracy: 0.6723\n",
            "Epoch 156/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6739 - val_loss: 0.5987 - val_accuracy: 0.6770\n",
            "Epoch 157/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6022 - accuracy: 0.6680 - val_loss: 0.5986 - val_accuracy: 0.6784\n",
            "Epoch 158/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.6675 - val_loss: 0.5985 - val_accuracy: 0.6763\n",
            "Epoch 159/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6051 - accuracy: 0.6640 - val_loss: 0.5984 - val_accuracy: 0.6787\n",
            "Epoch 160/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.6649 - val_loss: 0.5981 - val_accuracy: 0.6770\n",
            "Epoch 161/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6730 - val_loss: 0.5981 - val_accuracy: 0.6745\n",
            "Epoch 162/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.6707 - val_loss: 0.5979 - val_accuracy: 0.6763\n",
            "Epoch 163/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6741 - val_loss: 0.5990 - val_accuracy: 0.6752\n",
            "Epoch 164/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6695 - val_loss: 0.5976 - val_accuracy: 0.6784\n",
            "Epoch 165/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.6735 - val_loss: 0.5976 - val_accuracy: 0.6766\n",
            "Epoch 166/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6694 - val_loss: 0.5976 - val_accuracy: 0.6770\n",
            "Epoch 167/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6045 - accuracy: 0.6664 - val_loss: 0.5973 - val_accuracy: 0.6748\n",
            "Epoch 168/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.6677 - val_loss: 0.5971 - val_accuracy: 0.6759\n",
            "Epoch 169/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6727 - val_loss: 0.5970 - val_accuracy: 0.6777\n",
            "Epoch 170/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.6685 - val_loss: 0.5975 - val_accuracy: 0.6759\n",
            "Epoch 171/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.6676 - val_loss: 0.5968 - val_accuracy: 0.6777\n",
            "Epoch 172/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6698 - val_loss: 0.5966 - val_accuracy: 0.6770\n",
            "Epoch 173/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6690 - val_loss: 0.5973 - val_accuracy: 0.6755\n",
            "Epoch 174/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6741 - val_loss: 0.5965 - val_accuracy: 0.6780\n",
            "Epoch 175/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.6679 - val_loss: 0.5965 - val_accuracy: 0.6766\n",
            "Epoch 176/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6721 - val_loss: 0.5967 - val_accuracy: 0.6773\n",
            "Epoch 177/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.6649 - val_loss: 0.5963 - val_accuracy: 0.6770\n",
            "Epoch 178/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.6640 - val_loss: 0.5966 - val_accuracy: 0.6812\n",
            "Epoch 179/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6721 - val_loss: 0.5959 - val_accuracy: 0.6766\n",
            "Epoch 180/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.6667 - val_loss: 0.5963 - val_accuracy: 0.6802\n",
            "Epoch 181/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6746 - val_loss: 0.5957 - val_accuracy: 0.6773\n",
            "Epoch 182/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.6652 - val_loss: 0.5956 - val_accuracy: 0.6773\n",
            "Epoch 183/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6754 - val_loss: 0.5963 - val_accuracy: 0.6819\n",
            "Epoch 184/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6695 - val_loss: 0.5955 - val_accuracy: 0.6773\n",
            "Epoch 185/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6723 - val_loss: 0.5955 - val_accuracy: 0.6784\n",
            "Epoch 186/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6779 - val_loss: 0.5962 - val_accuracy: 0.6791\n",
            "Epoch 187/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6740 - val_loss: 0.5953 - val_accuracy: 0.6784\n",
            "Epoch 188/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6767 - val_loss: 0.5951 - val_accuracy: 0.6784\n",
            "Epoch 189/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6709 - val_loss: 0.5951 - val_accuracy: 0.6791\n",
            "Epoch 190/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.6690 - val_loss: 0.5949 - val_accuracy: 0.6784\n",
            "Epoch 191/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.6655 - val_loss: 0.5952 - val_accuracy: 0.6766\n",
            "Epoch 192/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6709 - val_loss: 0.5951 - val_accuracy: 0.6816\n",
            "Epoch 193/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.6728 - val_loss: 0.5949 - val_accuracy: 0.6784\n",
            "Epoch 194/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.6726 - val_loss: 0.5963 - val_accuracy: 0.6773\n",
            "Epoch 195/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6728 - val_loss: 0.5947 - val_accuracy: 0.6777\n",
            "Epoch 196/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.6696 - val_loss: 0.5944 - val_accuracy: 0.6809\n",
            "Epoch 197/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6766 - val_loss: 0.5946 - val_accuracy: 0.6791\n",
            "Epoch 198/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6684 - val_loss: 0.5945 - val_accuracy: 0.6794\n",
            "Epoch 199/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6818 - val_loss: 0.5943 - val_accuracy: 0.6787\n",
            "Epoch 200/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6017 - accuracy: 0.6648 - val_loss: 0.5942 - val_accuracy: 0.6787\n",
            "Epoch 201/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6774 - val_loss: 0.5940 - val_accuracy: 0.6809\n",
            "Epoch 202/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6699 - val_loss: 0.5941 - val_accuracy: 0.6791\n",
            "Epoch 203/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6726 - val_loss: 0.5940 - val_accuracy: 0.6784\n",
            "Epoch 204/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6742 - val_loss: 0.5938 - val_accuracy: 0.6794\n",
            "Epoch 205/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6773 - val_loss: 0.5937 - val_accuracy: 0.6816\n",
            "Epoch 206/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6808 - val_loss: 0.5941 - val_accuracy: 0.6777\n",
            "Epoch 207/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6680 - val_loss: 0.5940 - val_accuracy: 0.6784\n",
            "Epoch 208/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6782 - val_loss: 0.5941 - val_accuracy: 0.6780\n",
            "Epoch 209/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.6732 - val_loss: 0.5938 - val_accuracy: 0.6780\n",
            "Epoch 210/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6780 - val_loss: 0.5934 - val_accuracy: 0.6826\n",
            "Epoch 211/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.6767 - val_loss: 0.5934 - val_accuracy: 0.6805\n",
            "Epoch 212/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6764 - val_loss: 0.5933 - val_accuracy: 0.6809\n",
            "Epoch 213/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6749 - val_loss: 0.5933 - val_accuracy: 0.6787\n",
            "Epoch 214/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.6698 - val_loss: 0.5931 - val_accuracy: 0.6823\n",
            "Epoch 215/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6718 - val_loss: 0.5931 - val_accuracy: 0.6819\n",
            "Epoch 216/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6722 - val_loss: 0.5931 - val_accuracy: 0.6802\n",
            "Epoch 217/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6773 - val_loss: 0.5935 - val_accuracy: 0.6791\n",
            "Epoch 218/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6777 - val_loss: 0.5929 - val_accuracy: 0.6809\n",
            "Epoch 219/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6725 - val_loss: 0.5932 - val_accuracy: 0.6802\n",
            "Epoch 220/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6763 - val_loss: 0.5938 - val_accuracy: 0.6841\n",
            "Epoch 221/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6684 - val_loss: 0.5932 - val_accuracy: 0.6787\n",
            "Epoch 222/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6702 - val_loss: 0.5927 - val_accuracy: 0.6834\n",
            "Epoch 223/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6704 - val_loss: 0.5927 - val_accuracy: 0.6805\n",
            "Epoch 224/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6813 - val_loss: 0.5926 - val_accuracy: 0.6823\n",
            "Epoch 225/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6797 - val_loss: 0.5928 - val_accuracy: 0.6809\n",
            "Epoch 226/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6782 - val_loss: 0.5928 - val_accuracy: 0.6809\n",
            "Epoch 227/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.6701 - val_loss: 0.5926 - val_accuracy: 0.6798\n",
            "Epoch 228/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6738 - val_loss: 0.5924 - val_accuracy: 0.6826\n",
            "Epoch 229/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6786 - val_loss: 0.5923 - val_accuracy: 0.6805\n",
            "Epoch 230/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6794 - val_loss: 0.5923 - val_accuracy: 0.6805\n",
            "Epoch 231/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6824 - val_loss: 0.5929 - val_accuracy: 0.6819\n",
            "Epoch 232/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6728 - val_loss: 0.5925 - val_accuracy: 0.6802\n",
            "Epoch 233/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6685 - val_loss: 0.5921 - val_accuracy: 0.6826\n",
            "Epoch 234/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6731 - val_loss: 0.5921 - val_accuracy: 0.6823\n",
            "Epoch 235/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.6733 - val_loss: 0.5921 - val_accuracy: 0.6802\n",
            "Epoch 236/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6762 - val_loss: 0.5924 - val_accuracy: 0.6812\n",
            "Epoch 237/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6722 - val_loss: 0.5919 - val_accuracy: 0.6816\n",
            "Epoch 238/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6754 - val_loss: 0.5919 - val_accuracy: 0.6805\n",
            "Epoch 239/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6720 - val_loss: 0.5919 - val_accuracy: 0.6834\n",
            "Epoch 240/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6732 - val_loss: 0.5918 - val_accuracy: 0.6837\n",
            "Epoch 241/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6714 - val_loss: 0.5918 - val_accuracy: 0.6830\n",
            "Epoch 242/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.6774 - val_loss: 0.5923 - val_accuracy: 0.6823\n",
            "Epoch 243/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6729 - val_loss: 0.5917 - val_accuracy: 0.6823\n",
            "Epoch 244/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6730 - val_loss: 0.5918 - val_accuracy: 0.6816\n",
            "Epoch 245/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6757 - val_loss: 0.5916 - val_accuracy: 0.6830\n",
            "Epoch 246/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6758 - val_loss: 0.5915 - val_accuracy: 0.6826\n",
            "Epoch 247/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6704 - val_loss: 0.5917 - val_accuracy: 0.6826\n",
            "Epoch 248/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6664 - val_loss: 0.5920 - val_accuracy: 0.6837\n",
            "Epoch 249/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6793 - val_loss: 0.5914 - val_accuracy: 0.6841\n",
            "Epoch 250/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6748 - val_loss: 0.5915 - val_accuracy: 0.6816\n",
            "Epoch 251/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6793 - val_loss: 0.5915 - val_accuracy: 0.6826\n",
            "Epoch 252/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6689 - val_loss: 0.5913 - val_accuracy: 0.6812\n",
            "Epoch 253/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6741 - val_loss: 0.5913 - val_accuracy: 0.6809\n",
            "Epoch 254/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6718 - val_loss: 0.5912 - val_accuracy: 0.6841\n",
            "Epoch 255/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.6765 - val_loss: 0.5911 - val_accuracy: 0.6819\n",
            "Epoch 256/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6762 - val_loss: 0.5911 - val_accuracy: 0.6841\n",
            "Epoch 257/1000\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6738 - val_loss: 0.5920 - val_accuracy: 0.6819\n",
            "Epoch 258/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6757 - val_loss: 0.5910 - val_accuracy: 0.6823\n",
            "Epoch 259/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.6749 - val_loss: 0.5910 - val_accuracy: 0.6816\n",
            "Epoch 260/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6711 - val_loss: 0.5913 - val_accuracy: 0.6826\n",
            "Epoch 261/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6758 - val_loss: 0.5908 - val_accuracy: 0.6823\n",
            "Epoch 262/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6753 - val_loss: 0.5908 - val_accuracy: 0.6837\n",
            "Epoch 263/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6713 - val_loss: 0.5910 - val_accuracy: 0.6826\n",
            "Epoch 264/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6686 - val_loss: 0.5908 - val_accuracy: 0.6830\n",
            "Epoch 265/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6739 - val_loss: 0.5907 - val_accuracy: 0.6823\n",
            "Epoch 266/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6739 - val_loss: 0.5907 - val_accuracy: 0.6816\n",
            "Epoch 267/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6711 - val_loss: 0.5905 - val_accuracy: 0.6812\n",
            "Epoch 268/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6718 - val_loss: 0.5908 - val_accuracy: 0.6837\n",
            "Epoch 269/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6793 - val_loss: 0.5905 - val_accuracy: 0.6837\n",
            "Epoch 270/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6798 - val_loss: 0.5905 - val_accuracy: 0.6851\n",
            "Epoch 271/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6746 - val_loss: 0.5906 - val_accuracy: 0.6837\n",
            "Epoch 272/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6809 - val_loss: 0.5904 - val_accuracy: 0.6823\n",
            "Epoch 273/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6717 - val_loss: 0.5903 - val_accuracy: 0.6816\n",
            "Epoch 274/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6689 - val_loss: 0.5902 - val_accuracy: 0.6830\n",
            "Epoch 275/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6801 - val_loss: 0.5902 - val_accuracy: 0.6819\n",
            "Epoch 276/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6763 - val_loss: 0.5903 - val_accuracy: 0.6826\n",
            "Epoch 277/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6774 - val_loss: 0.5906 - val_accuracy: 0.6837\n",
            "Epoch 278/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6766 - val_loss: 0.5901 - val_accuracy: 0.6844\n",
            "Epoch 279/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6785 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
            "Epoch 280/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6020 - accuracy: 0.6704 - val_loss: 0.5909 - val_accuracy: 0.6834\n",
            "Epoch 281/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6801 - val_loss: 0.5904 - val_accuracy: 0.6837\n",
            "Epoch 282/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6789 - val_loss: 0.5900 - val_accuracy: 0.6844\n",
            "Epoch 283/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6780 - val_loss: 0.5899 - val_accuracy: 0.6826\n",
            "Epoch 284/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6804 - val_loss: 0.5907 - val_accuracy: 0.6848\n",
            "Epoch 285/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6748 - val_loss: 0.5900 - val_accuracy: 0.6848\n",
            "Epoch 286/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6749 - val_loss: 0.5898 - val_accuracy: 0.6837\n",
            "Epoch 287/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6726 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
            "Epoch 288/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.6752 - val_loss: 0.5900 - val_accuracy: 0.6837\n",
            "Epoch 289/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6706 - val_loss: 0.5897 - val_accuracy: 0.6834\n",
            "Epoch 290/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6709 - val_loss: 0.5904 - val_accuracy: 0.6855\n",
            "Epoch 291/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6737 - val_loss: 0.5903 - val_accuracy: 0.6855\n",
            "Epoch 292/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6711 - val_loss: 0.5898 - val_accuracy: 0.6851\n",
            "Epoch 293/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6701 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
            "Epoch 294/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6778 - val_loss: 0.5904 - val_accuracy: 0.6851\n",
            "Epoch 295/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6740 - val_loss: 0.5896 - val_accuracy: 0.6826\n",
            "Epoch 296/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.6753 - val_loss: 0.5900 - val_accuracy: 0.6851\n",
            "Epoch 297/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6756 - val_loss: 0.5900 - val_accuracy: 0.6851\n",
            "Epoch 298/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.6783 - val_loss: 0.5894 - val_accuracy: 0.6837\n",
            "Epoch 299/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6725 - val_loss: 0.5898 - val_accuracy: 0.6841\n",
            "Epoch 300/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6720 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
            "Epoch 301/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6747 - val_loss: 0.5893 - val_accuracy: 0.6830\n",
            "Epoch 302/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6755 - val_loss: 0.5893 - val_accuracy: 0.6837\n",
            "Epoch 303/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6778 - val_loss: 0.5898 - val_accuracy: 0.6865\n",
            "Epoch 304/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6695 - val_loss: 0.5892 - val_accuracy: 0.6837\n",
            "Epoch 305/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6809 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
            "Epoch 306/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6695 - val_loss: 0.5894 - val_accuracy: 0.6851\n",
            "Epoch 307/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6752 - val_loss: 0.5892 - val_accuracy: 0.6837\n",
            "Epoch 308/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6726 - val_loss: 0.5892 - val_accuracy: 0.6855\n",
            "Epoch 309/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6717 - val_loss: 0.5897 - val_accuracy: 0.6858\n",
            "Epoch 310/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6772 - val_loss: 0.5891 - val_accuracy: 0.6837\n",
            "Epoch 311/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6789 - val_loss: 0.5900 - val_accuracy: 0.6858\n",
            "Epoch 312/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6771 - val_loss: 0.5898 - val_accuracy: 0.6865\n",
            "Epoch 313/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6749 - val_loss: 0.5890 - val_accuracy: 0.6812\n",
            "Epoch 314/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6780 - val_loss: 0.5890 - val_accuracy: 0.6841\n",
            "Epoch 315/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6783 - val_loss: 0.5891 - val_accuracy: 0.6844\n",
            "Epoch 316/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.6749 - val_loss: 0.5893 - val_accuracy: 0.6855\n",
            "Epoch 317/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6755 - val_loss: 0.5889 - val_accuracy: 0.6848\n",
            "Epoch 318/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.6793 - val_loss: 0.5891 - val_accuracy: 0.6841\n",
            "Epoch 319/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6761 - val_loss: 0.5889 - val_accuracy: 0.6865\n",
            "Epoch 320/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6758 - val_loss: 0.5888 - val_accuracy: 0.6830\n",
            "Epoch 321/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6737 - val_loss: 0.5891 - val_accuracy: 0.6855\n",
            "Epoch 322/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6761 - val_loss: 0.5889 - val_accuracy: 0.6830\n",
            "Epoch 323/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6758 - val_loss: 0.5887 - val_accuracy: 0.6837\n",
            "Epoch 324/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.6845 - val_loss: 0.5890 - val_accuracy: 0.6862\n",
            "Epoch 325/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6736 - val_loss: 0.5887 - val_accuracy: 0.6844\n",
            "Epoch 326/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5963 - accuracy: 0.6750 - val_loss: 0.5890 - val_accuracy: 0.6862\n",
            "Epoch 327/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6730 - val_loss: 0.5887 - val_accuracy: 0.6830\n",
            "Epoch 328/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.6781 - val_loss: 0.5901 - val_accuracy: 0.6876\n",
            "Epoch 329/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6832 - val_loss: 0.5888 - val_accuracy: 0.6837\n",
            "Epoch 330/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6736 - val_loss: 0.5886 - val_accuracy: 0.6848\n",
            "Epoch 331/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.6729 - val_loss: 0.5886 - val_accuracy: 0.6834\n",
            "Epoch 332/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6811 - val_loss: 0.5886 - val_accuracy: 0.6834\n",
            "Epoch 333/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6725 - val_loss: 0.5885 - val_accuracy: 0.6841\n",
            "Epoch 334/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6745 - val_loss: 0.5887 - val_accuracy: 0.6876\n",
            "Epoch 335/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6760 - val_loss: 0.5884 - val_accuracy: 0.6830\n",
            "Epoch 336/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6722 - val_loss: 0.5885 - val_accuracy: 0.6855\n",
            "Epoch 337/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6747 - val_loss: 0.5884 - val_accuracy: 0.6858\n",
            "Epoch 338/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6719 - val_loss: 0.5884 - val_accuracy: 0.6851\n",
            "Epoch 339/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6740 - val_loss: 0.5883 - val_accuracy: 0.6837\n",
            "Epoch 340/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.6774 - val_loss: 0.5889 - val_accuracy: 0.6862\n",
            "Epoch 341/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6735 - val_loss: 0.5886 - val_accuracy: 0.6873\n",
            "Epoch 342/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5890 - accuracy: 0.6808 - val_loss: 0.5883 - val_accuracy: 0.6848\n",
            "Epoch 343/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6795 - val_loss: 0.5883 - val_accuracy: 0.6841\n",
            "Epoch 344/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6758 - val_loss: 0.5882 - val_accuracy: 0.6855\n",
            "Epoch 345/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5850 - accuracy: 0.6817 - val_loss: 0.5883 - val_accuracy: 0.6858\n",
            "Epoch 346/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6711 - val_loss: 0.5883 - val_accuracy: 0.6834\n",
            "Epoch 347/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6794 - val_loss: 0.5902 - val_accuracy: 0.6841\n",
            "Epoch 348/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6712 - val_loss: 0.5882 - val_accuracy: 0.6848\n",
            "Epoch 349/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6789 - val_loss: 0.5882 - val_accuracy: 0.6844\n",
            "Epoch 350/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6724 - val_loss: 0.5881 - val_accuracy: 0.6858\n",
            "Epoch 351/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6824 - val_loss: 0.5883 - val_accuracy: 0.6865\n",
            "Epoch 352/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6747 - val_loss: 0.5881 - val_accuracy: 0.6837\n",
            "Epoch 353/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6760 - val_loss: 0.5889 - val_accuracy: 0.6865\n",
            "Epoch 354/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6742 - val_loss: 0.5893 - val_accuracy: 0.6876\n",
            "Epoch 355/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6779 - val_loss: 0.5894 - val_accuracy: 0.6858\n",
            "Epoch 356/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6743 - val_loss: 0.5879 - val_accuracy: 0.6855\n",
            "Epoch 357/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6770 - val_loss: 0.5885 - val_accuracy: 0.6865\n",
            "Epoch 358/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6745 - val_loss: 0.5880 - val_accuracy: 0.6848\n",
            "Epoch 359/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6822 - val_loss: 0.5882 - val_accuracy: 0.6894\n",
            "Epoch 360/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6779 - val_loss: 0.5879 - val_accuracy: 0.6851\n",
            "Epoch 361/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6799 - val_loss: 0.5881 - val_accuracy: 0.6858\n",
            "Epoch 362/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6742 - val_loss: 0.5881 - val_accuracy: 0.6855\n",
            "Epoch 363/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6781 - val_loss: 0.5881 - val_accuracy: 0.6855\n",
            "Epoch 364/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6751 - val_loss: 0.5880 - val_accuracy: 0.6865\n",
            "Epoch 365/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6769 - val_loss: 0.5882 - val_accuracy: 0.6855\n",
            "Epoch 366/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6699 - val_loss: 0.5884 - val_accuracy: 0.6862\n",
            "Epoch 367/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6794 - val_loss: 0.5877 - val_accuracy: 0.6855\n",
            "Epoch 368/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6843 - val_loss: 0.5878 - val_accuracy: 0.6844\n",
            "Epoch 369/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6762 - val_loss: 0.5885 - val_accuracy: 0.6865\n",
            "Epoch 370/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6825 - val_loss: 0.5878 - val_accuracy: 0.6862\n",
            "Epoch 371/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6724 - val_loss: 0.5877 - val_accuracy: 0.6858\n",
            "Epoch 372/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6774 - val_loss: 0.5880 - val_accuracy: 0.6887\n",
            "Epoch 373/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.6670 - val_loss: 0.5883 - val_accuracy: 0.6862\n",
            "Epoch 374/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6746 - val_loss: 0.5876 - val_accuracy: 0.6858\n",
            "Epoch 375/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.6703 - val_loss: 0.5877 - val_accuracy: 0.6844\n",
            "Epoch 376/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6750 - val_loss: 0.5876 - val_accuracy: 0.6848\n",
            "Epoch 377/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6797 - val_loss: 0.5880 - val_accuracy: 0.6855\n",
            "Epoch 378/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6754 - val_loss: 0.5883 - val_accuracy: 0.6869\n",
            "Epoch 379/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6721 - val_loss: 0.5876 - val_accuracy: 0.6837\n",
            "Epoch 380/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6753 - val_loss: 0.5878 - val_accuracy: 0.6851\n",
            "Epoch 381/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6788 - val_loss: 0.5875 - val_accuracy: 0.6844\n",
            "Epoch 382/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6757 - val_loss: 0.5876 - val_accuracy: 0.6837\n",
            "Epoch 383/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6807 - val_loss: 0.5875 - val_accuracy: 0.6855\n",
            "Epoch 384/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6737 - val_loss: 0.5876 - val_accuracy: 0.6844\n",
            "Epoch 385/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6810 - val_loss: 0.5874 - val_accuracy: 0.6865\n",
            "Epoch 386/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6684 - val_loss: 0.5881 - val_accuracy: 0.6890\n",
            "Epoch 387/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6791 - val_loss: 0.5881 - val_accuracy: 0.6873\n",
            "Epoch 388/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6810 - val_loss: 0.5874 - val_accuracy: 0.6848\n",
            "Epoch 389/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6702 - val_loss: 0.5876 - val_accuracy: 0.6851\n",
            "Epoch 390/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6771 - val_loss: 0.5874 - val_accuracy: 0.6855\n",
            "Epoch 391/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6751 - val_loss: 0.5906 - val_accuracy: 0.6883\n",
            "Epoch 392/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6765 - val_loss: 0.5874 - val_accuracy: 0.6841\n",
            "Epoch 393/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6785 - val_loss: 0.5877 - val_accuracy: 0.6887\n",
            "Epoch 394/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6819 - val_loss: 0.5873 - val_accuracy: 0.6851\n",
            "Epoch 395/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6761 - val_loss: 0.5872 - val_accuracy: 0.6869\n",
            "Epoch 396/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6727 - val_loss: 0.5874 - val_accuracy: 0.6880\n",
            "Epoch 397/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6719 - val_loss: 0.5872 - val_accuracy: 0.6869\n",
            "Epoch 398/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6748 - val_loss: 0.5872 - val_accuracy: 0.6855\n",
            "Epoch 399/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6723 - val_loss: 0.5873 - val_accuracy: 0.6876\n",
            "Epoch 400/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6803 - val_loss: 0.5872 - val_accuracy: 0.6858\n",
            "Epoch 401/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.6824 - val_loss: 0.5873 - val_accuracy: 0.6880\n",
            "Epoch 402/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6806 - val_loss: 0.5871 - val_accuracy: 0.6873\n",
            "Epoch 403/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6795 - val_loss: 0.5871 - val_accuracy: 0.6869\n",
            "Epoch 404/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6796 - val_loss: 0.5878 - val_accuracy: 0.6848\n",
            "Epoch 405/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6752 - val_loss: 0.5872 - val_accuracy: 0.6844\n",
            "Epoch 406/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6753 - val_loss: 0.5873 - val_accuracy: 0.6894\n",
            "Epoch 407/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6819 - val_loss: 0.5871 - val_accuracy: 0.6855\n",
            "Epoch 408/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6767 - val_loss: 0.5871 - val_accuracy: 0.6862\n",
            "Epoch 409/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6700 - val_loss: 0.5872 - val_accuracy: 0.6887\n",
            "Epoch 410/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.6743 - val_loss: 0.5870 - val_accuracy: 0.6858\n",
            "Epoch 411/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.6814 - val_loss: 0.5871 - val_accuracy: 0.6844\n",
            "Epoch 412/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6734 - val_loss: 0.5870 - val_accuracy: 0.6848\n",
            "Epoch 413/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6720 - val_loss: 0.5871 - val_accuracy: 0.6844\n",
            "Epoch 414/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6729 - val_loss: 0.5871 - val_accuracy: 0.6869\n",
            "Epoch 415/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6776 - val_loss: 0.5876 - val_accuracy: 0.6873\n",
            "Epoch 416/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6772 - val_loss: 0.5873 - val_accuracy: 0.6858\n",
            "Epoch 417/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6769 - val_loss: 0.5873 - val_accuracy: 0.6858\n",
            "Epoch 418/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6729 - val_loss: 0.5871 - val_accuracy: 0.6844\n",
            "Epoch 419/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6764 - val_loss: 0.5872 - val_accuracy: 0.6901\n",
            "Epoch 420/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.6702 - val_loss: 0.5870 - val_accuracy: 0.6855\n",
            "Epoch 421/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6739 - val_loss: 0.5871 - val_accuracy: 0.6858\n",
            "Epoch 422/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6668 - val_loss: 0.5868 - val_accuracy: 0.6873\n",
            "Epoch 423/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6795 - val_loss: 0.5870 - val_accuracy: 0.6873\n",
            "Epoch 424/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6702 - val_loss: 0.5868 - val_accuracy: 0.6858\n",
            "Epoch 425/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6732 - val_loss: 0.5870 - val_accuracy: 0.6848\n",
            "Epoch 426/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6753 - val_loss: 0.5872 - val_accuracy: 0.6855\n",
            "Epoch 427/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6717 - val_loss: 0.5873 - val_accuracy: 0.6876\n",
            "Epoch 428/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6739 - val_loss: 0.5871 - val_accuracy: 0.6905\n",
            "Epoch 429/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6778 - val_loss: 0.5868 - val_accuracy: 0.6848\n",
            "Epoch 430/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.6720 - val_loss: 0.5867 - val_accuracy: 0.6873\n",
            "Epoch 431/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5854 - accuracy: 0.6843 - val_loss: 0.5868 - val_accuracy: 0.6862\n",
            "Epoch 432/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6775 - val_loss: 0.5868 - val_accuracy: 0.6851\n",
            "Epoch 433/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6750 - val_loss: 0.5868 - val_accuracy: 0.6848\n",
            "Epoch 434/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6764 - val_loss: 0.5868 - val_accuracy: 0.6851\n",
            "Epoch 435/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6722 - val_loss: 0.5875 - val_accuracy: 0.6880\n",
            "Epoch 436/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6748 - val_loss: 0.5871 - val_accuracy: 0.6865\n",
            "Epoch 437/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6714 - val_loss: 0.5871 - val_accuracy: 0.6876\n",
            "Epoch 438/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5897 - accuracy: 0.6811 - val_loss: 0.5866 - val_accuracy: 0.6865\n",
            "Epoch 439/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6752 - val_loss: 0.5868 - val_accuracy: 0.6876\n",
            "Epoch 440/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6775 - val_loss: 0.5868 - val_accuracy: 0.6869\n",
            "Epoch 441/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6711 - val_loss: 0.5871 - val_accuracy: 0.6873\n",
            "Epoch 442/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6813 - val_loss: 0.5868 - val_accuracy: 0.6883\n",
            "Epoch 443/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6706 - val_loss: 0.5873 - val_accuracy: 0.6880\n",
            "Epoch 444/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6719 - val_loss: 0.5866 - val_accuracy: 0.6865\n",
            "Epoch 445/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6791 - val_loss: 0.5868 - val_accuracy: 0.6858\n",
            "Epoch 446/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6705 - val_loss: 0.5865 - val_accuracy: 0.6869\n",
            "Epoch 447/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.6722 - val_loss: 0.5866 - val_accuracy: 0.6855\n",
            "Epoch 448/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6722 - val_loss: 0.5869 - val_accuracy: 0.6858\n",
            "Epoch 449/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6783 - val_loss: 0.5865 - val_accuracy: 0.6869\n",
            "Epoch 450/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6798 - val_loss: 0.5865 - val_accuracy: 0.6862\n",
            "Epoch 451/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6770 - val_loss: 0.5870 - val_accuracy: 0.6855\n",
            "Epoch 452/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6794 - val_loss: 0.5865 - val_accuracy: 0.6862\n",
            "Epoch 453/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6783 - val_loss: 0.5867 - val_accuracy: 0.6897\n",
            "Epoch 454/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6712 - val_loss: 0.5865 - val_accuracy: 0.6873\n",
            "Epoch 455/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6740 - val_loss: 0.5869 - val_accuracy: 0.6851\n",
            "Epoch 456/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6710 - val_loss: 0.5865 - val_accuracy: 0.6851\n",
            "Epoch 457/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6746 - val_loss: 0.5866 - val_accuracy: 0.6862\n",
            "Epoch 458/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6727 - val_loss: 0.5864 - val_accuracy: 0.6855\n",
            "Epoch 459/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6735 - val_loss: 0.5864 - val_accuracy: 0.6865\n",
            "Epoch 460/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6818 - val_loss: 0.5866 - val_accuracy: 0.6855\n",
            "Epoch 461/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6746 - val_loss: 0.5867 - val_accuracy: 0.6894\n",
            "Epoch 462/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6756 - val_loss: 0.5867 - val_accuracy: 0.6897\n",
            "Epoch 463/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6735 - val_loss: 0.5863 - val_accuracy: 0.6858\n",
            "Epoch 464/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6768 - val_loss: 0.5863 - val_accuracy: 0.6844\n",
            "Epoch 465/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6758 - val_loss: 0.5865 - val_accuracy: 0.6855\n",
            "Epoch 466/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6742 - val_loss: 0.5875 - val_accuracy: 0.6858\n",
            "Epoch 467/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6744 - val_loss: 0.5864 - val_accuracy: 0.6876\n",
            "Epoch 468/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6751 - val_loss: 0.5864 - val_accuracy: 0.6876\n",
            "Epoch 469/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6722 - val_loss: 0.5866 - val_accuracy: 0.6858\n",
            "Epoch 470/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6690 - val_loss: 0.5863 - val_accuracy: 0.6855\n",
            "Epoch 471/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6756 - val_loss: 0.5864 - val_accuracy: 0.6851\n",
            "Epoch 472/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6765 - val_loss: 0.5866 - val_accuracy: 0.6865\n",
            "Epoch 473/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5836 - accuracy: 0.6819 - val_loss: 0.5863 - val_accuracy: 0.6873\n",
            "Epoch 474/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6706 - val_loss: 0.5867 - val_accuracy: 0.6890\n",
            "Epoch 475/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6768 - val_loss: 0.5862 - val_accuracy: 0.6855\n",
            "Epoch 476/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6729 - val_loss: 0.5863 - val_accuracy: 0.6883\n",
            "Epoch 477/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6768 - val_loss: 0.5873 - val_accuracy: 0.6862\n",
            "Epoch 478/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5843 - accuracy: 0.6841 - val_loss: 0.5863 - val_accuracy: 0.6880\n",
            "Epoch 479/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6778 - val_loss: 0.5862 - val_accuracy: 0.6851\n",
            "Epoch 480/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6760 - val_loss: 0.5863 - val_accuracy: 0.6883\n",
            "Epoch 481/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6710 - val_loss: 0.5862 - val_accuracy: 0.6883\n",
            "Epoch 482/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5890 - accuracy: 0.6797 - val_loss: 0.5869 - val_accuracy: 0.6873\n",
            "Epoch 483/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6769 - val_loss: 0.5863 - val_accuracy: 0.6851\n",
            "Epoch 484/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6708 - val_loss: 0.5865 - val_accuracy: 0.6887\n",
            "Epoch 485/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6749 - val_loss: 0.5863 - val_accuracy: 0.6855\n",
            "Epoch 486/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6782 - val_loss: 0.5862 - val_accuracy: 0.6876\n",
            "Epoch 487/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6794 - val_loss: 0.5862 - val_accuracy: 0.6851\n",
            "Epoch 488/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6796 - val_loss: 0.5864 - val_accuracy: 0.6894\n",
            "Epoch 489/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6781 - val_loss: 0.5868 - val_accuracy: 0.6848\n",
            "Epoch 490/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6800 - val_loss: 0.5861 - val_accuracy: 0.6855\n",
            "Epoch 491/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6747 - val_loss: 0.5861 - val_accuracy: 0.6862\n",
            "Epoch 492/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.6700 - val_loss: 0.5862 - val_accuracy: 0.6855\n",
            "Epoch 493/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6775 - val_loss: 0.5862 - val_accuracy: 0.6897\n",
            "Epoch 494/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6777 - val_loss: 0.5860 - val_accuracy: 0.6848\n",
            "Epoch 495/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6790 - val_loss: 0.5863 - val_accuracy: 0.6890\n",
            "Epoch 496/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6790 - val_loss: 0.5867 - val_accuracy: 0.6851\n",
            "Epoch 497/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.6817 - val_loss: 0.5860 - val_accuracy: 0.6848\n",
            "Epoch 498/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6747 - val_loss: 0.5860 - val_accuracy: 0.6858\n",
            "Epoch 499/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6740 - val_loss: 0.5866 - val_accuracy: 0.6890\n",
            "Epoch 500/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6729 - val_loss: 0.5866 - val_accuracy: 0.6883\n",
            "Epoch 501/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6770 - val_loss: 0.5862 - val_accuracy: 0.6865\n",
            "Epoch 502/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6790 - val_loss: 0.5865 - val_accuracy: 0.6844\n",
            "Epoch 503/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6749 - val_loss: 0.5862 - val_accuracy: 0.6873\n",
            "Epoch 504/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6774 - val_loss: 0.5860 - val_accuracy: 0.6858\n",
            "Epoch 505/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6803 - val_loss: 0.5861 - val_accuracy: 0.6862\n",
            "Epoch 506/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6849 - val_loss: 0.5860 - val_accuracy: 0.6858\n",
            "Epoch 507/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6715 - val_loss: 0.5860 - val_accuracy: 0.6862\n",
            "Epoch 508/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6785 - val_loss: 0.5860 - val_accuracy: 0.6869\n",
            "Epoch 509/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6809 - val_loss: 0.5860 - val_accuracy: 0.6855\n",
            "Epoch 510/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6762 - val_loss: 0.5861 - val_accuracy: 0.6858\n",
            "Epoch 511/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6747 - val_loss: 0.5865 - val_accuracy: 0.6905\n",
            "Epoch 512/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6815 - val_loss: 0.5859 - val_accuracy: 0.6858\n",
            "Epoch 513/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6741 - val_loss: 0.5860 - val_accuracy: 0.6865\n",
            "Epoch 514/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6800 - val_loss: 0.5859 - val_accuracy: 0.6851\n",
            "Epoch 515/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6788 - val_loss: 0.5861 - val_accuracy: 0.6890\n",
            "Epoch 516/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6671 - val_loss: 0.5859 - val_accuracy: 0.6858\n",
            "Epoch 517/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6782 - val_loss: 0.5859 - val_accuracy: 0.6851\n",
            "Epoch 518/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6755 - val_loss: 0.5859 - val_accuracy: 0.6865\n",
            "Epoch 519/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6759 - val_loss: 0.5860 - val_accuracy: 0.6865\n",
            "Epoch 520/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6770 - val_loss: 0.5861 - val_accuracy: 0.6865\n",
            "Epoch 521/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5881 - accuracy: 0.6815 - val_loss: 0.5865 - val_accuracy: 0.6887\n",
            "Epoch 522/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6667 - val_loss: 0.5866 - val_accuracy: 0.6869\n",
            "Epoch 523/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6761 - val_loss: 0.5858 - val_accuracy: 0.6844\n",
            "Epoch 524/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6727 - val_loss: 0.5866 - val_accuracy: 0.6855\n",
            "Epoch 525/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6790 - val_loss: 0.5860 - val_accuracy: 0.6873\n",
            "Epoch 526/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6806 - val_loss: 0.5861 - val_accuracy: 0.6858\n",
            "Epoch 527/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6725 - val_loss: 0.5858 - val_accuracy: 0.6844\n",
            "Epoch 528/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.6821 - val_loss: 0.5861 - val_accuracy: 0.6851\n",
            "Epoch 529/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6742 - val_loss: 0.5869 - val_accuracy: 0.6862\n",
            "Epoch 530/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6749 - val_loss: 0.5866 - val_accuracy: 0.6858\n",
            "Epoch 531/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.6738 - val_loss: 0.5865 - val_accuracy: 0.6894\n",
            "Epoch 532/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6799 - val_loss: 0.5859 - val_accuracy: 0.6894\n",
            "Epoch 533/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6766 - val_loss: 0.5859 - val_accuracy: 0.6887\n",
            "Epoch 534/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6775 - val_loss: 0.5858 - val_accuracy: 0.6855\n",
            "Epoch 535/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6799 - val_loss: 0.5859 - val_accuracy: 0.6869\n",
            "Epoch 536/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6757 - val_loss: 0.5860 - val_accuracy: 0.6901\n",
            "Epoch 537/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6762 - val_loss: 0.5862 - val_accuracy: 0.6841\n",
            "Epoch 538/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5868 - accuracy: 0.6825 - val_loss: 0.5857 - val_accuracy: 0.6876\n",
            "Epoch 539/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6756 - val_loss: 0.5857 - val_accuracy: 0.6862\n",
            "Epoch 540/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6724 - val_loss: 0.5870 - val_accuracy: 0.6855\n",
            "Epoch 541/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.6818 - val_loss: 0.5858 - val_accuracy: 0.6869\n",
            "Epoch 542/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6745 - val_loss: 0.5857 - val_accuracy: 0.6855\n",
            "Epoch 543/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6750 - val_loss: 0.5857 - val_accuracy: 0.6862\n",
            "Epoch 544/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.6810 - val_loss: 0.5859 - val_accuracy: 0.6887\n",
            "Epoch 545/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6778 - val_loss: 0.5858 - val_accuracy: 0.6873\n",
            "Epoch 546/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.6842 - val_loss: 0.5860 - val_accuracy: 0.6887\n",
            "Epoch 547/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6816 - val_loss: 0.5857 - val_accuracy: 0.6862\n",
            "Epoch 548/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6768 - val_loss: 0.5862 - val_accuracy: 0.6848\n",
            "Epoch 549/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6718 - val_loss: 0.5857 - val_accuracy: 0.6865\n",
            "Epoch 550/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.6856 - val_loss: 0.5859 - val_accuracy: 0.6897\n",
            "Epoch 551/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6702 - val_loss: 0.5856 - val_accuracy: 0.6848\n",
            "Epoch 552/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6766 - val_loss: 0.5865 - val_accuracy: 0.6873\n",
            "Epoch 553/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6728 - val_loss: 0.5859 - val_accuracy: 0.6894\n",
            "Epoch 554/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6694 - val_loss: 0.5858 - val_accuracy: 0.6869\n",
            "Epoch 555/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6768 - val_loss: 0.5863 - val_accuracy: 0.6897\n",
            "Epoch 556/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.6810 - val_loss: 0.5858 - val_accuracy: 0.6894\n",
            "Epoch 557/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6766 - val_loss: 0.5857 - val_accuracy: 0.6890\n",
            "Epoch 558/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6779 - val_loss: 0.5863 - val_accuracy: 0.6848\n",
            "Epoch 559/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6765 - val_loss: 0.5862 - val_accuracy: 0.6855\n",
            "Epoch 560/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6691 - val_loss: 0.5858 - val_accuracy: 0.6890\n",
            "Epoch 561/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6786 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 562/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6747 - val_loss: 0.5858 - val_accuracy: 0.6890\n",
            "Epoch 563/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6790 - val_loss: 0.5860 - val_accuracy: 0.6851\n",
            "Epoch 564/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.6872 - val_loss: 0.5861 - val_accuracy: 0.6897\n",
            "Epoch 565/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6710 - val_loss: 0.5857 - val_accuracy: 0.6890\n",
            "Epoch 566/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6722 - val_loss: 0.5861 - val_accuracy: 0.6855\n",
            "Epoch 567/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6816 - val_loss: 0.5861 - val_accuracy: 0.6894\n",
            "Epoch 568/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6753 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 569/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6717 - val_loss: 0.5859 - val_accuracy: 0.6897\n",
            "Epoch 570/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.6796 - val_loss: 0.5857 - val_accuracy: 0.6883\n",
            "Epoch 571/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6790 - val_loss: 0.5855 - val_accuracy: 0.6851\n",
            "Epoch 572/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6759 - val_loss: 0.5860 - val_accuracy: 0.6841\n",
            "Epoch 573/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6761 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 574/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6736 - val_loss: 0.5862 - val_accuracy: 0.6901\n",
            "Epoch 575/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6732 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 576/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6747 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 577/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6722 - val_loss: 0.5859 - val_accuracy: 0.6848\n",
            "Epoch 578/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6797 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 579/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.6798 - val_loss: 0.5856 - val_accuracy: 0.6880\n",
            "Epoch 580/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6729 - val_loss: 0.5886 - val_accuracy: 0.6873\n",
            "Epoch 581/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6746 - val_loss: 0.5884 - val_accuracy: 0.6873\n",
            "Epoch 582/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6752 - val_loss: 0.5866 - val_accuracy: 0.6869\n",
            "Epoch 583/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6738 - val_loss: 0.5856 - val_accuracy: 0.6880\n",
            "Epoch 584/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6749 - val_loss: 0.5858 - val_accuracy: 0.6897\n",
            "Epoch 585/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6752 - val_loss: 0.5857 - val_accuracy: 0.6890\n",
            "Epoch 586/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5875 - accuracy: 0.6849 - val_loss: 0.5865 - val_accuracy: 0.6887\n",
            "Epoch 587/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.6846 - val_loss: 0.5857 - val_accuracy: 0.6876\n",
            "Epoch 588/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6680 - val_loss: 0.5861 - val_accuracy: 0.6887\n",
            "Epoch 589/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5897 - accuracy: 0.6778 - val_loss: 0.5855 - val_accuracy: 0.6851\n",
            "Epoch 590/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6777 - val_loss: 0.5854 - val_accuracy: 0.6869\n",
            "Epoch 591/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6823 - val_loss: 0.5855 - val_accuracy: 0.6873\n",
            "Epoch 592/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6755 - val_loss: 0.5855 - val_accuracy: 0.6865\n",
            "Epoch 593/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6803 - val_loss: 0.5856 - val_accuracy: 0.6873\n",
            "Epoch 594/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6776 - val_loss: 0.5855 - val_accuracy: 0.6855\n",
            "Epoch 595/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6777 - val_loss: 0.5857 - val_accuracy: 0.6894\n",
            "Epoch 596/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6748 - val_loss: 0.5854 - val_accuracy: 0.6844\n",
            "Epoch 597/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6715 - val_loss: 0.5858 - val_accuracy: 0.6851\n",
            "Epoch 598/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6747 - val_loss: 0.5854 - val_accuracy: 0.6848\n",
            "Epoch 599/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6760 - val_loss: 0.5864 - val_accuracy: 0.6858\n",
            "Epoch 600/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6812 - val_loss: 0.5854 - val_accuracy: 0.6858\n",
            "Epoch 601/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6813 - val_loss: 0.5854 - val_accuracy: 0.6862\n",
            "Epoch 602/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6697 - val_loss: 0.5857 - val_accuracy: 0.6894\n",
            "Epoch 603/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6766 - val_loss: 0.5855 - val_accuracy: 0.6887\n",
            "Epoch 604/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6784 - val_loss: 0.5861 - val_accuracy: 0.6908\n",
            "Epoch 605/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6774 - val_loss: 0.5855 - val_accuracy: 0.6887\n",
            "Epoch 606/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6734 - val_loss: 0.5855 - val_accuracy: 0.6855\n",
            "Epoch 607/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.6789 - val_loss: 0.5855 - val_accuracy: 0.6851\n",
            "Epoch 608/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6802 - val_loss: 0.5855 - val_accuracy: 0.6876\n",
            "Epoch 609/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6770 - val_loss: 0.5855 - val_accuracy: 0.6873\n",
            "Epoch 610/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6736 - val_loss: 0.5854 - val_accuracy: 0.6862\n",
            "Epoch 611/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6765 - val_loss: 0.5860 - val_accuracy: 0.6862\n",
            "Epoch 612/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.6802 - val_loss: 0.5854 - val_accuracy: 0.6862\n",
            "Epoch 613/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6752 - val_loss: 0.5857 - val_accuracy: 0.6851\n",
            "Epoch 614/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6757 - val_loss: 0.5854 - val_accuracy: 0.6858\n",
            "Epoch 615/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6731 - val_loss: 0.5856 - val_accuracy: 0.6894\n",
            "Epoch 616/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6781 - val_loss: 0.5866 - val_accuracy: 0.6887\n",
            "Epoch 617/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5969 - accuracy: 0.6742 - val_loss: 0.5853 - val_accuracy: 0.6862\n",
            "Epoch 618/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6727 - val_loss: 0.5858 - val_accuracy: 0.6908\n",
            "Epoch 619/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6728 - val_loss: 0.5864 - val_accuracy: 0.6862\n",
            "Epoch 620/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6835 - val_loss: 0.5858 - val_accuracy: 0.6848\n",
            "Epoch 621/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6731 - val_loss: 0.5865 - val_accuracy: 0.6876\n",
            "Epoch 622/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6769 - val_loss: 0.5853 - val_accuracy: 0.6869\n",
            "Epoch 623/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6763 - val_loss: 0.5857 - val_accuracy: 0.6905\n",
            "Epoch 624/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6766 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 625/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5854 - accuracy: 0.6880 - val_loss: 0.5859 - val_accuracy: 0.6855\n",
            "Epoch 626/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6748 - val_loss: 0.5853 - val_accuracy: 0.6844\n",
            "Epoch 627/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6738 - val_loss: 0.5856 - val_accuracy: 0.6855\n",
            "Epoch 628/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6794 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 629/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.6753 - val_loss: 0.5856 - val_accuracy: 0.6901\n",
            "Epoch 630/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5899 - accuracy: 0.6769 - val_loss: 0.5855 - val_accuracy: 0.6883\n",
            "Epoch 631/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.6800 - val_loss: 0.5860 - val_accuracy: 0.6905\n",
            "Epoch 632/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6740 - val_loss: 0.5853 - val_accuracy: 0.6837\n",
            "Epoch 633/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6755 - val_loss: 0.5859 - val_accuracy: 0.6858\n",
            "Epoch 634/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6783 - val_loss: 0.5855 - val_accuracy: 0.6873\n",
            "Epoch 635/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5850 - accuracy: 0.6860 - val_loss: 0.5853 - val_accuracy: 0.6848\n",
            "Epoch 636/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6744 - val_loss: 0.5862 - val_accuracy: 0.6873\n",
            "Epoch 637/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6770 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 638/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6737 - val_loss: 0.5864 - val_accuracy: 0.6876\n",
            "Epoch 639/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6748 - val_loss: 0.5853 - val_accuracy: 0.6876\n",
            "Epoch 640/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6713 - val_loss: 0.5856 - val_accuracy: 0.6894\n",
            "Epoch 641/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6755 - val_loss: 0.5853 - val_accuracy: 0.6858\n",
            "Epoch 642/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6840 - val_loss: 0.5854 - val_accuracy: 0.6883\n",
            "Epoch 643/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6714 - val_loss: 0.5854 - val_accuracy: 0.6873\n",
            "Epoch 644/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.6781 - val_loss: 0.5852 - val_accuracy: 0.6876\n",
            "Epoch 645/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6764 - val_loss: 0.5853 - val_accuracy: 0.6862\n",
            "Epoch 646/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6740 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 647/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6810 - val_loss: 0.5857 - val_accuracy: 0.6855\n",
            "Epoch 648/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6798 - val_loss: 0.5852 - val_accuracy: 0.6844\n",
            "Epoch 649/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6741 - val_loss: 0.5852 - val_accuracy: 0.6865\n",
            "Epoch 650/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6770 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 651/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6750 - val_loss: 0.5856 - val_accuracy: 0.6905\n",
            "Epoch 652/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6765 - val_loss: 0.5854 - val_accuracy: 0.6876\n",
            "Epoch 653/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6712 - val_loss: 0.5852 - val_accuracy: 0.6841\n",
            "Epoch 654/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6797 - val_loss: 0.5868 - val_accuracy: 0.6876\n",
            "Epoch 655/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6756 - val_loss: 0.5859 - val_accuracy: 0.6858\n",
            "Epoch 656/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6734 - val_loss: 0.5852 - val_accuracy: 0.6844\n",
            "Epoch 657/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6770 - val_loss: 0.5852 - val_accuracy: 0.6873\n",
            "Epoch 658/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6782 - val_loss: 0.5862 - val_accuracy: 0.6880\n",
            "Epoch 659/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6771 - val_loss: 0.5853 - val_accuracy: 0.6887\n",
            "Epoch 660/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6772 - val_loss: 0.5852 - val_accuracy: 0.6880\n",
            "Epoch 661/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6758 - val_loss: 0.5852 - val_accuracy: 0.6876\n",
            "Epoch 662/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6797 - val_loss: 0.5855 - val_accuracy: 0.6901\n",
            "Epoch 663/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6766 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 664/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6778 - val_loss: 0.5851 - val_accuracy: 0.6869\n",
            "Epoch 665/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6771 - val_loss: 0.5853 - val_accuracy: 0.6876\n",
            "Epoch 666/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6727 - val_loss: 0.5855 - val_accuracy: 0.6901\n",
            "Epoch 667/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6739 - val_loss: 0.5852 - val_accuracy: 0.6894\n",
            "Epoch 668/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6776 - val_loss: 0.5851 - val_accuracy: 0.6862\n",
            "Epoch 669/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6755 - val_loss: 0.5853 - val_accuracy: 0.6890\n",
            "Epoch 670/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6764 - val_loss: 0.5851 - val_accuracy: 0.6841\n",
            "Epoch 671/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6782 - val_loss: 0.5852 - val_accuracy: 0.6880\n",
            "Epoch 672/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6779 - val_loss: 0.5858 - val_accuracy: 0.6865\n",
            "Epoch 673/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6776 - val_loss: 0.5854 - val_accuracy: 0.6855\n",
            "Epoch 674/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6790 - val_loss: 0.5861 - val_accuracy: 0.6876\n",
            "Epoch 675/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.6814 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 676/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6738 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 677/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5877 - accuracy: 0.6795 - val_loss: 0.5857 - val_accuracy: 0.6862\n",
            "Epoch 678/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6790 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 679/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5894 - accuracy: 0.6798 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 680/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.6762 - val_loss: 0.5853 - val_accuracy: 0.6883\n",
            "Epoch 681/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.6685 - val_loss: 0.5852 - val_accuracy: 0.6887\n",
            "Epoch 682/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6795 - val_loss: 0.5851 - val_accuracy: 0.6858\n",
            "Epoch 683/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6731 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 684/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5869 - accuracy: 0.6802 - val_loss: 0.5851 - val_accuracy: 0.6869\n",
            "Epoch 685/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.6817 - val_loss: 0.5853 - val_accuracy: 0.6858\n",
            "Epoch 686/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6018 - accuracy: 0.6664 - val_loss: 0.5851 - val_accuracy: 0.6855\n",
            "Epoch 687/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6825 - val_loss: 0.5856 - val_accuracy: 0.6855\n",
            "Epoch 688/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6756 - val_loss: 0.5855 - val_accuracy: 0.6848\n",
            "Epoch 689/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6759 - val_loss: 0.5854 - val_accuracy: 0.6844\n",
            "Epoch 690/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6806 - val_loss: 0.5851 - val_accuracy: 0.6841\n",
            "Epoch 691/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6809 - val_loss: 0.5854 - val_accuracy: 0.6848\n",
            "Epoch 692/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.6811 - val_loss: 0.5853 - val_accuracy: 0.6851\n",
            "Epoch 693/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6694 - val_loss: 0.5854 - val_accuracy: 0.6887\n",
            "Epoch 694/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6795 - val_loss: 0.5852 - val_accuracy: 0.6851\n",
            "Epoch 695/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6747 - val_loss: 0.5854 - val_accuracy: 0.6876\n",
            "Epoch 696/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6774 - val_loss: 0.5858 - val_accuracy: 0.6905\n",
            "Epoch 697/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6759 - val_loss: 0.5851 - val_accuracy: 0.6834\n",
            "Epoch 698/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5889 - accuracy: 0.6793 - val_loss: 0.5863 - val_accuracy: 0.6887\n",
            "Epoch 699/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.6834 - val_loss: 0.5858 - val_accuracy: 0.6912\n",
            "Epoch 700/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5964 - accuracy: 0.6736 - val_loss: 0.5851 - val_accuracy: 0.6887\n",
            "Epoch 701/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6752 - val_loss: 0.5851 - val_accuracy: 0.6883\n",
            "Epoch 702/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6753 - val_loss: 0.5863 - val_accuracy: 0.6873\n",
            "Epoch 703/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6729 - val_loss: 0.5852 - val_accuracy: 0.6869\n",
            "Epoch 704/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6720 - val_loss: 0.5853 - val_accuracy: 0.6883\n",
            "Epoch 705/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.6785 - val_loss: 0.5854 - val_accuracy: 0.6851\n",
            "Epoch 706/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6772 - val_loss: 0.5851 - val_accuracy: 0.6848\n",
            "Epoch 707/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6751 - val_loss: 0.5851 - val_accuracy: 0.6841\n",
            "Epoch 708/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.6892 - val_loss: 0.5850 - val_accuracy: 0.6844\n",
            "Epoch 709/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6801 - val_loss: 0.5851 - val_accuracy: 0.6883\n",
            "Epoch 710/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6796 - val_loss: 0.5853 - val_accuracy: 0.6841\n",
            "Epoch 711/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6775 - val_loss: 0.5850 - val_accuracy: 0.6869\n",
            "Epoch 712/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6744 - val_loss: 0.5850 - val_accuracy: 0.6855\n",
            "Epoch 713/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5946 - accuracy: 0.6726 - val_loss: 0.5850 - val_accuracy: 0.6841\n",
            "Epoch 714/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6736 - val_loss: 0.5851 - val_accuracy: 0.6890\n",
            "Epoch 715/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6736 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 716/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6773 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 717/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5878 - accuracy: 0.6754 - val_loss: 0.5851 - val_accuracy: 0.6855\n",
            "Epoch 718/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6828 - val_loss: 0.5850 - val_accuracy: 0.6865\n",
            "Epoch 719/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5953 - accuracy: 0.6736 - val_loss: 0.5852 - val_accuracy: 0.6887\n",
            "Epoch 720/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.6818 - val_loss: 0.5859 - val_accuracy: 0.6908\n",
            "Epoch 721/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6737 - val_loss: 0.5852 - val_accuracy: 0.6869\n",
            "Epoch 722/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.6710 - val_loss: 0.5851 - val_accuracy: 0.6883\n",
            "Epoch 723/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6765 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 724/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6756 - val_loss: 0.5855 - val_accuracy: 0.6901\n",
            "Epoch 725/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6798 - val_loss: 0.5850 - val_accuracy: 0.6848\n",
            "Epoch 726/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6814 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 727/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5875 - accuracy: 0.6832 - val_loss: 0.5851 - val_accuracy: 0.6876\n",
            "Epoch 728/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6779 - val_loss: 0.5875 - val_accuracy: 0.6862\n",
            "Epoch 729/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6802 - val_loss: 0.5850 - val_accuracy: 0.6848\n",
            "Epoch 730/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.6837 - val_loss: 0.5851 - val_accuracy: 0.6841\n",
            "Epoch 731/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6802 - val_loss: 0.5855 - val_accuracy: 0.6855\n",
            "Epoch 732/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6748 - val_loss: 0.5850 - val_accuracy: 0.6883\n",
            "Epoch 733/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6816 - val_loss: 0.5851 - val_accuracy: 0.6858\n",
            "Epoch 734/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6776 - val_loss: 0.5852 - val_accuracy: 0.6841\n",
            "Epoch 735/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6819 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 736/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.6806 - val_loss: 0.5867 - val_accuracy: 0.6894\n",
            "Epoch 737/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.6864 - val_loss: 0.5852 - val_accuracy: 0.6855\n",
            "Epoch 738/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6816 - val_loss: 0.5851 - val_accuracy: 0.6880\n",
            "Epoch 739/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6739 - val_loss: 0.5856 - val_accuracy: 0.6887\n",
            "Epoch 740/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6794 - val_loss: 0.5860 - val_accuracy: 0.6876\n",
            "Epoch 741/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5969 - accuracy: 0.6736 - val_loss: 0.5851 - val_accuracy: 0.6865\n",
            "Epoch 742/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.6788 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 743/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6809 - val_loss: 0.5852 - val_accuracy: 0.6890\n",
            "Epoch 744/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6810 - val_loss: 0.5850 - val_accuracy: 0.6883\n",
            "Epoch 745/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6745 - val_loss: 0.5850 - val_accuracy: 0.6883\n",
            "Epoch 746/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5874 - accuracy: 0.6853 - val_loss: 0.5852 - val_accuracy: 0.6873\n",
            "Epoch 747/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6784 - val_loss: 0.5849 - val_accuracy: 0.6858\n",
            "Epoch 748/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6797 - val_loss: 0.5850 - val_accuracy: 0.6880\n",
            "Epoch 749/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6760 - val_loss: 0.5851 - val_accuracy: 0.6858\n",
            "Epoch 750/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6732 - val_loss: 0.5860 - val_accuracy: 0.6876\n",
            "Epoch 751/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5868 - accuracy: 0.6782 - val_loss: 0.5857 - val_accuracy: 0.6876\n",
            "Epoch 752/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.6768 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 753/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.6821 - val_loss: 0.5849 - val_accuracy: 0.6887\n",
            "Epoch 754/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.6766 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 755/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6789 - val_loss: 0.5886 - val_accuracy: 0.6848\n",
            "Epoch 756/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.6813 - val_loss: 0.5857 - val_accuracy: 0.6873\n",
            "Epoch 757/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6757 - val_loss: 0.5850 - val_accuracy: 0.6858\n",
            "Epoch 758/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6756 - val_loss: 0.5850 - val_accuracy: 0.6869\n",
            "Epoch 759/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5864 - accuracy: 0.6823 - val_loss: 0.5857 - val_accuracy: 0.6908\n",
            "Epoch 760/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6739 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 761/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.6721 - val_loss: 0.5849 - val_accuracy: 0.6887\n",
            "Epoch 762/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6760 - val_loss: 0.5854 - val_accuracy: 0.6858\n",
            "Epoch 763/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6727 - val_loss: 0.5852 - val_accuracy: 0.6880\n",
            "Epoch 764/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6742 - val_loss: 0.5851 - val_accuracy: 0.6858\n",
            "Epoch 765/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6764 - val_loss: 0.5849 - val_accuracy: 0.6873\n",
            "Epoch 766/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6812 - val_loss: 0.5865 - val_accuracy: 0.6890\n",
            "Epoch 767/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5862 - accuracy: 0.6810 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 768/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6707 - val_loss: 0.5858 - val_accuracy: 0.6876\n",
            "Epoch 769/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6745 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 770/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6741 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 771/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6761 - val_loss: 0.5851 - val_accuracy: 0.6865\n",
            "Epoch 772/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6780 - val_loss: 0.5849 - val_accuracy: 0.6851\n",
            "Epoch 773/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6710 - val_loss: 0.5851 - val_accuracy: 0.6876\n",
            "Epoch 774/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6779 - val_loss: 0.5856 - val_accuracy: 0.6908\n",
            "Epoch 775/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6800 - val_loss: 0.5860 - val_accuracy: 0.6894\n",
            "Epoch 776/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.6838 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 777/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5941 - accuracy: 0.6723 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 778/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6796 - val_loss: 0.5853 - val_accuracy: 0.6858\n",
            "Epoch 779/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6783 - val_loss: 0.5849 - val_accuracy: 0.6887\n",
            "Epoch 780/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6785 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 781/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.6762 - val_loss: 0.5852 - val_accuracy: 0.6841\n",
            "Epoch 782/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.6807 - val_loss: 0.5850 - val_accuracy: 0.6865\n",
            "Epoch 783/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6742 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 784/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6802 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 785/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6813 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 786/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.6812 - val_loss: 0.5861 - val_accuracy: 0.6901\n",
            "Epoch 787/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5927 - accuracy: 0.6787 - val_loss: 0.5852 - val_accuracy: 0.6855\n",
            "Epoch 788/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6794 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 789/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.6805 - val_loss: 0.5849 - val_accuracy: 0.6880\n",
            "Epoch 790/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5849 - accuracy: 0.6810 - val_loss: 0.5850 - val_accuracy: 0.6858\n",
            "Epoch 791/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6757 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 792/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6826 - val_loss: 0.5853 - val_accuracy: 0.6887\n",
            "Epoch 793/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6800 - val_loss: 0.5850 - val_accuracy: 0.6865\n",
            "Epoch 794/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.6814 - val_loss: 0.5852 - val_accuracy: 0.6851\n",
            "Epoch 795/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.6811 - val_loss: 0.5850 - val_accuracy: 0.6858\n",
            "Epoch 796/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6757 - val_loss: 0.5851 - val_accuracy: 0.6869\n",
            "Epoch 797/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6808 - val_loss: 0.5868 - val_accuracy: 0.6890\n",
            "Epoch 798/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6759 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 799/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6721 - val_loss: 0.5848 - val_accuracy: 0.6887\n",
            "Epoch 800/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6723 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 801/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6845 - val_loss: 0.5862 - val_accuracy: 0.6887\n",
            "Epoch 802/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6796 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 803/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6825 - val_loss: 0.5856 - val_accuracy: 0.6912\n",
            "Epoch 804/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5899 - accuracy: 0.6798 - val_loss: 0.5851 - val_accuracy: 0.6841\n",
            "Epoch 805/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6804 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
            "Epoch 806/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5858 - accuracy: 0.6801 - val_loss: 0.5854 - val_accuracy: 0.6869\n",
            "Epoch 807/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6755 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 808/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.6737 - val_loss: 0.5848 - val_accuracy: 0.6901\n",
            "Epoch 809/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6755 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 810/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6801 - val_loss: 0.5851 - val_accuracy: 0.6873\n",
            "Epoch 811/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6752 - val_loss: 0.5854 - val_accuracy: 0.6858\n",
            "Epoch 812/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.6792 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 813/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6828 - val_loss: 0.5861 - val_accuracy: 0.6887\n",
            "Epoch 814/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6754 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 815/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6815 - val_loss: 0.5848 - val_accuracy: 0.6887\n",
            "Epoch 816/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6816 - val_loss: 0.5850 - val_accuracy: 0.6858\n",
            "Epoch 817/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6731 - val_loss: 0.5850 - val_accuracy: 0.6880\n",
            "Epoch 818/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5894 - accuracy: 0.6800 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 819/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.6010 - accuracy: 0.6677 - val_loss: 0.5848 - val_accuracy: 0.6865\n",
            "Epoch 820/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6743 - val_loss: 0.5855 - val_accuracy: 0.6919\n",
            "Epoch 821/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5910 - accuracy: 0.6762 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 822/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.6820 - val_loss: 0.5848 - val_accuracy: 0.6880\n",
            "Epoch 823/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5855 - accuracy: 0.6821 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 824/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5945 - accuracy: 0.6787 - val_loss: 0.5849 - val_accuracy: 0.6873\n",
            "Epoch 825/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6734 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 826/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6764 - val_loss: 0.5860 - val_accuracy: 0.6880\n",
            "Epoch 827/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6792 - val_loss: 0.5870 - val_accuracy: 0.6869\n",
            "Epoch 828/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6803 - val_loss: 0.5853 - val_accuracy: 0.6876\n",
            "Epoch 829/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6760 - val_loss: 0.5860 - val_accuracy: 0.6880\n",
            "Epoch 830/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5852 - accuracy: 0.6803 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 831/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6768 - val_loss: 0.5848 - val_accuracy: 0.6873\n",
            "Epoch 832/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6721 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 833/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5834 - accuracy: 0.6851 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 834/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6689 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 835/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6821 - val_loss: 0.5850 - val_accuracy: 0.6858\n",
            "Epoch 836/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5837 - accuracy: 0.6845 - val_loss: 0.5852 - val_accuracy: 0.6855\n",
            "Epoch 837/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6785 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 838/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6803 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 839/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6752 - val_loss: 0.5856 - val_accuracy: 0.6908\n",
            "Epoch 840/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6801 - val_loss: 0.5856 - val_accuracy: 0.6880\n",
            "Epoch 841/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.6780 - val_loss: 0.5850 - val_accuracy: 0.6851\n",
            "Epoch 842/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.6771 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 843/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6824 - val_loss: 0.5848 - val_accuracy: 0.6883\n",
            "Epoch 844/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6774 - val_loss: 0.5850 - val_accuracy: 0.6851\n",
            "Epoch 845/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.6802 - val_loss: 0.5850 - val_accuracy: 0.6855\n",
            "Epoch 846/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.6804 - val_loss: 0.5849 - val_accuracy: 0.6873\n",
            "Epoch 847/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6761 - val_loss: 0.5855 - val_accuracy: 0.6897\n",
            "Epoch 848/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.6803 - val_loss: 0.5852 - val_accuracy: 0.6851\n",
            "Epoch 849/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6750 - val_loss: 0.5848 - val_accuracy: 0.6883\n",
            "Epoch 850/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.6847 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 851/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6764 - val_loss: 0.5849 - val_accuracy: 0.6855\n",
            "Epoch 852/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.6769 - val_loss: 0.5872 - val_accuracy: 0.6880\n",
            "Epoch 853/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6795 - val_loss: 0.5849 - val_accuracy: 0.6855\n",
            "Epoch 854/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.6742 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 855/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6709 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 856/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6765 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 857/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6791 - val_loss: 0.5854 - val_accuracy: 0.6887\n",
            "Epoch 858/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.6831 - val_loss: 0.5849 - val_accuracy: 0.6894\n",
            "Epoch 859/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5867 - accuracy: 0.6840 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 860/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6801 - val_loss: 0.5857 - val_accuracy: 0.6887\n",
            "Epoch 861/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.6794 - val_loss: 0.5859 - val_accuracy: 0.6894\n",
            "Epoch 862/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6752 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 863/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5823 - accuracy: 0.6800 - val_loss: 0.5850 - val_accuracy: 0.6865\n",
            "Epoch 864/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6805 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 865/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6877 - val_loss: 0.5851 - val_accuracy: 0.6876\n",
            "Epoch 866/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5854 - accuracy: 0.6850 - val_loss: 0.5864 - val_accuracy: 0.6844\n",
            "Epoch 867/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6791 - val_loss: 0.5854 - val_accuracy: 0.6869\n",
            "Epoch 868/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5861 - accuracy: 0.6811 - val_loss: 0.5859 - val_accuracy: 0.6887\n",
            "Epoch 869/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.6785 - val_loss: 0.5853 - val_accuracy: 0.6862\n",
            "Epoch 870/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6781 - val_loss: 0.5854 - val_accuracy: 0.6897\n",
            "Epoch 871/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5870 - accuracy: 0.6804 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 872/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6762 - val_loss: 0.5850 - val_accuracy: 0.6844\n",
            "Epoch 873/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.6800 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 874/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6731 - val_loss: 0.5851 - val_accuracy: 0.6873\n",
            "Epoch 875/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.6723 - val_loss: 0.5854 - val_accuracy: 0.6880\n",
            "Epoch 876/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6807 - val_loss: 0.5850 - val_accuracy: 0.6873\n",
            "Epoch 877/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6788 - val_loss: 0.5848 - val_accuracy: 0.6883\n",
            "Epoch 878/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5831 - accuracy: 0.6845 - val_loss: 0.5848 - val_accuracy: 0.6887\n",
            "Epoch 879/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.6789 - val_loss: 0.5848 - val_accuracy: 0.6880\n",
            "Epoch 880/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5874 - accuracy: 0.6824 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 881/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6866 - val_loss: 0.5848 - val_accuracy: 0.6880\n",
            "Epoch 882/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.6744 - val_loss: 0.5849 - val_accuracy: 0.6844\n",
            "Epoch 883/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6802 - val_loss: 0.5848 - val_accuracy: 0.6883\n",
            "Epoch 884/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.6818 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 885/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6778 - val_loss: 0.5853 - val_accuracy: 0.6880\n",
            "Epoch 886/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6720 - val_loss: 0.5853 - val_accuracy: 0.6865\n",
            "Epoch 887/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.6772 - val_loss: 0.5848 - val_accuracy: 0.6873\n",
            "Epoch 888/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6784 - val_loss: 0.5867 - val_accuracy: 0.6873\n",
            "Epoch 889/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5951 - accuracy: 0.6759 - val_loss: 0.5856 - val_accuracy: 0.6883\n",
            "Epoch 890/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5864 - accuracy: 0.6821 - val_loss: 0.5853 - val_accuracy: 0.6890\n",
            "Epoch 891/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.6769 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 892/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5948 - accuracy: 0.6757 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 893/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.6783 - val_loss: 0.5850 - val_accuracy: 0.6841\n",
            "Epoch 894/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6827 - val_loss: 0.5854 - val_accuracy: 0.6890\n",
            "Epoch 895/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6759 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 896/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6816 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 897/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.6847 - val_loss: 0.5852 - val_accuracy: 0.6865\n",
            "Epoch 898/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6766 - val_loss: 0.5849 - val_accuracy: 0.6848\n",
            "Epoch 899/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6814 - val_loss: 0.5848 - val_accuracy: 0.6883\n",
            "Epoch 900/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.6802 - val_loss: 0.5848 - val_accuracy: 0.6858\n",
            "Epoch 901/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6803 - val_loss: 0.5848 - val_accuracy: 0.6880\n",
            "Epoch 902/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5953 - accuracy: 0.6726 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 903/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5922 - accuracy: 0.6774 - val_loss: 0.5866 - val_accuracy: 0.6880\n",
            "Epoch 904/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.6866 - val_loss: 0.5860 - val_accuracy: 0.6865\n",
            "Epoch 905/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6774 - val_loss: 0.5848 - val_accuracy: 0.6855\n",
            "Epoch 906/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6805 - val_loss: 0.5848 - val_accuracy: 0.6858\n",
            "Epoch 907/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6831 - val_loss: 0.5848 - val_accuracy: 0.6880\n",
            "Epoch 908/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6746 - val_loss: 0.5847 - val_accuracy: 0.6887\n",
            "Epoch 909/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6782 - val_loss: 0.5847 - val_accuracy: 0.6887\n",
            "Epoch 910/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5910 - accuracy: 0.6781 - val_loss: 0.5848 - val_accuracy: 0.6851\n",
            "Epoch 911/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.6832 - val_loss: 0.5850 - val_accuracy: 0.6855\n",
            "Epoch 912/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6789 - val_loss: 0.5854 - val_accuracy: 0.6876\n",
            "Epoch 913/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6775 - val_loss: 0.5848 - val_accuracy: 0.6869\n",
            "Epoch 914/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.6763 - val_loss: 0.5849 - val_accuracy: 0.6855\n",
            "Epoch 915/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6787 - val_loss: 0.5851 - val_accuracy: 0.6887\n",
            "Epoch 916/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6781 - val_loss: 0.5852 - val_accuracy: 0.6865\n",
            "Epoch 917/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.6848 - val_loss: 0.5853 - val_accuracy: 0.6851\n",
            "Epoch 918/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.6807 - val_loss: 0.5853 - val_accuracy: 0.6855\n",
            "Epoch 919/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5874 - accuracy: 0.6809 - val_loss: 0.5850 - val_accuracy: 0.6848\n",
            "Epoch 920/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5854 - accuracy: 0.6821 - val_loss: 0.5848 - val_accuracy: 0.6862\n",
            "Epoch 921/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6751 - val_loss: 0.5848 - val_accuracy: 0.6865\n",
            "Epoch 922/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5819 - accuracy: 0.6908 - val_loss: 0.5847 - val_accuracy: 0.6890\n",
            "Epoch 923/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5878 - accuracy: 0.6803 - val_loss: 0.5847 - val_accuracy: 0.6890\n",
            "Epoch 924/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5894 - accuracy: 0.6774 - val_loss: 0.5851 - val_accuracy: 0.6858\n",
            "Epoch 925/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5960 - accuracy: 0.6776 - val_loss: 0.5848 - val_accuracy: 0.6851\n",
            "Epoch 926/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6826 - val_loss: 0.5848 - val_accuracy: 0.6851\n",
            "Epoch 927/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.6796 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 928/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6773 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 929/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.6785 - val_loss: 0.5859 - val_accuracy: 0.6848\n",
            "Epoch 930/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.6812 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 931/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.6876 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 932/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6794 - val_loss: 0.5847 - val_accuracy: 0.6876\n",
            "Epoch 933/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6764 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 934/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6808 - val_loss: 0.5847 - val_accuracy: 0.6876\n",
            "Epoch 935/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.6794 - val_loss: 0.5848 - val_accuracy: 0.6862\n",
            "Epoch 936/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6803 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 937/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.6021 - accuracy: 0.6657 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 938/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6867 - val_loss: 0.5848 - val_accuracy: 0.6873\n",
            "Epoch 939/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5872 - accuracy: 0.6791 - val_loss: 0.5849 - val_accuracy: 0.6865\n",
            "Epoch 940/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6851 - val_loss: 0.5850 - val_accuracy: 0.6862\n",
            "Epoch 941/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5862 - accuracy: 0.6834 - val_loss: 0.5852 - val_accuracy: 0.6862\n",
            "Epoch 942/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6853 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 943/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5876 - accuracy: 0.6790 - val_loss: 0.5848 - val_accuracy: 0.6862\n",
            "Epoch 944/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5875 - accuracy: 0.6819 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 945/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5848 - accuracy: 0.6850 - val_loss: 0.5848 - val_accuracy: 0.6865\n",
            "Epoch 946/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6838 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 947/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5907 - accuracy: 0.6796 - val_loss: 0.5861 - val_accuracy: 0.6862\n",
            "Epoch 948/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.6803 - val_loss: 0.5855 - val_accuracy: 0.6901\n",
            "Epoch 949/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6840 - val_loss: 0.5852 - val_accuracy: 0.6894\n",
            "Epoch 950/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6769 - val_loss: 0.5849 - val_accuracy: 0.6873\n",
            "Epoch 951/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6794 - val_loss: 0.5859 - val_accuracy: 0.6855\n",
            "Epoch 952/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6751 - val_loss: 0.5848 - val_accuracy: 0.6858\n",
            "Epoch 953/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5852 - accuracy: 0.6831 - val_loss: 0.5847 - val_accuracy: 0.6873\n",
            "Epoch 954/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.6748 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 955/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6810 - val_loss: 0.5851 - val_accuracy: 0.6887\n",
            "Epoch 956/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6797 - val_loss: 0.5850 - val_accuracy: 0.6869\n",
            "Epoch 957/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6811 - val_loss: 0.5847 - val_accuracy: 0.6873\n",
            "Epoch 958/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6802 - val_loss: 0.5854 - val_accuracy: 0.6887\n",
            "Epoch 959/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.6763 - val_loss: 0.5850 - val_accuracy: 0.6862\n",
            "Epoch 960/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6773 - val_loss: 0.5847 - val_accuracy: 0.6865\n",
            "Epoch 961/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.6788 - val_loss: 0.5848 - val_accuracy: 0.6865\n",
            "Epoch 962/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6796 - val_loss: 0.5848 - val_accuracy: 0.6865\n",
            "Epoch 963/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5933 - accuracy: 0.6775 - val_loss: 0.5849 - val_accuracy: 0.6862\n",
            "Epoch 964/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5868 - accuracy: 0.6812 - val_loss: 0.5852 - val_accuracy: 0.6897\n",
            "Epoch 965/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6769 - val_loss: 0.5851 - val_accuracy: 0.6890\n",
            "Epoch 966/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.6767 - val_loss: 0.5848 - val_accuracy: 0.6876\n",
            "Epoch 967/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.6782 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 968/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5876 - accuracy: 0.6837 - val_loss: 0.5854 - val_accuracy: 0.6883\n",
            "Epoch 969/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.6831 - val_loss: 0.5852 - val_accuracy: 0.6890\n",
            "Epoch 970/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5844 - accuracy: 0.6849 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 971/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5871 - accuracy: 0.6829 - val_loss: 0.5849 - val_accuracy: 0.6876\n",
            "Epoch 972/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6784 - val_loss: 0.5857 - val_accuracy: 0.6865\n",
            "Epoch 973/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5944 - accuracy: 0.6713 - val_loss: 0.5848 - val_accuracy: 0.6862\n",
            "Epoch 974/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5951 - accuracy: 0.6760 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 975/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.6788 - val_loss: 0.5857 - val_accuracy: 0.6880\n",
            "Epoch 976/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6833 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 977/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6835 - val_loss: 0.5853 - val_accuracy: 0.6890\n",
            "Epoch 978/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.6768 - val_loss: 0.5846 - val_accuracy: 0.6873\n",
            "Epoch 979/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6776 - val_loss: 0.5853 - val_accuracy: 0.6883\n",
            "Epoch 980/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6787 - val_loss: 0.5846 - val_accuracy: 0.6887\n",
            "Epoch 981/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6754 - val_loss: 0.5847 - val_accuracy: 0.6880\n",
            "Epoch 982/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5922 - accuracy: 0.6740 - val_loss: 0.5847 - val_accuracy: 0.6876\n",
            "Epoch 983/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6750 - val_loss: 0.5847 - val_accuracy: 0.6883\n",
            "Epoch 984/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.6823 - val_loss: 0.5850 - val_accuracy: 0.6851\n",
            "Epoch 985/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6776 - val_loss: 0.5850 - val_accuracy: 0.6883\n",
            "Epoch 986/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.6837 - val_loss: 0.5847 - val_accuracy: 0.6887\n",
            "Epoch 987/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.6787 - val_loss: 0.5847 - val_accuracy: 0.6876\n",
            "Epoch 988/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.6836 - val_loss: 0.5856 - val_accuracy: 0.6901\n",
            "Epoch 989/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.6782 - val_loss: 0.5847 - val_accuracy: 0.6876\n",
            "Epoch 990/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.6830 - val_loss: 0.5847 - val_accuracy: 0.6873\n",
            "Epoch 991/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6789 - val_loss: 0.5849 - val_accuracy: 0.6869\n",
            "Epoch 992/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6790 - val_loss: 0.5856 - val_accuracy: 0.6851\n",
            "Epoch 993/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6783 - val_loss: 0.5846 - val_accuracy: 0.6883\n",
            "Epoch 994/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6742 - val_loss: 0.5857 - val_accuracy: 0.6901\n",
            "Epoch 995/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5871 - accuracy: 0.6832 - val_loss: 0.5873 - val_accuracy: 0.6837\n",
            "Epoch 996/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6880 - val_loss: 0.5847 - val_accuracy: 0.6873\n",
            "Epoch 997/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6794 - val_loss: 0.5847 - val_accuracy: 0.6858\n",
            "Epoch 998/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5955 - accuracy: 0.6723 - val_loss: 0.5847 - val_accuracy: 0.6869\n",
            "Epoch 999/1000\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6782 - val_loss: 0.5847 - val_accuracy: 0.6858\n",
            "Epoch 1000/1000\n",
            "247/247 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6787 - val_loss: 0.5846 - val_accuracy: 0.6883\n",
            "Accuracy on training data: 0.6818354725837708% \n",
            " Error on training data: 0.31816452741622925\n",
            "Accuracy on test data: 0.6883209347724915% \n",
            " Error on test data: 0.31167906522750854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "6ff7efea-95ae-4cac-e9d6-cf9e07714465"
      },
      "source": [
        "Xnew=np.array([[1.8,1.9,26,23,0.63,0.64,0.509,0.591,1.16,0.68,0.7,1.26,84.3,0.75,0.5,1.11,7.4,1.13,0.64,0.72,1.11,78.0,0.72,0.57,1.13,3.2,1.0,0.67,0.69,0.95,69.3,0.64,0.58,0.95,4.2,0.99,0.65,0.69,0.95,67.7,0.62,0.58,0.94,3.3,1.07,0.66,0.7,1.0675000000000001,74.825,0.6825,0.5575,1.0325000000000002,4.525,1.23,0.6,0.75,1.26,79.4,0.77,0.31,1.29,3.4,1.24,0.61,0.77,1.15,82.8,0.82,0.52,1.35,3.4,1.14,0.62,0.73,1.11,76.1,0.72,0.5,1.16,5.2,1.0,0.68,0.7,0.98,70.2,0.61,0.51,0.90,3.9,0.98,0.69,0.69,0.96,71.7,0.6,0.48,0.87,5.3],\n",
        "                [1.43,2.5,21,40,0.7,0.56,0.532,0.5,1.18,0.6,0.74,1.16,78.1,0.74,0.57,1.24,3.8,1.17,0.62,0.71,1.2,78.5,0.77,0.28,1.23,3.0,1.1,0.63,0.72,1.09,75.8,0.71,0.56,1.12,4.0,1.08,0.67,0.71,1.12,76.3,0.68,0.58,1.02,5.0,0.99,0.68,0.69,0.98,72.7,0.61,0.5,0.90,6.7,1.1,0.67,0.71,1.14,77.6,0.71,0.53,1.05,6.0,1.06,0.67,0.72,0.99,76.3,0.69,0.52,1.03,4.7,1.02,0.7,0.72,0.97,74.1,0.66,0.52,0.95,4.5,0.97,0.72,0.69,0.99,73.5,0.6,0.42,0.83,7.2,1.0375,0.69,0.71,1.0225,75.375,0.665,0.4975,0.9650000000000001,5.6],\n",
        "                [1.8,1.9,29,59,0.53,0.57,0.519,0.5,1.11,0.65,0.7,1.13,77.9,0.72,0.57,1.11,6.2,1.06,0.67,0.72,0.99,74.7,0.67,0.53,1.00,3.6,1.06,0.68,0.71,1.06,76.8,0.68,0.49,1.00,6.3,1.05,0.68,0.7,1.08,72.9,0.67,0.39,0.99,5.0,0.93,0.69,0.69,0.82,68.8,0.59,0.53,0.86,5.5,1.34,0.61,0.74,1.34,90.6,0.9,0.41,1.47,3.9,1.08,0.62,0.75,0.89,72.9,0.66,0.6,1.07,4.2,1.08,0.67,0.71,1.19,73.4,0.66,0.49,0.99,10.7,0.99,0.67,0.72,0.8,71.4,0.63,0.52,0.93,5.6,0.95,0.62,0.68,0.79,60.9,0.58,0.4,0.93,3.0],\n",
        "                [1.45,2.5,32,54,0.62,0.27,0.452,0.5,1.28,0.59,0.78,1.22,88.5,0.8,0.5,1.35,7.9,1.16,0.62,0.72,1.17,78.4,0.74,0.24,1.19,4.4,1.07,0.67,0.73,1.05,76.2,0.65,0.42,0.97,5.5,1.05,0.64,0.73,0.99,70.3,0.64,0.51,1.01,5.3,1.05,0.65,0.72,1.05,70.2,0.66,0.43,1.02,4.1,1.1,0.69,0.71,1.07,83.1,0.72,0.49,1.05,7.7,1.06,0.74,0.66,1.28,78.5,0.71,0.52,0.96,4.3,0.97,0.66,0.72,0.85,68.6,0.59,0.52,0.89,3.7,0.94,0.66,0.69,0.92,63.5,0.59,0.36,0.88,3.5,0.88,0.73,0.68,0.84,64.6,0.56,0.56,0.77,4.2],\n",
        "                [1.5,2.5,36,44,0.55,0.57,0.529,0.5,1.13,0.63,0.7,1.18,75.6,0.75,0.27,1.19,2.4,1.13,0.59,0.73,1.03,78.6,0.69,0.38,1.17,5.8,1.07,0.71,0.67,1.17,78.9,0.73,0.47,1.03,3.7,0.96,0.68,0.69,0.87,70.0,0.61,0.52,0.90,5.6,0.94,0.67,0.67,0.95,65.1,0.59,0.57,0.88,4.0,1.23,0.59,0.74,1.25,79.8,0.79,0.38,1.34,2.6,1.09,0.64,0.73,0.97,79.2,0.7,0.49,1.09,4.9,1.06,0.67,0.7,1.05,76.1,0.67,0.54,0.99,4.2,1.1266666666666667,0.6333333333333333,0.7233333333333333,1.0899999999999999,78.36666666666666,0.7200000000000001,0.47000000000000003,1.14,3.9,1.1266666666666667,0.6333333333333333,0.7233333333333333,1.0899999999999999,78.36666666666666,0.7200000000000001,0.47000000000000003,1.14,3.9]\n",
        "               ,[1.25,3.75,25,146,0.58,0.64,0.537,0.5,1.12,0.63,0.7,1.18,74.8,0.72,0.3,1.13,5.8,1.11,0.61,0.74,0.98,76.4,0.68,0.43,1.12,7.8,1.08,0.69,0.7,1.13,78.6,0.69,0.58,1.00,7.6,1.03,0.67,0.69,1.05,73.4,0.66,0.6,0.97,5.7,1.02,0.63,0.7,0.95,69.1,0.63,0.55,1.01,4.3,1.21,0.64,0.74,1.12,86.7,0.82,0.51,1.28,4.4,1.19,0.63,0.74,1.13,84.0,0.76,0.5,1.21,4.7,0.99,0.66,0.68,1.01,68.3,0.64,0.57,0.96,4.2,0.97,0.61,0.68,0.9,64.6,0.59,0.45,0.96,7.1,0.95,0.69,0.67,0.99,66.8,0.6,0.28,0.87,4.3]\n",
        "               ])\n",
        "Xnew=norm.fit_transform(Xnew)\n",
        "Xnew = scaler.fit_transform(Xnew)\n",
        "\n",
        "ynew=(model.predict([Xnew]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 98) dtype=float32>,)\n",
            "Consider rewriting this model with the Functional API.\n",
            "[[0.04357523]\n",
            " [0.04865813]\n",
            " [0.11653918]\n",
            " [0.10641721]\n",
            " [0.10350421]\n",
            " [0.9388274 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}