{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMulRaLuTF9M6bvQzi2Tr0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKqaUrXHmtCK"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCY-aVPMK1aO",
        "outputId": "6d4e1d97-d429-45ff-ed3c-a4d9d3374a41"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import keras\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "import sklearn\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "\n",
        "dataset=pd.read_csv('/content/data.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(dataset.shape)#vypíše nám dimenzionalitu našeho dataframu např.(2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "dataset['team_one_name']=pd.Categorical(dataset['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "dataset['team_two_name']=pd.Categorical(dataset['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "dataset.pop('Match_link')\n",
        "dataset.pop('team_one_name')\n",
        "dataset.pop('team_two_name')\n",
        "#https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "#frac=1 znamená, vrať všechny řádky\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True) #náhodně zamícháme řádky (můžeme využít seed)\n",
        "\n",
        "main_scaler=sklearn.preprocessing.StandardScaler()#standardscaler narozdíl od minmaxscaleru vykazuje o 2 procenta lepší přesnost, navíc je logické ho použít\n",
        "y = dataset['Result'].values\n",
        "dataset.pop('Result')\n",
        "X = dataset.values\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18930, 102)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL-_SH1Afa5K",
        "outputId": "3015134f-f1ad-4e04-91f9-314248836634"
      },
      "source": [
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#5% dat \n",
        "#https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/\n",
        "#https://datascience.stackexchange.com/questions/75702/when-should-you-remove-outliers\n",
        "from sklearn.ensemble import IsolationForest #0.412 mae\n",
        "from sklearn.svm import OneClassSVM #0.412 mae\n",
        "from sklearn.covariance import EllipticEnvelope #0.412 mae\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "#lof Minimum Covariance Determinant One-Class SVM\n",
        "lof = LocalOutlierFactor(contamination=0.05)\n",
        "yhat = lof.fit_predict(X)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "X, y = X[mask, :], y[mask]\n",
        "# summarize the shape of the updated training dataset\n",
        "print(X.shape, y.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17983, 98) (17983,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6j-gbpOfdtg",
        "outputId": "03d13ffe-8bd3-4fde-b9e4-2836c80e7960"
      },
      "source": [
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% \n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.15)#32 #888 887\n",
        "\n",
        "#validační set bude 15% \n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.1764) # 0.1764 x 0.859 = 0.15 \n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) \n",
        "\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "\n",
        "main_scaler.fit(X_train)#model pracuje jen s poznatky, které získal na trénovacím datasetu, proto později používám pouze transform na trénovacím datasetu\n",
        "\n",
        "X_train=main_scaler.transform(X_train)#:https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
        "X_test=main_scaler.transform(X_test)\n",
        "X_val=main_scaler.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12588, 98)\n",
            "(2698, 98)\n",
            "(2697, 98)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWMwlR9emmxS",
        "outputId": "afebcc88-fd7a-4a0d-a825-da2adea31af4"
      },
      "source": [
        "import optuna\n",
        "def objective(trial):\n",
        "    bs  = trial.suggest_int('batch size', 100, 256)\n",
        "    opt_name = trial.suggest_categorical('optimizer', ['Adagrad'])\n",
        "    lr=trial.suggest_uniform('lr', 1e-2, 1e-1)\n",
        "    min_learning_rate=trial.suggest_uniform('minimum_learning_rate', 1e-4, lr)\n",
        "    opt=keras.optimizers.get(opt_name)\n",
        "    opt.learning_rate=lr\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "    model.add(keras.layers.Dropout(rate=0.2)) \n",
        "    model.add(keras.layers.Dense(64,activation='relu'))\n",
        "    model.add(keras.layers.Dropout(rate=0.2))\n",
        "    model.add(keras.layers.Dense(32,activation='relu'))\n",
        "    model.add(keras.layers.Dropout(rate=0.2))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    model.compile(optimizer=opt, \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "    reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=min_learning_rate,verbose=0)\n",
        "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)#patience-kolik epoch se nezmění val_loss pak stop\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=200, shuffle=True,batch_size=bs,validation_data=(X_val, y_val), callbacks=[reduce_lr_callback,early_stopping_callback])\n",
        "    return model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print('params:', study.best_trial.params)\n",
        "print('best accuracy:', study.best_value)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:17:18,068]\u001b[0m A new study created in memory with name: no-name-0bcae236-0a57-4f1b-8707-779994b4f663\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "106/106 [==============================] - 1s 3ms/step - loss: 0.6913 - binary_accuracy: 0.5874 - val_loss: 0.6389 - val_binary_accuracy: 0.6370\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6464 - binary_accuracy: 0.6188 - val_loss: 0.6286 - val_binary_accuracy: 0.6478\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6303 - val_loss: 0.6183 - val_binary_accuracy: 0.6644\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6461 - val_loss: 0.6155 - val_binary_accuracy: 0.6674\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6430 - val_loss: 0.6130 - val_binary_accuracy: 0.6726\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6518 - val_loss: 0.6103 - val_binary_accuracy: 0.6700\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6515 - val_loss: 0.6065 - val_binary_accuracy: 0.6733\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6515 - val_loss: 0.6084 - val_binary_accuracy: 0.6700\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6575 - val_loss: 0.6073 - val_binary_accuracy: 0.6696\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6584 - val_loss: 0.6065 - val_binary_accuracy: 0.6715\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6627 - val_loss: 0.6051 - val_binary_accuracy: 0.6737\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6644 - val_loss: 0.6047 - val_binary_accuracy: 0.6745\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6660 - val_loss: 0.6054 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6644 - val_loss: 0.6031 - val_binary_accuracy: 0.6745\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6629 - val_loss: 0.6030 - val_binary_accuracy: 0.6800\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6694 - val_loss: 0.6024 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6688 - val_loss: 0.6030 - val_binary_accuracy: 0.6789\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6670 - val_loss: 0.6021 - val_binary_accuracy: 0.6733\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6653 - val_loss: 0.6020 - val_binary_accuracy: 0.6763\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6701 - val_loss: 0.6024 - val_binary_accuracy: 0.6774\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6751 - val_loss: 0.6018 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6743 - val_loss: 0.6019 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6714 - val_loss: 0.6011 - val_binary_accuracy: 0.6774\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6690 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 25/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6718 - val_loss: 0.6013 - val_binary_accuracy: 0.6704\n",
            "Epoch 26/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6749 - val_loss: 0.6003 - val_binary_accuracy: 0.6707\n",
            "Epoch 27/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6733 - val_loss: 0.6009 - val_binary_accuracy: 0.6767\n",
            "Epoch 28/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6738 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 29/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6709 - val_loss: 0.6004 - val_binary_accuracy: 0.6752\n",
            "Epoch 30/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6768 - val_loss: 0.6006 - val_binary_accuracy: 0.6793\n",
            "Epoch 31/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6792 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 32/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6736 - val_loss: 0.6011 - val_binary_accuracy: 0.6752\n",
            "Epoch 33/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6774 - val_loss: 0.6004 - val_binary_accuracy: 0.6759\n",
            "Epoch 34/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6738 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 35/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5935 - binary_accuracy: 0.6805 - val_loss: 0.6003 - val_binary_accuracy: 0.6785\n",
            "Epoch 36/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6770 - val_loss: 0.5997 - val_binary_accuracy: 0.6793\n",
            "Epoch 37/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6787 - val_loss: 0.5999 - val_binary_accuracy: 0.6782\n",
            "Epoch 38/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6779 - val_loss: 0.6003 - val_binary_accuracy: 0.6748\n",
            "Epoch 39/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6779 - val_loss: 0.6003 - val_binary_accuracy: 0.6785\n",
            "Epoch 40/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6775 - val_loss: 0.6000 - val_binary_accuracy: 0.6789\n",
            "Epoch 41/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5920 - binary_accuracy: 0.6799 - val_loss: 0.6008 - val_binary_accuracy: 0.6704\n",
            "Epoch 42/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6768 - val_loss: 0.6003 - val_binary_accuracy: 0.6726\n",
            "Epoch 43/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6777 - val_loss: 0.6003 - val_binary_accuracy: 0.6763\n",
            "Epoch 44/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.6823 - val_loss: 0.5995 - val_binary_accuracy: 0.6767\n",
            "Epoch 45/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5928 - binary_accuracy: 0.6756 - val_loss: 0.6006 - val_binary_accuracy: 0.6756\n",
            "Epoch 46/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6768 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 47/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5938 - binary_accuracy: 0.6793 - val_loss: 0.6010 - val_binary_accuracy: 0.6730\n",
            "Epoch 48/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6809 - val_loss: 0.6004 - val_binary_accuracy: 0.6756\n",
            "Epoch 49/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5917 - binary_accuracy: 0.6833 - val_loss: 0.6009 - val_binary_accuracy: 0.6737\n",
            "Epoch 50/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5915 - binary_accuracy: 0.6800 - val_loss: 0.6006 - val_binary_accuracy: 0.6741\n",
            "Epoch 51/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6814 - val_loss: 0.6009 - val_binary_accuracy: 0.6756\n",
            "Epoch 52/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5929 - binary_accuracy: 0.6801 - val_loss: 0.6008 - val_binary_accuracy: 0.6796\n",
            "Epoch 53/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5911 - binary_accuracy: 0.6818 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 54/200\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5892 - binary_accuracy: 0.6838 - val_loss: 0.6015 - val_binary_accuracy: 0.6704\n",
            "Epoch 00054: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:17:39,053]\u001b[0m Trial 0 finished with value: 0.6704966425895691 and parameters: {'batch size': 119, 'optimizer': 'Adagrad', 'lr': 0.0403951296312157, 'minimum_learning_rate': 0.03578899773840477}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "71/71 [==============================] - 1s 4ms/step - loss: 0.6665 - binary_accuracy: 0.5910 - val_loss: 0.6286 - val_binary_accuracy: 0.6500\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6398 - binary_accuracy: 0.6285 - val_loss: 0.6188 - val_binary_accuracy: 0.6667\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6395 - val_loss: 0.6102 - val_binary_accuracy: 0.6685\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6516 - val_loss: 0.6068 - val_binary_accuracy: 0.6745\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6578 - val_loss: 0.6081 - val_binary_accuracy: 0.6719\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6584 - val_loss: 0.6061 - val_binary_accuracy: 0.6730\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6613 - val_loss: 0.6057 - val_binary_accuracy: 0.6759\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6652 - val_loss: 0.6026 - val_binary_accuracy: 0.6778\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6698 - val_loss: 0.6033 - val_binary_accuracy: 0.6726\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6650 - val_loss: 0.6010 - val_binary_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6740 - val_loss: 0.6017 - val_binary_accuracy: 0.6737\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6659 - val_loss: 0.6022 - val_binary_accuracy: 0.6722\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6684 - val_loss: 0.6011 - val_binary_accuracy: 0.6700\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6736 - val_loss: 0.6015 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6714 - val_loss: 0.6024 - val_binary_accuracy: 0.6696\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6699 - val_loss: 0.6008 - val_binary_accuracy: 0.6719\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6725 - val_loss: 0.6001 - val_binary_accuracy: 0.6689\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6752 - val_loss: 0.6009 - val_binary_accuracy: 0.6707\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6765 - val_loss: 0.6015 - val_binary_accuracy: 0.6700\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6729 - val_loss: 0.5999 - val_binary_accuracy: 0.6663\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6752 - val_loss: 0.6014 - val_binary_accuracy: 0.6707\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6739 - val_loss: 0.6012 - val_binary_accuracy: 0.6707\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6757 - val_loss: 0.6009 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6748 - val_loss: 0.5996 - val_binary_accuracy: 0.6737\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6768 - val_loss: 0.6003 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6780 - val_loss: 0.6016 - val_binary_accuracy: 0.6745\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6788 - val_loss: 0.5999 - val_binary_accuracy: 0.6696\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5940 - binary_accuracy: 0.6803 - val_loss: 0.5988 - val_binary_accuracy: 0.6770\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6792 - val_loss: 0.6001 - val_binary_accuracy: 0.6711\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6779 - val_loss: 0.6002 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5933 - binary_accuracy: 0.6776 - val_loss: 0.6007 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5929 - binary_accuracy: 0.6787 - val_loss: 0.6013 - val_binary_accuracy: 0.6685\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6819 - val_loss: 0.6016 - val_binary_accuracy: 0.6711\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6798 - val_loss: 0.6011 - val_binary_accuracy: 0.6693\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6783 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5896 - binary_accuracy: 0.6854 - val_loss: 0.6013 - val_binary_accuracy: 0.6748\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6824 - val_loss: 0.6008 - val_binary_accuracy: 0.6719\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5920 - binary_accuracy: 0.6818 - val_loss: 0.6016 - val_binary_accuracy: 0.6715\n",
            "Epoch 00038: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:17:49,806]\u001b[0m Trial 1 finished with value: 0.6664195656776428 and parameters: {'batch size': 178, 'optimizer': 'Adagrad', 'lr': 0.09370249316618479, 'minimum_learning_rate': 0.08117722275711566}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "74/74 [==============================] - 1s 3ms/step - loss: 0.6745 - binary_accuracy: 0.6037 - val_loss: 0.6393 - val_binary_accuracy: 0.6437\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6364 - binary_accuracy: 0.6327 - val_loss: 0.6166 - val_binary_accuracy: 0.6644\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6428 - val_loss: 0.6096 - val_binary_accuracy: 0.6715\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6491 - val_loss: 0.6074 - val_binary_accuracy: 0.6770\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6525 - val_loss: 0.6068 - val_binary_accuracy: 0.6707\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6551 - val_loss: 0.6061 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6570 - val_loss: 0.6055 - val_binary_accuracy: 0.6730\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6600 - val_loss: 0.6033 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6614 - val_loss: 0.6034 - val_binary_accuracy: 0.6674\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6648 - val_loss: 0.6029 - val_binary_accuracy: 0.6782\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6636 - val_loss: 0.6040 - val_binary_accuracy: 0.6733\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6636 - val_loss: 0.6028 - val_binary_accuracy: 0.6693\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6644 - val_loss: 0.6020 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6759 - val_loss: 0.6018 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6667 - val_loss: 0.6006 - val_binary_accuracy: 0.6741\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6691 - val_loss: 0.6017 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6714 - val_loss: 0.6009 - val_binary_accuracy: 0.6741\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6702 - val_loss: 0.6025 - val_binary_accuracy: 0.6756\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6741 - val_loss: 0.6016 - val_binary_accuracy: 0.6726\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6742 - val_loss: 0.6009 - val_binary_accuracy: 0.6763\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6713 - val_loss: 0.6005 - val_binary_accuracy: 0.6748\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6734 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6733 - val_loss: 0.6001 - val_binary_accuracy: 0.6752\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6736 - val_loss: 0.6002 - val_binary_accuracy: 0.6763\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6768 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6782 - val_loss: 0.6004 - val_binary_accuracy: 0.6748\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6761 - val_loss: 0.6006 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6776 - val_loss: 0.6003 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6779 - val_loss: 0.6003 - val_binary_accuracy: 0.6730\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6728 - val_loss: 0.6003 - val_binary_accuracy: 0.6763\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6791 - val_loss: 0.6003 - val_binary_accuracy: 0.6767\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6730 - val_loss: 0.6006 - val_binary_accuracy: 0.6745\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6745 - val_loss: 0.6008 - val_binary_accuracy: 0.6748\n",
            "Epoch 00033: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:00,533]\u001b[0m Trial 2 finished with value: 0.6679021716117859 and parameters: {'batch size': 172, 'optimizer': 'Adagrad', 'lr': 0.06934313374234799, 'minimum_learning_rate': 0.01449154567836865}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "69/69 [==============================] - 1s 4ms/step - loss: 0.6723 - binary_accuracy: 0.5820 - val_loss: 0.6332 - val_binary_accuracy: 0.6415\n",
            "Epoch 2/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6458 - binary_accuracy: 0.6195 - val_loss: 0.6236 - val_binary_accuracy: 0.6559\n",
            "Epoch 3/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6333 - val_loss: 0.6169 - val_binary_accuracy: 0.6618\n",
            "Epoch 4/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6392 - val_loss: 0.6120 - val_binary_accuracy: 0.6726\n",
            "Epoch 5/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6467 - val_loss: 0.6092 - val_binary_accuracy: 0.6711\n",
            "Epoch 6/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6551 - val_loss: 0.6049 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6594 - val_loss: 0.6057 - val_binary_accuracy: 0.6726\n",
            "Epoch 8/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6616 - val_loss: 0.6031 - val_binary_accuracy: 0.6700\n",
            "Epoch 9/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6551 - val_loss: 0.6039 - val_binary_accuracy: 0.6700\n",
            "Epoch 10/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6593 - val_loss: 0.6033 - val_binary_accuracy: 0.6733\n",
            "Epoch 11/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6583 - val_loss: 0.6024 - val_binary_accuracy: 0.6715\n",
            "Epoch 12/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6675 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 13/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6649 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6633 - val_loss: 0.6018 - val_binary_accuracy: 0.6756\n",
            "Epoch 15/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6672 - val_loss: 0.6017 - val_binary_accuracy: 0.6789\n",
            "Epoch 16/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6680 - val_loss: 0.6028 - val_binary_accuracy: 0.6726\n",
            "Epoch 17/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6675 - val_loss: 0.6011 - val_binary_accuracy: 0.6774\n",
            "Epoch 18/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6715 - val_loss: 0.6018 - val_binary_accuracy: 0.6722\n",
            "Epoch 19/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6663 - val_loss: 0.6009 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6671 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6707 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 22/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6737 - val_loss: 0.6003 - val_binary_accuracy: 0.6752\n",
            "Epoch 23/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6756 - val_loss: 0.6005 - val_binary_accuracy: 0.6756\n",
            "Epoch 24/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6729 - val_loss: 0.5992 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6692 - val_loss: 0.6013 - val_binary_accuracy: 0.6737\n",
            "Epoch 26/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6728 - val_loss: 0.5990 - val_binary_accuracy: 0.6767\n",
            "Epoch 27/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6763 - val_loss: 0.5985 - val_binary_accuracy: 0.6748\n",
            "Epoch 28/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6704 - val_loss: 0.5991 - val_binary_accuracy: 0.6741\n",
            "Epoch 29/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6775 - val_loss: 0.5998 - val_binary_accuracy: 0.6726\n",
            "Epoch 30/200\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6748 - val_loss: 0.5996 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6752 - val_loss: 0.5985 - val_binary_accuracy: 0.6748\n",
            "Epoch 32/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6784 - val_loss: 0.5987 - val_binary_accuracy: 0.6745\n",
            "Epoch 33/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6776 - val_loss: 0.5986 - val_binary_accuracy: 0.6756\n",
            "Epoch 34/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6777 - val_loss: 0.5988 - val_binary_accuracy: 0.6763\n",
            "Epoch 35/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6800 - val_loss: 0.5981 - val_binary_accuracy: 0.6774\n",
            "Epoch 36/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6794 - val_loss: 0.5981 - val_binary_accuracy: 0.6752\n",
            "Epoch 37/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6774 - val_loss: 0.5980 - val_binary_accuracy: 0.6770\n",
            "Epoch 38/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6756 - val_loss: 0.5983 - val_binary_accuracy: 0.6748\n",
            "Epoch 39/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6805 - val_loss: 0.5979 - val_binary_accuracy: 0.6778\n",
            "Epoch 40/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6806 - val_loss: 0.5980 - val_binary_accuracy: 0.6789\n",
            "Epoch 41/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6764 - val_loss: 0.5977 - val_binary_accuracy: 0.6778\n",
            "Epoch 42/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6765 - val_loss: 0.5979 - val_binary_accuracy: 0.6811\n",
            "Epoch 43/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6776 - val_loss: 0.5979 - val_binary_accuracy: 0.6808\n",
            "Epoch 44/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6750 - val_loss: 0.5982 - val_binary_accuracy: 0.6789\n",
            "Epoch 45/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6824 - val_loss: 0.5980 - val_binary_accuracy: 0.6796\n",
            "Epoch 46/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6791 - val_loss: 0.5985 - val_binary_accuracy: 0.6804\n",
            "Epoch 47/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6769 - val_loss: 0.5986 - val_binary_accuracy: 0.6782\n",
            "Epoch 48/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6752 - val_loss: 0.5983 - val_binary_accuracy: 0.6778\n",
            "Epoch 49/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6805 - val_loss: 0.5986 - val_binary_accuracy: 0.6763\n",
            "Epoch 50/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6785 - val_loss: 0.5985 - val_binary_accuracy: 0.6770\n",
            "Epoch 51/200\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6787 - val_loss: 0.5982 - val_binary_accuracy: 0.6778\n",
            "Epoch 00051: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:11,249]\u001b[0m Trial 3 finished with value: 0.664195716381073 and parameters: {'batch size': 184, 'optimizer': 'Adagrad', 'lr': 0.057284492360588954, 'minimum_learning_rate': 0.036888549851675126}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.6954 - binary_accuracy: 0.5684 - val_loss: 0.6482 - val_binary_accuracy: 0.6129\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6641 - binary_accuracy: 0.5995 - val_loss: 0.6386 - val_binary_accuracy: 0.6259\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6536 - binary_accuracy: 0.6080 - val_loss: 0.6321 - val_binary_accuracy: 0.6403\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6454 - binary_accuracy: 0.6167 - val_loss: 0.6280 - val_binary_accuracy: 0.6478\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6435 - binary_accuracy: 0.6220 - val_loss: 0.6251 - val_binary_accuracy: 0.6504\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6393 - binary_accuracy: 0.6248 - val_loss: 0.6220 - val_binary_accuracy: 0.6552\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6312 - val_loss: 0.6199 - val_binary_accuracy: 0.6552\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6362 - val_loss: 0.6175 - val_binary_accuracy: 0.6567\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6414 - val_loss: 0.6158 - val_binary_accuracy: 0.6574\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6341 - val_loss: 0.6149 - val_binary_accuracy: 0.6607\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6425 - val_loss: 0.6130 - val_binary_accuracy: 0.6637\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6414 - val_loss: 0.6113 - val_binary_accuracy: 0.6663\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6472 - val_loss: 0.6108 - val_binary_accuracy: 0.6611\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6463 - val_loss: 0.6099 - val_binary_accuracy: 0.6644\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6511 - val_loss: 0.6085 - val_binary_accuracy: 0.6685\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6521 - val_loss: 0.6080 - val_binary_accuracy: 0.6659\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6528 - val_loss: 0.6074 - val_binary_accuracy: 0.6674\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6497 - val_loss: 0.6072 - val_binary_accuracy: 0.6696\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6520 - val_loss: 0.6063 - val_binary_accuracy: 0.6681\n",
            "Epoch 20/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6562 - val_loss: 0.6060 - val_binary_accuracy: 0.6681\n",
            "Epoch 21/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6567 - val_loss: 0.6053 - val_binary_accuracy: 0.6700\n",
            "Epoch 22/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6549 - val_loss: 0.6051 - val_binary_accuracy: 0.6704\n",
            "Epoch 23/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6555 - val_loss: 0.6049 - val_binary_accuracy: 0.6685\n",
            "Epoch 24/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6606 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 25/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6626 - val_loss: 0.6034 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6590 - val_loss: 0.6035 - val_binary_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6597 - val_loss: 0.6034 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6563 - val_loss: 0.6034 - val_binary_accuracy: 0.6745\n",
            "Epoch 29/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6599 - val_loss: 0.6032 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6631 - val_loss: 0.6032 - val_binary_accuracy: 0.6745\n",
            "Epoch 31/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6625 - val_loss: 0.6027 - val_binary_accuracy: 0.6778\n",
            "Epoch 32/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6601 - val_loss: 0.6026 - val_binary_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6582 - val_loss: 0.6027 - val_binary_accuracy: 0.6752\n",
            "Epoch 34/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6625 - val_loss: 0.6025 - val_binary_accuracy: 0.6770\n",
            "Epoch 35/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6594 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6621 - val_loss: 0.6024 - val_binary_accuracy: 0.6756\n",
            "Epoch 37/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6609 - val_loss: 0.6024 - val_binary_accuracy: 0.6759\n",
            "Epoch 38/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6674 - val_loss: 0.6023 - val_binary_accuracy: 0.6770\n",
            "Epoch 39/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6626 - val_loss: 0.6021 - val_binary_accuracy: 0.6774\n",
            "Epoch 40/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6652 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 41/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6604 - val_loss: 0.6019 - val_binary_accuracy: 0.6782\n",
            "Epoch 42/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6625 - val_loss: 0.6021 - val_binary_accuracy: 0.6770\n",
            "Epoch 43/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6684 - val_loss: 0.6021 - val_binary_accuracy: 0.6763\n",
            "Epoch 44/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6647 - val_loss: 0.6019 - val_binary_accuracy: 0.6785\n",
            "Epoch 45/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6624 - val_loss: 0.6017 - val_binary_accuracy: 0.6785\n",
            "Epoch 46/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6633 - val_loss: 0.6016 - val_binary_accuracy: 0.6800\n",
            "Epoch 47/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6659 - val_loss: 0.6015 - val_binary_accuracy: 0.6785\n",
            "Epoch 48/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6675 - val_loss: 0.6014 - val_binary_accuracy: 0.6789\n",
            "Epoch 49/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6633 - val_loss: 0.6014 - val_binary_accuracy: 0.6804\n",
            "Epoch 50/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6634 - val_loss: 0.6015 - val_binary_accuracy: 0.6800\n",
            "Epoch 51/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6652 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 52/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6728 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 53/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6676 - val_loss: 0.6015 - val_binary_accuracy: 0.6789\n",
            "Epoch 54/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6694 - val_loss: 0.6014 - val_binary_accuracy: 0.6782\n",
            "Epoch 55/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6651 - val_loss: 0.6013 - val_binary_accuracy: 0.6796\n",
            "Epoch 56/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6669 - val_loss: 0.6015 - val_binary_accuracy: 0.6800\n",
            "Epoch 57/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6685 - val_loss: 0.6013 - val_binary_accuracy: 0.6789\n",
            "Epoch 58/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6651 - val_loss: 0.6013 - val_binary_accuracy: 0.6793\n",
            "Epoch 59/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6686 - val_loss: 0.6012 - val_binary_accuracy: 0.6789\n",
            "Epoch 60/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6640 - val_loss: 0.6011 - val_binary_accuracy: 0.6793\n",
            "Epoch 61/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6714 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "Epoch 62/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6637 - val_loss: 0.6012 - val_binary_accuracy: 0.6789\n",
            "Epoch 63/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6671 - val_loss: 0.6012 - val_binary_accuracy: 0.6789\n",
            "Epoch 64/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6699 - val_loss: 0.6012 - val_binary_accuracy: 0.6778\n",
            "Epoch 65/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6674 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "Epoch 66/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6734 - val_loss: 0.6011 - val_binary_accuracy: 0.6770\n",
            "Epoch 67/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6676 - val_loss: 0.6011 - val_binary_accuracy: 0.6785\n",
            "Epoch 68/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6675 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 69/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6698 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 70/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6724 - val_loss: 0.6008 - val_binary_accuracy: 0.6793\n",
            "Epoch 71/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6725 - val_loss: 0.6009 - val_binary_accuracy: 0.6785\n",
            "Epoch 72/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6667 - val_loss: 0.6007 - val_binary_accuracy: 0.6785\n",
            "Epoch 73/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6714 - val_loss: 0.6007 - val_binary_accuracy: 0.6796\n",
            "Epoch 74/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6713 - val_loss: 0.6006 - val_binary_accuracy: 0.6782\n",
            "Epoch 75/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6723 - val_loss: 0.6007 - val_binary_accuracy: 0.6785\n",
            "Epoch 76/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6729 - val_loss: 0.6006 - val_binary_accuracy: 0.6782\n",
            "Epoch 77/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6689 - val_loss: 0.6005 - val_binary_accuracy: 0.6759\n",
            "Epoch 78/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6699 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 79/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6656 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 80/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6738 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 81/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6671 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 82/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6729 - val_loss: 0.6006 - val_binary_accuracy: 0.6778\n",
            "Epoch 83/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6670 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 84/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6671 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 85/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6708 - val_loss: 0.6005 - val_binary_accuracy: 0.6774\n",
            "Epoch 86/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6702 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 87/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6749 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 88/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6663 - val_loss: 0.6005 - val_binary_accuracy: 0.6778\n",
            "Epoch 00088: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:32,558]\u001b[0m Trial 4 finished with value: 0.6697553992271423 and parameters: {'batch size': 186, 'optimizer': 'Adagrad', 'lr': 0.017527372245750135, 'minimum_learning_rate': 0.01023223447336114}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "67/67 [==============================] - 1s 4ms/step - loss: 0.6705 - binary_accuracy: 0.5974 - val_loss: 0.6331 - val_binary_accuracy: 0.6344\n",
            "Epoch 2/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6376 - binary_accuracy: 0.6244 - val_loss: 0.6199 - val_binary_accuracy: 0.6593\n",
            "Epoch 3/200\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.6276 - binary_accuracy: 0.6466 - val_loss: 0.6130 - val_binary_accuracy: 0.6663\n",
            "Epoch 4/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6455 - val_loss: 0.6089 - val_binary_accuracy: 0.6707\n",
            "Epoch 5/200\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6490 - val_loss: 0.6095 - val_binary_accuracy: 0.6722\n",
            "Epoch 6/200\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6578 - val_loss: 0.6072 - val_binary_accuracy: 0.6711\n",
            "Epoch 7/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6613 - val_loss: 0.6061 - val_binary_accuracy: 0.6733\n",
            "Epoch 8/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6582 - val_loss: 0.6045 - val_binary_accuracy: 0.6774\n",
            "Epoch 9/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6634 - val_loss: 0.6052 - val_binary_accuracy: 0.6745\n",
            "Epoch 10/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6096 - binary_accuracy: 0.6587 - val_loss: 0.6043 - val_binary_accuracy: 0.6707\n",
            "Epoch 11/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6672 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6653 - val_loss: 0.6038 - val_binary_accuracy: 0.6730\n",
            "Epoch 13/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6686 - val_loss: 0.6040 - val_binary_accuracy: 0.6681\n",
            "Epoch 14/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6706 - val_loss: 0.6031 - val_binary_accuracy: 0.6748\n",
            "Epoch 15/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6683 - val_loss: 0.6024 - val_binary_accuracy: 0.6759\n",
            "Epoch 16/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6684 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 17/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6640 - val_loss: 0.6026 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6715 - val_loss: 0.6031 - val_binary_accuracy: 0.6685\n",
            "Epoch 19/200\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6728 - val_loss: 0.6028 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6726 - val_loss: 0.6028 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6739 - val_loss: 0.6031 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6706 - val_loss: 0.6022 - val_binary_accuracy: 0.6696\n",
            "Epoch 23/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6710 - val_loss: 0.6027 - val_binary_accuracy: 0.6737\n",
            "Epoch 24/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6779 - val_loss: 0.6022 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6743 - val_loss: 0.6021 - val_binary_accuracy: 0.6726\n",
            "Epoch 26/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6710 - val_loss: 0.6016 - val_binary_accuracy: 0.6730\n",
            "Epoch 27/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6744 - val_loss: 0.6022 - val_binary_accuracy: 0.6767\n",
            "Epoch 28/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6729 - val_loss: 0.6031 - val_binary_accuracy: 0.6730\n",
            "Epoch 29/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6753 - val_loss: 0.6026 - val_binary_accuracy: 0.6719\n",
            "Epoch 30/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6737 - val_loss: 0.6029 - val_binary_accuracy: 0.6719\n",
            "Epoch 31/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6774 - val_loss: 0.6022 - val_binary_accuracy: 0.6722\n",
            "Epoch 32/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6720 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 33/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6753 - val_loss: 0.6021 - val_binary_accuracy: 0.6707\n",
            "Epoch 34/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6756 - val_loss: 0.6027 - val_binary_accuracy: 0.6693\n",
            "Epoch 35/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6782 - val_loss: 0.6022 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6723 - val_loss: 0.6023 - val_binary_accuracy: 0.6730\n",
            "Epoch 00036: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:38,965]\u001b[0m Trial 5 finished with value: 0.6686434149742126 and parameters: {'batch size': 188, 'optimizer': 'Adagrad', 'lr': 0.07961598025192826, 'minimum_learning_rate': 0.053592826478042026}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.6600 - binary_accuracy: 0.6091 - val_loss: 0.6183 - val_binary_accuracy: 0.6589\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6316 - val_loss: 0.6121 - val_binary_accuracy: 0.6674\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6457 - val_loss: 0.6077 - val_binary_accuracy: 0.6719\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6526 - val_loss: 0.6070 - val_binary_accuracy: 0.6759\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6597 - val_loss: 0.6067 - val_binary_accuracy: 0.6730\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6594 - val_loss: 0.6050 - val_binary_accuracy: 0.6707\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6626 - val_loss: 0.6037 - val_binary_accuracy: 0.6770\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6638 - val_loss: 0.6031 - val_binary_accuracy: 0.6785\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6699 - val_loss: 0.6025 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6680 - val_loss: 0.6035 - val_binary_accuracy: 0.6748\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6677 - val_loss: 0.6056 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6693 - val_loss: 0.6033 - val_binary_accuracy: 0.6752\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6725 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6755 - val_loss: 0.6034 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6694 - val_loss: 0.6035 - val_binary_accuracy: 0.6707\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6752 - val_loss: 0.6032 - val_binary_accuracy: 0.6700\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6747 - val_loss: 0.6035 - val_binary_accuracy: 0.6759\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6768 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6772 - val_loss: 0.6026 - val_binary_accuracy: 0.6696\n",
            "Epoch 00019: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:44,598]\u001b[0m Trial 6 finished with value: 0.6690140962600708 and parameters: {'batch size': 101, 'optimizer': 'Adagrad', 'lr': 0.0659102222563784, 'minimum_learning_rate': 0.06249321367297081}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "59/59 [==============================] - 1s 4ms/step - loss: 0.6928 - binary_accuracy: 0.5713 - val_loss: 0.6517 - val_binary_accuracy: 0.6151\n",
            "Epoch 2/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6604 - binary_accuracy: 0.6074 - val_loss: 0.6443 - val_binary_accuracy: 0.6311\n",
            "Epoch 3/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6527 - binary_accuracy: 0.6161 - val_loss: 0.6337 - val_binary_accuracy: 0.6485\n",
            "Epoch 4/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6396 - binary_accuracy: 0.6286 - val_loss: 0.6296 - val_binary_accuracy: 0.6533\n",
            "Epoch 5/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6369 - binary_accuracy: 0.6367 - val_loss: 0.6238 - val_binary_accuracy: 0.6570\n",
            "Epoch 6/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6310 - val_loss: 0.6206 - val_binary_accuracy: 0.6552\n",
            "Epoch 7/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6334 - val_loss: 0.6183 - val_binary_accuracy: 0.6600\n",
            "Epoch 8/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6462 - val_loss: 0.6190 - val_binary_accuracy: 0.6652\n",
            "Epoch 9/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6435 - val_loss: 0.6166 - val_binary_accuracy: 0.6656\n",
            "Epoch 10/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6241 - binary_accuracy: 0.6490 - val_loss: 0.6146 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6467 - val_loss: 0.6150 - val_binary_accuracy: 0.6633\n",
            "Epoch 12/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6547 - val_loss: 0.6133 - val_binary_accuracy: 0.6678\n",
            "Epoch 13/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6241 - binary_accuracy: 0.6463 - val_loss: 0.6122 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6536 - val_loss: 0.6107 - val_binary_accuracy: 0.6733\n",
            "Epoch 15/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6553 - val_loss: 0.6087 - val_binary_accuracy: 0.6782\n",
            "Epoch 16/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6165 - binary_accuracy: 0.6543 - val_loss: 0.6140 - val_binary_accuracy: 0.6685\n",
            "Epoch 17/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6556 - val_loss: 0.6113 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6604 - val_loss: 0.6100 - val_binary_accuracy: 0.6715\n",
            "Epoch 19/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6588 - val_loss: 0.6100 - val_binary_accuracy: 0.6663\n",
            "Epoch 20/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6551 - val_loss: 0.6101 - val_binary_accuracy: 0.6674\n",
            "Epoch 21/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6616 - val_loss: 0.6078 - val_binary_accuracy: 0.6711\n",
            "Epoch 22/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6594 - val_loss: 0.6070 - val_binary_accuracy: 0.6733\n",
            "Epoch 23/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6592 - val_loss: 0.6068 - val_binary_accuracy: 0.6696\n",
            "Epoch 24/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6615 - val_loss: 0.6064 - val_binary_accuracy: 0.6711\n",
            "Epoch 25/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6644 - val_loss: 0.6054 - val_binary_accuracy: 0.6737\n",
            "Epoch 26/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6618 - val_loss: 0.6068 - val_binary_accuracy: 0.6722\n",
            "Epoch 27/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6585 - val_loss: 0.6061 - val_binary_accuracy: 0.6759\n",
            "Epoch 28/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6593 - val_loss: 0.6060 - val_binary_accuracy: 0.6763\n",
            "Epoch 29/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6648 - val_loss: 0.6059 - val_binary_accuracy: 0.6756\n",
            "Epoch 30/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6598 - val_loss: 0.6060 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6582 - val_loss: 0.6065 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6616 - val_loss: 0.6053 - val_binary_accuracy: 0.6778\n",
            "Epoch 33/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6596 - val_loss: 0.6049 - val_binary_accuracy: 0.6793\n",
            "Epoch 34/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6604 - val_loss: 0.6049 - val_binary_accuracy: 0.6767\n",
            "Epoch 35/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6650 - val_loss: 0.6040 - val_binary_accuracy: 0.6808\n",
            "Epoch 36/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6649 - val_loss: 0.6041 - val_binary_accuracy: 0.6767\n",
            "Epoch 37/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6629 - val_loss: 0.6077 - val_binary_accuracy: 0.6759\n",
            "Epoch 38/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6669 - val_loss: 0.6056 - val_binary_accuracy: 0.6741\n",
            "Epoch 39/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6605 - val_loss: 0.6053 - val_binary_accuracy: 0.6782\n",
            "Epoch 40/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6605 - val_loss: 0.6050 - val_binary_accuracy: 0.6756\n",
            "Epoch 41/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6702 - val_loss: 0.6041 - val_binary_accuracy: 0.6782\n",
            "Epoch 42/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6677 - val_loss: 0.6041 - val_binary_accuracy: 0.6774\n",
            "Epoch 43/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6702 - val_loss: 0.6043 - val_binary_accuracy: 0.6785\n",
            "Epoch 44/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6660 - val_loss: 0.6039 - val_binary_accuracy: 0.6789\n",
            "Epoch 45/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6646 - val_loss: 0.6039 - val_binary_accuracy: 0.6782\n",
            "Epoch 46/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6630 - val_loss: 0.6040 - val_binary_accuracy: 0.6785\n",
            "Epoch 47/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6682 - val_loss: 0.6036 - val_binary_accuracy: 0.6804\n",
            "Epoch 48/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6646 - val_loss: 0.6037 - val_binary_accuracy: 0.6804\n",
            "Epoch 49/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6663 - val_loss: 0.6034 - val_binary_accuracy: 0.6785\n",
            "Epoch 50/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6689 - val_loss: 0.6030 - val_binary_accuracy: 0.6796\n",
            "Epoch 51/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6666 - val_loss: 0.6037 - val_binary_accuracy: 0.6767\n",
            "Epoch 52/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6694 - val_loss: 0.6035 - val_binary_accuracy: 0.6770\n",
            "Epoch 53/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6710 - val_loss: 0.6037 - val_binary_accuracy: 0.6782\n",
            "Epoch 54/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6665 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 55/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6683 - val_loss: 0.6038 - val_binary_accuracy: 0.6759\n",
            "Epoch 56/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6678 - val_loss: 0.6035 - val_binary_accuracy: 0.6763\n",
            "Epoch 57/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6671 - val_loss: 0.6035 - val_binary_accuracy: 0.6763\n",
            "Epoch 58/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6703 - val_loss: 0.6036 - val_binary_accuracy: 0.6759\n",
            "Epoch 59/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6663 - val_loss: 0.6031 - val_binary_accuracy: 0.6752\n",
            "Epoch 60/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6691 - val_loss: 0.6028 - val_binary_accuracy: 0.6756\n",
            "Epoch 61/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6680 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 62/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6726 - val_loss: 0.6030 - val_binary_accuracy: 0.6730\n",
            "Epoch 63/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6663 - val_loss: 0.6034 - val_binary_accuracy: 0.6748\n",
            "Epoch 64/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6683 - val_loss: 0.6037 - val_binary_accuracy: 0.6745\n",
            "Epoch 65/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6652 - val_loss: 0.6034 - val_binary_accuracy: 0.6733\n",
            "Epoch 66/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6697 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 67/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6694 - val_loss: 0.6054 - val_binary_accuracy: 0.6726\n",
            "Epoch 68/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6714 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 69/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6709 - val_loss: 0.6027 - val_binary_accuracy: 0.6774\n",
            "Epoch 70/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6710 - val_loss: 0.6025 - val_binary_accuracy: 0.6789\n",
            "Epoch 71/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6736 - val_loss: 0.6030 - val_binary_accuracy: 0.6767\n",
            "Epoch 72/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6731 - val_loss: 0.6025 - val_binary_accuracy: 0.6770\n",
            "Epoch 73/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6730 - val_loss: 0.6025 - val_binary_accuracy: 0.6785\n",
            "Epoch 74/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6684 - val_loss: 0.6025 - val_binary_accuracy: 0.6785\n",
            "Epoch 75/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6707 - val_loss: 0.6028 - val_binary_accuracy: 0.6759\n",
            "Epoch 76/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6738 - val_loss: 0.6030 - val_binary_accuracy: 0.6752\n",
            "Epoch 77/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6725 - val_loss: 0.6028 - val_binary_accuracy: 0.6756\n",
            "Epoch 78/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6687 - val_loss: 0.6024 - val_binary_accuracy: 0.6767\n",
            "Epoch 79/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6684 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 80/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6736 - val_loss: 0.6028 - val_binary_accuracy: 0.6737\n",
            "Epoch 81/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6703 - val_loss: 0.6025 - val_binary_accuracy: 0.6745\n",
            "Epoch 82/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6773 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 83/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6715 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 84/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6687 - val_loss: 0.6036 - val_binary_accuracy: 0.6741\n",
            "Epoch 85/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6734 - val_loss: 0.6031 - val_binary_accuracy: 0.6715\n",
            "Epoch 86/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6741 - val_loss: 0.6027 - val_binary_accuracy: 0.6719\n",
            "Epoch 87/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6749 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 88/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6677 - val_loss: 0.6031 - val_binary_accuracy: 0.6711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:18:59,082]\u001b[0m Trial 7 finished with value: 0.6597479581832886 and parameters: {'batch size': 217, 'optimizer': 'Adagrad', 'lr': 0.024398377388710812, 'minimum_learning_rate': 0.014870930733935684}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00088: early stopping\n",
            "Epoch 1/200\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 0.7208 - binary_accuracy: 0.5484 - val_loss: 0.6548 - val_binary_accuracy: 0.6188\n",
            "Epoch 2/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6772 - binary_accuracy: 0.5833 - val_loss: 0.6471 - val_binary_accuracy: 0.6266\n",
            "Epoch 3/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6633 - binary_accuracy: 0.5993 - val_loss: 0.6432 - val_binary_accuracy: 0.6333\n",
            "Epoch 4/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6583 - binary_accuracy: 0.6049 - val_loss: 0.6405 - val_binary_accuracy: 0.6355\n",
            "Epoch 5/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6504 - binary_accuracy: 0.6161 - val_loss: 0.6379 - val_binary_accuracy: 0.6392\n",
            "Epoch 6/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6478 - binary_accuracy: 0.6198 - val_loss: 0.6359 - val_binary_accuracy: 0.6385\n",
            "Epoch 7/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6434 - binary_accuracy: 0.6212 - val_loss: 0.6336 - val_binary_accuracy: 0.6392\n",
            "Epoch 8/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6461 - binary_accuracy: 0.6236 - val_loss: 0.6319 - val_binary_accuracy: 0.6433\n",
            "Epoch 9/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6414 - binary_accuracy: 0.6204 - val_loss: 0.6298 - val_binary_accuracy: 0.6440\n",
            "Epoch 10/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6315 - val_loss: 0.6279 - val_binary_accuracy: 0.6492\n",
            "Epoch 11/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6379 - binary_accuracy: 0.6259 - val_loss: 0.6265 - val_binary_accuracy: 0.6504\n",
            "Epoch 12/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6336 - val_loss: 0.6252 - val_binary_accuracy: 0.6522\n",
            "Epoch 13/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6370 - val_loss: 0.6233 - val_binary_accuracy: 0.6537\n",
            "Epoch 14/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6402 - val_loss: 0.6221 - val_binary_accuracy: 0.6563\n",
            "Epoch 15/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6385 - val_loss: 0.6210 - val_binary_accuracy: 0.6548\n",
            "Epoch 16/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6424 - val_loss: 0.6198 - val_binary_accuracy: 0.6552\n",
            "Epoch 17/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6448 - val_loss: 0.6186 - val_binary_accuracy: 0.6552\n",
            "Epoch 18/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6422 - val_loss: 0.6175 - val_binary_accuracy: 0.6581\n",
            "Epoch 19/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6457 - val_loss: 0.6167 - val_binary_accuracy: 0.6600\n",
            "Epoch 20/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6426 - val_loss: 0.6162 - val_binary_accuracy: 0.6596\n",
            "Epoch 21/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6447 - val_loss: 0.6156 - val_binary_accuracy: 0.6630\n",
            "Epoch 22/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6439 - val_loss: 0.6148 - val_binary_accuracy: 0.6630\n",
            "Epoch 23/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6477 - val_loss: 0.6141 - val_binary_accuracy: 0.6604\n",
            "Epoch 24/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6505 - val_loss: 0.6135 - val_binary_accuracy: 0.6618\n",
            "Epoch 25/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6532 - val_loss: 0.6128 - val_binary_accuracy: 0.6659\n",
            "Epoch 26/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6510 - val_loss: 0.6124 - val_binary_accuracy: 0.6652\n",
            "Epoch 27/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6542 - val_loss: 0.6119 - val_binary_accuracy: 0.6667\n",
            "Epoch 28/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6460 - val_loss: 0.6114 - val_binary_accuracy: 0.6670\n",
            "Epoch 29/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6560 - val_loss: 0.6110 - val_binary_accuracy: 0.6667\n",
            "Epoch 30/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6549 - val_loss: 0.6105 - val_binary_accuracy: 0.6693\n",
            "Epoch 31/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6524 - val_loss: 0.6106 - val_binary_accuracy: 0.6674\n",
            "Epoch 32/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6544 - val_loss: 0.6101 - val_binary_accuracy: 0.6707\n",
            "Epoch 33/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6575 - val_loss: 0.6096 - val_binary_accuracy: 0.6681\n",
            "Epoch 34/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6561 - val_loss: 0.6095 - val_binary_accuracy: 0.6693\n",
            "Epoch 35/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6551 - val_loss: 0.6092 - val_binary_accuracy: 0.6693\n",
            "Epoch 36/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6579 - val_loss: 0.6087 - val_binary_accuracy: 0.6704\n",
            "Epoch 37/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6656 - val_loss: 0.6082 - val_binary_accuracy: 0.6693\n",
            "Epoch 38/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6586 - val_loss: 0.6082 - val_binary_accuracy: 0.6681\n",
            "Epoch 39/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6589 - val_loss: 0.6081 - val_binary_accuracy: 0.6685\n",
            "Epoch 40/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6581 - val_loss: 0.6077 - val_binary_accuracy: 0.6693\n",
            "Epoch 41/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6553 - val_loss: 0.6076 - val_binary_accuracy: 0.6693\n",
            "Epoch 42/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6609 - val_loss: 0.6074 - val_binary_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6591 - val_loss: 0.6072 - val_binary_accuracy: 0.6700\n",
            "Epoch 44/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6621 - val_loss: 0.6069 - val_binary_accuracy: 0.6689\n",
            "Epoch 45/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6585 - val_loss: 0.6066 - val_binary_accuracy: 0.6707\n",
            "Epoch 46/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6609 - val_loss: 0.6064 - val_binary_accuracy: 0.6704\n",
            "Epoch 47/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6658 - val_loss: 0.6061 - val_binary_accuracy: 0.6707\n",
            "Epoch 48/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6658 - val_loss: 0.6061 - val_binary_accuracy: 0.6670\n",
            "Epoch 49/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6633 - val_loss: 0.6058 - val_binary_accuracy: 0.6707\n",
            "Epoch 50/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6687 - val_loss: 0.6058 - val_binary_accuracy: 0.6711\n",
            "Epoch 51/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6592 - val_loss: 0.6058 - val_binary_accuracy: 0.6707\n",
            "Epoch 52/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6610 - val_loss: 0.6057 - val_binary_accuracy: 0.6678\n",
            "Epoch 53/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6607 - val_loss: 0.6055 - val_binary_accuracy: 0.6670\n",
            "Epoch 54/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6656 - val_loss: 0.6053 - val_binary_accuracy: 0.6696\n",
            "Epoch 55/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6690 - val_loss: 0.6051 - val_binary_accuracy: 0.6715\n",
            "Epoch 56/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6661 - val_loss: 0.6051 - val_binary_accuracy: 0.6722\n",
            "Epoch 57/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6629 - val_loss: 0.6051 - val_binary_accuracy: 0.6722\n",
            "Epoch 58/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6633 - val_loss: 0.6050 - val_binary_accuracy: 0.6737\n",
            "Epoch 59/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6700 - val_loss: 0.6049 - val_binary_accuracy: 0.6722\n",
            "Epoch 60/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6625 - val_loss: 0.6049 - val_binary_accuracy: 0.6722\n",
            "Epoch 61/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6687 - val_loss: 0.6048 - val_binary_accuracy: 0.6700\n",
            "Epoch 62/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6617 - val_loss: 0.6047 - val_binary_accuracy: 0.6700\n",
            "Epoch 63/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6640 - val_loss: 0.6048 - val_binary_accuracy: 0.6704\n",
            "Epoch 64/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6716 - val_loss: 0.6046 - val_binary_accuracy: 0.6711\n",
            "Epoch 65/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6698 - val_loss: 0.6045 - val_binary_accuracy: 0.6693\n",
            "Epoch 66/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6673 - val_loss: 0.6044 - val_binary_accuracy: 0.6696\n",
            "Epoch 67/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6660 - val_loss: 0.6043 - val_binary_accuracy: 0.6693\n",
            "Epoch 68/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6633 - val_loss: 0.6043 - val_binary_accuracy: 0.6696\n",
            "Epoch 69/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6651 - val_loss: 0.6043 - val_binary_accuracy: 0.6700\n",
            "Epoch 70/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6659 - val_loss: 0.6042 - val_binary_accuracy: 0.6704\n",
            "Epoch 71/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6644 - val_loss: 0.6040 - val_binary_accuracy: 0.6700\n",
            "Epoch 72/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6667 - val_loss: 0.6040 - val_binary_accuracy: 0.6700\n",
            "Epoch 73/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6669 - val_loss: 0.6038 - val_binary_accuracy: 0.6704\n",
            "Epoch 74/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6712 - val_loss: 0.6037 - val_binary_accuracy: 0.6704\n",
            "Epoch 75/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6658 - val_loss: 0.6037 - val_binary_accuracy: 0.6704\n",
            "Epoch 76/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6650 - val_loss: 0.6037 - val_binary_accuracy: 0.6700\n",
            "Epoch 77/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6651 - val_loss: 0.6038 - val_binary_accuracy: 0.6704\n",
            "Epoch 78/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6690 - val_loss: 0.6037 - val_binary_accuracy: 0.6711\n",
            "Epoch 79/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6680 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 80/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6695 - val_loss: 0.6035 - val_binary_accuracy: 0.6711\n",
            "Epoch 81/200\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6709 - val_loss: 0.6035 - val_binary_accuracy: 0.6707\n",
            "Epoch 82/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6673 - val_loss: 0.6035 - val_binary_accuracy: 0.6715\n",
            "Epoch 83/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6739 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 84/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6661 - val_loss: 0.6035 - val_binary_accuracy: 0.6722\n",
            "Epoch 85/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6640 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 86/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6640 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 87/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6673 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 88/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6688 - val_loss: 0.6034 - val_binary_accuracy: 0.6719\n",
            "Epoch 89/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6717 - val_loss: 0.6033 - val_binary_accuracy: 0.6733\n",
            "Epoch 90/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6721 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 91/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6667 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 92/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6678 - val_loss: 0.6033 - val_binary_accuracy: 0.6722\n",
            "Epoch 93/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6670 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 94/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6688 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 95/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6700 - val_loss: 0.6031 - val_binary_accuracy: 0.6726\n",
            "Epoch 96/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6683 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 97/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6654 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 98/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6695 - val_loss: 0.6029 - val_binary_accuracy: 0.6741\n",
            "Epoch 99/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6702 - val_loss: 0.6030 - val_binary_accuracy: 0.6733\n",
            "Epoch 100/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6689 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 101/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6681 - val_loss: 0.6029 - val_binary_accuracy: 0.6737\n",
            "Epoch 102/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6699 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 103/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6690 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 104/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6673 - val_loss: 0.6028 - val_binary_accuracy: 0.6730\n",
            "Epoch 105/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6681 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 106/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6709 - val_loss: 0.6028 - val_binary_accuracy: 0.6733\n",
            "Epoch 107/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6710 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 108/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6711 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 109/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6708 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 110/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6703 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 111/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6726 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 112/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6690 - val_loss: 0.6027 - val_binary_accuracy: 0.6726\n",
            "Epoch 113/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6721 - val_loss: 0.6025 - val_binary_accuracy: 0.6730\n",
            "Epoch 114/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6652 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 115/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6775 - val_loss: 0.6026 - val_binary_accuracy: 0.6726\n",
            "Epoch 116/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6763 - val_loss: 0.6025 - val_binary_accuracy: 0.6730\n",
            "Epoch 117/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6722 - val_loss: 0.6025 - val_binary_accuracy: 0.6722\n",
            "Epoch 118/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6704 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 119/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6694 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 120/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6685 - val_loss: 0.6024 - val_binary_accuracy: 0.6730\n",
            "Epoch 121/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6718 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 122/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6713 - val_loss: 0.6024 - val_binary_accuracy: 0.6722\n",
            "Epoch 123/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6702 - val_loss: 0.6024 - val_binary_accuracy: 0.6733\n",
            "Epoch 124/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6705 - val_loss: 0.6024 - val_binary_accuracy: 0.6726\n",
            "Epoch 125/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6708 - val_loss: 0.6024 - val_binary_accuracy: 0.6726\n",
            "Epoch 126/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6720 - val_loss: 0.6024 - val_binary_accuracy: 0.6737\n",
            "Epoch 127/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6729 - val_loss: 0.6023 - val_binary_accuracy: 0.6737\n",
            "Epoch 128/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6687 - val_loss: 0.6023 - val_binary_accuracy: 0.6733\n",
            "Epoch 129/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6727 - val_loss: 0.6023 - val_binary_accuracy: 0.6745\n",
            "Epoch 130/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6703 - val_loss: 0.6023 - val_binary_accuracy: 0.6733\n",
            "Epoch 131/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6754 - val_loss: 0.6022 - val_binary_accuracy: 0.6741\n",
            "Epoch 132/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6732 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 133/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6700 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 134/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6737 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 135/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6735 - val_loss: 0.6021 - val_binary_accuracy: 0.6733\n",
            "Epoch 136/200\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6661 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 137/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6679 - val_loss: 0.6020 - val_binary_accuracy: 0.6748\n",
            "Epoch 138/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6715 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 139/200\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6760 - val_loss: 0.6019 - val_binary_accuracy: 0.6745\n",
            "Epoch 140/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6683 - val_loss: 0.6018 - val_binary_accuracy: 0.6741\n",
            "Epoch 141/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6756 - val_loss: 0.6017 - val_binary_accuracy: 0.6748\n",
            "Epoch 142/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6725 - val_loss: 0.6017 - val_binary_accuracy: 0.6748\n",
            "Epoch 143/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6706 - val_loss: 0.6017 - val_binary_accuracy: 0.6737\n",
            "Epoch 144/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6731 - val_loss: 0.6017 - val_binary_accuracy: 0.6726\n",
            "Epoch 145/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6768 - val_loss: 0.6016 - val_binary_accuracy: 0.6733\n",
            "Epoch 146/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6696 - val_loss: 0.6017 - val_binary_accuracy: 0.6733\n",
            "Epoch 147/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6714 - val_loss: 0.6016 - val_binary_accuracy: 0.6737\n",
            "Epoch 148/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6706 - val_loss: 0.6017 - val_binary_accuracy: 0.6748\n",
            "Epoch 149/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6720 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 150/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6739 - val_loss: 0.6017 - val_binary_accuracy: 0.6741\n",
            "Epoch 151/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6745 - val_loss: 0.6017 - val_binary_accuracy: 0.6759\n",
            "Epoch 152/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6736 - val_loss: 0.6017 - val_binary_accuracy: 0.6745\n",
            "Epoch 153/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6715 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 154/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6729 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 155/200\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6732 - val_loss: 0.6017 - val_binary_accuracy: 0.6752\n",
            "Epoch 00155: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:19:46,958]\u001b[0m Trial 8 finished with value: 0.6679021716117859 and parameters: {'batch size': 154, 'optimizer': 'Adagrad', 'lr': 0.010983315399784135, 'minimum_learning_rate': 0.006690756896516009}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "89/89 [==============================] - 1s 3ms/step - loss: 0.7128 - binary_accuracy: 0.5570 - val_loss: 0.6475 - val_binary_accuracy: 0.6181\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6728 - binary_accuracy: 0.5949 - val_loss: 0.6383 - val_binary_accuracy: 0.6337\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6606 - binary_accuracy: 0.6026 - val_loss: 0.6344 - val_binary_accuracy: 0.6381\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6546 - binary_accuracy: 0.6094 - val_loss: 0.6289 - val_binary_accuracy: 0.6455\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6262 - val_loss: 0.6256 - val_binary_accuracy: 0.6504\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6438 - binary_accuracy: 0.6235 - val_loss: 0.6237 - val_binary_accuracy: 0.6492\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6265 - val_loss: 0.6206 - val_binary_accuracy: 0.6552\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6361 - binary_accuracy: 0.6311 - val_loss: 0.6192 - val_binary_accuracy: 0.6567\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6350 - val_loss: 0.6169 - val_binary_accuracy: 0.6615\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6393 - val_loss: 0.6148 - val_binary_accuracy: 0.6615\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6430 - val_loss: 0.6133 - val_binary_accuracy: 0.6633\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6389 - val_loss: 0.6125 - val_binary_accuracy: 0.6648\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6427 - val_loss: 0.6124 - val_binary_accuracy: 0.6667\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6451 - val_loss: 0.6112 - val_binary_accuracy: 0.6644\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6458 - val_loss: 0.6103 - val_binary_accuracy: 0.6667\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6451 - val_loss: 0.6093 - val_binary_accuracy: 0.6674\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6488 - val_loss: 0.6085 - val_binary_accuracy: 0.6667\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6533 - val_loss: 0.6077 - val_binary_accuracy: 0.6656\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6537 - val_loss: 0.6071 - val_binary_accuracy: 0.6659\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6541 - val_loss: 0.6068 - val_binary_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6548 - val_loss: 0.6062 - val_binary_accuracy: 0.6689\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6541 - val_loss: 0.6061 - val_binary_accuracy: 0.6704\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6564 - val_loss: 0.6056 - val_binary_accuracy: 0.6689\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6566 - val_loss: 0.6047 - val_binary_accuracy: 0.6685\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6618 - val_loss: 0.6046 - val_binary_accuracy: 0.6689\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6548 - val_loss: 0.6043 - val_binary_accuracy: 0.6700\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6567 - val_loss: 0.6042 - val_binary_accuracy: 0.6715\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6548 - val_loss: 0.6042 - val_binary_accuracy: 0.6715\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6597 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6578 - val_loss: 0.6036 - val_binary_accuracy: 0.6748\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6620 - val_loss: 0.6032 - val_binary_accuracy: 0.6741\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6602 - val_loss: 0.6032 - val_binary_accuracy: 0.6741\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6663 - val_loss: 0.6028 - val_binary_accuracy: 0.6741\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6630 - val_loss: 0.6029 - val_binary_accuracy: 0.6737\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6610 - val_loss: 0.6027 - val_binary_accuracy: 0.6726\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6605 - val_loss: 0.6028 - val_binary_accuracy: 0.6707\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6645 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6663 - val_loss: 0.6025 - val_binary_accuracy: 0.6715\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6626 - val_loss: 0.6024 - val_binary_accuracy: 0.6719\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6609 - val_loss: 0.6025 - val_binary_accuracy: 0.6715\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6617 - val_loss: 0.6023 - val_binary_accuracy: 0.6722\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6636 - val_loss: 0.6022 - val_binary_accuracy: 0.6715\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6660 - val_loss: 0.6021 - val_binary_accuracy: 0.6715\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6680 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6656 - val_loss: 0.6019 - val_binary_accuracy: 0.6722\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6634 - val_loss: 0.6018 - val_binary_accuracy: 0.6719\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6656 - val_loss: 0.6018 - val_binary_accuracy: 0.6715\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6655 - val_loss: 0.6018 - val_binary_accuracy: 0.6704\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6667 - val_loss: 0.6016 - val_binary_accuracy: 0.6711\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6667 - val_loss: 0.6017 - val_binary_accuracy: 0.6704\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6613 - val_loss: 0.6017 - val_binary_accuracy: 0.6719\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6680 - val_loss: 0.6016 - val_binary_accuracy: 0.6719\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6645 - val_loss: 0.6016 - val_binary_accuracy: 0.6719\n",
            "Epoch 54/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6636 - val_loss: 0.6017 - val_binary_accuracy: 0.6707\n",
            "Epoch 55/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6661 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 56/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6652 - val_loss: 0.6016 - val_binary_accuracy: 0.6722\n",
            "Epoch 57/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6680 - val_loss: 0.6015 - val_binary_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6674 - val_loss: 0.6014 - val_binary_accuracy: 0.6719\n",
            "Epoch 59/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6660 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 60/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6672 - val_loss: 0.6015 - val_binary_accuracy: 0.6722\n",
            "Epoch 61/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6673 - val_loss: 0.6015 - val_binary_accuracy: 0.6711\n",
            "Epoch 62/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6710 - val_loss: 0.6015 - val_binary_accuracy: 0.6711\n",
            "Epoch 63/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6661 - val_loss: 0.6014 - val_binary_accuracy: 0.6719\n",
            "Epoch 64/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6729 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 65/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6690 - val_loss: 0.6013 - val_binary_accuracy: 0.6730\n",
            "Epoch 66/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6669 - val_loss: 0.6013 - val_binary_accuracy: 0.6722\n",
            "Epoch 67/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6662 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 68/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6644 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 69/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6673 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 70/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6718 - val_loss: 0.6011 - val_binary_accuracy: 0.6719\n",
            "Epoch 71/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6685 - val_loss: 0.6011 - val_binary_accuracy: 0.6715\n",
            "Epoch 72/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6688 - val_loss: 0.6010 - val_binary_accuracy: 0.6704\n",
            "Epoch 73/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6707 - val_loss: 0.6011 - val_binary_accuracy: 0.6711\n",
            "Epoch 74/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6099 - binary_accuracy: 0.6614 - val_loss: 0.6012 - val_binary_accuracy: 0.6715\n",
            "Epoch 75/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6666 - val_loss: 0.6012 - val_binary_accuracy: 0.6696\n",
            "Epoch 76/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6663 - val_loss: 0.6012 - val_binary_accuracy: 0.6696\n",
            "Epoch 77/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6703 - val_loss: 0.6011 - val_binary_accuracy: 0.6693\n",
            "Epoch 78/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6658 - val_loss: 0.6012 - val_binary_accuracy: 0.6693\n",
            "Epoch 79/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6683 - val_loss: 0.6012 - val_binary_accuracy: 0.6689\n",
            "Epoch 80/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6725 - val_loss: 0.6012 - val_binary_accuracy: 0.6700\n",
            "Epoch 81/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6679 - val_loss: 0.6012 - val_binary_accuracy: 0.6704\n",
            "Epoch 82/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6702 - val_loss: 0.6011 - val_binary_accuracy: 0.6696\n",
            "Epoch 00082: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:20:07,944]\u001b[0m Trial 9 finished with value: 0.6630837917327881 and parameters: {'batch size': 142, 'optimizer': 'Adagrad', 'lr': 0.012828784337796563, 'minimum_learning_rate': 0.004901913836085487}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "122/122 [==============================] - 1s 3ms/step - loss: 0.6708 - binary_accuracy: 0.5876 - val_loss: 0.6333 - val_binary_accuracy: 0.6288\n",
            "Epoch 2/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6449 - binary_accuracy: 0.6156 - val_loss: 0.6249 - val_binary_accuracy: 0.6533\n",
            "Epoch 3/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6346 - val_loss: 0.6262 - val_binary_accuracy: 0.6570\n",
            "Epoch 4/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6439 - val_loss: 0.6114 - val_binary_accuracy: 0.6615\n",
            "Epoch 5/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6457 - val_loss: 0.6081 - val_binary_accuracy: 0.6644\n",
            "Epoch 6/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6528 - val_loss: 0.6076 - val_binary_accuracy: 0.6611\n",
            "Epoch 7/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6549 - val_loss: 0.6069 - val_binary_accuracy: 0.6696\n",
            "Epoch 8/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6538 - val_loss: 0.6044 - val_binary_accuracy: 0.6704\n",
            "Epoch 9/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6577 - val_loss: 0.6077 - val_binary_accuracy: 0.6644\n",
            "Epoch 10/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6567 - val_loss: 0.6036 - val_binary_accuracy: 0.6707\n",
            "Epoch 11/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6621 - val_loss: 0.6037 - val_binary_accuracy: 0.6745\n",
            "Epoch 12/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6624 - val_loss: 0.6057 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6647 - val_loss: 0.6048 - val_binary_accuracy: 0.6678\n",
            "Epoch 14/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6646 - val_loss: 0.6030 - val_binary_accuracy: 0.6689\n",
            "Epoch 15/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6661 - val_loss: 0.6030 - val_binary_accuracy: 0.6696\n",
            "Epoch 16/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6653 - val_loss: 0.6027 - val_binary_accuracy: 0.6711\n",
            "Epoch 17/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6671 - val_loss: 0.6029 - val_binary_accuracy: 0.6700\n",
            "Epoch 18/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6676 - val_loss: 0.6028 - val_binary_accuracy: 0.6711\n",
            "Epoch 19/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6654 - val_loss: 0.6020 - val_binary_accuracy: 0.6685\n",
            "Epoch 20/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6686 - val_loss: 0.6020 - val_binary_accuracy: 0.6693\n",
            "Epoch 21/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6725 - val_loss: 0.6017 - val_binary_accuracy: 0.6689\n",
            "Epoch 22/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6653 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 23/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6691 - val_loss: 0.6016 - val_binary_accuracy: 0.6693\n",
            "Epoch 24/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6667 - val_loss: 0.6013 - val_binary_accuracy: 0.6644\n",
            "Epoch 25/200\n",
            "122/122 [==============================] - 0s 1ms/step - loss: 0.6031 - binary_accuracy: 0.6760 - val_loss: 0.6008 - val_binary_accuracy: 0.6711\n",
            "Epoch 26/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6742 - val_loss: 0.6005 - val_binary_accuracy: 0.6719\n",
            "Epoch 27/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6721 - val_loss: 0.6009 - val_binary_accuracy: 0.6711\n",
            "Epoch 28/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6727 - val_loss: 0.6004 - val_binary_accuracy: 0.6719\n",
            "Epoch 29/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6723 - val_loss: 0.6012 - val_binary_accuracy: 0.6704\n",
            "Epoch 30/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6758 - val_loss: 0.6007 - val_binary_accuracy: 0.6707\n",
            "Epoch 31/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6661 - val_loss: 0.6006 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6710 - val_loss: 0.6007 - val_binary_accuracy: 0.6719\n",
            "Epoch 33/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6722 - val_loss: 0.6011 - val_binary_accuracy: 0.6737\n",
            "Epoch 34/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6725 - val_loss: 0.5999 - val_binary_accuracy: 0.6689\n",
            "Epoch 35/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6725 - val_loss: 0.6001 - val_binary_accuracy: 0.6707\n",
            "Epoch 36/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6767 - val_loss: 0.6003 - val_binary_accuracy: 0.6711\n",
            "Epoch 37/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6779 - val_loss: 0.6005 - val_binary_accuracy: 0.6719\n",
            "Epoch 38/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6748 - val_loss: 0.6010 - val_binary_accuracy: 0.6719\n",
            "Epoch 39/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6784 - val_loss: 0.5999 - val_binary_accuracy: 0.6719\n",
            "Epoch 40/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6766 - val_loss: 0.6008 - val_binary_accuracy: 0.6681\n",
            "Epoch 41/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6764 - val_loss: 0.6004 - val_binary_accuracy: 0.6693\n",
            "Epoch 42/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6753 - val_loss: 0.6020 - val_binary_accuracy: 0.6685\n",
            "Epoch 43/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6755 - val_loss: 0.6012 - val_binary_accuracy: 0.6704\n",
            "Epoch 44/200\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6814 - val_loss: 0.6009 - val_binary_accuracy: 0.6704\n",
            "Epoch 00044: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:20:18,715]\u001b[0m Trial 10 finished with value: 0.6649370193481445 and parameters: {'batch size': 104, 'optimizer': 'Adagrad', 'lr': 0.03674229576983069, 'minimum_learning_rate': 0.023754715913216224}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "55/55 [==============================] - 1s 5ms/step - loss: 0.6840 - binary_accuracy: 0.5790 - val_loss: 0.6378 - val_binary_accuracy: 0.6288\n",
            "Epoch 2/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6534 - binary_accuracy: 0.6078 - val_loss: 0.6283 - val_binary_accuracy: 0.6459\n",
            "Epoch 3/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6422 - binary_accuracy: 0.6211 - val_loss: 0.6211 - val_binary_accuracy: 0.6615\n",
            "Epoch 4/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6382 - binary_accuracy: 0.6339 - val_loss: 0.6229 - val_binary_accuracy: 0.6596\n",
            "Epoch 5/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6361 - val_loss: 0.6171 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6298 - binary_accuracy: 0.6373 - val_loss: 0.6134 - val_binary_accuracy: 0.6652\n",
            "Epoch 7/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6401 - val_loss: 0.6127 - val_binary_accuracy: 0.6745\n",
            "Epoch 8/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6436 - val_loss: 0.6169 - val_binary_accuracy: 0.6693\n",
            "Epoch 9/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6215 - binary_accuracy: 0.6482 - val_loss: 0.6098 - val_binary_accuracy: 0.6711\n",
            "Epoch 10/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6523 - val_loss: 0.6073 - val_binary_accuracy: 0.6756\n",
            "Epoch 11/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6526 - val_loss: 0.6116 - val_binary_accuracy: 0.6745\n",
            "Epoch 12/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6544 - val_loss: 0.6054 - val_binary_accuracy: 0.6715\n",
            "Epoch 13/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6610 - val_loss: 0.6029 - val_binary_accuracy: 0.6748\n",
            "Epoch 14/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6538 - val_loss: 0.6031 - val_binary_accuracy: 0.6830\n",
            "Epoch 15/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6585 - val_loss: 0.6093 - val_binary_accuracy: 0.6722\n",
            "Epoch 16/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6557 - val_loss: 0.6021 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6643 - val_loss: 0.6023 - val_binary_accuracy: 0.6782\n",
            "Epoch 18/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6617 - val_loss: 0.6024 - val_binary_accuracy: 0.6789\n",
            "Epoch 19/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6671 - val_loss: 0.6020 - val_binary_accuracy: 0.6785\n",
            "Epoch 20/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6617 - val_loss: 0.6035 - val_binary_accuracy: 0.6759\n",
            "Epoch 21/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6584 - val_loss: 0.6023 - val_binary_accuracy: 0.6782\n",
            "Epoch 22/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6629 - val_loss: 0.6019 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6648 - val_loss: 0.6020 - val_binary_accuracy: 0.6741\n",
            "Epoch 24/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6687 - val_loss: 0.6020 - val_binary_accuracy: 0.6759\n",
            "Epoch 25/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6660 - val_loss: 0.6019 - val_binary_accuracy: 0.6745\n",
            "Epoch 26/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6659 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 27/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6671 - val_loss: 0.6015 - val_binary_accuracy: 0.6748\n",
            "Epoch 28/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6671 - val_loss: 0.6014 - val_binary_accuracy: 0.6737\n",
            "Epoch 29/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6693 - val_loss: 0.6013 - val_binary_accuracy: 0.6745\n",
            "Epoch 30/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6640 - val_loss: 0.6014 - val_binary_accuracy: 0.6756\n",
            "Epoch 31/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6682 - val_loss: 0.6012 - val_binary_accuracy: 0.6774\n",
            "Epoch 32/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6676 - val_loss: 0.6011 - val_binary_accuracy: 0.6796\n",
            "Epoch 33/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6714 - val_loss: 0.6009 - val_binary_accuracy: 0.6782\n",
            "Epoch 34/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6663 - val_loss: 0.6008 - val_binary_accuracy: 0.6763\n",
            "Epoch 35/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6714 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 36/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6672 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 37/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6692 - val_loss: 0.6009 - val_binary_accuracy: 0.6778\n",
            "Epoch 38/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6706 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 39/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6680 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 40/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6677 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 41/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6730 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 42/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6675 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 43/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6644 - val_loss: 0.6004 - val_binary_accuracy: 0.6763\n",
            "Epoch 44/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6690 - val_loss: 0.6004 - val_binary_accuracy: 0.6763\n",
            "Epoch 45/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6690 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 46/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6690 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 47/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6708 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 48/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6640 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 49/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6696 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 50/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6732 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 51/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6679 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 52/200\n",
            "55/55 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6732 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 53/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6659 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 54/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6746 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 55/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6661 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 56/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6693 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 57/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6667 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 58/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6687 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 00058: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:20:28,478]\u001b[0m Trial 11 finished with value: 0.6660489439964294 and parameters: {'batch size': 233, 'optimizer': 'Adagrad', 'lr': 0.03934957578010348, 'minimum_learning_rate': 0.00024398863225257028}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "97/97 [==============================] - 1s 3ms/step - loss: 0.6801 - binary_accuracy: 0.5847 - val_loss: 0.6310 - val_binary_accuracy: 0.6522\n",
            "Epoch 2/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6455 - binary_accuracy: 0.6208 - val_loss: 0.6219 - val_binary_accuracy: 0.6618\n",
            "Epoch 3/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6323 - val_loss: 0.6140 - val_binary_accuracy: 0.6678\n",
            "Epoch 4/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6444 - val_loss: 0.6108 - val_binary_accuracy: 0.6711\n",
            "Epoch 5/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6516 - val_loss: 0.6097 - val_binary_accuracy: 0.6700\n",
            "Epoch 6/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6498 - val_loss: 0.6099 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6528 - val_loss: 0.6052 - val_binary_accuracy: 0.6726\n",
            "Epoch 8/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6548 - val_loss: 0.6058 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6584 - val_loss: 0.6041 - val_binary_accuracy: 0.6730\n",
            "Epoch 10/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6583 - val_loss: 0.6046 - val_binary_accuracy: 0.6733\n",
            "Epoch 11/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6573 - val_loss: 0.6033 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6603 - val_loss: 0.6035 - val_binary_accuracy: 0.6707\n",
            "Epoch 13/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6626 - val_loss: 0.6099 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6611 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 15/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6695 - val_loss: 0.6016 - val_binary_accuracy: 0.6711\n",
            "Epoch 16/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6648 - val_loss: 0.6012 - val_binary_accuracy: 0.6737\n",
            "Epoch 17/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6662 - val_loss: 0.6017 - val_binary_accuracy: 0.6763\n",
            "Epoch 18/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6647 - val_loss: 0.6015 - val_binary_accuracy: 0.6759\n",
            "Epoch 19/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6708 - val_loss: 0.6013 - val_binary_accuracy: 0.6759\n",
            "Epoch 20/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6724 - val_loss: 0.6015 - val_binary_accuracy: 0.6759\n",
            "Epoch 21/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6654 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6721 - val_loss: 0.6015 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6674 - val_loss: 0.6018 - val_binary_accuracy: 0.6730\n",
            "Epoch 24/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6718 - val_loss: 0.6019 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6667 - val_loss: 0.6023 - val_binary_accuracy: 0.6726\n",
            "Epoch 26/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6704 - val_loss: 0.6022 - val_binary_accuracy: 0.6730\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:20:33,915]\u001b[0m Trial 12 finished with value: 0.6693847179412842 and parameters: {'batch size': 131, 'optimizer': 'Adagrad', 'lr': 0.037888034620444995, 'minimum_learning_rate': 0.022434993990633458}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 1s 5ms/step - loss: 0.6934 - binary_accuracy: 0.5643 - val_loss: 0.6490 - val_binary_accuracy: 0.6162\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6607 - binary_accuracy: 0.5973 - val_loss: 0.6383 - val_binary_accuracy: 0.6377\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6508 - binary_accuracy: 0.6163 - val_loss: 0.6328 - val_binary_accuracy: 0.6437\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6461 - binary_accuracy: 0.6184 - val_loss: 0.6286 - val_binary_accuracy: 0.6470\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.6248 - val_loss: 0.6256 - val_binary_accuracy: 0.6500\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.6242 - val_loss: 0.6222 - val_binary_accuracy: 0.6552\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6346 - binary_accuracy: 0.6361 - val_loss: 0.6202 - val_binary_accuracy: 0.6581\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.6355 - val_loss: 0.6182 - val_binary_accuracy: 0.6607\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6302 - binary_accuracy: 0.6343 - val_loss: 0.6155 - val_binary_accuracy: 0.6593\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6298 - binary_accuracy: 0.6405 - val_loss: 0.6157 - val_binary_accuracy: 0.6567\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6286 - binary_accuracy: 0.6351 - val_loss: 0.6135 - val_binary_accuracy: 0.6615\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6255 - binary_accuracy: 0.6467 - val_loss: 0.6121 - val_binary_accuracy: 0.6615\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6223 - binary_accuracy: 0.6482 - val_loss: 0.6103 - val_binary_accuracy: 0.6644\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6490 - val_loss: 0.6090 - val_binary_accuracy: 0.6630\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6161 - binary_accuracy: 0.6535 - val_loss: 0.6082 - val_binary_accuracy: 0.6604\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6482 - val_loss: 0.6086 - val_binary_accuracy: 0.6589\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6567 - val_loss: 0.6071 - val_binary_accuracy: 0.6578\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6526 - val_loss: 0.6067 - val_binary_accuracy: 0.6652\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6542 - val_loss: 0.6059 - val_binary_accuracy: 0.6644\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6581 - val_loss: 0.6056 - val_binary_accuracy: 0.6641\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6163 - binary_accuracy: 0.6528 - val_loss: 0.6051 - val_binary_accuracy: 0.6663\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6577 - val_loss: 0.6046 - val_binary_accuracy: 0.6663\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6648 - val_loss: 0.6044 - val_binary_accuracy: 0.6704\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6605 - val_loss: 0.6043 - val_binary_accuracy: 0.6704\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6589 - val_loss: 0.6041 - val_binary_accuracy: 0.6670\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6575 - val_loss: 0.6045 - val_binary_accuracy: 0.6659\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6578 - val_loss: 0.6045 - val_binary_accuracy: 0.6693\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6633 - val_loss: 0.6044 - val_binary_accuracy: 0.6670\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6617 - val_loss: 0.6038 - val_binary_accuracy: 0.6693\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6651 - val_loss: 0.6039 - val_binary_accuracy: 0.6678\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6660 - val_loss: 0.6035 - val_binary_accuracy: 0.6670\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6632 - val_loss: 0.6035 - val_binary_accuracy: 0.6667\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6669 - val_loss: 0.6033 - val_binary_accuracy: 0.6667\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6677 - val_loss: 0.6031 - val_binary_accuracy: 0.6674\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6615 - val_loss: 0.6030 - val_binary_accuracy: 0.6681\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6664 - val_loss: 0.6030 - val_binary_accuracy: 0.6674\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6635 - val_loss: 0.6029 - val_binary_accuracy: 0.6685\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6609 - val_loss: 0.6029 - val_binary_accuracy: 0.6696\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6654 - val_loss: 0.6029 - val_binary_accuracy: 0.6689\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6691 - val_loss: 0.6026 - val_binary_accuracy: 0.6685\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6587 - val_loss: 0.6026 - val_binary_accuracy: 0.6693\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6669 - val_loss: 0.6024 - val_binary_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6683 - val_loss: 0.6024 - val_binary_accuracy: 0.6678\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6594 - val_loss: 0.6026 - val_binary_accuracy: 0.6681\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6659 - val_loss: 0.6029 - val_binary_accuracy: 0.6685\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6618 - val_loss: 0.6027 - val_binary_accuracy: 0.6689\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6631 - val_loss: 0.6026 - val_binary_accuracy: 0.6719\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6671 - val_loss: 0.6025 - val_binary_accuracy: 0.6696\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6680 - val_loss: 0.6024 - val_binary_accuracy: 0.6704\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6673 - val_loss: 0.6022 - val_binary_accuracy: 0.6700\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6645 - val_loss: 0.6021 - val_binary_accuracy: 0.6693\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6690 - val_loss: 0.6021 - val_binary_accuracy: 0.6707\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6655 - val_loss: 0.6021 - val_binary_accuracy: 0.6696\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6640 - val_loss: 0.6019 - val_binary_accuracy: 0.6693\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6719 - val_loss: 0.6019 - val_binary_accuracy: 0.6670\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6682 - val_loss: 0.6019 - val_binary_accuracy: 0.6674\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6696 - val_loss: 0.6017 - val_binary_accuracy: 0.6681\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6624 - val_loss: 0.6017 - val_binary_accuracy: 0.6707\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6689 - val_loss: 0.6016 - val_binary_accuracy: 0.6711\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6632 - val_loss: 0.6016 - val_binary_accuracy: 0.6678\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6657 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6663 - val_loss: 0.6016 - val_binary_accuracy: 0.6715\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6646 - val_loss: 0.6018 - val_binary_accuracy: 0.6689\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6652 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 65/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6680 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 66/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6664 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 67/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6703 - val_loss: 0.6014 - val_binary_accuracy: 0.6700\n",
            "Epoch 68/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6683 - val_loss: 0.6013 - val_binary_accuracy: 0.6704\n",
            "Epoch 69/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6662 - val_loss: 0.6013 - val_binary_accuracy: 0.6711\n",
            "Epoch 70/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6666 - val_loss: 0.6014 - val_binary_accuracy: 0.6700\n",
            "Epoch 71/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6703 - val_loss: 0.6015 - val_binary_accuracy: 0.6704\n",
            "Epoch 72/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6671 - val_loss: 0.6015 - val_binary_accuracy: 0.6719\n",
            "Epoch 73/200\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6644 - val_loss: 0.6014 - val_binary_accuracy: 0.6704\n",
            "Epoch 74/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6694 - val_loss: 0.6014 - val_binary_accuracy: 0.6726\n",
            "Epoch 75/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6712 - val_loss: 0.6013 - val_binary_accuracy: 0.6715\n",
            "Epoch 76/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6653 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 77/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6703 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 78/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6686 - val_loss: 0.6011 - val_binary_accuracy: 0.6707\n",
            "Epoch 79/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6668 - val_loss: 0.6013 - val_binary_accuracy: 0.6707\n",
            "Epoch 80/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6721 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 81/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6667 - val_loss: 0.6013 - val_binary_accuracy: 0.6707\n",
            "Epoch 82/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6683 - val_loss: 0.6012 - val_binary_accuracy: 0.6707\n",
            "Epoch 83/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6713 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 84/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6677 - val_loss: 0.6011 - val_binary_accuracy: 0.6726\n",
            "Epoch 85/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6704 - val_loss: 0.6010 - val_binary_accuracy: 0.6726\n",
            "Epoch 86/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6688 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 87/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6690 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 88/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6680 - val_loss: 0.6011 - val_binary_accuracy: 0.6715\n",
            "Epoch 89/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6722 - val_loss: 0.6012 - val_binary_accuracy: 0.6722\n",
            "Epoch 90/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6721 - val_loss: 0.6010 - val_binary_accuracy: 0.6730\n",
            "Epoch 91/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6714 - val_loss: 0.6009 - val_binary_accuracy: 0.6748\n",
            "Epoch 92/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6649 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 93/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6709 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 94/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6752 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 95/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6692 - val_loss: 0.6011 - val_binary_accuracy: 0.6733\n",
            "Epoch 96/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6706 - val_loss: 0.6010 - val_binary_accuracy: 0.6741\n",
            "Epoch 97/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6661 - val_loss: 0.6009 - val_binary_accuracy: 0.6737\n",
            "Epoch 98/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6698 - val_loss: 0.6008 - val_binary_accuracy: 0.6748\n",
            "Epoch 99/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6693 - val_loss: 0.6008 - val_binary_accuracy: 0.6745\n",
            "Epoch 100/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6729 - val_loss: 0.6009 - val_binary_accuracy: 0.6722\n",
            "Epoch 101/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6697 - val_loss: 0.6008 - val_binary_accuracy: 0.6733\n",
            "Epoch 102/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6683 - val_loss: 0.6009 - val_binary_accuracy: 0.6730\n",
            "Epoch 103/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6679 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 104/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6700 - val_loss: 0.6010 - val_binary_accuracy: 0.6733\n",
            "Epoch 105/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6685 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 106/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6692 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 107/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6753 - val_loss: 0.6008 - val_binary_accuracy: 0.6715\n",
            "Epoch 108/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6696 - val_loss: 0.6008 - val_binary_accuracy: 0.6715\n",
            "Epoch 109/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6687 - val_loss: 0.6007 - val_binary_accuracy: 0.6730\n",
            "Epoch 110/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6706 - val_loss: 0.6008 - val_binary_accuracy: 0.6722\n",
            "Epoch 111/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6738 - val_loss: 0.6008 - val_binary_accuracy: 0.6715\n",
            "Epoch 112/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6689 - val_loss: 0.6008 - val_binary_accuracy: 0.6730\n",
            "Epoch 113/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6714 - val_loss: 0.6007 - val_binary_accuracy: 0.6722\n",
            "Epoch 114/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6721 - val_loss: 0.6007 - val_binary_accuracy: 0.6719\n",
            "Epoch 115/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6709 - val_loss: 0.6007 - val_binary_accuracy: 0.6737\n",
            "Epoch 116/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6709 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 117/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6738 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 118/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6733 - val_loss: 0.6007 - val_binary_accuracy: 0.6730\n",
            "Epoch 119/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6694 - val_loss: 0.6007 - val_binary_accuracy: 0.6733\n",
            "Epoch 00119: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:20:54,920]\u001b[0m Trial 13 finished with value: 0.6627131104469299 and parameters: {'batch size': 256, 'optimizer': 'Adagrad', 'lr': 0.02881330746902063, 'minimum_learning_rate': 0.010131155896492359}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "60/60 [==============================] - 1s 4ms/step - loss: 0.6879 - binary_accuracy: 0.5767 - val_loss: 0.6376 - val_binary_accuracy: 0.6411\n",
            "Epoch 2/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.6185 - val_loss: 0.6267 - val_binary_accuracy: 0.6526\n",
            "Epoch 3/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6402 - binary_accuracy: 0.6238 - val_loss: 0.6233 - val_binary_accuracy: 0.6607\n",
            "Epoch 4/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6356 - val_loss: 0.6167 - val_binary_accuracy: 0.6726\n",
            "Epoch 5/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6462 - val_loss: 0.6134 - val_binary_accuracy: 0.6737\n",
            "Epoch 6/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6431 - val_loss: 0.6132 - val_binary_accuracy: 0.6745\n",
            "Epoch 7/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6516 - val_loss: 0.6101 - val_binary_accuracy: 0.6756\n",
            "Epoch 8/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6217 - binary_accuracy: 0.6444 - val_loss: 0.6087 - val_binary_accuracy: 0.6782\n",
            "Epoch 9/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6578 - val_loss: 0.6062 - val_binary_accuracy: 0.6796\n",
            "Epoch 10/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6518 - val_loss: 0.6097 - val_binary_accuracy: 0.6678\n",
            "Epoch 11/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6597 - val_loss: 0.6059 - val_binary_accuracy: 0.6800\n",
            "Epoch 12/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6586 - val_loss: 0.6080 - val_binary_accuracy: 0.6733\n",
            "Epoch 13/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6567 - val_loss: 0.6070 - val_binary_accuracy: 0.6767\n",
            "Epoch 14/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6613 - val_loss: 0.6059 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6613 - val_loss: 0.6053 - val_binary_accuracy: 0.6741\n",
            "Epoch 16/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6667 - val_loss: 0.6055 - val_binary_accuracy: 0.6737\n",
            "Epoch 17/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6668 - val_loss: 0.6052 - val_binary_accuracy: 0.6745\n",
            "Epoch 18/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6638 - val_loss: 0.6045 - val_binary_accuracy: 0.6730\n",
            "Epoch 19/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6621 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 20/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6694 - val_loss: 0.6042 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6686 - val_loss: 0.6036 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6706 - val_loss: 0.6043 - val_binary_accuracy: 0.6696\n",
            "Epoch 23/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6629 - val_loss: 0.6041 - val_binary_accuracy: 0.6741\n",
            "Epoch 24/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6667 - val_loss: 0.6041 - val_binary_accuracy: 0.6648\n",
            "Epoch 25/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6688 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 26/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6710 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 27/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6741 - val_loss: 0.6029 - val_binary_accuracy: 0.6696\n",
            "Epoch 28/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6626 - val_loss: 0.6023 - val_binary_accuracy: 0.6700\n",
            "Epoch 29/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6709 - val_loss: 0.6025 - val_binary_accuracy: 0.6693\n",
            "Epoch 30/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6689 - val_loss: 0.6017 - val_binary_accuracy: 0.6730\n",
            "Epoch 31/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6712 - val_loss: 0.6017 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6718 - val_loss: 0.6018 - val_binary_accuracy: 0.6696\n",
            "Epoch 33/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6686 - val_loss: 0.6009 - val_binary_accuracy: 0.6748\n",
            "Epoch 34/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6698 - val_loss: 0.6012 - val_binary_accuracy: 0.6737\n",
            "Epoch 35/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6722 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 36/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6710 - val_loss: 0.6027 - val_binary_accuracy: 0.6663\n",
            "Epoch 37/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6727 - val_loss: 0.6008 - val_binary_accuracy: 0.6733\n",
            "Epoch 38/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6703 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 39/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6693 - val_loss: 0.6010 - val_binary_accuracy: 0.6711\n",
            "Epoch 40/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6689 - val_loss: 0.6009 - val_binary_accuracy: 0.6730\n",
            "Epoch 41/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6730 - val_loss: 0.6010 - val_binary_accuracy: 0.6726\n",
            "Epoch 42/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6750 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 43/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6721 - val_loss: 0.5997 - val_binary_accuracy: 0.6759\n",
            "Epoch 44/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6733 - val_loss: 0.6004 - val_binary_accuracy: 0.6741\n",
            "Epoch 45/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6750 - val_loss: 0.6009 - val_binary_accuracy: 0.6730\n",
            "Epoch 46/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6723 - val_loss: 0.6003 - val_binary_accuracy: 0.6759\n",
            "Epoch 47/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6764 - val_loss: 0.6002 - val_binary_accuracy: 0.6763\n",
            "Epoch 48/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6779 - val_loss: 0.6003 - val_binary_accuracy: 0.6704\n",
            "Epoch 49/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6708 - val_loss: 0.6007 - val_binary_accuracy: 0.6759\n",
            "Epoch 50/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6727 - val_loss: 0.6000 - val_binary_accuracy: 0.6737\n",
            "Epoch 51/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6727 - val_loss: 0.6005 - val_binary_accuracy: 0.6752\n",
            "Epoch 52/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6764 - val_loss: 0.6000 - val_binary_accuracy: 0.6748\n",
            "Epoch 53/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6708 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 00053: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:21:04,478]\u001b[0m Trial 14 finished with value: 0.6690140962600708 and parameters: {'batch size': 213, 'optimizer': 'Adagrad', 'lr': 0.050009731969015925, 'minimum_learning_rate': 0.0320391076278805}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: 0.6994 - binary_accuracy: 0.5663 - val_loss: 0.6463 - val_binary_accuracy: 0.6211\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6601 - binary_accuracy: 0.6013 - val_loss: 0.6342 - val_binary_accuracy: 0.6418\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6488 - binary_accuracy: 0.6153 - val_loss: 0.6283 - val_binary_accuracy: 0.6504\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6379 - binary_accuracy: 0.6322 - val_loss: 0.6225 - val_binary_accuracy: 0.6581\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.6325 - binary_accuracy: 0.6370 - val_loss: 0.6190 - val_binary_accuracy: 0.6611\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6370 - val_loss: 0.6167 - val_binary_accuracy: 0.6652\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6421 - val_loss: 0.6133 - val_binary_accuracy: 0.6656\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6398 - val_loss: 0.6115 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6428 - val_loss: 0.6108 - val_binary_accuracy: 0.6681\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6550 - val_loss: 0.6093 - val_binary_accuracy: 0.6700\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6519 - val_loss: 0.6080 - val_binary_accuracy: 0.6726\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6502 - val_loss: 0.6070 - val_binary_accuracy: 0.6722\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6594 - val_loss: 0.6062 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6562 - val_loss: 0.6058 - val_binary_accuracy: 0.6778\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6592 - val_loss: 0.6054 - val_binary_accuracy: 0.6748\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6599 - val_loss: 0.6044 - val_binary_accuracy: 0.6722\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6593 - val_loss: 0.6036 - val_binary_accuracy: 0.6756\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6623 - val_loss: 0.6034 - val_binary_accuracy: 0.6785\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6621 - val_loss: 0.6028 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6667 - val_loss: 0.6034 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6638 - val_loss: 0.6031 - val_binary_accuracy: 0.6800\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6608 - val_loss: 0.6033 - val_binary_accuracy: 0.6778\n",
            "Epoch 23/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6602 - val_loss: 0.6033 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6658 - val_loss: 0.6030 - val_binary_accuracy: 0.6774\n",
            "Epoch 25/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6645 - val_loss: 0.6027 - val_binary_accuracy: 0.6778\n",
            "Epoch 26/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6650 - val_loss: 0.6027 - val_binary_accuracy: 0.6778\n",
            "Epoch 27/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6634 - val_loss: 0.6026 - val_binary_accuracy: 0.6785\n",
            "Epoch 28/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6666 - val_loss: 0.6026 - val_binary_accuracy: 0.6782\n",
            "Epoch 29/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6660 - val_loss: 0.6027 - val_binary_accuracy: 0.6793\n",
            "Epoch 30/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6623 - val_loss: 0.6028 - val_binary_accuracy: 0.6782\n",
            "Epoch 31/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6619 - val_loss: 0.6028 - val_binary_accuracy: 0.6774\n",
            "Epoch 32/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6674 - val_loss: 0.6025 - val_binary_accuracy: 0.6800\n",
            "Epoch 33/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6739 - val_loss: 0.6022 - val_binary_accuracy: 0.6800\n",
            "Epoch 34/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6734 - val_loss: 0.6021 - val_binary_accuracy: 0.6796\n",
            "Epoch 35/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6602 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 36/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6678 - val_loss: 0.6024 - val_binary_accuracy: 0.6778\n",
            "Epoch 37/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6666 - val_loss: 0.6023 - val_binary_accuracy: 0.6767\n",
            "Epoch 38/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6711 - val_loss: 0.6021 - val_binary_accuracy: 0.6789\n",
            "Epoch 39/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6665 - val_loss: 0.6022 - val_binary_accuracy: 0.6789\n",
            "Epoch 40/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6710 - val_loss: 0.6021 - val_binary_accuracy: 0.6767\n",
            "Epoch 41/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6659 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 42/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6672 - val_loss: 0.6020 - val_binary_accuracy: 0.6782\n",
            "Epoch 43/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6714 - val_loss: 0.6018 - val_binary_accuracy: 0.6778\n",
            "Epoch 44/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6697 - val_loss: 0.6016 - val_binary_accuracy: 0.6793\n",
            "Epoch 45/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6643 - val_loss: 0.6017 - val_binary_accuracy: 0.6767\n",
            "Epoch 46/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6651 - val_loss: 0.6021 - val_binary_accuracy: 0.6778\n",
            "Epoch 47/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6683 - val_loss: 0.6019 - val_binary_accuracy: 0.6789\n",
            "Epoch 48/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6700 - val_loss: 0.6018 - val_binary_accuracy: 0.6774\n",
            "Epoch 49/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6711 - val_loss: 0.6017 - val_binary_accuracy: 0.6763\n",
            "Epoch 50/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6695 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 51/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6675 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 52/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6703 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 53/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6702 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 54/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6738 - val_loss: 0.6016 - val_binary_accuracy: 0.6774\n",
            "Epoch 55/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6748 - val_loss: 0.6016 - val_binary_accuracy: 0.6782\n",
            "Epoch 56/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6687 - val_loss: 0.6017 - val_binary_accuracy: 0.6759\n",
            "Epoch 57/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6729 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 58/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6700 - val_loss: 0.6017 - val_binary_accuracy: 0.6778\n",
            "Epoch 59/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6683 - val_loss: 0.6017 - val_binary_accuracy: 0.6767\n",
            "Epoch 60/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6725 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 61/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6729 - val_loss: 0.6013 - val_binary_accuracy: 0.6774\n",
            "Epoch 62/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6715 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 63/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6765 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 64/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6742 - val_loss: 0.6012 - val_binary_accuracy: 0.6774\n",
            "Epoch 65/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6777 - val_loss: 0.6011 - val_binary_accuracy: 0.6778\n",
            "Epoch 66/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6713 - val_loss: 0.6013 - val_binary_accuracy: 0.6763\n",
            "Epoch 67/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6701 - val_loss: 0.6013 - val_binary_accuracy: 0.6756\n",
            "Epoch 68/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6694 - val_loss: 0.6010 - val_binary_accuracy: 0.6756\n",
            "Epoch 69/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6683 - val_loss: 0.6009 - val_binary_accuracy: 0.6770\n",
            "Epoch 70/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6733 - val_loss: 0.6009 - val_binary_accuracy: 0.6763\n",
            "Epoch 71/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6729 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 72/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6772 - val_loss: 0.6007 - val_binary_accuracy: 0.6759\n",
            "Epoch 73/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6737 - val_loss: 0.6008 - val_binary_accuracy: 0.6785\n",
            "Epoch 74/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6698 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 75/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6775 - val_loss: 0.6010 - val_binary_accuracy: 0.6782\n",
            "Epoch 76/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6745 - val_loss: 0.6009 - val_binary_accuracy: 0.6774\n",
            "Epoch 77/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6759 - val_loss: 0.6008 - val_binary_accuracy: 0.6782\n",
            "Epoch 78/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6742 - val_loss: 0.6006 - val_binary_accuracy: 0.6785\n",
            "Epoch 79/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6760 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 80/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6725 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 81/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6720 - val_loss: 0.6008 - val_binary_accuracy: 0.6763\n",
            "Epoch 82/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6689 - val_loss: 0.6008 - val_binary_accuracy: 0.6778\n",
            "Epoch 83/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6776 - val_loss: 0.6007 - val_binary_accuracy: 0.6756\n",
            "Epoch 84/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6768 - val_loss: 0.6006 - val_binary_accuracy: 0.6756\n",
            "Epoch 85/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6787 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 86/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6678 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 87/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6743 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 88/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6716 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 89/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6698 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 90/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6761 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 91/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6725 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 92/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6679 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 93/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6827 - val_loss: 0.6008 - val_binary_accuracy: 0.6767\n",
            "Epoch 94/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6756 - val_loss: 0.6009 - val_binary_accuracy: 0.6778\n",
            "Epoch 95/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6721 - val_loss: 0.6008 - val_binary_accuracy: 0.6793\n",
            "Epoch 00095: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:21:23,813]\u001b[0m Trial 15 finished with value: 0.6634544134140015 and parameters: {'batch size': 134, 'optimizer': 'Adagrad', 'lr': 0.02203258860748155, 'minimum_learning_rate': 0.009488361596862668}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "81/81 [==============================] - 1s 3ms/step - loss: 0.6764 - binary_accuracy: 0.5831 - val_loss: 0.6331 - val_binary_accuracy: 0.6359\n",
            "Epoch 2/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.6161 - val_loss: 0.6232 - val_binary_accuracy: 0.6529\n",
            "Epoch 3/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6293 - val_loss: 0.6152 - val_binary_accuracy: 0.6633\n",
            "Epoch 4/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6377 - val_loss: 0.6104 - val_binary_accuracy: 0.6670\n",
            "Epoch 5/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6480 - val_loss: 0.6074 - val_binary_accuracy: 0.6689\n",
            "Epoch 6/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6476 - val_loss: 0.6060 - val_binary_accuracy: 0.6722\n",
            "Epoch 7/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6524 - val_loss: 0.6042 - val_binary_accuracy: 0.6752\n",
            "Epoch 8/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6554 - val_loss: 0.6058 - val_binary_accuracy: 0.6730\n",
            "Epoch 9/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6613 - val_loss: 0.6021 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6582 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 11/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6652 - val_loss: 0.6016 - val_binary_accuracy: 0.6726\n",
            "Epoch 12/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6633 - val_loss: 0.6003 - val_binary_accuracy: 0.6719\n",
            "Epoch 13/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6626 - val_loss: 0.6017 - val_binary_accuracy: 0.6707\n",
            "Epoch 14/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6607 - val_loss: 0.6020 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6632 - val_loss: 0.6017 - val_binary_accuracy: 0.6681\n",
            "Epoch 16/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6646 - val_loss: 0.6000 - val_binary_accuracy: 0.6730\n",
            "Epoch 17/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6710 - val_loss: 0.5999 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6698 - val_loss: 0.5996 - val_binary_accuracy: 0.6745\n",
            "Epoch 19/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6686 - val_loss: 0.5987 - val_binary_accuracy: 0.6745\n",
            "Epoch 20/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6674 - val_loss: 0.5988 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6706 - val_loss: 0.5988 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6688 - val_loss: 0.5994 - val_binary_accuracy: 0.6748\n",
            "Epoch 23/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6689 - val_loss: 0.5986 - val_binary_accuracy: 0.6752\n",
            "Epoch 24/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6704 - val_loss: 0.5984 - val_binary_accuracy: 0.6778\n",
            "Epoch 25/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6713 - val_loss: 0.5988 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6741 - val_loss: 0.5985 - val_binary_accuracy: 0.6770\n",
            "Epoch 27/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6741 - val_loss: 0.5983 - val_binary_accuracy: 0.6756\n",
            "Epoch 28/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6714 - val_loss: 0.5986 - val_binary_accuracy: 0.6730\n",
            "Epoch 29/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6749 - val_loss: 0.5983 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6694 - val_loss: 0.5986 - val_binary_accuracy: 0.6737\n",
            "Epoch 31/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6720 - val_loss: 0.5991 - val_binary_accuracy: 0.6707\n",
            "Epoch 32/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6730 - val_loss: 0.5989 - val_binary_accuracy: 0.6726\n",
            "Epoch 33/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6714 - val_loss: 0.5985 - val_binary_accuracy: 0.6752\n",
            "Epoch 34/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6710 - val_loss: 0.5991 - val_binary_accuracy: 0.6707\n",
            "Epoch 35/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6752 - val_loss: 0.5994 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6747 - val_loss: 0.5983 - val_binary_accuracy: 0.6730\n",
            "Epoch 37/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6738 - val_loss: 0.5984 - val_binary_accuracy: 0.6763\n",
            "Epoch 38/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6759 - val_loss: 0.5987 - val_binary_accuracy: 0.6711\n",
            "Epoch 39/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6787 - val_loss: 0.5992 - val_binary_accuracy: 0.6715\n",
            "Epoch 00039: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:21:31,296]\u001b[0m Trial 16 finished with value: 0.6667901873588562 and parameters: {'batch size': 157, 'optimizer': 'Adagrad', 'lr': 0.05251330512957892, 'minimum_learning_rate': 0.03646155510141093}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.6890 - binary_accuracy: 0.5701 - val_loss: 0.6360 - val_binary_accuracy: 0.6344\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6518 - binary_accuracy: 0.6068 - val_loss: 0.6284 - val_binary_accuracy: 0.6474\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6437 - binary_accuracy: 0.6180 - val_loss: 0.6232 - val_binary_accuracy: 0.6581\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6316 - val_loss: 0.6163 - val_binary_accuracy: 0.6596\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6385 - val_loss: 0.6125 - val_binary_accuracy: 0.6633\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6238 - binary_accuracy: 0.6486 - val_loss: 0.6082 - val_binary_accuracy: 0.6700\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6482 - val_loss: 0.6076 - val_binary_accuracy: 0.6741\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6513 - val_loss: 0.6063 - val_binary_accuracy: 0.6726\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6555 - val_loss: 0.6058 - val_binary_accuracy: 0.6719\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6609 - val_loss: 0.6036 - val_binary_accuracy: 0.6782\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6545 - val_loss: 0.6038 - val_binary_accuracy: 0.6726\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6575 - val_loss: 0.6037 - val_binary_accuracy: 0.6704\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6616 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6571 - val_loss: 0.6028 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6619 - val_loss: 0.6019 - val_binary_accuracy: 0.6759\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6657 - val_loss: 0.6016 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6633 - val_loss: 0.6024 - val_binary_accuracy: 0.6737\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6647 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6660 - val_loss: 0.6005 - val_binary_accuracy: 0.6733\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6693 - val_loss: 0.6005 - val_binary_accuracy: 0.6759\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6710 - val_loss: 0.6001 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6694 - val_loss: 0.6003 - val_binary_accuracy: 0.6722\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6684 - val_loss: 0.6002 - val_binary_accuracy: 0.6741\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6671 - val_loss: 0.6006 - val_binary_accuracy: 0.6748\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6731 - val_loss: 0.6005 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6713 - val_loss: 0.6003 - val_binary_accuracy: 0.6719\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6714 - val_loss: 0.6005 - val_binary_accuracy: 0.6707\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6721 - val_loss: 0.6001 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6707 - val_loss: 0.5997 - val_binary_accuracy: 0.6748\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6729 - val_loss: 0.5995 - val_binary_accuracy: 0.6752\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6681 - val_loss: 0.5996 - val_binary_accuracy: 0.6752\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6702 - val_loss: 0.5996 - val_binary_accuracy: 0.6752\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6720 - val_loss: 0.5996 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6722 - val_loss: 0.6001 - val_binary_accuracy: 0.6707\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6712 - val_loss: 0.6007 - val_binary_accuracy: 0.6719\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6762 - val_loss: 0.6002 - val_binary_accuracy: 0.6722\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6733 - val_loss: 0.6001 - val_binary_accuracy: 0.6741\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6756 - val_loss: 0.6002 - val_binary_accuracy: 0.6752\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6758 - val_loss: 0.5999 - val_binary_accuracy: 0.6752\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6706 - val_loss: 0.6000 - val_binary_accuracy: 0.6752\n",
            "Epoch 00040: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:21:39,073]\u001b[0m Trial 17 finished with value: 0.664195716381073 and parameters: {'batch size': 205, 'optimizer': 'Adagrad', 'lr': 0.043831919632418614, 'minimum_learning_rate': 0.02985423996101991}. Best is trial 0 with value: 0.6704966425895691.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "64/64 [==============================] - 1s 4ms/step - loss: 0.7006 - binary_accuracy: 0.5665 - val_loss: 0.6472 - val_binary_accuracy: 0.6133\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6593 - binary_accuracy: 0.6017 - val_loss: 0.6374 - val_binary_accuracy: 0.6318\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6538 - binary_accuracy: 0.6049 - val_loss: 0.6310 - val_binary_accuracy: 0.6481\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6425 - binary_accuracy: 0.6225 - val_loss: 0.6263 - val_binary_accuracy: 0.6507\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.6281 - val_loss: 0.6221 - val_binary_accuracy: 0.6570\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6279 - val_loss: 0.6196 - val_binary_accuracy: 0.6618\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6358 - val_loss: 0.6173 - val_binary_accuracy: 0.6648\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_accuracy: 0.6420 - val_loss: 0.6143 - val_binary_accuracy: 0.6641\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6215 - binary_accuracy: 0.6475 - val_loss: 0.6111 - val_binary_accuracy: 0.6656\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6461 - val_loss: 0.6102 - val_binary_accuracy: 0.6663\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6497 - val_loss: 0.6092 - val_binary_accuracy: 0.6704\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6501 - val_loss: 0.6087 - val_binary_accuracy: 0.6656\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6563 - val_loss: 0.6071 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6524 - val_loss: 0.6065 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6609 - val_loss: 0.6062 - val_binary_accuracy: 0.6700\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6547 - val_loss: 0.6057 - val_binary_accuracy: 0.6707\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6526 - val_loss: 0.6054 - val_binary_accuracy: 0.6659\n",
            "Epoch 18/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6595 - val_loss: 0.6054 - val_binary_accuracy: 0.6685\n",
            "Epoch 19/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6509 - val_loss: 0.6048 - val_binary_accuracy: 0.6678\n",
            "Epoch 20/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6612 - val_loss: 0.6043 - val_binary_accuracy: 0.6685\n",
            "Epoch 21/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6602 - val_loss: 0.6043 - val_binary_accuracy: 0.6681\n",
            "Epoch 22/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6651 - val_loss: 0.6036 - val_binary_accuracy: 0.6681\n",
            "Epoch 23/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6613 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 24/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6579 - val_loss: 0.6036 - val_binary_accuracy: 0.6711\n",
            "Epoch 25/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6614 - val_loss: 0.6038 - val_binary_accuracy: 0.6674\n",
            "Epoch 26/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6650 - val_loss: 0.6034 - val_binary_accuracy: 0.6674\n",
            "Epoch 27/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6667 - val_loss: 0.6030 - val_binary_accuracy: 0.6681\n",
            "Epoch 28/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6648 - val_loss: 0.6028 - val_binary_accuracy: 0.6674\n",
            "Epoch 29/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6648 - val_loss: 0.6025 - val_binary_accuracy: 0.6689\n",
            "Epoch 30/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6687 - val_loss: 0.6023 - val_binary_accuracy: 0.6704\n",
            "Epoch 31/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6644 - val_loss: 0.6022 - val_binary_accuracy: 0.6704\n",
            "Epoch 32/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6634 - val_loss: 0.6026 - val_binary_accuracy: 0.6681\n",
            "Epoch 33/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6646 - val_loss: 0.6024 - val_binary_accuracy: 0.6689\n",
            "Epoch 34/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6687 - val_loss: 0.6024 - val_binary_accuracy: 0.6693\n",
            "Epoch 35/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6677 - val_loss: 0.6022 - val_binary_accuracy: 0.6685\n",
            "Epoch 36/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6679 - val_loss: 0.6019 - val_binary_accuracy: 0.6689\n",
            "Epoch 37/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6649 - val_loss: 0.6020 - val_binary_accuracy: 0.6681\n",
            "Epoch 38/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6693 - val_loss: 0.6018 - val_binary_accuracy: 0.6685\n",
            "Epoch 39/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6696 - val_loss: 0.6017 - val_binary_accuracy: 0.6696\n",
            "Epoch 40/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6687 - val_loss: 0.6015 - val_binary_accuracy: 0.6693\n",
            "Epoch 41/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6644 - val_loss: 0.6018 - val_binary_accuracy: 0.6678\n",
            "Epoch 42/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6668 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 43/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6730 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
            "Epoch 44/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6649 - val_loss: 0.6018 - val_binary_accuracy: 0.6685\n",
            "Epoch 45/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6688 - val_loss: 0.6015 - val_binary_accuracy: 0.6693\n",
            "Epoch 46/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6714 - val_loss: 0.6012 - val_binary_accuracy: 0.6689\n",
            "Epoch 47/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6682 - val_loss: 0.6014 - val_binary_accuracy: 0.6711\n",
            "Epoch 48/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6693 - val_loss: 0.6013 - val_binary_accuracy: 0.6700\n",
            "Epoch 49/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6699 - val_loss: 0.6010 - val_binary_accuracy: 0.6696\n",
            "Epoch 50/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6637 - val_loss: 0.6011 - val_binary_accuracy: 0.6707\n",
            "Epoch 51/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6681 - val_loss: 0.6014 - val_binary_accuracy: 0.6715\n",
            "Epoch 52/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6723 - val_loss: 0.6010 - val_binary_accuracy: 0.6693\n",
            "Epoch 53/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6706 - val_loss: 0.6010 - val_binary_accuracy: 0.6704\n",
            "Epoch 54/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6736 - val_loss: 0.6010 - val_binary_accuracy: 0.6711\n",
            "Epoch 55/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6697 - val_loss: 0.6009 - val_binary_accuracy: 0.6726\n",
            "Epoch 56/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6683 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 57/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6721 - val_loss: 0.6011 - val_binary_accuracy: 0.6722\n",
            "Epoch 58/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6706 - val_loss: 0.6010 - val_binary_accuracy: 0.6722\n",
            "Epoch 59/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6701 - val_loss: 0.6008 - val_binary_accuracy: 0.6722\n",
            "Epoch 60/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6797 - val_loss: 0.6006 - val_binary_accuracy: 0.6726\n",
            "Epoch 61/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6736 - val_loss: 0.6007 - val_binary_accuracy: 0.6726\n",
            "Epoch 62/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6721 - val_loss: 0.6006 - val_binary_accuracy: 0.6726\n",
            "Epoch 63/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6703 - val_loss: 0.6007 - val_binary_accuracy: 0.6722\n",
            "Epoch 64/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6723 - val_loss: 0.6007 - val_binary_accuracy: 0.6722\n",
            "Epoch 65/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6675 - val_loss: 0.6006 - val_binary_accuracy: 0.6715\n",
            "Epoch 66/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6694 - val_loss: 0.6004 - val_binary_accuracy: 0.6726\n",
            "Epoch 67/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6709 - val_loss: 0.6003 - val_binary_accuracy: 0.6726\n",
            "Epoch 68/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6743 - val_loss: 0.6003 - val_binary_accuracy: 0.6733\n",
            "Epoch 69/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6688 - val_loss: 0.6005 - val_binary_accuracy: 0.6715\n",
            "Epoch 70/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6733 - val_loss: 0.6002 - val_binary_accuracy: 0.6726\n",
            "Epoch 71/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6754 - val_loss: 0.6002 - val_binary_accuracy: 0.6715\n",
            "Epoch 72/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6724 - val_loss: 0.6002 - val_binary_accuracy: 0.6726\n",
            "Epoch 73/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6718 - val_loss: 0.6003 - val_binary_accuracy: 0.6722\n",
            "Epoch 74/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6744 - val_loss: 0.6004 - val_binary_accuracy: 0.6711\n",
            "Epoch 75/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6728 - val_loss: 0.6003 - val_binary_accuracy: 0.6704\n",
            "Epoch 76/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6738 - val_loss: 0.6003 - val_binary_accuracy: 0.6711\n",
            "Epoch 77/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6731 - val_loss: 0.6004 - val_binary_accuracy: 0.6696\n",
            "Epoch 78/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6725 - val_loss: 0.6004 - val_binary_accuracy: 0.6700\n",
            "Epoch 79/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6717 - val_loss: 0.6005 - val_binary_accuracy: 0.6693\n",
            "Epoch 80/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6718 - val_loss: 0.6005 - val_binary_accuracy: 0.6707\n",
            "Epoch 81/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6749 - val_loss: 0.6004 - val_binary_accuracy: 0.6707\n",
            "Epoch 00081: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:21:53,626]\u001b[0m Trial 18 finished with value: 0.6738324761390686 and parameters: {'batch size': 198, 'optimizer': 'Adagrad', 'lr': 0.02902014860204378, 'minimum_learning_rate': 0.014981073559435183}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.6786 - binary_accuracy: 0.5898 - val_loss: 0.6335 - val_binary_accuracy: 0.6411\n",
            "Epoch 2/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6490 - binary_accuracy: 0.6150 - val_loss: 0.6248 - val_binary_accuracy: 0.6537\n",
            "Epoch 3/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6295 - val_loss: 0.6193 - val_binary_accuracy: 0.6641\n",
            "Epoch 4/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6337 - val_loss: 0.6162 - val_binary_accuracy: 0.6652\n",
            "Epoch 5/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6418 - val_loss: 0.6138 - val_binary_accuracy: 0.6693\n",
            "Epoch 6/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6425 - val_loss: 0.6125 - val_binary_accuracy: 0.6737\n",
            "Epoch 7/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6529 - val_loss: 0.6081 - val_binary_accuracy: 0.6752\n",
            "Epoch 8/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6551 - val_loss: 0.6075 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6597 - val_loss: 0.6064 - val_binary_accuracy: 0.6756\n",
            "Epoch 10/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6555 - val_loss: 0.6063 - val_binary_accuracy: 0.6748\n",
            "Epoch 11/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6589 - val_loss: 0.6051 - val_binary_accuracy: 0.6767\n",
            "Epoch 12/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6633 - val_loss: 0.6048 - val_binary_accuracy: 0.6748\n",
            "Epoch 13/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6583 - val_loss: 0.6052 - val_binary_accuracy: 0.6745\n",
            "Epoch 14/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6644 - val_loss: 0.6040 - val_binary_accuracy: 0.6774\n",
            "Epoch 15/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6682 - val_loss: 0.6032 - val_binary_accuracy: 0.6774\n",
            "Epoch 16/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6613 - val_loss: 0.6040 - val_binary_accuracy: 0.6741\n",
            "Epoch 17/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6650 - val_loss: 0.6037 - val_binary_accuracy: 0.6774\n",
            "Epoch 18/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6714 - val_loss: 0.6035 - val_binary_accuracy: 0.6741\n",
            "Epoch 19/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6695 - val_loss: 0.6035 - val_binary_accuracy: 0.6726\n",
            "Epoch 20/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6688 - val_loss: 0.6030 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6675 - val_loss: 0.6026 - val_binary_accuracy: 0.6752\n",
            "Epoch 22/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6682 - val_loss: 0.6024 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6690 - val_loss: 0.6024 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6660 - val_loss: 0.6025 - val_binary_accuracy: 0.6741\n",
            "Epoch 25/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6712 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 26/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6682 - val_loss: 0.6026 - val_binary_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6695 - val_loss: 0.6026 - val_binary_accuracy: 0.6726\n",
            "Epoch 28/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6718 - val_loss: 0.6029 - val_binary_accuracy: 0.6719\n",
            "Epoch 29/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6714 - val_loss: 0.6025 - val_binary_accuracy: 0.6711\n",
            "Epoch 30/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6707 - val_loss: 0.6029 - val_binary_accuracy: 0.6726\n",
            "Epoch 31/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6733 - val_loss: 0.6025 - val_binary_accuracy: 0.6741\n",
            "Epoch 32/200\n",
            "112/112 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6694 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 00032: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:22:01,100]\u001b[0m Trial 19 finished with value: 0.6656782627105713 and parameters: {'batch size': 113, 'optimizer': 'Adagrad', 'lr': 0.030764403692979767, 'minimum_learning_rate': 0.019762563084583705}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "54/54 [==============================] - 1s 4ms/step - loss: 0.6787 - binary_accuracy: 0.5864 - val_loss: 0.6335 - val_binary_accuracy: 0.6396\n",
            "Epoch 2/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6183 - val_loss: 0.6250 - val_binary_accuracy: 0.6563\n",
            "Epoch 3/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6278 - val_loss: 0.6175 - val_binary_accuracy: 0.6581\n",
            "Epoch 4/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6384 - val_loss: 0.6120 - val_binary_accuracy: 0.6663\n",
            "Epoch 5/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6273 - binary_accuracy: 0.6456 - val_loss: 0.6112 - val_binary_accuracy: 0.6670\n",
            "Epoch 6/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6245 - binary_accuracy: 0.6453 - val_loss: 0.6081 - val_binary_accuracy: 0.6733\n",
            "Epoch 7/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6187 - binary_accuracy: 0.6545 - val_loss: 0.6060 - val_binary_accuracy: 0.6741\n",
            "Epoch 8/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6165 - binary_accuracy: 0.6524 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 9/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6563 - val_loss: 0.6043 - val_binary_accuracy: 0.6741\n",
            "Epoch 10/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6621 - val_loss: 0.6025 - val_binary_accuracy: 0.6730\n",
            "Epoch 11/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6627 - val_loss: 0.6020 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6578 - val_loss: 0.6028 - val_binary_accuracy: 0.6707\n",
            "Epoch 13/200\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6608 - val_loss: 0.6016 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6606 - val_loss: 0.6005 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6590 - val_loss: 0.6014 - val_binary_accuracy: 0.6752\n",
            "Epoch 16/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6671 - val_loss: 0.6005 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6654 - val_loss: 0.5998 - val_binary_accuracy: 0.6737\n",
            "Epoch 18/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6690 - val_loss: 0.5991 - val_binary_accuracy: 0.6715\n",
            "Epoch 19/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6683 - val_loss: 0.5987 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6657 - val_loss: 0.5998 - val_binary_accuracy: 0.6770\n",
            "Epoch 21/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6733 - val_loss: 0.5992 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6701 - val_loss: 0.5989 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6675 - val_loss: 0.5992 - val_binary_accuracy: 0.6782\n",
            "Epoch 24/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6694 - val_loss: 0.5989 - val_binary_accuracy: 0.6770\n",
            "Epoch 25/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6727 - val_loss: 0.5990 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6706 - val_loss: 0.5984 - val_binary_accuracy: 0.6759\n",
            "Epoch 27/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6713 - val_loss: 0.5990 - val_binary_accuracy: 0.6759\n",
            "Epoch 28/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6718 - val_loss: 0.5987 - val_binary_accuracy: 0.6741\n",
            "Epoch 29/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6699 - val_loss: 0.5995 - val_binary_accuracy: 0.6722\n",
            "Epoch 30/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6689 - val_loss: 0.5985 - val_binary_accuracy: 0.6752\n",
            "Epoch 31/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6732 - val_loss: 0.5989 - val_binary_accuracy: 0.6778\n",
            "Epoch 32/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6724 - val_loss: 0.5990 - val_binary_accuracy: 0.6789\n",
            "Epoch 33/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6673 - val_loss: 0.5992 - val_binary_accuracy: 0.6793\n",
            "Epoch 34/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6725 - val_loss: 0.5992 - val_binary_accuracy: 0.6774\n",
            "Epoch 35/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6748 - val_loss: 0.5988 - val_binary_accuracy: 0.6767\n",
            "Epoch 36/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6754 - val_loss: 0.5991 - val_binary_accuracy: 0.6789\n",
            "Epoch 00036: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:22:07,510]\u001b[0m Trial 20 finished with value: 0.6645663380622864 and parameters: {'batch size': 236, 'optimizer': 'Adagrad', 'lr': 0.06065943227786195, 'minimum_learning_rate': 0.04599211088626401}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 4ms/step - loss: 0.7346 - binary_accuracy: 0.5506 - val_loss: 0.6534 - val_binary_accuracy: 0.6096\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6702 - binary_accuracy: 0.5887 - val_loss: 0.6418 - val_binary_accuracy: 0.6244\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6628 - binary_accuracy: 0.6010 - val_loss: 0.6363 - val_binary_accuracy: 0.6292\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6527 - binary_accuracy: 0.6093 - val_loss: 0.6322 - val_binary_accuracy: 0.6348\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6172 - val_loss: 0.6285 - val_binary_accuracy: 0.6385\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6428 - binary_accuracy: 0.6204 - val_loss: 0.6255 - val_binary_accuracy: 0.6411\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6385 - binary_accuracy: 0.6268 - val_loss: 0.6229 - val_binary_accuracy: 0.6429\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6338 - val_loss: 0.6205 - val_binary_accuracy: 0.6474\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6327 - val_loss: 0.6186 - val_binary_accuracy: 0.6500\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6351 - val_loss: 0.6161 - val_binary_accuracy: 0.6537\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6370 - val_loss: 0.6142 - val_binary_accuracy: 0.6548\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6395 - val_loss: 0.6125 - val_binary_accuracy: 0.6570\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6434 - val_loss: 0.6114 - val_binary_accuracy: 0.6581\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_accuracy: 0.6493 - val_loss: 0.6102 - val_binary_accuracy: 0.6593\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6235 - binary_accuracy: 0.6489 - val_loss: 0.6096 - val_binary_accuracy: 0.6618\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6506 - val_loss: 0.6089 - val_binary_accuracy: 0.6611\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6538 - val_loss: 0.6077 - val_binary_accuracy: 0.6626\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6192 - binary_accuracy: 0.6527 - val_loss: 0.6073 - val_binary_accuracy: 0.6656\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6214 - binary_accuracy: 0.6526 - val_loss: 0.6066 - val_binary_accuracy: 0.6607\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6544 - val_loss: 0.6062 - val_binary_accuracy: 0.6622\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6551 - val_loss: 0.6060 - val_binary_accuracy: 0.6615\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6569 - val_loss: 0.6053 - val_binary_accuracy: 0.6648\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6540 - val_loss: 0.6047 - val_binary_accuracy: 0.6633\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6582 - val_loss: 0.6044 - val_binary_accuracy: 0.6618\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6603 - val_loss: 0.6040 - val_binary_accuracy: 0.6633\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6602 - val_loss: 0.6040 - val_binary_accuracy: 0.6659\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6632 - val_loss: 0.6033 - val_binary_accuracy: 0.6648\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6594 - val_loss: 0.6030 - val_binary_accuracy: 0.6622\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6582 - val_loss: 0.6032 - val_binary_accuracy: 0.6648\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6591 - val_loss: 0.6028 - val_binary_accuracy: 0.6633\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6649 - val_loss: 0.6027 - val_binary_accuracy: 0.6615\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6675 - val_loss: 0.6022 - val_binary_accuracy: 0.6630\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6616 - val_loss: 0.6022 - val_binary_accuracy: 0.6648\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6654 - val_loss: 0.6016 - val_binary_accuracy: 0.6659\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6618 - val_loss: 0.6016 - val_binary_accuracy: 0.6678\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6629 - val_loss: 0.6012 - val_binary_accuracy: 0.6670\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6634 - val_loss: 0.6013 - val_binary_accuracy: 0.6659\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6598 - val_loss: 0.6013 - val_binary_accuracy: 0.6656\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6631 - val_loss: 0.6010 - val_binary_accuracy: 0.6659\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6639 - val_loss: 0.6007 - val_binary_accuracy: 0.6656\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6652 - val_loss: 0.6007 - val_binary_accuracy: 0.6659\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6636 - val_loss: 0.6004 - val_binary_accuracy: 0.6667\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6638 - val_loss: 0.6003 - val_binary_accuracy: 0.6674\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6641 - val_loss: 0.6000 - val_binary_accuracy: 0.6693\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6611 - val_loss: 0.6001 - val_binary_accuracy: 0.6670\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6696 - val_loss: 0.6001 - val_binary_accuracy: 0.6693\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6667 - val_loss: 0.6000 - val_binary_accuracy: 0.6700\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6675 - val_loss: 0.5999 - val_binary_accuracy: 0.6722\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6670 - val_loss: 0.5999 - val_binary_accuracy: 0.6711\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6720 - val_loss: 0.5998 - val_binary_accuracy: 0.6696\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6657 - val_loss: 0.5998 - val_binary_accuracy: 0.6707\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6648 - val_loss: 0.5998 - val_binary_accuracy: 0.6696\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6666 - val_loss: 0.5999 - val_binary_accuracy: 0.6704\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6652 - val_loss: 0.5998 - val_binary_accuracy: 0.6696\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6617 - val_loss: 0.5999 - val_binary_accuracy: 0.6700\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6656 - val_loss: 0.5998 - val_binary_accuracy: 0.6693\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6639 - val_loss: 0.5998 - val_binary_accuracy: 0.6700\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6704 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6701 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6665 - val_loss: 0.5997 - val_binary_accuracy: 0.6696\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6703 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6660 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6675 - val_loss: 0.5997 - val_binary_accuracy: 0.6689\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6671 - val_loss: 0.5997 - val_binary_accuracy: 0.6689\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6695 - val_loss: 0.5997 - val_binary_accuracy: 0.6689\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6633 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6689 - val_loss: 0.5997 - val_binary_accuracy: 0.6696\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6671 - val_loss: 0.5997 - val_binary_accuracy: 0.6689\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6721 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6682 - val_loss: 0.5997 - val_binary_accuracy: 0.6693\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6679 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6713 - val_loss: 0.5997 - val_binary_accuracy: 0.6696\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6715 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6706 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6656 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6736 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6683 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6674 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6709 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6671 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6664 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6656 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6673 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6701 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6714 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6712 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6663 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6694 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6693 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6679 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6697 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6718 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6660 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6733 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6688 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6668 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6649 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6676 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6629 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6668 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6748 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6671 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6652 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6649 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6714 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6666 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6699 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6738 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6693 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6731 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6720 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6667 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6652 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6715 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6702 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6682 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6676 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6675 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6732 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6679 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6679 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6643 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6691 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6688 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6690 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6698 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6754 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6664 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6694 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6602 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6685 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6624 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6702 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6690 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6670 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6697 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6690 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6689 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6651 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6733 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6665 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6664 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6666 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6727 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6677 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6684 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6671 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6691 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6648 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6669 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6682 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6691 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6675 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6723 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6701 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6751 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6698 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6671 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6753 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6663 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6693 - val_loss: 0.5996 - val_binary_accuracy: 0.6700\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6685 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6653 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6730 - val_loss: 0.5996 - val_binary_accuracy: 0.6696\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6678 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6633 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6646 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6639 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6653 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6647 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6690 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6718 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6698 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6688 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6752 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6636 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6672 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6650 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6736 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6692 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6696 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6655 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6707 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6687 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6637 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6690 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6626 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6701 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6636 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6697 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6693 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6647 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6683 - val_loss: 0.5996 - val_binary_accuracy: 0.6689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:22:48,991]\u001b[0m Trial 21 finished with value: 0.6638250350952148 and parameters: {'batch size': 195, 'optimizer': 'Adagrad', 'lr': 0.01842029178505191, 'minimum_learning_rate': 0.0001145309284211072}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "76/76 [==============================] - 1s 4ms/step - loss: 0.6907 - binary_accuracy: 0.5830 - val_loss: 0.6404 - val_binary_accuracy: 0.6370\n",
            "Epoch 2/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6517 - binary_accuracy: 0.6153 - val_loss: 0.6341 - val_binary_accuracy: 0.6429\n",
            "Epoch 3/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.6194 - val_loss: 0.6297 - val_binary_accuracy: 0.6511\n",
            "Epoch 4/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6379 - binary_accuracy: 0.6322 - val_loss: 0.6224 - val_binary_accuracy: 0.6615\n",
            "Epoch 5/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6331 - binary_accuracy: 0.6314 - val_loss: 0.6206 - val_binary_accuracy: 0.6622\n",
            "Epoch 6/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6427 - val_loss: 0.6160 - val_binary_accuracy: 0.6674\n",
            "Epoch 7/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6412 - val_loss: 0.6145 - val_binary_accuracy: 0.6685\n",
            "Epoch 8/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6460 - val_loss: 0.6134 - val_binary_accuracy: 0.6693\n",
            "Epoch 9/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6490 - val_loss: 0.6128 - val_binary_accuracy: 0.6693\n",
            "Epoch 10/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6551 - val_loss: 0.6103 - val_binary_accuracy: 0.6693\n",
            "Epoch 11/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6558 - val_loss: 0.6103 - val_binary_accuracy: 0.6737\n",
            "Epoch 12/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6162 - binary_accuracy: 0.6515 - val_loss: 0.6087 - val_binary_accuracy: 0.6689\n",
            "Epoch 13/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6624 - val_loss: 0.6080 - val_binary_accuracy: 0.6730\n",
            "Epoch 14/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6544 - val_loss: 0.6082 - val_binary_accuracy: 0.6693\n",
            "Epoch 15/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6559 - val_loss: 0.6075 - val_binary_accuracy: 0.6722\n",
            "Epoch 16/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6636 - val_loss: 0.6070 - val_binary_accuracy: 0.6696\n",
            "Epoch 17/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6596 - val_loss: 0.6066 - val_binary_accuracy: 0.6678\n",
            "Epoch 18/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6605 - val_loss: 0.6065 - val_binary_accuracy: 0.6681\n",
            "Epoch 19/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6650 - val_loss: 0.6054 - val_binary_accuracy: 0.6689\n",
            "Epoch 20/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6640 - val_loss: 0.6049 - val_binary_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6640 - val_loss: 0.6047 - val_binary_accuracy: 0.6700\n",
            "Epoch 22/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6692 - val_loss: 0.6044 - val_binary_accuracy: 0.6696\n",
            "Epoch 23/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6679 - val_loss: 0.6044 - val_binary_accuracy: 0.6711\n",
            "Epoch 24/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6660 - val_loss: 0.6041 - val_binary_accuracy: 0.6681\n",
            "Epoch 25/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6647 - val_loss: 0.6046 - val_binary_accuracy: 0.6700\n",
            "Epoch 26/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6714 - val_loss: 0.6044 - val_binary_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6651 - val_loss: 0.6046 - val_binary_accuracy: 0.6711\n",
            "Epoch 28/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6648 - val_loss: 0.6040 - val_binary_accuracy: 0.6730\n",
            "Epoch 29/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6692 - val_loss: 0.6039 - val_binary_accuracy: 0.6715\n",
            "Epoch 30/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6703 - val_loss: 0.6037 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6656 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6694 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 33/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6699 - val_loss: 0.6029 - val_binary_accuracy: 0.6741\n",
            "Epoch 34/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6729 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 35/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6686 - val_loss: 0.6030 - val_binary_accuracy: 0.6733\n",
            "Epoch 36/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6707 - val_loss: 0.6026 - val_binary_accuracy: 0.6752\n",
            "Epoch 37/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6703 - val_loss: 0.6028 - val_binary_accuracy: 0.6715\n",
            "Epoch 38/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6748 - val_loss: 0.6028 - val_binary_accuracy: 0.6715\n",
            "Epoch 39/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6682 - val_loss: 0.6028 - val_binary_accuracy: 0.6741\n",
            "Epoch 40/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6676 - val_loss: 0.6025 - val_binary_accuracy: 0.6722\n",
            "Epoch 41/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6668 - val_loss: 0.6024 - val_binary_accuracy: 0.6745\n",
            "Epoch 42/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6702 - val_loss: 0.6026 - val_binary_accuracy: 0.6745\n",
            "Epoch 43/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6740 - val_loss: 0.6025 - val_binary_accuracy: 0.6763\n",
            "Epoch 44/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6690 - val_loss: 0.6025 - val_binary_accuracy: 0.6759\n",
            "Epoch 45/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6737 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 46/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6740 - val_loss: 0.6025 - val_binary_accuracy: 0.6733\n",
            "Epoch 47/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6706 - val_loss: 0.6023 - val_binary_accuracy: 0.6748\n",
            "Epoch 48/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6696 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 49/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6661 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 50/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6700 - val_loss: 0.6025 - val_binary_accuracy: 0.6756\n",
            "Epoch 51/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6701 - val_loss: 0.6026 - val_binary_accuracy: 0.6722\n",
            "Epoch 52/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6707 - val_loss: 0.6023 - val_binary_accuracy: 0.6737\n",
            "Epoch 53/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6726 - val_loss: 0.6022 - val_binary_accuracy: 0.6730\n",
            "Epoch 54/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6750 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 55/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6740 - val_loss: 0.6022 - val_binary_accuracy: 0.6722\n",
            "Epoch 56/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6675 - val_loss: 0.6021 - val_binary_accuracy: 0.6719\n",
            "Epoch 57/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6717 - val_loss: 0.6020 - val_binary_accuracy: 0.6733\n",
            "Epoch 58/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6732 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 59/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6713 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 60/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6748 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 61/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6721 - val_loss: 0.6020 - val_binary_accuracy: 0.6741\n",
            "Epoch 62/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6735 - val_loss: 0.6021 - val_binary_accuracy: 0.6722\n",
            "Epoch 63/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6778 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 64/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6659 - val_loss: 0.6019 - val_binary_accuracy: 0.6759\n",
            "Epoch 65/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6706 - val_loss: 0.6020 - val_binary_accuracy: 0.6759\n",
            "Epoch 66/200\n",
            "76/76 [==============================] - 0s 4ms/step - loss: 0.5996 - binary_accuracy: 0.6744 - val_loss: 0.6021 - val_binary_accuracy: 0.6748\n",
            "Epoch 67/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6746 - val_loss: 0.6021 - val_binary_accuracy: 0.6763\n",
            "Epoch 68/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6744 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 69/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6736 - val_loss: 0.6019 - val_binary_accuracy: 0.6767\n",
            "Epoch 70/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6718 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 71/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6736 - val_loss: 0.6019 - val_binary_accuracy: 0.6748\n",
            "Epoch 72/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6695 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 73/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6743 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 74/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6715 - val_loss: 0.6021 - val_binary_accuracy: 0.6741\n",
            "Epoch 75/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6700 - val_loss: 0.6021 - val_binary_accuracy: 0.6733\n",
            "Epoch 76/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6741 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 77/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6763 - val_loss: 0.6020 - val_binary_accuracy: 0.6763\n",
            "Epoch 78/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6761 - val_loss: 0.6018 - val_binary_accuracy: 0.6770\n",
            "Epoch 79/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6709 - val_loss: 0.6016 - val_binary_accuracy: 0.6778\n",
            "Epoch 80/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6747 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 81/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6778 - val_loss: 0.6017 - val_binary_accuracy: 0.6767\n",
            "Epoch 82/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6752 - val_loss: 0.6015 - val_binary_accuracy: 0.6759\n",
            "Epoch 83/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6746 - val_loss: 0.6015 - val_binary_accuracy: 0.6767\n",
            "Epoch 84/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6725 - val_loss: 0.6014 - val_binary_accuracy: 0.6782\n",
            "Epoch 85/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6706 - val_loss: 0.6016 - val_binary_accuracy: 0.6774\n",
            "Epoch 86/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6734 - val_loss: 0.6017 - val_binary_accuracy: 0.6785\n",
            "Epoch 87/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6733 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 88/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6781 - val_loss: 0.6015 - val_binary_accuracy: 0.6778\n",
            "Epoch 89/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6764 - val_loss: 0.6015 - val_binary_accuracy: 0.6774\n",
            "Epoch 90/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6695 - val_loss: 0.6015 - val_binary_accuracy: 0.6756\n",
            "Epoch 91/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6759 - val_loss: 0.6014 - val_binary_accuracy: 0.6759\n",
            "Epoch 92/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6741 - val_loss: 0.6016 - val_binary_accuracy: 0.6759\n",
            "Epoch 93/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6758 - val_loss: 0.6015 - val_binary_accuracy: 0.6763\n",
            "Epoch 94/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6706 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 95/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6804 - val_loss: 0.6014 - val_binary_accuracy: 0.6785\n",
            "Epoch 96/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6804 - val_loss: 0.6014 - val_binary_accuracy: 0.6778\n",
            "Epoch 97/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6754 - val_loss: 0.6014 - val_binary_accuracy: 0.6759\n",
            "Epoch 98/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6751 - val_loss: 0.6014 - val_binary_accuracy: 0.6763\n",
            "Epoch 99/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6793 - val_loss: 0.6013 - val_binary_accuracy: 0.6770\n",
            "Epoch 100/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6751 - val_loss: 0.6012 - val_binary_accuracy: 0.6752\n",
            "Epoch 101/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6799 - val_loss: 0.6012 - val_binary_accuracy: 0.6752\n",
            "Epoch 102/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6736 - val_loss: 0.6012 - val_binary_accuracy: 0.6752\n",
            "Epoch 103/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5957 - binary_accuracy: 0.6795 - val_loss: 0.6013 - val_binary_accuracy: 0.6733\n",
            "Epoch 104/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6803 - val_loss: 0.6014 - val_binary_accuracy: 0.6730\n",
            "Epoch 105/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6793 - val_loss: 0.6013 - val_binary_accuracy: 0.6748\n",
            "Epoch 106/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6768 - val_loss: 0.6011 - val_binary_accuracy: 0.6763\n",
            "Epoch 107/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6751 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 108/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6744 - val_loss: 0.6012 - val_binary_accuracy: 0.6737\n",
            "Epoch 109/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5942 - binary_accuracy: 0.6804 - val_loss: 0.6012 - val_binary_accuracy: 0.6759\n",
            "Epoch 110/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6778 - val_loss: 0.6012 - val_binary_accuracy: 0.6763\n",
            "Epoch 111/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6744 - val_loss: 0.6012 - val_binary_accuracy: 0.6756\n",
            "Epoch 112/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6742 - val_loss: 0.6013 - val_binary_accuracy: 0.6759\n",
            "Epoch 113/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6796 - val_loss: 0.6013 - val_binary_accuracy: 0.6741\n",
            "Epoch 114/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6768 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 115/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6788 - val_loss: 0.6015 - val_binary_accuracy: 0.6733\n",
            "Epoch 116/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6738 - val_loss: 0.6015 - val_binary_accuracy: 0.6733\n",
            "Epoch 00116: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:23:30,463]\u001b[0m Trial 22 finished with value: 0.6649370193481445 and parameters: {'batch size': 167, 'optimizer': 'Adagrad', 'lr': 0.028084375108660655, 'minimum_learning_rate': 0.011434491235759335}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 0.6959 - binary_accuracy: 0.5717 - val_loss: 0.6347 - val_binary_accuracy: 0.6392\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6164 - val_loss: 0.6259 - val_binary_accuracy: 0.6548\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6273 - val_loss: 0.6225 - val_binary_accuracy: 0.6544\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6343 - val_loss: 0.6156 - val_binary_accuracy: 0.6622\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6286 - binary_accuracy: 0.6382 - val_loss: 0.6126 - val_binary_accuracy: 0.6589\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6245 - binary_accuracy: 0.6431 - val_loss: 0.6100 - val_binary_accuracy: 0.6670\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6455 - val_loss: 0.6099 - val_binary_accuracy: 0.6719\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6499 - val_loss: 0.6070 - val_binary_accuracy: 0.6681\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6505 - val_loss: 0.6058 - val_binary_accuracy: 0.6719\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6173 - binary_accuracy: 0.6540 - val_loss: 0.6055 - val_binary_accuracy: 0.6737\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6514 - val_loss: 0.6048 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6599 - val_loss: 0.6048 - val_binary_accuracy: 0.6748\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6587 - val_loss: 0.6040 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6612 - val_loss: 0.6040 - val_binary_accuracy: 0.6726\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6623 - val_loss: 0.6027 - val_binary_accuracy: 0.6778\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6634 - val_loss: 0.6041 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6626 - val_loss: 0.6040 - val_binary_accuracy: 0.6759\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6668 - val_loss: 0.6034 - val_binary_accuracy: 0.6759\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6629 - val_loss: 0.6027 - val_binary_accuracy: 0.6759\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6652 - val_loss: 0.6026 - val_binary_accuracy: 0.6763\n",
            "Epoch 21/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6633 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6609 - val_loss: 0.6030 - val_binary_accuracy: 0.6785\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6657 - val_loss: 0.6028 - val_binary_accuracy: 0.6767\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6695 - val_loss: 0.6025 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6646 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6640 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6752 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 28/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6687 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 29/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6660 - val_loss: 0.6025 - val_binary_accuracy: 0.6733\n",
            "Epoch 30/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6710 - val_loss: 0.6026 - val_binary_accuracy: 0.6733\n",
            "Epoch 31/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6678 - val_loss: 0.6023 - val_binary_accuracy: 0.6759\n",
            "Epoch 32/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6644 - val_loss: 0.6023 - val_binary_accuracy: 0.6733\n",
            "Epoch 33/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6685 - val_loss: 0.6022 - val_binary_accuracy: 0.6748\n",
            "Epoch 34/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6737 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 35/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6694 - val_loss: 0.6020 - val_binary_accuracy: 0.6767\n",
            "Epoch 36/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6694 - val_loss: 0.6020 - val_binary_accuracy: 0.6737\n",
            "Epoch 37/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6687 - val_loss: 0.6020 - val_binary_accuracy: 0.6737\n",
            "Epoch 38/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6635 - val_loss: 0.6019 - val_binary_accuracy: 0.6752\n",
            "Epoch 39/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6696 - val_loss: 0.6018 - val_binary_accuracy: 0.6711\n",
            "Epoch 40/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6652 - val_loss: 0.6022 - val_binary_accuracy: 0.6741\n",
            "Epoch 41/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6704 - val_loss: 0.6021 - val_binary_accuracy: 0.6733\n",
            "Epoch 42/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6714 - val_loss: 0.6019 - val_binary_accuracy: 0.6741\n",
            "Epoch 43/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6678 - val_loss: 0.6022 - val_binary_accuracy: 0.6719\n",
            "Epoch 44/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6717 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 45/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6710 - val_loss: 0.6019 - val_binary_accuracy: 0.6741\n",
            "Epoch 46/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6714 - val_loss: 0.6018 - val_binary_accuracy: 0.6748\n",
            "Epoch 47/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6762 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 48/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6701 - val_loss: 0.6017 - val_binary_accuracy: 0.6711\n",
            "Epoch 49/200\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6033 - binary_accuracy: 0.6717 - val_loss: 0.6022 - val_binary_accuracy: 0.6719\n",
            "Epoch 50/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6691 - val_loss: 0.6022 - val_binary_accuracy: 0.6722\n",
            "Epoch 51/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6754 - val_loss: 0.6021 - val_binary_accuracy: 0.6700\n",
            "Epoch 52/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6748 - val_loss: 0.6020 - val_binary_accuracy: 0.6722\n",
            "Epoch 53/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6702 - val_loss: 0.6020 - val_binary_accuracy: 0.6722\n",
            "Epoch 54/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6725 - val_loss: 0.6019 - val_binary_accuracy: 0.6741\n",
            "Epoch 55/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6729 - val_loss: 0.6018 - val_binary_accuracy: 0.6733\n",
            "Epoch 56/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6694 - val_loss: 0.6016 - val_binary_accuracy: 0.6722\n",
            "Epoch 57/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6764 - val_loss: 0.6018 - val_binary_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6710 - val_loss: 0.6016 - val_binary_accuracy: 0.6722\n",
            "Epoch 59/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6736 - val_loss: 0.6018 - val_binary_accuracy: 0.6707\n",
            "Epoch 60/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6737 - val_loss: 0.6018 - val_binary_accuracy: 0.6719\n",
            "Epoch 61/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6683 - val_loss: 0.6019 - val_binary_accuracy: 0.6733\n",
            "Epoch 62/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6725 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 63/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6785 - val_loss: 0.6021 - val_binary_accuracy: 0.6741\n",
            "Epoch 64/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6744 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 65/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6779 - val_loss: 0.6019 - val_binary_accuracy: 0.6715\n",
            "Epoch 66/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6779 - val_loss: 0.6019 - val_binary_accuracy: 0.6741\n",
            "Epoch 00066: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:23:51,469]\u001b[0m Trial 23 finished with value: 0.6671608686447144 and parameters: {'batch size': 202, 'optimizer': 'Adagrad', 'lr': 0.04521974512757968, 'minimum_learning_rate': 0.017814427857558407}. Best is trial 18 with value: 0.6738324761390686.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6952 - binary_accuracy: 0.5740 - val_loss: 0.6443 - val_binary_accuracy: 0.6270\n",
            "Epoch 2/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6576 - binary_accuracy: 0.6071 - val_loss: 0.6301 - val_binary_accuracy: 0.6433\n",
            "Epoch 3/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6464 - binary_accuracy: 0.6125 - val_loss: 0.6258 - val_binary_accuracy: 0.6481\n",
            "Epoch 4/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6270 - val_loss: 0.6240 - val_binary_accuracy: 0.6567\n",
            "Epoch 5/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6369 - binary_accuracy: 0.6281 - val_loss: 0.6201 - val_binary_accuracy: 0.6626\n",
            "Epoch 6/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6323 - val_loss: 0.6176 - val_binary_accuracy: 0.6611\n",
            "Epoch 7/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6439 - val_loss: 0.6159 - val_binary_accuracy: 0.6674\n",
            "Epoch 8/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6387 - val_loss: 0.6143 - val_binary_accuracy: 0.6704\n",
            "Epoch 9/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6442 - val_loss: 0.6108 - val_binary_accuracy: 0.6711\n",
            "Epoch 10/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6463 - val_loss: 0.6093 - val_binary_accuracy: 0.6737\n",
            "Epoch 11/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6463 - val_loss: 0.6095 - val_binary_accuracy: 0.6767\n",
            "Epoch 12/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6526 - val_loss: 0.6087 - val_binary_accuracy: 0.6756\n",
            "Epoch 13/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6496 - val_loss: 0.6073 - val_binary_accuracy: 0.6763\n",
            "Epoch 14/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6557 - val_loss: 0.6072 - val_binary_accuracy: 0.6770\n",
            "Epoch 15/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6525 - val_loss: 0.6061 - val_binary_accuracy: 0.6767\n",
            "Epoch 16/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6594 - val_loss: 0.6055 - val_binary_accuracy: 0.6796\n",
            "Epoch 17/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6568 - val_loss: 0.6053 - val_binary_accuracy: 0.6800\n",
            "Epoch 18/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6571 - val_loss: 0.6059 - val_binary_accuracy: 0.6778\n",
            "Epoch 19/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6595 - val_loss: 0.6049 - val_binary_accuracy: 0.6822\n",
            "Epoch 20/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6619 - val_loss: 0.6055 - val_binary_accuracy: 0.6759\n",
            "Epoch 21/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6595 - val_loss: 0.6053 - val_binary_accuracy: 0.6770\n",
            "Epoch 22/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6630 - val_loss: 0.6046 - val_binary_accuracy: 0.6796\n",
            "Epoch 23/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6637 - val_loss: 0.6039 - val_binary_accuracy: 0.6767\n",
            "Epoch 24/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6617 - val_loss: 0.6043 - val_binary_accuracy: 0.6770\n",
            "Epoch 25/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6627 - val_loss: 0.6039 - val_binary_accuracy: 0.6759\n",
            "Epoch 26/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6583 - val_loss: 0.6042 - val_binary_accuracy: 0.6763\n",
            "Epoch 27/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6617 - val_loss: 0.6037 - val_binary_accuracy: 0.6789\n",
            "Epoch 28/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6635 - val_loss: 0.6033 - val_binary_accuracy: 0.6796\n",
            "Epoch 29/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6652 - val_loss: 0.6034 - val_binary_accuracy: 0.6778\n",
            "Epoch 30/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6699 - val_loss: 0.6031 - val_binary_accuracy: 0.6815\n",
            "Epoch 31/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6690 - val_loss: 0.6034 - val_binary_accuracy: 0.6763\n",
            "Epoch 32/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6683 - val_loss: 0.6032 - val_binary_accuracy: 0.6782\n",
            "Epoch 33/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6666 - val_loss: 0.6032 - val_binary_accuracy: 0.6796\n",
            "Epoch 34/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6641 - val_loss: 0.6031 - val_binary_accuracy: 0.6808\n",
            "Epoch 35/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6690 - val_loss: 0.6031 - val_binary_accuracy: 0.6770\n",
            "Epoch 36/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6676 - val_loss: 0.6029 - val_binary_accuracy: 0.6796\n",
            "Epoch 37/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6619 - val_loss: 0.6030 - val_binary_accuracy: 0.6782\n",
            "Epoch 38/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6676 - val_loss: 0.6031 - val_binary_accuracy: 0.6774\n",
            "Epoch 39/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6689 - val_loss: 0.6031 - val_binary_accuracy: 0.6796\n",
            "Epoch 40/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6687 - val_loss: 0.6031 - val_binary_accuracy: 0.6800\n",
            "Epoch 41/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6678 - val_loss: 0.6030 - val_binary_accuracy: 0.6793\n",
            "Epoch 42/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6664 - val_loss: 0.6030 - val_binary_accuracy: 0.6789\n",
            "Epoch 43/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6682 - val_loss: 0.6028 - val_binary_accuracy: 0.6811\n",
            "Epoch 44/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6649 - val_loss: 0.6029 - val_binary_accuracy: 0.6793\n",
            "Epoch 45/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6671 - val_loss: 0.6027 - val_binary_accuracy: 0.6819\n",
            "Epoch 46/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6706 - val_loss: 0.6030 - val_binary_accuracy: 0.6815\n",
            "Epoch 47/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6697 - val_loss: 0.6030 - val_binary_accuracy: 0.6793\n",
            "Epoch 48/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6729 - val_loss: 0.6029 - val_binary_accuracy: 0.6782\n",
            "Epoch 49/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6653 - val_loss: 0.6029 - val_binary_accuracy: 0.6774\n",
            "Epoch 50/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6626 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 51/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6726 - val_loss: 0.6029 - val_binary_accuracy: 0.6770\n",
            "Epoch 52/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6696 - val_loss: 0.6027 - val_binary_accuracy: 0.6785\n",
            "Epoch 53/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6663 - val_loss: 0.6025 - val_binary_accuracy: 0.6789\n",
            "Epoch 54/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6685 - val_loss: 0.6026 - val_binary_accuracy: 0.6785\n",
            "Epoch 55/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6690 - val_loss: 0.6026 - val_binary_accuracy: 0.6763\n",
            "Epoch 56/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6687 - val_loss: 0.6024 - val_binary_accuracy: 0.6778\n",
            "Epoch 57/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6715 - val_loss: 0.6024 - val_binary_accuracy: 0.6778\n",
            "Epoch 58/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6749 - val_loss: 0.6026 - val_binary_accuracy: 0.6770\n",
            "Epoch 59/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6692 - val_loss: 0.6024 - val_binary_accuracy: 0.6767\n",
            "Epoch 60/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6652 - val_loss: 0.6026 - val_binary_accuracy: 0.6763\n",
            "Epoch 61/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6704 - val_loss: 0.6023 - val_binary_accuracy: 0.6759\n",
            "Epoch 62/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6654 - val_loss: 0.6022 - val_binary_accuracy: 0.6774\n",
            "Epoch 63/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6741 - val_loss: 0.6021 - val_binary_accuracy: 0.6774\n",
            "Epoch 64/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6718 - val_loss: 0.6019 - val_binary_accuracy: 0.6782\n",
            "Epoch 65/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6697 - val_loss: 0.6018 - val_binary_accuracy: 0.6778\n",
            "Epoch 66/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6690 - val_loss: 0.6019 - val_binary_accuracy: 0.6774\n",
            "Epoch 67/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6690 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 68/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6698 - val_loss: 0.6016 - val_binary_accuracy: 0.6782\n",
            "Epoch 69/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6676 - val_loss: 0.6017 - val_binary_accuracy: 0.6774\n",
            "Epoch 70/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6730 - val_loss: 0.6019 - val_binary_accuracy: 0.6778\n",
            "Epoch 71/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6726 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 72/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6698 - val_loss: 0.6017 - val_binary_accuracy: 0.6782\n",
            "Epoch 73/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6698 - val_loss: 0.6015 - val_binary_accuracy: 0.6793\n",
            "Epoch 74/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6705 - val_loss: 0.6015 - val_binary_accuracy: 0.6789\n",
            "Epoch 75/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6729 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 76/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6681 - val_loss: 0.6016 - val_binary_accuracy: 0.6789\n",
            "Epoch 77/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6715 - val_loss: 0.6015 - val_binary_accuracy: 0.6800\n",
            "Epoch 78/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6710 - val_loss: 0.6014 - val_binary_accuracy: 0.6770\n",
            "Epoch 79/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6685 - val_loss: 0.6015 - val_binary_accuracy: 0.6767\n",
            "Epoch 80/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6690 - val_loss: 0.6013 - val_binary_accuracy: 0.6782\n",
            "Epoch 81/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6683 - val_loss: 0.6014 - val_binary_accuracy: 0.6796\n",
            "Epoch 82/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6750 - val_loss: 0.6015 - val_binary_accuracy: 0.6778\n",
            "Epoch 83/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6777 - val_loss: 0.6014 - val_binary_accuracy: 0.6796\n",
            "Epoch 84/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6719 - val_loss: 0.6013 - val_binary_accuracy: 0.6796\n",
            "Epoch 85/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6709 - val_loss: 0.6013 - val_binary_accuracy: 0.6800\n",
            "Epoch 86/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6724 - val_loss: 0.6012 - val_binary_accuracy: 0.6796\n",
            "Epoch 87/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6698 - val_loss: 0.6012 - val_binary_accuracy: 0.6778\n",
            "Epoch 88/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6703 - val_loss: 0.6013 - val_binary_accuracy: 0.6796\n",
            "Epoch 89/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6729 - val_loss: 0.6014 - val_binary_accuracy: 0.6785\n",
            "Epoch 90/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6728 - val_loss: 0.6013 - val_binary_accuracy: 0.6800\n",
            "Epoch 91/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6716 - val_loss: 0.6013 - val_binary_accuracy: 0.6808\n",
            "Epoch 92/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6701 - val_loss: 0.6014 - val_binary_accuracy: 0.6800\n",
            "Epoch 93/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6746 - val_loss: 0.6015 - val_binary_accuracy: 0.6785\n",
            "Epoch 94/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6748 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 95/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6730 - val_loss: 0.6014 - val_binary_accuracy: 0.6774\n",
            "Epoch 96/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6732 - val_loss: 0.6015 - val_binary_accuracy: 0.6785\n",
            "Epoch 00096: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:24:32,928]\u001b[0m Trial 24 finished with value: 0.675685703754425 and parameters: {'batch size': 121, 'optimizer': 'Adagrad', 'lr': 0.018592998721270466, 'minimum_learning_rate': 0.006775732026971621}. Best is trial 24 with value: 0.675685703754425.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "107/107 [==============================] - 1s 3ms/step - loss: 0.6801 - binary_accuracy: 0.5868 - val_loss: 0.6363 - val_binary_accuracy: 0.6418\n",
            "Epoch 2/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6453 - binary_accuracy: 0.6187 - val_loss: 0.6255 - val_binary_accuracy: 0.6581\n",
            "Epoch 3/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6337 - binary_accuracy: 0.6305 - val_loss: 0.6178 - val_binary_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6310 - val_loss: 0.6150 - val_binary_accuracy: 0.6670\n",
            "Epoch 5/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6412 - val_loss: 0.6127 - val_binary_accuracy: 0.6659\n",
            "Epoch 6/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6466 - val_loss: 0.6097 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6548 - val_loss: 0.6108 - val_binary_accuracy: 0.6700\n",
            "Epoch 8/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6564 - val_loss: 0.6085 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6501 - val_loss: 0.6083 - val_binary_accuracy: 0.6711\n",
            "Epoch 10/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6553 - val_loss: 0.6061 - val_binary_accuracy: 0.6741\n",
            "Epoch 11/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6579 - val_loss: 0.6058 - val_binary_accuracy: 0.6681\n",
            "Epoch 12/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6636 - val_loss: 0.6039 - val_binary_accuracy: 0.6715\n",
            "Epoch 13/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6640 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 14/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6607 - val_loss: 0.6041 - val_binary_accuracy: 0.6719\n",
            "Epoch 15/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6648 - val_loss: 0.6032 - val_binary_accuracy: 0.6700\n",
            "Epoch 16/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6688 - val_loss: 0.6031 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6717 - val_loss: 0.6027 - val_binary_accuracy: 0.6700\n",
            "Epoch 18/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6620 - val_loss: 0.6035 - val_binary_accuracy: 0.6685\n",
            "Epoch 19/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6673 - val_loss: 0.6032 - val_binary_accuracy: 0.6681\n",
            "Epoch 20/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6630 - val_loss: 0.6028 - val_binary_accuracy: 0.6741\n",
            "Epoch 21/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6680 - val_loss: 0.6023 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6690 - val_loss: 0.6019 - val_binary_accuracy: 0.6759\n",
            "Epoch 23/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6727 - val_loss: 0.6017 - val_binary_accuracy: 0.6752\n",
            "Epoch 24/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6714 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 25/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6705 - val_loss: 0.6017 - val_binary_accuracy: 0.6763\n",
            "Epoch 26/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6737 - val_loss: 0.6012 - val_binary_accuracy: 0.6763\n",
            "Epoch 27/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6645 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 28/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6756 - val_loss: 0.6015 - val_binary_accuracy: 0.6759\n",
            "Epoch 29/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6728 - val_loss: 0.6013 - val_binary_accuracy: 0.6774\n",
            "Epoch 30/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6698 - val_loss: 0.6013 - val_binary_accuracy: 0.6767\n",
            "Epoch 31/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6671 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 32/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6694 - val_loss: 0.6013 - val_binary_accuracy: 0.6763\n",
            "Epoch 33/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6749 - val_loss: 0.6013 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6699 - val_loss: 0.6012 - val_binary_accuracy: 0.6759\n",
            "Epoch 35/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6719 - val_loss: 0.6011 - val_binary_accuracy: 0.6770\n",
            "Epoch 36/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6718 - val_loss: 0.6012 - val_binary_accuracy: 0.6770\n",
            "Epoch 37/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6742 - val_loss: 0.6012 - val_binary_accuracy: 0.6774\n",
            "Epoch 38/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6676 - val_loss: 0.6012 - val_binary_accuracy: 0.6793\n",
            "Epoch 39/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6737 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "Epoch 40/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6659 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "Epoch 41/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6746 - val_loss: 0.6012 - val_binary_accuracy: 0.6774\n",
            "Epoch 42/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6704 - val_loss: 0.6011 - val_binary_accuracy: 0.6782\n",
            "Epoch 43/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6772 - val_loss: 0.6009 - val_binary_accuracy: 0.6778\n",
            "Epoch 44/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6687 - val_loss: 0.6010 - val_binary_accuracy: 0.6778\n",
            "Epoch 45/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6748 - val_loss: 0.6010 - val_binary_accuracy: 0.6778\n",
            "Epoch 46/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6695 - val_loss: 0.6010 - val_binary_accuracy: 0.6767\n",
            "Epoch 47/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6750 - val_loss: 0.6010 - val_binary_accuracy: 0.6774\n",
            "Epoch 48/200\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6704 - val_loss: 0.6010 - val_binary_accuracy: 0.6767\n",
            "Epoch 49/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6687 - val_loss: 0.6010 - val_binary_accuracy: 0.6770\n",
            "Epoch 50/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6756 - val_loss: 0.6009 - val_binary_accuracy: 0.6770\n",
            "Epoch 51/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6732 - val_loss: 0.6009 - val_binary_accuracy: 0.6774\n",
            "Epoch 52/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6737 - val_loss: 0.6008 - val_binary_accuracy: 0.6785\n",
            "Epoch 53/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6717 - val_loss: 0.6008 - val_binary_accuracy: 0.6774\n",
            "Epoch 54/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6752 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 55/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6768 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 56/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6739 - val_loss: 0.6007 - val_binary_accuracy: 0.6770\n",
            "Epoch 57/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6721 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 58/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6753 - val_loss: 0.6006 - val_binary_accuracy: 0.6782\n",
            "Epoch 59/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6717 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 60/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6733 - val_loss: 0.6008 - val_binary_accuracy: 0.6789\n",
            "Epoch 61/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6756 - val_loss: 0.6008 - val_binary_accuracy: 0.6785\n",
            "Epoch 62/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6748 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 63/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6725 - val_loss: 0.6008 - val_binary_accuracy: 0.6785\n",
            "Epoch 64/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6700 - val_loss: 0.6008 - val_binary_accuracy: 0.6774\n",
            "Epoch 65/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6689 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 66/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6768 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 67/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6773 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 68/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6737 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 69/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6756 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 70/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6695 - val_loss: 0.6007 - val_binary_accuracy: 0.6770\n",
            "Epoch 71/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6773 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 72/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6702 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 73/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6732 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 74/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6709 - val_loss: 0.6005 - val_binary_accuracy: 0.6756\n",
            "Epoch 75/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6768 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 76/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6730 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 77/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6721 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 78/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6752 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 79/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6749 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 80/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6726 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 81/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6713 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 82/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6770 - val_loss: 0.6005 - val_binary_accuracy: 0.6774\n",
            "Epoch 83/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6789 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 84/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6764 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 85/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6788 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 86/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6751 - val_loss: 0.6005 - val_binary_accuracy: 0.6774\n",
            "Epoch 87/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6760 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 00087: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:24:52,403]\u001b[0m Trial 25 finished with value: 0.678280234336853 and parameters: {'batch size': 118, 'optimizer': 'Adagrad', 'lr': 0.032214580661926416, 'minimum_learning_rate': 0.004712080335294012}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "104/104 [==============================] - 1s 3ms/step - loss: 0.6880 - binary_accuracy: 0.5782 - val_loss: 0.6384 - val_binary_accuracy: 0.6385\n",
            "Epoch 2/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6478 - binary_accuracy: 0.6131 - val_loss: 0.6273 - val_binary_accuracy: 0.6559\n",
            "Epoch 3/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6285 - val_loss: 0.6202 - val_binary_accuracy: 0.6544\n",
            "Epoch 4/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6323 - val_loss: 0.6153 - val_binary_accuracy: 0.6526\n",
            "Epoch 5/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6421 - val_loss: 0.6129 - val_binary_accuracy: 0.6607\n",
            "Epoch 6/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6472 - val_loss: 0.6103 - val_binary_accuracy: 0.6611\n",
            "Epoch 7/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6493 - val_loss: 0.6084 - val_binary_accuracy: 0.6648\n",
            "Epoch 8/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6512 - val_loss: 0.6072 - val_binary_accuracy: 0.6685\n",
            "Epoch 9/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6534 - val_loss: 0.6074 - val_binary_accuracy: 0.6674\n",
            "Epoch 10/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6614 - val_loss: 0.6064 - val_binary_accuracy: 0.6644\n",
            "Epoch 11/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6584 - val_loss: 0.6053 - val_binary_accuracy: 0.6670\n",
            "Epoch 12/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6625 - val_loss: 0.6050 - val_binary_accuracy: 0.6667\n",
            "Epoch 13/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6624 - val_loss: 0.6047 - val_binary_accuracy: 0.6700\n",
            "Epoch 14/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6629 - val_loss: 0.6052 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6666 - val_loss: 0.6034 - val_binary_accuracy: 0.6719\n",
            "Epoch 16/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6657 - val_loss: 0.6037 - val_binary_accuracy: 0.6693\n",
            "Epoch 17/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6694 - val_loss: 0.6038 - val_binary_accuracy: 0.6722\n",
            "Epoch 18/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6666 - val_loss: 0.6033 - val_binary_accuracy: 0.6730\n",
            "Epoch 19/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6661 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 20/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6656 - val_loss: 0.6028 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6679 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 22/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6711 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6661 - val_loss: 0.6026 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6704 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 25/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6687 - val_loss: 0.6026 - val_binary_accuracy: 0.6748\n",
            "Epoch 26/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6681 - val_loss: 0.6024 - val_binary_accuracy: 0.6730\n",
            "Epoch 27/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6702 - val_loss: 0.6022 - val_binary_accuracy: 0.6730\n",
            "Epoch 28/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6671 - val_loss: 0.6022 - val_binary_accuracy: 0.6722\n",
            "Epoch 29/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6710 - val_loss: 0.6020 - val_binary_accuracy: 0.6741\n",
            "Epoch 30/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6761 - val_loss: 0.6019 - val_binary_accuracy: 0.6730\n",
            "Epoch 31/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6685 - val_loss: 0.6017 - val_binary_accuracy: 0.6733\n",
            "Epoch 32/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6733 - val_loss: 0.6017 - val_binary_accuracy: 0.6726\n",
            "Epoch 33/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6744 - val_loss: 0.6016 - val_binary_accuracy: 0.6748\n",
            "Epoch 34/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6739 - val_loss: 0.6016 - val_binary_accuracy: 0.6745\n",
            "Epoch 35/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6756 - val_loss: 0.6016 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6694 - val_loss: 0.6017 - val_binary_accuracy: 0.6722\n",
            "Epoch 37/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6690 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 38/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6737 - val_loss: 0.6019 - val_binary_accuracy: 0.6730\n",
            "Epoch 39/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6691 - val_loss: 0.6017 - val_binary_accuracy: 0.6745\n",
            "Epoch 40/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6725 - val_loss: 0.6017 - val_binary_accuracy: 0.6752\n",
            "Epoch 41/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6758 - val_loss: 0.6016 - val_binary_accuracy: 0.6737\n",
            "Epoch 42/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6739 - val_loss: 0.6015 - val_binary_accuracy: 0.6737\n",
            "Epoch 43/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6767 - val_loss: 0.6016 - val_binary_accuracy: 0.6730\n",
            "Epoch 44/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6743 - val_loss: 0.6015 - val_binary_accuracy: 0.6726\n",
            "Epoch 45/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6720 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 46/200\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6709 - val_loss: 0.6013 - val_binary_accuracy: 0.6722\n",
            "Epoch 47/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6787 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 48/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6711 - val_loss: 0.6013 - val_binary_accuracy: 0.6715\n",
            "Epoch 49/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6710 - val_loss: 0.6012 - val_binary_accuracy: 0.6722\n",
            "Epoch 50/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6710 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 51/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6731 - val_loss: 0.6012 - val_binary_accuracy: 0.6737\n",
            "Epoch 52/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6788 - val_loss: 0.6012 - val_binary_accuracy: 0.6741\n",
            "Epoch 53/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6699 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 54/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6700 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 55/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6710 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 56/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6721 - val_loss: 0.6013 - val_binary_accuracy: 0.6737\n",
            "Epoch 57/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6747 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6720 - val_loss: 0.6014 - val_binary_accuracy: 0.6730\n",
            "Epoch 59/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6770 - val_loss: 0.6013 - val_binary_accuracy: 0.6730\n",
            "Epoch 60/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6737 - val_loss: 0.6013 - val_binary_accuracy: 0.6745\n",
            "Epoch 61/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6717 - val_loss: 0.6012 - val_binary_accuracy: 0.6737\n",
            "Epoch 62/200\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6752 - val_loss: 0.6012 - val_binary_accuracy: 0.6745\n",
            "Epoch 00062: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:25:13,383]\u001b[0m Trial 26 finished with value: 0.6682727932929993 and parameters: {'batch size': 122, 'optimizer': 'Adagrad', 'lr': 0.03255066042585337, 'minimum_learning_rate': 0.006806516269429051}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "86/86 [==============================] - 1s 3ms/step - loss: 0.6834 - binary_accuracy: 0.5852 - val_loss: 0.6434 - val_binary_accuracy: 0.6277\n",
            "Epoch 2/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6598 - binary_accuracy: 0.6023 - val_loss: 0.6322 - val_binary_accuracy: 0.6444\n",
            "Epoch 3/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6198 - val_loss: 0.6260 - val_binary_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6425 - binary_accuracy: 0.6247 - val_loss: 0.6251 - val_binary_accuracy: 0.6537\n",
            "Epoch 5/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6298 - val_loss: 0.6195 - val_binary_accuracy: 0.6637\n",
            "Epoch 6/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6344 - binary_accuracy: 0.6322 - val_loss: 0.6154 - val_binary_accuracy: 0.6648\n",
            "Epoch 7/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6345 - val_loss: 0.6125 - val_binary_accuracy: 0.6663\n",
            "Epoch 8/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6393 - val_loss: 0.6105 - val_binary_accuracy: 0.6685\n",
            "Epoch 9/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6397 - val_loss: 0.6119 - val_binary_accuracy: 0.6663\n",
            "Epoch 10/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6439 - val_loss: 0.6107 - val_binary_accuracy: 0.6656\n",
            "Epoch 11/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6458 - val_loss: 0.6078 - val_binary_accuracy: 0.6678\n",
            "Epoch 12/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6505 - val_loss: 0.6077 - val_binary_accuracy: 0.6670\n",
            "Epoch 13/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6460 - val_loss: 0.6072 - val_binary_accuracy: 0.6696\n",
            "Epoch 14/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6519 - val_loss: 0.6052 - val_binary_accuracy: 0.6711\n",
            "Epoch 15/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6534 - val_loss: 0.6051 - val_binary_accuracy: 0.6741\n",
            "Epoch 16/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6533 - val_loss: 0.6057 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6594 - val_loss: 0.6043 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6524 - val_loss: 0.6041 - val_binary_accuracy: 0.6704\n",
            "Epoch 19/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6586 - val_loss: 0.6039 - val_binary_accuracy: 0.6752\n",
            "Epoch 20/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6627 - val_loss: 0.6042 - val_binary_accuracy: 0.6719\n",
            "Epoch 21/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6587 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 22/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6540 - val_loss: 0.6038 - val_binary_accuracy: 0.6726\n",
            "Epoch 23/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6609 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 24/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6590 - val_loss: 0.6037 - val_binary_accuracy: 0.6726\n",
            "Epoch 25/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6577 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 26/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6637 - val_loss: 0.6031 - val_binary_accuracy: 0.6759\n",
            "Epoch 27/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6619 - val_loss: 0.6031 - val_binary_accuracy: 0.6741\n",
            "Epoch 28/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6099 - binary_accuracy: 0.6628 - val_loss: 0.6026 - val_binary_accuracy: 0.6726\n",
            "Epoch 29/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6628 - val_loss: 0.6025 - val_binary_accuracy: 0.6741\n",
            "Epoch 30/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6656 - val_loss: 0.6024 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6627 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6694 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 33/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6641 - val_loss: 0.6021 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6648 - val_loss: 0.6022 - val_binary_accuracy: 0.6737\n",
            "Epoch 35/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6671 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 36/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6688 - val_loss: 0.6020 - val_binary_accuracy: 0.6737\n",
            "Epoch 37/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6660 - val_loss: 0.6021 - val_binary_accuracy: 0.6711\n",
            "Epoch 38/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6659 - val_loss: 0.6020 - val_binary_accuracy: 0.6722\n",
            "Epoch 39/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6645 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 40/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6661 - val_loss: 0.6019 - val_binary_accuracy: 0.6737\n",
            "Epoch 41/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6679 - val_loss: 0.6021 - val_binary_accuracy: 0.6737\n",
            "Epoch 42/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6691 - val_loss: 0.6020 - val_binary_accuracy: 0.6737\n",
            "Epoch 00042: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:25:22,003]\u001b[0m Trial 27 finished with value: 0.6634544134140015 and parameters: {'batch size': 148, 'optimizer': 'Adagrad', 'lr': 0.02036385168290517, 'minimum_learning_rate': 0.006673958389542934}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97/97 [==============================] - 1s 3ms/step - loss: 0.7160 - binary_accuracy: 0.5694 - val_loss: 0.6458 - val_binary_accuracy: 0.6166\n",
            "Epoch 2/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6644 - binary_accuracy: 0.6003 - val_loss: 0.6329 - val_binary_accuracy: 0.6377\n",
            "Epoch 3/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6510 - binary_accuracy: 0.6159 - val_loss: 0.6276 - val_binary_accuracy: 0.6474\n",
            "Epoch 4/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6468 - binary_accuracy: 0.6203 - val_loss: 0.6246 - val_binary_accuracy: 0.6518\n",
            "Epoch 5/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6218 - val_loss: 0.6206 - val_binary_accuracy: 0.6563\n",
            "Epoch 6/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6375 - binary_accuracy: 0.6269 - val_loss: 0.6186 - val_binary_accuracy: 0.6637\n",
            "Epoch 7/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6351 - binary_accuracy: 0.6302 - val_loss: 0.6177 - val_binary_accuracy: 0.6615\n",
            "Epoch 8/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6318 - val_loss: 0.6155 - val_binary_accuracy: 0.6644\n",
            "Epoch 9/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6412 - val_loss: 0.6140 - val_binary_accuracy: 0.6633\n",
            "Epoch 10/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6478 - val_loss: 0.6111 - val_binary_accuracy: 0.6700\n",
            "Epoch 11/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6415 - val_loss: 0.6099 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6478 - val_loss: 0.6088 - val_binary_accuracy: 0.6741\n",
            "Epoch 13/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6488 - val_loss: 0.6085 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6482 - val_loss: 0.6075 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6464 - val_loss: 0.6079 - val_binary_accuracy: 0.6774\n",
            "Epoch 16/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6493 - val_loss: 0.6063 - val_binary_accuracy: 0.6767\n",
            "Epoch 17/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6503 - val_loss: 0.6066 - val_binary_accuracy: 0.6819\n",
            "Epoch 18/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6578 - val_loss: 0.6055 - val_binary_accuracy: 0.6767\n",
            "Epoch 19/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6558 - val_loss: 0.6055 - val_binary_accuracy: 0.6826\n",
            "Epoch 20/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6514 - val_loss: 0.6049 - val_binary_accuracy: 0.6826\n",
            "Epoch 21/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6550 - val_loss: 0.6049 - val_binary_accuracy: 0.6822\n",
            "Epoch 22/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6527 - val_loss: 0.6047 - val_binary_accuracy: 0.6830\n",
            "Epoch 23/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6567 - val_loss: 0.6039 - val_binary_accuracy: 0.6826\n",
            "Epoch 24/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6564 - val_loss: 0.6037 - val_binary_accuracy: 0.6830\n",
            "Epoch 25/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6613 - val_loss: 0.6038 - val_binary_accuracy: 0.6819\n",
            "Epoch 26/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6629 - val_loss: 0.6038 - val_binary_accuracy: 0.6822\n",
            "Epoch 27/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6609 - val_loss: 0.6033 - val_binary_accuracy: 0.6815\n",
            "Epoch 28/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6606 - val_loss: 0.6025 - val_binary_accuracy: 0.6822\n",
            "Epoch 29/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6653 - val_loss: 0.6028 - val_binary_accuracy: 0.6819\n",
            "Epoch 30/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6616 - val_loss: 0.6030 - val_binary_accuracy: 0.6808\n",
            "Epoch 31/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6672 - val_loss: 0.6024 - val_binary_accuracy: 0.6800\n",
            "Epoch 32/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6628 - val_loss: 0.6022 - val_binary_accuracy: 0.6811\n",
            "Epoch 33/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6683 - val_loss: 0.6021 - val_binary_accuracy: 0.6815\n",
            "Epoch 34/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6623 - val_loss: 0.6021 - val_binary_accuracy: 0.6822\n",
            "Epoch 35/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6597 - val_loss: 0.6019 - val_binary_accuracy: 0.6819\n",
            "Epoch 36/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6641 - val_loss: 0.6022 - val_binary_accuracy: 0.6804\n",
            "Epoch 37/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6649 - val_loss: 0.6019 - val_binary_accuracy: 0.6811\n",
            "Epoch 38/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6594 - val_loss: 0.6020 - val_binary_accuracy: 0.6811\n",
            "Epoch 39/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6682 - val_loss: 0.6019 - val_binary_accuracy: 0.6819\n",
            "Epoch 40/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6644 - val_loss: 0.6018 - val_binary_accuracy: 0.6815\n",
            "Epoch 41/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6096 - binary_accuracy: 0.6656 - val_loss: 0.6018 - val_binary_accuracy: 0.6830\n",
            "Epoch 42/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6637 - val_loss: 0.6018 - val_binary_accuracy: 0.6837\n",
            "Epoch 43/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6697 - val_loss: 0.6018 - val_binary_accuracy: 0.6826\n",
            "Epoch 44/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6679 - val_loss: 0.6018 - val_binary_accuracy: 0.6826\n",
            "Epoch 45/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6680 - val_loss: 0.6017 - val_binary_accuracy: 0.6826\n",
            "Epoch 46/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6672 - val_loss: 0.6017 - val_binary_accuracy: 0.6834\n",
            "Epoch 47/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6650 - val_loss: 0.6016 - val_binary_accuracy: 0.6830\n",
            "Epoch 48/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6682 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 49/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6633 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 50/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6667 - val_loss: 0.6017 - val_binary_accuracy: 0.6826\n",
            "Epoch 51/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6586 - val_loss: 0.6017 - val_binary_accuracy: 0.6826\n",
            "Epoch 52/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6663 - val_loss: 0.6017 - val_binary_accuracy: 0.6826\n",
            "Epoch 53/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6681 - val_loss: 0.6017 - val_binary_accuracy: 0.6826\n",
            "Epoch 54/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6637 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 55/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6636 - val_loss: 0.6016 - val_binary_accuracy: 0.6822\n",
            "Epoch 56/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6701 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 57/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6619 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 58/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6671 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 59/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6675 - val_loss: 0.6016 - val_binary_accuracy: 0.6822\n",
            "Epoch 60/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6718 - val_loss: 0.6016 - val_binary_accuracy: 0.6822\n",
            "Epoch 61/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6694 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 62/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6664 - val_loss: 0.6016 - val_binary_accuracy: 0.6830\n",
            "Epoch 63/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6687 - val_loss: 0.6016 - val_binary_accuracy: 0.6834\n",
            "Epoch 64/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6660 - val_loss: 0.6016 - val_binary_accuracy: 0.6830\n",
            "Epoch 65/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6635 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 66/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6683 - val_loss: 0.6016 - val_binary_accuracy: 0.6826\n",
            "Epoch 67/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6669 - val_loss: 0.6016 - val_binary_accuracy: 0.6822\n",
            "Epoch 68/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6661 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 69/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6714 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 70/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6595 - val_loss: 0.6016 - val_binary_accuracy: 0.6822\n",
            "Epoch 71/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6612 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 72/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6691 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 73/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6706 - val_loss: 0.6016 - val_binary_accuracy: 0.6819\n",
            "Epoch 74/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6684 - val_loss: 0.6016 - val_binary_accuracy: 0.6815\n",
            "Epoch 75/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6702 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 76/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6699 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 77/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6636 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 78/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6702 - val_loss: 0.6015 - val_binary_accuracy: 0.6815\n",
            "Epoch 79/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6681 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 80/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6702 - val_loss: 0.6015 - val_binary_accuracy: 0.6811\n",
            "Epoch 81/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6667 - val_loss: 0.6015 - val_binary_accuracy: 0.6808\n",
            "Epoch 82/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6673 - val_loss: 0.6014 - val_binary_accuracy: 0.6804\n",
            "Epoch 83/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6648 - val_loss: 0.6014 - val_binary_accuracy: 0.6808\n",
            "Epoch 84/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6687 - val_loss: 0.6014 - val_binary_accuracy: 0.6800\n",
            "Epoch 85/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6663 - val_loss: 0.6014 - val_binary_accuracy: 0.6804\n",
            "Epoch 86/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6644 - val_loss: 0.6014 - val_binary_accuracy: 0.6811\n",
            "Epoch 87/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6687 - val_loss: 0.6014 - val_binary_accuracy: 0.6811\n",
            "Epoch 88/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6640 - val_loss: 0.6014 - val_binary_accuracy: 0.6811\n",
            "Epoch 89/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6628 - val_loss: 0.6014 - val_binary_accuracy: 0.6811\n",
            "Epoch 90/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6671 - val_loss: 0.6014 - val_binary_accuracy: 0.6808\n",
            "Epoch 91/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6696 - val_loss: 0.6013 - val_binary_accuracy: 0.6808\n",
            "Epoch 92/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6683 - val_loss: 0.6013 - val_binary_accuracy: 0.6811\n",
            "Epoch 93/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6683 - val_loss: 0.6013 - val_binary_accuracy: 0.6811\n",
            "Epoch 94/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6688 - val_loss: 0.6013 - val_binary_accuracy: 0.6811\n",
            "Epoch 95/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6680 - val_loss: 0.6013 - val_binary_accuracy: 0.6811\n",
            "Epoch 96/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6681 - val_loss: 0.6012 - val_binary_accuracy: 0.6811\n",
            "Epoch 97/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6646 - val_loss: 0.6012 - val_binary_accuracy: 0.6819\n",
            "Epoch 98/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6689 - val_loss: 0.6012 - val_binary_accuracy: 0.6819\n",
            "Epoch 99/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6632 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 100/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6661 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 101/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6633 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 102/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6677 - val_loss: 0.6012 - val_binary_accuracy: 0.6815\n",
            "Epoch 103/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6680 - val_loss: 0.6012 - val_binary_accuracy: 0.6811\n",
            "Epoch 104/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6706 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 105/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6668 - val_loss: 0.6012 - val_binary_accuracy: 0.6804\n",
            "Epoch 106/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6679 - val_loss: 0.6012 - val_binary_accuracy: 0.6804\n",
            "Epoch 107/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6650 - val_loss: 0.6012 - val_binary_accuracy: 0.6804\n",
            "Epoch 108/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6679 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 109/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6662 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 110/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6618 - val_loss: 0.6012 - val_binary_accuracy: 0.6811\n",
            "Epoch 111/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6701 - val_loss: 0.6012 - val_binary_accuracy: 0.6808\n",
            "Epoch 112/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6689 - val_loss: 0.6011 - val_binary_accuracy: 0.6811\n",
            "Epoch 113/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6649 - val_loss: 0.6011 - val_binary_accuracy: 0.6804\n",
            "Epoch 114/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6693 - val_loss: 0.6011 - val_binary_accuracy: 0.6800\n",
            "Epoch 115/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6667 - val_loss: 0.6011 - val_binary_accuracy: 0.6808\n",
            "Epoch 116/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6687 - val_loss: 0.6011 - val_binary_accuracy: 0.6804\n",
            "Epoch 117/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6681 - val_loss: 0.6011 - val_binary_accuracy: 0.6808\n",
            "Epoch 118/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6648 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 119/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6660 - val_loss: 0.6010 - val_binary_accuracy: 0.6811\n",
            "Epoch 120/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6606 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 121/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6631 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 122/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6661 - val_loss: 0.6010 - val_binary_accuracy: 0.6808\n",
            "Epoch 123/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6671 - val_loss: 0.6011 - val_binary_accuracy: 0.6804\n",
            "Epoch 124/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6678 - val_loss: 0.6011 - val_binary_accuracy: 0.6804\n",
            "Epoch 125/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6663 - val_loss: 0.6011 - val_binary_accuracy: 0.6808\n",
            "Epoch 126/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6672 - val_loss: 0.6011 - val_binary_accuracy: 0.6796\n",
            "Epoch 127/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6641 - val_loss: 0.6011 - val_binary_accuracy: 0.6800\n",
            "Epoch 128/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6685 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 129/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6663 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 130/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6714 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 131/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6655 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 132/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6693 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 133/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6627 - val_loss: 0.6010 - val_binary_accuracy: 0.6793\n",
            "Epoch 134/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6663 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 135/200\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6718 - val_loss: 0.6010 - val_binary_accuracy: 0.6796\n",
            "Epoch 136/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6662 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 137/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6690 - val_loss: 0.6010 - val_binary_accuracy: 0.6796\n",
            "Epoch 138/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6694 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 139/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6671 - val_loss: 0.6010 - val_binary_accuracy: 0.6800\n",
            "Epoch 140/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6741 - val_loss: 0.6009 - val_binary_accuracy: 0.6800\n",
            "Epoch 141/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6632 - val_loss: 0.6009 - val_binary_accuracy: 0.6804\n",
            "Epoch 142/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6671 - val_loss: 0.6009 - val_binary_accuracy: 0.6800\n",
            "Epoch 143/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6572 - val_loss: 0.6010 - val_binary_accuracy: 0.6808\n",
            "Epoch 144/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6667 - val_loss: 0.6010 - val_binary_accuracy: 0.6808\n",
            "Epoch 145/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6644 - val_loss: 0.6010 - val_binary_accuracy: 0.6808\n",
            "Epoch 146/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6679 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 147/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6668 - val_loss: 0.6009 - val_binary_accuracy: 0.6804\n",
            "Epoch 148/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6662 - val_loss: 0.6010 - val_binary_accuracy: 0.6804\n",
            "Epoch 149/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6713 - val_loss: 0.6009 - val_binary_accuracy: 0.6804\n",
            "Epoch 150/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6714 - val_loss: 0.6009 - val_binary_accuracy: 0.6804\n",
            "Epoch 151/200\n",
            "97/97 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6668 - val_loss: 0.6009 - val_binary_accuracy: 0.6804\n",
            "Epoch 00151: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:03,497]\u001b[0m Trial 28 finished with value: 0.6675314903259277 and parameters: {'batch size': 130, 'optimizer': 'Adagrad', 'lr': 0.014150681412588495, 'minimum_learning_rate': 0.0009186565394704973}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 0.6790 - binary_accuracy: 0.5829 - val_loss: 0.6373 - val_binary_accuracy: 0.6370\n",
            "Epoch 2/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6497 - binary_accuracy: 0.6166 - val_loss: 0.6285 - val_binary_accuracy: 0.6537\n",
            "Epoch 3/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6431 - binary_accuracy: 0.6187 - val_loss: 0.6214 - val_binary_accuracy: 0.6607\n",
            "Epoch 4/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.6314 - val_loss: 0.6189 - val_binary_accuracy: 0.6656\n",
            "Epoch 5/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6310 - binary_accuracy: 0.6308 - val_loss: 0.6141 - val_binary_accuracy: 0.6726\n",
            "Epoch 6/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6470 - val_loss: 0.6113 - val_binary_accuracy: 0.6722\n",
            "Epoch 7/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6470 - val_loss: 0.6095 - val_binary_accuracy: 0.6722\n",
            "Epoch 8/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6511 - val_loss: 0.6082 - val_binary_accuracy: 0.6719\n",
            "Epoch 9/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6533 - val_loss: 0.6080 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6582 - val_loss: 0.6088 - val_binary_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6552 - val_loss: 0.6066 - val_binary_accuracy: 0.6715\n",
            "Epoch 12/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6619 - val_loss: 0.6059 - val_binary_accuracy: 0.6741\n",
            "Epoch 13/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6545 - val_loss: 0.6052 - val_binary_accuracy: 0.6730\n",
            "Epoch 14/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6592 - val_loss: 0.6047 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6629 - val_loss: 0.6052 - val_binary_accuracy: 0.6730\n",
            "Epoch 16/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6099 - binary_accuracy: 0.6633 - val_loss: 0.6040 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6643 - val_loss: 0.6035 - val_binary_accuracy: 0.6774\n",
            "Epoch 18/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6664 - val_loss: 0.6033 - val_binary_accuracy: 0.6737\n",
            "Epoch 19/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6641 - val_loss: 0.6028 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6675 - val_loss: 0.6028 - val_binary_accuracy: 0.6704\n",
            "Epoch 21/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6646 - val_loss: 0.6029 - val_binary_accuracy: 0.6719\n",
            "Epoch 22/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6626 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6710 - val_loss: 0.6026 - val_binary_accuracy: 0.6763\n",
            "Epoch 24/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6694 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 25/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6677 - val_loss: 0.6018 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6733 - val_loss: 0.6016 - val_binary_accuracy: 0.6759\n",
            "Epoch 27/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6755 - val_loss: 0.6019 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6710 - val_loss: 0.6014 - val_binary_accuracy: 0.6715\n",
            "Epoch 29/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6692 - val_loss: 0.6019 - val_binary_accuracy: 0.6748\n",
            "Epoch 30/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6667 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 31/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6693 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 32/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6690 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6765 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6754 - val_loss: 0.6018 - val_binary_accuracy: 0.6748\n",
            "Epoch 35/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6732 - val_loss: 0.6017 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6720 - val_loss: 0.6016 - val_binary_accuracy: 0.6733\n",
            "Epoch 37/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6728 - val_loss: 0.6018 - val_binary_accuracy: 0.6733\n",
            "Epoch 38/200\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6744 - val_loss: 0.6014 - val_binary_accuracy: 0.6737\n",
            "Epoch 00038: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:12,952]\u001b[0m Trial 29 finished with value: 0.6701260209083557 and parameters: {'batch size': 116, 'optimizer': 'Adagrad', 'lr': 0.025048355026575805, 'minimum_learning_rate': 0.01614491242823877}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 0.6868 - binary_accuracy: 0.5697 - val_loss: 0.6445 - val_binary_accuracy: 0.6181\n",
            "Epoch 2/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.6103 - val_loss: 0.6352 - val_binary_accuracy: 0.6288\n",
            "Epoch 3/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.6231 - val_loss: 0.6272 - val_binary_accuracy: 0.6437\n",
            "Epoch 4/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.6277 - val_loss: 0.6233 - val_binary_accuracy: 0.6466\n",
            "Epoch 5/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6320 - val_loss: 0.6192 - val_binary_accuracy: 0.6548\n",
            "Epoch 6/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6401 - val_loss: 0.6153 - val_binary_accuracy: 0.6618\n",
            "Epoch 7/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6432 - val_loss: 0.6132 - val_binary_accuracy: 0.6633\n",
            "Epoch 8/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6481 - val_loss: 0.6103 - val_binary_accuracy: 0.6626\n",
            "Epoch 9/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6219 - binary_accuracy: 0.6514 - val_loss: 0.6090 - val_binary_accuracy: 0.6633\n",
            "Epoch 10/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6497 - val_loss: 0.6085 - val_binary_accuracy: 0.6644\n",
            "Epoch 11/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6534 - val_loss: 0.6082 - val_binary_accuracy: 0.6659\n",
            "Epoch 12/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6183 - binary_accuracy: 0.6548 - val_loss: 0.6073 - val_binary_accuracy: 0.6689\n",
            "Epoch 13/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6534 - val_loss: 0.6065 - val_binary_accuracy: 0.6670\n",
            "Epoch 14/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6609 - val_loss: 0.6063 - val_binary_accuracy: 0.6689\n",
            "Epoch 15/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6621 - val_loss: 0.6055 - val_binary_accuracy: 0.6689\n",
            "Epoch 16/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6624 - val_loss: 0.6059 - val_binary_accuracy: 0.6722\n",
            "Epoch 17/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6653 - val_loss: 0.6057 - val_binary_accuracy: 0.6730\n",
            "Epoch 18/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6664 - val_loss: 0.6040 - val_binary_accuracy: 0.6748\n",
            "Epoch 19/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6628 - val_loss: 0.6053 - val_binary_accuracy: 0.6745\n",
            "Epoch 20/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6666 - val_loss: 0.6047 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6620 - val_loss: 0.6043 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6702 - val_loss: 0.6039 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6653 - val_loss: 0.6042 - val_binary_accuracy: 0.6748\n",
            "Epoch 24/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6644 - val_loss: 0.6039 - val_binary_accuracy: 0.6733\n",
            "Epoch 25/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6654 - val_loss: 0.6045 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6679 - val_loss: 0.6043 - val_binary_accuracy: 0.6715\n",
            "Epoch 27/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6652 - val_loss: 0.6041 - val_binary_accuracy: 0.6722\n",
            "Epoch 28/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6671 - val_loss: 0.6041 - val_binary_accuracy: 0.6715\n",
            "Epoch 29/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6745 - val_loss: 0.6040 - val_binary_accuracy: 0.6726\n",
            "Epoch 30/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6702 - val_loss: 0.6040 - val_binary_accuracy: 0.6730\n",
            "Epoch 31/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6698 - val_loss: 0.6038 - val_binary_accuracy: 0.6726\n",
            "Epoch 32/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6694 - val_loss: 0.6038 - val_binary_accuracy: 0.6719\n",
            "Epoch 33/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6710 - val_loss: 0.6038 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6062 - binary_accuracy: 0.6687 - val_loss: 0.6037 - val_binary_accuracy: 0.6719\n",
            "Epoch 35/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6694 - val_loss: 0.6037 - val_binary_accuracy: 0.6719\n",
            "Epoch 36/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6651 - val_loss: 0.6037 - val_binary_accuracy: 0.6722\n",
            "Epoch 37/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6702 - val_loss: 0.6036 - val_binary_accuracy: 0.6726\n",
            "Epoch 38/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6690 - val_loss: 0.6037 - val_binary_accuracy: 0.6737\n",
            "Epoch 39/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6733 - val_loss: 0.6036 - val_binary_accuracy: 0.6737\n",
            "Epoch 40/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6711 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 41/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6727 - val_loss: 0.6035 - val_binary_accuracy: 0.6737\n",
            "Epoch 42/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6682 - val_loss: 0.6035 - val_binary_accuracy: 0.6737\n",
            "Epoch 43/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6695 - val_loss: 0.6035 - val_binary_accuracy: 0.6730\n",
            "Epoch 44/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6676 - val_loss: 0.6035 - val_binary_accuracy: 0.6722\n",
            "Epoch 45/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6710 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 46/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6698 - val_loss: 0.6035 - val_binary_accuracy: 0.6730\n",
            "Epoch 47/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6679 - val_loss: 0.6035 - val_binary_accuracy: 0.6722\n",
            "Epoch 48/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6724 - val_loss: 0.6035 - val_binary_accuracy: 0.6730\n",
            "Epoch 49/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6716 - val_loss: 0.6034 - val_binary_accuracy: 0.6722\n",
            "Epoch 50/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6698 - val_loss: 0.6034 - val_binary_accuracy: 0.6719\n",
            "Epoch 51/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6694 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 52/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6705 - val_loss: 0.6034 - val_binary_accuracy: 0.6722\n",
            "Epoch 53/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6683 - val_loss: 0.6034 - val_binary_accuracy: 0.6733\n",
            "Epoch 54/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6684 - val_loss: 0.6034 - val_binary_accuracy: 0.6722\n",
            "Epoch 55/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6645 - val_loss: 0.6034 - val_binary_accuracy: 0.6715\n",
            "Epoch 56/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6740 - val_loss: 0.6033 - val_binary_accuracy: 0.6726\n",
            "Epoch 57/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6689 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 58/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6687 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 59/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6705 - val_loss: 0.6033 - val_binary_accuracy: 0.6704\n",
            "Epoch 60/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6669 - val_loss: 0.6034 - val_binary_accuracy: 0.6707\n",
            "Epoch 61/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6669 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 62/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6707 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 63/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6729 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 64/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6717 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 65/200\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6671 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 66/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6698 - val_loss: 0.6033 - val_binary_accuracy: 0.6715\n",
            "Epoch 67/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6705 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 68/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6714 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 00068: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:26,259]\u001b[0m Trial 30 finished with value: 0.6638250350952148 and parameters: {'batch size': 164, 'optimizer': 'Adagrad', 'lr': 0.03469066324893851, 'minimum_learning_rate': 0.004209228340409003}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6783 - binary_accuracy: 0.5931 - val_loss: 0.6345 - val_binary_accuracy: 0.6326\n",
            "Epoch 2/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6186 - val_loss: 0.6181 - val_binary_accuracy: 0.6593\n",
            "Epoch 3/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6306 - binary_accuracy: 0.6403 - val_loss: 0.6154 - val_binary_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6377 - val_loss: 0.6139 - val_binary_accuracy: 0.6696\n",
            "Epoch 5/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6491 - val_loss: 0.6141 - val_binary_accuracy: 0.6644\n",
            "Epoch 6/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6577 - val_loss: 0.6036 - val_binary_accuracy: 0.6733\n",
            "Epoch 7/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6582 - val_loss: 0.6030 - val_binary_accuracy: 0.6711\n",
            "Epoch 8/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6573 - val_loss: 0.6035 - val_binary_accuracy: 0.6789\n",
            "Epoch 9/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6629 - val_loss: 0.6007 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6629 - val_loss: 0.6011 - val_binary_accuracy: 0.6763\n",
            "Epoch 11/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6646 - val_loss: 0.6010 - val_binary_accuracy: 0.6726\n",
            "Epoch 12/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6636 - val_loss: 0.6077 - val_binary_accuracy: 0.6644\n",
            "Epoch 13/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6640 - val_loss: 0.6066 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6633 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
            "Epoch 15/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6655 - val_loss: 0.6032 - val_binary_accuracy: 0.6711\n",
            "Epoch 16/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6666 - val_loss: 0.6011 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6697 - val_loss: 0.5998 - val_binary_accuracy: 0.6774\n",
            "Epoch 18/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6730 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 19/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6726 - val_loss: 0.6009 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6691 - val_loss: 0.5997 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6739 - val_loss: 0.5994 - val_binary_accuracy: 0.6726\n",
            "Epoch 22/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6729 - val_loss: 0.6000 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6708 - val_loss: 0.5997 - val_binary_accuracy: 0.6726\n",
            "Epoch 24/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6702 - val_loss: 0.6005 - val_binary_accuracy: 0.6711\n",
            "Epoch 25/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6715 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6671 - val_loss: 0.6004 - val_binary_accuracy: 0.6730\n",
            "Epoch 27/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6740 - val_loss: 0.5999 - val_binary_accuracy: 0.6782\n",
            "Epoch 28/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6728 - val_loss: 0.6004 - val_binary_accuracy: 0.6733\n",
            "Epoch 29/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6752 - val_loss: 0.5997 - val_binary_accuracy: 0.6763\n",
            "Epoch 30/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6679 - val_loss: 0.5998 - val_binary_accuracy: 0.6756\n",
            "Epoch 31/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6718 - val_loss: 0.5997 - val_binary_accuracy: 0.6752\n",
            "Epoch 00031: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:33,721]\u001b[0m Trial 31 finished with value: 0.6697553992271423 and parameters: {'batch size': 121, 'optimizer': 'Adagrad', 'lr': 0.04555940062207124, 'minimum_learning_rate': 0.026819460438208147}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 1s 3ms/step - loss: 0.6598 - binary_accuracy: 0.6051 - val_loss: 0.6242 - val_binary_accuracy: 0.6611\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6265 - val_loss: 0.6137 - val_binary_accuracy: 0.6678\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6448 - val_loss: 0.6078 - val_binary_accuracy: 0.6607\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6507 - val_loss: 0.6072 - val_binary_accuracy: 0.6644\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6527 - val_loss: 0.6067 - val_binary_accuracy: 0.6737\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6586 - val_loss: 0.6041 - val_binary_accuracy: 0.6693\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6668 - val_loss: 0.6020 - val_binary_accuracy: 0.6678\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6640 - val_loss: 0.6026 - val_binary_accuracy: 0.6704\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6652 - val_loss: 0.6028 - val_binary_accuracy: 0.6700\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6714 - val_loss: 0.6027 - val_binary_accuracy: 0.6722\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6676 - val_loss: 0.6016 - val_binary_accuracy: 0.6722\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6719 - val_loss: 0.6018 - val_binary_accuracy: 0.6696\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6671 - val_loss: 0.6004 - val_binary_accuracy: 0.6707\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6682 - val_loss: 0.6013 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6727 - val_loss: 0.6007 - val_binary_accuracy: 0.6715\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6702 - val_loss: 0.6008 - val_binary_accuracy: 0.6719\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6764 - val_loss: 0.5999 - val_binary_accuracy: 0.6704\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6719 - val_loss: 0.5994 - val_binary_accuracy: 0.6748\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6770 - val_loss: 0.5994 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6733 - val_loss: 0.5997 - val_binary_accuracy: 0.6715\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6781 - val_loss: 0.5995 - val_binary_accuracy: 0.6700\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6771 - val_loss: 0.5987 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5946 - binary_accuracy: 0.6810 - val_loss: 0.5991 - val_binary_accuracy: 0.6719\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6803 - val_loss: 0.5994 - val_binary_accuracy: 0.6693\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6777 - val_loss: 0.5989 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6750 - val_loss: 0.5986 - val_binary_accuracy: 0.6722\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6748 - val_loss: 0.5998 - val_binary_accuracy: 0.6685\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6796 - val_loss: 0.6001 - val_binary_accuracy: 0.6663\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6774 - val_loss: 0.5997 - val_binary_accuracy: 0.6670\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5935 - binary_accuracy: 0.6812 - val_loss: 0.5983 - val_binary_accuracy: 0.6726\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6808 - val_loss: 0.5982 - val_binary_accuracy: 0.6733\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5946 - binary_accuracy: 0.6792 - val_loss: 0.5993 - val_binary_accuracy: 0.6730\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6803 - val_loss: 0.5991 - val_binary_accuracy: 0.6759\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6771 - val_loss: 0.5996 - val_binary_accuracy: 0.6711\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6811 - val_loss: 0.5999 - val_binary_accuracy: 0.6707\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6749 - val_loss: 0.6004 - val_binary_accuracy: 0.6656\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6801 - val_loss: 0.6001 - val_binary_accuracy: 0.6730\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6823 - val_loss: 0.6014 - val_binary_accuracy: 0.6678\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.6803 - val_loss: 0.6002 - val_binary_accuracy: 0.6704\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6772 - val_loss: 0.5999 - val_binary_accuracy: 0.6726\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5904 - binary_accuracy: 0.6807 - val_loss: 0.6004 - val_binary_accuracy: 0.6711\n",
            "Epoch 00041: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:42,711]\u001b[0m Trial 32 finished with value: 0.6738324761390686 and parameters: {'batch size': 140, 'optimizer': 'Adagrad', 'lr': 0.09087940422115438, 'minimum_learning_rate': 0.06877720755258102}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.6586 - binary_accuracy: 0.5991 - val_loss: 0.6223 - val_binary_accuracy: 0.6611\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6347 - val_loss: 0.6098 - val_binary_accuracy: 0.6715\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6501 - val_loss: 0.6091 - val_binary_accuracy: 0.6693\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6591 - val_loss: 0.6055 - val_binary_accuracy: 0.6704\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6592 - val_loss: 0.6042 - val_binary_accuracy: 0.6759\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6655 - val_loss: 0.6052 - val_binary_accuracy: 0.6689\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6625 - val_loss: 0.6030 - val_binary_accuracy: 0.6711\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6710 - val_loss: 0.6033 - val_binary_accuracy: 0.6700\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6703 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6696 - val_loss: 0.6034 - val_binary_accuracy: 0.6756\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6756 - val_loss: 0.6032 - val_binary_accuracy: 0.6715\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6760 - val_loss: 0.6027 - val_binary_accuracy: 0.6759\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6712 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6681 - val_loss: 0.6000 - val_binary_accuracy: 0.6785\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6789 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6733 - val_loss: 0.6014 - val_binary_accuracy: 0.6767\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6748 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6782 - val_loss: 0.6015 - val_binary_accuracy: 0.6796\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6751 - val_loss: 0.6012 - val_binary_accuracy: 0.6782\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6763 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6841 - val_loss: 0.6019 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5923 - binary_accuracy: 0.6853 - val_loss: 0.6022 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6808 - val_loss: 0.6030 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6799 - val_loss: 0.6027 - val_binary_accuracy: 0.6800\n",
            "Epoch 00024: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:48,930]\u001b[0m Trial 33 finished with value: 0.6656782627105713 and parameters: {'batch size': 109, 'optimizer': 'Adagrad', 'lr': 0.09918239309767576, 'minimum_learning_rate': 0.08187395391589264}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "93/93 [==============================] - 1s 3ms/step - loss: 0.6641 - binary_accuracy: 0.6018 - val_loss: 0.6263 - val_binary_accuracy: 0.6444\n",
            "Epoch 2/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6316 - val_loss: 0.6224 - val_binary_accuracy: 0.6607\n",
            "Epoch 3/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6447 - val_loss: 0.6132 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6493 - val_loss: 0.6072 - val_binary_accuracy: 0.6648\n",
            "Epoch 5/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6609 - val_loss: 0.6074 - val_binary_accuracy: 0.6670\n",
            "Epoch 6/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6623 - val_loss: 0.6065 - val_binary_accuracy: 0.6693\n",
            "Epoch 7/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6630 - val_loss: 0.6068 - val_binary_accuracy: 0.6722\n",
            "Epoch 8/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6679 - val_loss: 0.6030 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6630 - val_loss: 0.6021 - val_binary_accuracy: 0.6715\n",
            "Epoch 10/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6691 - val_loss: 0.6018 - val_binary_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6697 - val_loss: 0.6036 - val_binary_accuracy: 0.6700\n",
            "Epoch 12/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6664 - val_loss: 0.6021 - val_binary_accuracy: 0.6741\n",
            "Epoch 13/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6745 - val_loss: 0.6024 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6752 - val_loss: 0.6020 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6729 - val_loss: 0.6025 - val_binary_accuracy: 0.6748\n",
            "Epoch 16/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6742 - val_loss: 0.6029 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6752 - val_loss: 0.6017 - val_binary_accuracy: 0.6722\n",
            "Epoch 18/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6741 - val_loss: 0.6005 - val_binary_accuracy: 0.6715\n",
            "Epoch 19/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6714 - val_loss: 0.6026 - val_binary_accuracy: 0.6793\n",
            "Epoch 20/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6773 - val_loss: 0.6011 - val_binary_accuracy: 0.6722\n",
            "Epoch 21/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6747 - val_loss: 0.6011 - val_binary_accuracy: 0.6774\n",
            "Epoch 22/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6760 - val_loss: 0.6035 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6791 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 24/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6759 - val_loss: 0.6016 - val_binary_accuracy: 0.6733\n",
            "Epoch 25/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6754 - val_loss: 0.6030 - val_binary_accuracy: 0.6715\n",
            "Epoch 26/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6765 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 27/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6787 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 28/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6775 - val_loss: 0.6025 - val_binary_accuracy: 0.6748\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:26:59,692]\u001b[0m Trial 34 finished with value: 0.6704966425895691 and parameters: {'batch size': 136, 'optimizer': 'Adagrad', 'lr': 0.08491782245310756, 'minimum_learning_rate': 0.0733371041552588}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "102/102 [==============================] - 1s 3ms/step - loss: 0.6605 - binary_accuracy: 0.6068 - val_loss: 0.6249 - val_binary_accuracy: 0.6555\n",
            "Epoch 2/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6333 - val_loss: 0.6122 - val_binary_accuracy: 0.6630\n",
            "Epoch 3/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6467 - val_loss: 0.6098 - val_binary_accuracy: 0.6715\n",
            "Epoch 4/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6530 - val_loss: 0.6077 - val_binary_accuracy: 0.6719\n",
            "Epoch 5/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6584 - val_loss: 0.6067 - val_binary_accuracy: 0.6737\n",
            "Epoch 6/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6629 - val_loss: 0.6057 - val_binary_accuracy: 0.6696\n",
            "Epoch 7/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6626 - val_loss: 0.6036 - val_binary_accuracy: 0.6693\n",
            "Epoch 8/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6641 - val_loss: 0.6026 - val_binary_accuracy: 0.6711\n",
            "Epoch 9/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6704 - val_loss: 0.6008 - val_binary_accuracy: 0.6733\n",
            "Epoch 10/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6687 - val_loss: 0.6018 - val_binary_accuracy: 0.6752\n",
            "Epoch 11/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6656 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 12/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6649 - val_loss: 0.6017 - val_binary_accuracy: 0.6715\n",
            "Epoch 13/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6690 - val_loss: 0.6008 - val_binary_accuracy: 0.6726\n",
            "Epoch 14/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6743 - val_loss: 0.6003 - val_binary_accuracy: 0.6778\n",
            "Epoch 15/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6706 - val_loss: 0.6008 - val_binary_accuracy: 0.6685\n",
            "Epoch 16/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6707 - val_loss: 0.6003 - val_binary_accuracy: 0.6789\n",
            "Epoch 17/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6755 - val_loss: 0.6000 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6772 - val_loss: 0.6010 - val_binary_accuracy: 0.6696\n",
            "Epoch 19/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6737 - val_loss: 0.6004 - val_binary_accuracy: 0.6730\n",
            "Epoch 20/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6772 - val_loss: 0.6012 - val_binary_accuracy: 0.6685\n",
            "Epoch 21/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6782 - val_loss: 0.6013 - val_binary_accuracy: 0.6678\n",
            "Epoch 22/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6773 - val_loss: 0.6020 - val_binary_accuracy: 0.6681\n",
            "Epoch 23/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6790 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
            "Epoch 24/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6733 - val_loss: 0.6009 - val_binary_accuracy: 0.6722\n",
            "Epoch 25/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6803 - val_loss: 0.6003 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6806 - val_loss: 0.6008 - val_binary_accuracy: 0.6704\n",
            "Epoch 27/200\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6752 - val_loss: 0.6015 - val_binary_accuracy: 0.6652\n",
            "Epoch 00027: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:27:06,126]\u001b[0m Trial 35 finished with value: 0.6671608686447144 and parameters: {'batch size': 124, 'optimizer': 'Adagrad', 'lr': 0.07822345822960082, 'minimum_learning_rate': 0.044123056914049524}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "71/71 [==============================] - 1s 4ms/step - loss: 0.6704 - binary_accuracy: 0.5945 - val_loss: 0.6301 - val_binary_accuracy: 0.6452\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6327 - val_loss: 0.6159 - val_binary_accuracy: 0.6600\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6469 - val_loss: 0.6090 - val_binary_accuracy: 0.6696\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6195 - binary_accuracy: 0.6441 - val_loss: 0.6061 - val_binary_accuracy: 0.6707\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6563 - val_loss: 0.6040 - val_binary_accuracy: 0.6722\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6548 - val_loss: 0.6063 - val_binary_accuracy: 0.6737\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.6639 - val_loss: 0.6008 - val_binary_accuracy: 0.6745\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6621 - val_loss: 0.6028 - val_binary_accuracy: 0.6748\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6661 - val_loss: 0.6038 - val_binary_accuracy: 0.6752\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6648 - val_loss: 0.6006 - val_binary_accuracy: 0.6756\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6693 - val_loss: 0.6006 - val_binary_accuracy: 0.6748\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6718 - val_loss: 0.6003 - val_binary_accuracy: 0.6782\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6702 - val_loss: 0.6025 - val_binary_accuracy: 0.6756\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6749 - val_loss: 0.6006 - val_binary_accuracy: 0.6745\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6732 - val_loss: 0.6018 - val_binary_accuracy: 0.6778\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6719 - val_loss: 0.6005 - val_binary_accuracy: 0.6826\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6745 - val_loss: 0.5998 - val_binary_accuracy: 0.6811\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6712 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6763 - val_loss: 0.5989 - val_binary_accuracy: 0.6845\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6730 - val_loss: 0.5997 - val_binary_accuracy: 0.6782\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6772 - val_loss: 0.5992 - val_binary_accuracy: 0.6796\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6749 - val_loss: 0.5996 - val_binary_accuracy: 0.6789\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6757 - val_loss: 0.5983 - val_binary_accuracy: 0.6808\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6788 - val_loss: 0.5995 - val_binary_accuracy: 0.6778\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6788 - val_loss: 0.5992 - val_binary_accuracy: 0.6796\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6742 - val_loss: 0.5998 - val_binary_accuracy: 0.6752\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6748 - val_loss: 0.5998 - val_binary_accuracy: 0.6796\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6775 - val_loss: 0.6002 - val_binary_accuracy: 0.6737\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6813 - val_loss: 0.6005 - val_binary_accuracy: 0.6778\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6756 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6815 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5942 - binary_accuracy: 0.6807 - val_loss: 0.6001 - val_binary_accuracy: 0.6756\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6775 - val_loss: 0.6004 - val_binary_accuracy: 0.6782\n",
            "Epoch 00033: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:27:12,896]\u001b[0m Trial 36 finished with value: 0.6704966425895691 and parameters: {'batch size': 178, 'optimizer': 'Adagrad', 'lr': 0.09351241733063088, 'minimum_learning_rate': 0.08911408631932718}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "86/86 [==============================] - 1s 3ms/step - loss: 0.6760 - binary_accuracy: 0.5904 - val_loss: 0.6483 - val_binary_accuracy: 0.6229\n",
            "Epoch 2/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6160 - val_loss: 0.6277 - val_binary_accuracy: 0.6507\n",
            "Epoch 3/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6343 - val_loss: 0.6233 - val_binary_accuracy: 0.6559\n",
            "Epoch 4/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6444 - val_loss: 0.6188 - val_binary_accuracy: 0.6652\n",
            "Epoch 5/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6482 - val_loss: 0.6158 - val_binary_accuracy: 0.6596\n",
            "Epoch 6/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6584 - val_loss: 0.6168 - val_binary_accuracy: 0.6693\n",
            "Epoch 7/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6554 - val_loss: 0.6115 - val_binary_accuracy: 0.6700\n",
            "Epoch 8/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6640 - val_loss: 0.6178 - val_binary_accuracy: 0.6648\n",
            "Epoch 9/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6584 - val_loss: 0.6091 - val_binary_accuracy: 0.6685\n",
            "Epoch 10/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6675 - val_loss: 0.6099 - val_binary_accuracy: 0.6663\n",
            "Epoch 11/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6681 - val_loss: 0.6081 - val_binary_accuracy: 0.6707\n",
            "Epoch 12/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6683 - val_loss: 0.6076 - val_binary_accuracy: 0.6685\n",
            "Epoch 13/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6772 - val_loss: 0.6074 - val_binary_accuracy: 0.6715\n",
            "Epoch 14/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6684 - val_loss: 0.6076 - val_binary_accuracy: 0.6719\n",
            "Epoch 15/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6711 - val_loss: 0.6050 - val_binary_accuracy: 0.6737\n",
            "Epoch 16/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6700 - val_loss: 0.6051 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6702 - val_loss: 0.6053 - val_binary_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6703 - val_loss: 0.6045 - val_binary_accuracy: 0.6689\n",
            "Epoch 19/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6723 - val_loss: 0.6051 - val_binary_accuracy: 0.6733\n",
            "Epoch 20/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6719 - val_loss: 0.6044 - val_binary_accuracy: 0.6696\n",
            "Epoch 21/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6783 - val_loss: 0.6050 - val_binary_accuracy: 0.6715\n",
            "Epoch 22/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6767 - val_loss: 0.6041 - val_binary_accuracy: 0.6770\n",
            "Epoch 23/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6709 - val_loss: 0.6042 - val_binary_accuracy: 0.6752\n",
            "Epoch 24/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6761 - val_loss: 0.6047 - val_binary_accuracy: 0.6685\n",
            "Epoch 25/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6752 - val_loss: 0.6053 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6785 - val_loss: 0.6045 - val_binary_accuracy: 0.6707\n",
            "Epoch 27/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6783 - val_loss: 0.6049 - val_binary_accuracy: 0.6715\n",
            "Epoch 28/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.6768 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 29/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6774 - val_loss: 0.6044 - val_binary_accuracy: 0.6715\n",
            "Epoch 30/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6728 - val_loss: 0.6042 - val_binary_accuracy: 0.6733\n",
            "Epoch 31/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6767 - val_loss: 0.6039 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6823 - val_loss: 0.6044 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5946 - binary_accuracy: 0.6768 - val_loss: 0.6044 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6741 - val_loss: 0.6037 - val_binary_accuracy: 0.6726\n",
            "Epoch 35/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6772 - val_loss: 0.6048 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6806 - val_loss: 0.6046 - val_binary_accuracy: 0.6696\n",
            "Epoch 37/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5929 - binary_accuracy: 0.6830 - val_loss: 0.6042 - val_binary_accuracy: 0.6711\n",
            "Epoch 38/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5885 - binary_accuracy: 0.6831 - val_loss: 0.6041 - val_binary_accuracy: 0.6704\n",
            "Epoch 39/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6769 - val_loss: 0.6047 - val_binary_accuracy: 0.6711\n",
            "Epoch 40/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5926 - binary_accuracy: 0.6810 - val_loss: 0.6059 - val_binary_accuracy: 0.6656\n",
            "Epoch 41/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5952 - binary_accuracy: 0.6807 - val_loss: 0.6058 - val_binary_accuracy: 0.6667\n",
            "Epoch 42/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5928 - binary_accuracy: 0.6830 - val_loss: 0.6049 - val_binary_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6814 - val_loss: 0.6053 - val_binary_accuracy: 0.6689\n",
            "Epoch 44/200\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.5913 - binary_accuracy: 0.6825 - val_loss: 0.6059 - val_binary_accuracy: 0.6696\n",
            "Epoch 00044: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:27:23,641]\u001b[0m Trial 37 finished with value: 0.664195716381073 and parameters: {'batch size': 148, 'optimizer': 'Adagrad', 'lr': 0.06339413395598023, 'minimum_learning_rate': 0.04285051389738616}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "89/89 [==============================] - 1s 3ms/step - loss: 0.6672 - binary_accuracy: 0.6031 - val_loss: 0.6337 - val_binary_accuracy: 0.6452\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.6281 - val_loss: 0.6193 - val_binary_accuracy: 0.6511\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6432 - val_loss: 0.6154 - val_binary_accuracy: 0.6596\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6513 - val_loss: 0.6091 - val_binary_accuracy: 0.6689\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6604 - val_loss: 0.6061 - val_binary_accuracy: 0.6733\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6629 - val_loss: 0.6050 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6629 - val_loss: 0.6044 - val_binary_accuracy: 0.6622\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6660 - val_loss: 0.6055 - val_binary_accuracy: 0.6689\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6653 - val_loss: 0.6045 - val_binary_accuracy: 0.6659\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6666 - val_loss: 0.6038 - val_binary_accuracy: 0.6700\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6736 - val_loss: 0.6034 - val_binary_accuracy: 0.6685\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6698 - val_loss: 0.6030 - val_binary_accuracy: 0.6707\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6705 - val_loss: 0.6024 - val_binary_accuracy: 0.6722\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6714 - val_loss: 0.6037 - val_binary_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6756 - val_loss: 0.6023 - val_binary_accuracy: 0.6737\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6723 - val_loss: 0.6023 - val_binary_accuracy: 0.6722\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6698 - val_loss: 0.6010 - val_binary_accuracy: 0.6759\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6779 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6750 - val_loss: 0.6016 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6745 - val_loss: 0.6018 - val_binary_accuracy: 0.6711\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6784 - val_loss: 0.6024 - val_binary_accuracy: 0.6681\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6775 - val_loss: 0.6019 - val_binary_accuracy: 0.6693\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6768 - val_loss: 0.6008 - val_binary_accuracy: 0.6748\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6735 - val_loss: 0.6021 - val_binary_accuracy: 0.6689\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6752 - val_loss: 0.6028 - val_binary_accuracy: 0.6704\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6795 - val_loss: 0.6026 - val_binary_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6805 - val_loss: 0.6017 - val_binary_accuracy: 0.6674\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6774 - val_loss: 0.6027 - val_binary_accuracy: 0.6641\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5931 - binary_accuracy: 0.6821 - val_loss: 0.6029 - val_binary_accuracy: 0.6637\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6812 - val_loss: 0.6022 - val_binary_accuracy: 0.6663\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5920 - binary_accuracy: 0.6856 - val_loss: 0.6025 - val_binary_accuracy: 0.6700\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6794 - val_loss: 0.6028 - val_binary_accuracy: 0.6659\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.6799 - val_loss: 0.6022 - val_binary_accuracy: 0.6719\n",
            "Epoch 00033: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:27:30,631]\u001b[0m Trial 38 finished with value: 0.6682727932929993 and parameters: {'batch size': 142, 'optimizer': 'Adagrad', 'lr': 0.07447528508698652, 'minimum_learning_rate': 0.060936377030049865}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "118/118 [==============================] - 1s 3ms/step - loss: 0.6639 - binary_accuracy: 0.5983 - val_loss: 0.6283 - val_binary_accuracy: 0.6485\n",
            "Epoch 2/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6332 - val_loss: 0.6172 - val_binary_accuracy: 0.6615\n",
            "Epoch 3/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6498 - val_loss: 0.6117 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6509 - val_loss: 0.6084 - val_binary_accuracy: 0.6763\n",
            "Epoch 5/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6540 - val_loss: 0.6073 - val_binary_accuracy: 0.6722\n",
            "Epoch 6/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6588 - val_loss: 0.6053 - val_binary_accuracy: 0.6711\n",
            "Epoch 7/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6602 - val_loss: 0.6043 - val_binary_accuracy: 0.6730\n",
            "Epoch 8/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6655 - val_loss: 0.6037 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6600 - val_loss: 0.6040 - val_binary_accuracy: 0.6715\n",
            "Epoch 10/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6675 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 11/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6722 - val_loss: 0.6031 - val_binary_accuracy: 0.6696\n",
            "Epoch 12/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6675 - val_loss: 0.6023 - val_binary_accuracy: 0.6785\n",
            "Epoch 13/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6662 - val_loss: 0.6017 - val_binary_accuracy: 0.6770\n",
            "Epoch 14/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6741 - val_loss: 0.6021 - val_binary_accuracy: 0.6759\n",
            "Epoch 15/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6706 - val_loss: 0.6012 - val_binary_accuracy: 0.6756\n",
            "Epoch 16/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6691 - val_loss: 0.6018 - val_binary_accuracy: 0.6752\n",
            "Epoch 17/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6692 - val_loss: 0.6008 - val_binary_accuracy: 0.6726\n",
            "Epoch 18/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6754 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 19/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6754 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 20/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6749 - val_loss: 0.6019 - val_binary_accuracy: 0.6704\n",
            "Epoch 21/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6744 - val_loss: 0.6014 - val_binary_accuracy: 0.6730\n",
            "Epoch 22/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6764 - val_loss: 0.6014 - val_binary_accuracy: 0.6730\n",
            "Epoch 23/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6766 - val_loss: 0.6015 - val_binary_accuracy: 0.6726\n",
            "Epoch 24/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6790 - val_loss: 0.6014 - val_binary_accuracy: 0.6726\n",
            "Epoch 25/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6793 - val_loss: 0.6014 - val_binary_accuracy: 0.6726\n",
            "Epoch 26/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6753 - val_loss: 0.6014 - val_binary_accuracy: 0.6726\n",
            "Epoch 27/200\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6787 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 00027: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:27:41,411]\u001b[0m Trial 39 finished with value: 0.6645663380622864 and parameters: {'batch size': 107, 'optimizer': 'Adagrad', 'lr': 0.05630990195995095, 'minimum_learning_rate': 0.013881727640152844}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 1s 3ms/step - loss: 0.7020 - binary_accuracy: 0.5693 - val_loss: 0.6400 - val_binary_accuracy: 0.6288\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6575 - binary_accuracy: 0.6026 - val_loss: 0.6321 - val_binary_accuracy: 0.6426\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6534 - binary_accuracy: 0.6119 - val_loss: 0.6284 - val_binary_accuracy: 0.6474\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6234 - val_loss: 0.6253 - val_binary_accuracy: 0.6437\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6394 - binary_accuracy: 0.6304 - val_loss: 0.6222 - val_binary_accuracy: 0.6485\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6397 - val_loss: 0.6195 - val_binary_accuracy: 0.6496\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6344 - val_loss: 0.6177 - val_binary_accuracy: 0.6511\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6387 - val_loss: 0.6156 - val_binary_accuracy: 0.6570\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6448 - val_loss: 0.6135 - val_binary_accuracy: 0.6581\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6414 - val_loss: 0.6124 - val_binary_accuracy: 0.6622\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6476 - val_loss: 0.6112 - val_binary_accuracy: 0.6622\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6506 - val_loss: 0.6099 - val_binary_accuracy: 0.6644\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6525 - val_loss: 0.6089 - val_binary_accuracy: 0.6637\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6516 - val_loss: 0.6082 - val_binary_accuracy: 0.6674\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6520 - val_loss: 0.6080 - val_binary_accuracy: 0.6670\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6530 - val_loss: 0.6081 - val_binary_accuracy: 0.6648\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6524 - val_loss: 0.6075 - val_binary_accuracy: 0.6670\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6563 - val_loss: 0.6076 - val_binary_accuracy: 0.6696\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6562 - val_loss: 0.6074 - val_binary_accuracy: 0.6711\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6560 - val_loss: 0.6067 - val_binary_accuracy: 0.6681\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6611 - val_loss: 0.6066 - val_binary_accuracy: 0.6693\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6533 - val_loss: 0.6066 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6602 - val_loss: 0.6061 - val_binary_accuracy: 0.6685\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6608 - val_loss: 0.6058 - val_binary_accuracy: 0.6700\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6604 - val_loss: 0.6053 - val_binary_accuracy: 0.6678\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6583 - val_loss: 0.6050 - val_binary_accuracy: 0.6670\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6608 - val_loss: 0.6049 - val_binary_accuracy: 0.6670\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6590 - val_loss: 0.6049 - val_binary_accuracy: 0.6722\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6639 - val_loss: 0.6050 - val_binary_accuracy: 0.6681\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6595 - val_loss: 0.6049 - val_binary_accuracy: 0.6693\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6642 - val_loss: 0.6047 - val_binary_accuracy: 0.6722\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6624 - val_loss: 0.6046 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6674 - val_loss: 0.6046 - val_binary_accuracy: 0.6715\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6617 - val_loss: 0.6045 - val_binary_accuracy: 0.6696\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6633 - val_loss: 0.6044 - val_binary_accuracy: 0.6715\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6667 - val_loss: 0.6042 - val_binary_accuracy: 0.6726\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6694 - val_loss: 0.6041 - val_binary_accuracy: 0.6707\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6642 - val_loss: 0.6040 - val_binary_accuracy: 0.6711\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6605 - val_loss: 0.6041 - val_binary_accuracy: 0.6711\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6669 - val_loss: 0.6040 - val_binary_accuracy: 0.6696\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6083 - binary_accuracy: 0.6623 - val_loss: 0.6040 - val_binary_accuracy: 0.6700\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6646 - val_loss: 0.6039 - val_binary_accuracy: 0.6693\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6681 - val_loss: 0.6039 - val_binary_accuracy: 0.6689\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6627 - val_loss: 0.6039 - val_binary_accuracy: 0.6704\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6657 - val_loss: 0.6038 - val_binary_accuracy: 0.6696\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6661 - val_loss: 0.6037 - val_binary_accuracy: 0.6715\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6641 - val_loss: 0.6037 - val_binary_accuracy: 0.6707\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6627 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6664 - val_loss: 0.6036 - val_binary_accuracy: 0.6711\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6675 - val_loss: 0.6035 - val_binary_accuracy: 0.6696\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6642 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6683 - val_loss: 0.6035 - val_binary_accuracy: 0.6689\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6677 - val_loss: 0.6036 - val_binary_accuracy: 0.6719\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6698 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6701 - val_loss: 0.6034 - val_binary_accuracy: 0.6715\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6656 - val_loss: 0.6034 - val_binary_accuracy: 0.6737\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6665 - val_loss: 0.6033 - val_binary_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6667 - val_loss: 0.6032 - val_binary_accuracy: 0.6737\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6709 - val_loss: 0.6032 - val_binary_accuracy: 0.6730\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6687 - val_loss: 0.6031 - val_binary_accuracy: 0.6726\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6662 - val_loss: 0.6031 - val_binary_accuracy: 0.6737\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6686 - val_loss: 0.6030 - val_binary_accuracy: 0.6730\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6701 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6684 - val_loss: 0.6030 - val_binary_accuracy: 0.6745\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6629 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6708 - val_loss: 0.6030 - val_binary_accuracy: 0.6737\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6664 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6679 - val_loss: 0.6028 - val_binary_accuracy: 0.6730\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6664 - val_loss: 0.6028 - val_binary_accuracy: 0.6748\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6692 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6644 - val_loss: 0.6028 - val_binary_accuracy: 0.6745\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6696 - val_loss: 0.6027 - val_binary_accuracy: 0.6737\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6661 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6713 - val_loss: 0.6028 - val_binary_accuracy: 0.6767\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6750 - val_loss: 0.6028 - val_binary_accuracy: 0.6759\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6670 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6698 - val_loss: 0.6027 - val_binary_accuracy: 0.6759\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6718 - val_loss: 0.6027 - val_binary_accuracy: 0.6748\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6710 - val_loss: 0.6026 - val_binary_accuracy: 0.6748\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6718 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6698 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6685 - val_loss: 0.6026 - val_binary_accuracy: 0.6752\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6723 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6719 - val_loss: 0.6025 - val_binary_accuracy: 0.6752\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6721 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6047 - binary_accuracy: 0.6683 - val_loss: 0.6026 - val_binary_accuracy: 0.6752\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6690 - val_loss: 0.6025 - val_binary_accuracy: 0.6756\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6730 - val_loss: 0.6024 - val_binary_accuracy: 0.6752\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6710 - val_loss: 0.6025 - val_binary_accuracy: 0.6752\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6677 - val_loss: 0.6026 - val_binary_accuracy: 0.6745\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6728 - val_loss: 0.6026 - val_binary_accuracy: 0.6733\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6766 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6738 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6690 - val_loss: 0.6025 - val_binary_accuracy: 0.6745\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6718 - val_loss: 0.6025 - val_binary_accuracy: 0.6741\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6715 - val_loss: 0.6024 - val_binary_accuracy: 0.6756\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6724 - val_loss: 0.6023 - val_binary_accuracy: 0.6756\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6701 - val_loss: 0.6023 - val_binary_accuracy: 0.6748\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6760 - val_loss: 0.6022 - val_binary_accuracy: 0.6748\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6759 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6752 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6785 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6741 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6786 - val_loss: 0.6021 - val_binary_accuracy: 0.6741\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6694 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6702 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6743 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6714 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6698 - val_loss: 0.6021 - val_binary_accuracy: 0.6748\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6728 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6793 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6676 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6706 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6695 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6706 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6711 - val_loss: 0.6022 - val_binary_accuracy: 0.6756\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6741 - val_loss: 0.6022 - val_binary_accuracy: 0.6763\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6696 - val_loss: 0.6023 - val_binary_accuracy: 0.6756\n",
            "Epoch 00118: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:28:22,926]\u001b[0m Trial 40 finished with value: 0.6604892611503601 and parameters: {'batch size': 126, 'optimizer': 'Adagrad', 'lr': 0.015886132115665492, 'minimum_learning_rate': 0.005983309037288026}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "107/107 [==============================] - 1s 3ms/step - loss: 0.6880 - binary_accuracy: 0.5771 - val_loss: 0.6409 - val_binary_accuracy: 0.6337\n",
            "Epoch 2/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6514 - binary_accuracy: 0.6166 - val_loss: 0.6310 - val_binary_accuracy: 0.6455\n",
            "Epoch 3/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6396 - binary_accuracy: 0.6293 - val_loss: 0.6242 - val_binary_accuracy: 0.6541\n",
            "Epoch 4/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6385 - val_loss: 0.6202 - val_binary_accuracy: 0.6585\n",
            "Epoch 5/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6368 - val_loss: 0.6165 - val_binary_accuracy: 0.6637\n",
            "Epoch 6/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6442 - val_loss: 0.6139 - val_binary_accuracy: 0.6652\n",
            "Epoch 7/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6408 - val_loss: 0.6118 - val_binary_accuracy: 0.6693\n",
            "Epoch 8/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6463 - val_loss: 0.6105 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6496 - val_loss: 0.6083 - val_binary_accuracy: 0.6730\n",
            "Epoch 10/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6528 - val_loss: 0.6067 - val_binary_accuracy: 0.6770\n",
            "Epoch 11/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6605 - val_loss: 0.6061 - val_binary_accuracy: 0.6767\n",
            "Epoch 12/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6566 - val_loss: 0.6061 - val_binary_accuracy: 0.6726\n",
            "Epoch 13/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6577 - val_loss: 0.6050 - val_binary_accuracy: 0.6748\n",
            "Epoch 14/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6582 - val_loss: 0.6043 - val_binary_accuracy: 0.6748\n",
            "Epoch 15/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6575 - val_loss: 0.6039 - val_binary_accuracy: 0.6774\n",
            "Epoch 16/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6605 - val_loss: 0.6030 - val_binary_accuracy: 0.6774\n",
            "Epoch 17/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6611 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 18/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6589 - val_loss: 0.6020 - val_binary_accuracy: 0.6785\n",
            "Epoch 19/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6656 - val_loss: 0.6014 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6683 - val_loss: 0.6011 - val_binary_accuracy: 0.6767\n",
            "Epoch 21/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6672 - val_loss: 0.6008 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6701 - val_loss: 0.6012 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.6698 - val_loss: 0.6013 - val_binary_accuracy: 0.6785\n",
            "Epoch 24/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6721 - val_loss: 0.6009 - val_binary_accuracy: 0.6741\n",
            "Epoch 25/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6657 - val_loss: 0.6011 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6702 - val_loss: 0.6009 - val_binary_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6721 - val_loss: 0.6003 - val_binary_accuracy: 0.6733\n",
            "Epoch 28/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6663 - val_loss: 0.5998 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6685 - val_loss: 0.6002 - val_binary_accuracy: 0.6733\n",
            "Epoch 30/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6708 - val_loss: 0.5998 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6686 - val_loss: 0.5998 - val_binary_accuracy: 0.6759\n",
            "Epoch 32/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6718 - val_loss: 0.5996 - val_binary_accuracy: 0.6752\n",
            "Epoch 33/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6687 - val_loss: 0.5997 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6717 - val_loss: 0.6000 - val_binary_accuracy: 0.6756\n",
            "Epoch 35/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6720 - val_loss: 0.5998 - val_binary_accuracy: 0.6759\n",
            "Epoch 36/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6711 - val_loss: 0.5992 - val_binary_accuracy: 0.6752\n",
            "Epoch 37/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6765 - val_loss: 0.5991 - val_binary_accuracy: 0.6763\n",
            "Epoch 38/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6731 - val_loss: 0.5993 - val_binary_accuracy: 0.6745\n",
            "Epoch 39/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6730 - val_loss: 0.5994 - val_binary_accuracy: 0.6756\n",
            "Epoch 40/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6773 - val_loss: 0.5989 - val_binary_accuracy: 0.6759\n",
            "Epoch 41/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6775 - val_loss: 0.5992 - val_binary_accuracy: 0.6748\n",
            "Epoch 42/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6759 - val_loss: 0.5990 - val_binary_accuracy: 0.6722\n",
            "Epoch 43/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6721 - val_loss: 0.5988 - val_binary_accuracy: 0.6774\n",
            "Epoch 44/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6752 - val_loss: 0.5989 - val_binary_accuracy: 0.6759\n",
            "Epoch 45/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6728 - val_loss: 0.5989 - val_binary_accuracy: 0.6748\n",
            "Epoch 46/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6776 - val_loss: 0.5989 - val_binary_accuracy: 0.6763\n",
            "Epoch 47/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6767 - val_loss: 0.5992 - val_binary_accuracy: 0.6770\n",
            "Epoch 48/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6767 - val_loss: 0.5991 - val_binary_accuracy: 0.6759\n",
            "Epoch 49/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5986 - binary_accuracy: 0.6742 - val_loss: 0.5992 - val_binary_accuracy: 0.6767\n",
            "Epoch 50/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6727 - val_loss: 0.5994 - val_binary_accuracy: 0.6737\n",
            "Epoch 51/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6746 - val_loss: 0.5994 - val_binary_accuracy: 0.6774\n",
            "Epoch 52/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6816 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 53/200\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6722 - val_loss: 0.5990 - val_binary_accuracy: 0.6767\n",
            "Epoch 54/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6719 - val_loss: 0.5990 - val_binary_accuracy: 0.6759\n",
            "Epoch 55/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6758 - val_loss: 0.5990 - val_binary_accuracy: 0.6756\n",
            "Epoch 56/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6746 - val_loss: 0.5990 - val_binary_accuracy: 0.6759\n",
            "Epoch 57/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5952 - binary_accuracy: 0.6813 - val_loss: 0.5990 - val_binary_accuracy: 0.6767\n",
            "Epoch 58/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6783 - val_loss: 0.5990 - val_binary_accuracy: 0.6759\n",
            "Epoch 59/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6770 - val_loss: 0.5989 - val_binary_accuracy: 0.6778\n",
            "Epoch 60/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5971 - binary_accuracy: 0.6823 - val_loss: 0.5987 - val_binary_accuracy: 0.6778\n",
            "Epoch 61/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6805 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 62/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6747 - val_loss: 0.5987 - val_binary_accuracy: 0.6767\n",
            "Epoch 63/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6738 - val_loss: 0.5989 - val_binary_accuracy: 0.6748\n",
            "Epoch 64/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6741 - val_loss: 0.5987 - val_binary_accuracy: 0.6763\n",
            "Epoch 65/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6799 - val_loss: 0.5985 - val_binary_accuracy: 0.6759\n",
            "Epoch 66/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6750 - val_loss: 0.5987 - val_binary_accuracy: 0.6782\n",
            "Epoch 67/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6752 - val_loss: 0.5988 - val_binary_accuracy: 0.6767\n",
            "Epoch 68/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6743 - val_loss: 0.5985 - val_binary_accuracy: 0.6767\n",
            "Epoch 69/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6763 - val_loss: 0.5984 - val_binary_accuracy: 0.6793\n",
            "Epoch 70/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.6807 - val_loss: 0.5980 - val_binary_accuracy: 0.6774\n",
            "Epoch 71/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5934 - binary_accuracy: 0.6801 - val_loss: 0.5980 - val_binary_accuracy: 0.6774\n",
            "Epoch 72/200\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5929 - binary_accuracy: 0.6862 - val_loss: 0.5980 - val_binary_accuracy: 0.6759\n",
            "Epoch 73/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6808 - val_loss: 0.5981 - val_binary_accuracy: 0.6796\n",
            "Epoch 74/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6795 - val_loss: 0.5984 - val_binary_accuracy: 0.6796\n",
            "Epoch 75/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5937 - binary_accuracy: 0.6810 - val_loss: 0.5984 - val_binary_accuracy: 0.6782\n",
            "Epoch 76/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5952 - binary_accuracy: 0.6816 - val_loss: 0.5987 - val_binary_accuracy: 0.6789\n",
            "Epoch 77/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5923 - binary_accuracy: 0.6787 - val_loss: 0.5984 - val_binary_accuracy: 0.6793\n",
            "Epoch 78/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6805 - val_loss: 0.5984 - val_binary_accuracy: 0.6756\n",
            "Epoch 79/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.6808 - val_loss: 0.5985 - val_binary_accuracy: 0.6778\n",
            "Epoch 80/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6764 - val_loss: 0.5982 - val_binary_accuracy: 0.6774\n",
            "Epoch 81/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5938 - binary_accuracy: 0.6775 - val_loss: 0.5985 - val_binary_accuracy: 0.6770\n",
            "Epoch 82/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6791 - val_loss: 0.5982 - val_binary_accuracy: 0.6770\n",
            "Epoch 00082: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:28:43,940]\u001b[0m Trial 41 finished with value: 0.6667901873588562 and parameters: {'batch size': 118, 'optimizer': 'Adagrad', 'lr': 0.025784970746659475, 'minimum_learning_rate': 0.023450389421011866}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "92/92 [==============================] - 1s 3ms/step - loss: 0.6621 - binary_accuracy: 0.5994 - val_loss: 0.6241 - val_binary_accuracy: 0.6559\n",
            "Epoch 2/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6379 - val_loss: 0.6195 - val_binary_accuracy: 0.6659\n",
            "Epoch 3/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6496 - val_loss: 0.6141 - val_binary_accuracy: 0.6670\n",
            "Epoch 4/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6517 - val_loss: 0.6062 - val_binary_accuracy: 0.6782\n",
            "Epoch 5/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6561 - val_loss: 0.6047 - val_binary_accuracy: 0.6756\n",
            "Epoch 6/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6609 - val_loss: 0.6043 - val_binary_accuracy: 0.6796\n",
            "Epoch 7/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6594 - val_loss: 0.6057 - val_binary_accuracy: 0.6767\n",
            "Epoch 8/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6655 - val_loss: 0.6013 - val_binary_accuracy: 0.6767\n",
            "Epoch 9/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6647 - val_loss: 0.6025 - val_binary_accuracy: 0.6767\n",
            "Epoch 10/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6721 - val_loss: 0.6038 - val_binary_accuracy: 0.6785\n",
            "Epoch 11/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6676 - val_loss: 0.6013 - val_binary_accuracy: 0.6796\n",
            "Epoch 12/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6709 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 13/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6694 - val_loss: 0.6003 - val_binary_accuracy: 0.6785\n",
            "Epoch 14/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6781 - val_loss: 0.5996 - val_binary_accuracy: 0.6741\n",
            "Epoch 15/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6689 - val_loss: 0.6012 - val_binary_accuracy: 0.6770\n",
            "Epoch 16/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6687 - val_loss: 0.6010 - val_binary_accuracy: 0.6767\n",
            "Epoch 17/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6723 - val_loss: 0.6004 - val_binary_accuracy: 0.6770\n",
            "Epoch 18/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6767 - val_loss: 0.6000 - val_binary_accuracy: 0.6774\n",
            "Epoch 19/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6760 - val_loss: 0.6011 - val_binary_accuracy: 0.6796\n",
            "Epoch 20/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6750 - val_loss: 0.6013 - val_binary_accuracy: 0.6800\n",
            "Epoch 21/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6743 - val_loss: 0.6013 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6777 - val_loss: 0.6005 - val_binary_accuracy: 0.6785\n",
            "Epoch 23/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6852 - val_loss: 0.6009 - val_binary_accuracy: 0.6782\n",
            "Epoch 24/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6779 - val_loss: 0.6005 - val_binary_accuracy: 0.6826\n",
            "Epoch 00024: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:28:49,513]\u001b[0m Trial 42 finished with value: 0.6690140962600708 and parameters: {'batch size': 138, 'optimizer': 'Adagrad', 'lr': 0.08272164985360934, 'minimum_learning_rate': 0.06749337740029702}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "113/113 [==============================] - 1s 3ms/step - loss: 0.6726 - binary_accuracy: 0.6022 - val_loss: 0.6205 - val_binary_accuracy: 0.6604\n",
            "Epoch 2/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6366 - binary_accuracy: 0.6245 - val_loss: 0.6117 - val_binary_accuracy: 0.6656\n",
            "Epoch 3/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6453 - val_loss: 0.6084 - val_binary_accuracy: 0.6748\n",
            "Epoch 4/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6471 - val_loss: 0.6060 - val_binary_accuracy: 0.6826\n",
            "Epoch 5/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6482 - val_loss: 0.6035 - val_binary_accuracy: 0.6759\n",
            "Epoch 6/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6599 - val_loss: 0.6030 - val_binary_accuracy: 0.6767\n",
            "Epoch 7/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6587 - val_loss: 0.6047 - val_binary_accuracy: 0.6741\n",
            "Epoch 8/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6565 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 9/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6633 - val_loss: 0.6022 - val_binary_accuracy: 0.6763\n",
            "Epoch 10/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6609 - val_loss: 0.6020 - val_binary_accuracy: 0.6767\n",
            "Epoch 11/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6663 - val_loss: 0.6021 - val_binary_accuracy: 0.6759\n",
            "Epoch 12/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6661 - val_loss: 0.6030 - val_binary_accuracy: 0.6733\n",
            "Epoch 13/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6629 - val_loss: 0.6005 - val_binary_accuracy: 0.6785\n",
            "Epoch 14/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6675 - val_loss: 0.6006 - val_binary_accuracy: 0.6752\n",
            "Epoch 15/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6679 - val_loss: 0.5995 - val_binary_accuracy: 0.6770\n",
            "Epoch 16/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6697 - val_loss: 0.6008 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6727 - val_loss: 0.6000 - val_binary_accuracy: 0.6782\n",
            "Epoch 18/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6709 - val_loss: 0.5998 - val_binary_accuracy: 0.6737\n",
            "Epoch 19/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6732 - val_loss: 0.5998 - val_binary_accuracy: 0.6741\n",
            "Epoch 20/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6695 - val_loss: 0.5999 - val_binary_accuracy: 0.6719\n",
            "Epoch 21/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6686 - val_loss: 0.5996 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6767 - val_loss: 0.5994 - val_binary_accuracy: 0.6733\n",
            "Epoch 23/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6692 - val_loss: 0.5991 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6688 - val_loss: 0.5994 - val_binary_accuracy: 0.6770\n",
            "Epoch 25/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6728 - val_loss: 0.5993 - val_binary_accuracy: 0.6763\n",
            "Epoch 26/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6760 - val_loss: 0.5990 - val_binary_accuracy: 0.6774\n",
            "Epoch 27/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6714 - val_loss: 0.5990 - val_binary_accuracy: 0.6767\n",
            "Epoch 28/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6764 - val_loss: 0.5991 - val_binary_accuracy: 0.6778\n",
            "Epoch 29/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6702 - val_loss: 0.5991 - val_binary_accuracy: 0.6778\n",
            "Epoch 30/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6720 - val_loss: 0.5991 - val_binary_accuracy: 0.6782\n",
            "Epoch 31/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5957 - binary_accuracy: 0.6785 - val_loss: 0.5990 - val_binary_accuracy: 0.6774\n",
            "Epoch 32/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6737 - val_loss: 0.5990 - val_binary_accuracy: 0.6774\n",
            "Epoch 33/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6768 - val_loss: 0.5989 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6751 - val_loss: 0.5990 - val_binary_accuracy: 0.6770\n",
            "Epoch 35/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6702 - val_loss: 0.5990 - val_binary_accuracy: 0.6763\n",
            "Epoch 36/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6768 - val_loss: 0.5989 - val_binary_accuracy: 0.6770\n",
            "Epoch 37/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6710 - val_loss: 0.5989 - val_binary_accuracy: 0.6774\n",
            "Epoch 38/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6754 - val_loss: 0.5989 - val_binary_accuracy: 0.6767\n",
            "Epoch 39/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6769 - val_loss: 0.5988 - val_binary_accuracy: 0.6767\n",
            "Epoch 40/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6781 - val_loss: 0.5988 - val_binary_accuracy: 0.6774\n",
            "Epoch 41/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6722 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 42/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6753 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 43/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6768 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 44/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6773 - val_loss: 0.5987 - val_binary_accuracy: 0.6756\n",
            "Epoch 45/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6760 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 46/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6715 - val_loss: 0.5987 - val_binary_accuracy: 0.6767\n",
            "Epoch 47/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6739 - val_loss: 0.5988 - val_binary_accuracy: 0.6774\n",
            "Epoch 48/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5959 - binary_accuracy: 0.6820 - val_loss: 0.5988 - val_binary_accuracy: 0.6770\n",
            "Epoch 49/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6767 - val_loss: 0.5987 - val_binary_accuracy: 0.6756\n",
            "Epoch 50/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6711 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 51/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6752 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 52/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6005 - binary_accuracy: 0.6770 - val_loss: 0.5988 - val_binary_accuracy: 0.6774\n",
            "Epoch 53/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6757 - val_loss: 0.5988 - val_binary_accuracy: 0.6767\n",
            "Epoch 54/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6761 - val_loss: 0.5988 - val_binary_accuracy: 0.6759\n",
            "Epoch 00054: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:02,351]\u001b[0m Trial 43 finished with value: 0.6690140962600708 and parameters: {'batch size': 112, 'optimizer': 'Adagrad', 'lr': 0.040847894915945225, 'minimum_learning_rate': 0.0033903564105006007}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "68/68 [==============================] - 1s 4ms/step - loss: 0.6954 - binary_accuracy: 0.5691 - val_loss: 0.6426 - val_binary_accuracy: 0.6381\n",
            "Epoch 2/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6574 - binary_accuracy: 0.6049 - val_loss: 0.6346 - val_binary_accuracy: 0.6459\n",
            "Epoch 3/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6489 - binary_accuracy: 0.6137 - val_loss: 0.6265 - val_binary_accuracy: 0.6578\n",
            "Epoch 4/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.6253 - val_loss: 0.6217 - val_binary_accuracy: 0.6574\n",
            "Epoch 5/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6318 - binary_accuracy: 0.6357 - val_loss: 0.6170 - val_binary_accuracy: 0.6648\n",
            "Epoch 6/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6289 - binary_accuracy: 0.6430 - val_loss: 0.6155 - val_binary_accuracy: 0.6670\n",
            "Epoch 7/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6444 - val_loss: 0.6121 - val_binary_accuracy: 0.6715\n",
            "Epoch 8/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6433 - val_loss: 0.6116 - val_binary_accuracy: 0.6674\n",
            "Epoch 9/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.6403 - val_loss: 0.6094 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6546 - val_loss: 0.6077 - val_binary_accuracy: 0.6763\n",
            "Epoch 11/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6160 - binary_accuracy: 0.6562 - val_loss: 0.6062 - val_binary_accuracy: 0.6774\n",
            "Epoch 12/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6571 - val_loss: 0.6061 - val_binary_accuracy: 0.6759\n",
            "Epoch 13/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6582 - val_loss: 0.6061 - val_binary_accuracy: 0.6693\n",
            "Epoch 14/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6577 - val_loss: 0.6051 - val_binary_accuracy: 0.6770\n",
            "Epoch 15/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6574 - val_loss: 0.6053 - val_binary_accuracy: 0.6752\n",
            "Epoch 16/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6603 - val_loss: 0.6054 - val_binary_accuracy: 0.6715\n",
            "Epoch 17/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6626 - val_loss: 0.6050 - val_binary_accuracy: 0.6696\n",
            "Epoch 18/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6599 - val_loss: 0.6037 - val_binary_accuracy: 0.6767\n",
            "Epoch 19/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6551 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 20/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6069 - binary_accuracy: 0.6657 - val_loss: 0.6038 - val_binary_accuracy: 0.6752\n",
            "Epoch 21/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6603 - val_loss: 0.6036 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6654 - val_loss: 0.6034 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6086 - binary_accuracy: 0.6672 - val_loss: 0.6033 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6676 - val_loss: 0.6031 - val_binary_accuracy: 0.6726\n",
            "Epoch 25/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6644 - val_loss: 0.6033 - val_binary_accuracy: 0.6707\n",
            "Epoch 26/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6676 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 27/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6661 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 28/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6687 - val_loss: 0.6027 - val_binary_accuracy: 0.6737\n",
            "Epoch 29/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6605 - val_loss: 0.6027 - val_binary_accuracy: 0.6748\n",
            "Epoch 30/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6644 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6674 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6697 - val_loss: 0.6023 - val_binary_accuracy: 0.6741\n",
            "Epoch 33/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6667 - val_loss: 0.6024 - val_binary_accuracy: 0.6741\n",
            "Epoch 34/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6672 - val_loss: 0.6026 - val_binary_accuracy: 0.6741\n",
            "Epoch 35/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6666 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6668 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 37/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6706 - val_loss: 0.6024 - val_binary_accuracy: 0.6737\n",
            "Epoch 38/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6697 - val_loss: 0.6023 - val_binary_accuracy: 0.6733\n",
            "Epoch 39/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6696 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 40/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6704 - val_loss: 0.6023 - val_binary_accuracy: 0.6726\n",
            "Epoch 41/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6650 - val_loss: 0.6024 - val_binary_accuracy: 0.6741\n",
            "Epoch 42/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6683 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 43/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6721 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 44/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6656 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 45/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6693 - val_loss: 0.6020 - val_binary_accuracy: 0.6733\n",
            "Epoch 46/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6665 - val_loss: 0.6020 - val_binary_accuracy: 0.6741\n",
            "Epoch 47/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6656 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 48/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6712 - val_loss: 0.6020 - val_binary_accuracy: 0.6733\n",
            "Epoch 49/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6706 - val_loss: 0.6019 - val_binary_accuracy: 0.6741\n",
            "Epoch 50/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6644 - val_loss: 0.6018 - val_binary_accuracy: 0.6752\n",
            "Epoch 51/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6683 - val_loss: 0.6017 - val_binary_accuracy: 0.6722\n",
            "Epoch 52/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6746 - val_loss: 0.6016 - val_binary_accuracy: 0.6730\n",
            "Epoch 53/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6699 - val_loss: 0.6018 - val_binary_accuracy: 0.6745\n",
            "Epoch 54/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6681 - val_loss: 0.6017 - val_binary_accuracy: 0.6730\n",
            "Epoch 55/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6683 - val_loss: 0.6017 - val_binary_accuracy: 0.6745\n",
            "Epoch 56/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6704 - val_loss: 0.6018 - val_binary_accuracy: 0.6745\n",
            "Epoch 57/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6652 - val_loss: 0.6017 - val_binary_accuracy: 0.6752\n",
            "Epoch 58/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6714 - val_loss: 0.6017 - val_binary_accuracy: 0.6737\n",
            "Epoch 59/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6704 - val_loss: 0.6017 - val_binary_accuracy: 0.6730\n",
            "Epoch 60/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6735 - val_loss: 0.6016 - val_binary_accuracy: 0.6733\n",
            "Epoch 61/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6699 - val_loss: 0.6017 - val_binary_accuracy: 0.6737\n",
            "Epoch 62/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6661 - val_loss: 0.6016 - val_binary_accuracy: 0.6748\n",
            "Epoch 63/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.6681 - val_loss: 0.6016 - val_binary_accuracy: 0.6745\n",
            "Epoch 64/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6689 - val_loss: 0.6015 - val_binary_accuracy: 0.6741\n",
            "Epoch 65/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6760 - val_loss: 0.6014 - val_binary_accuracy: 0.6752\n",
            "Epoch 66/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6678 - val_loss: 0.6013 - val_binary_accuracy: 0.6748\n",
            "Epoch 67/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6653 - val_loss: 0.6014 - val_binary_accuracy: 0.6741\n",
            "Epoch 68/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6726 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 69/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6692 - val_loss: 0.6014 - val_binary_accuracy: 0.6737\n",
            "Epoch 70/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6695 - val_loss: 0.6015 - val_binary_accuracy: 0.6733\n",
            "Epoch 71/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.6750 - val_loss: 0.6014 - val_binary_accuracy: 0.6730\n",
            "Epoch 72/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6705 - val_loss: 0.6013 - val_binary_accuracy: 0.6741\n",
            "Epoch 73/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6718 - val_loss: 0.6013 - val_binary_accuracy: 0.6752\n",
            "Epoch 74/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6752 - val_loss: 0.6012 - val_binary_accuracy: 0.6733\n",
            "Epoch 75/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6679 - val_loss: 0.6013 - val_binary_accuracy: 0.6745\n",
            "Epoch 76/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6683 - val_loss: 0.6013 - val_binary_accuracy: 0.6741\n",
            "Epoch 77/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6683 - val_loss: 0.6014 - val_binary_accuracy: 0.6748\n",
            "Epoch 78/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6695 - val_loss: 0.6014 - val_binary_accuracy: 0.6741\n",
            "Epoch 79/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6712 - val_loss: 0.6013 - val_binary_accuracy: 0.6741\n",
            "Epoch 80/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6704 - val_loss: 0.6014 - val_binary_accuracy: 0.6737\n",
            "Epoch 81/200\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6713 - val_loss: 0.6015 - val_binary_accuracy: 0.6741\n",
            "Epoch 82/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6736 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 83/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6702 - val_loss: 0.6014 - val_binary_accuracy: 0.6748\n",
            "Epoch 84/200\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6708 - val_loss: 0.6015 - val_binary_accuracy: 0.6752\n",
            "Epoch 00084: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:18,255]\u001b[0m Trial 44 finished with value: 0.664195716381073 and parameters: {'batch size': 187, 'optimizer': 'Adagrad', 'lr': 0.03424465819527926, 'minimum_learning_rate': 0.00880031573414998}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "120/120 [==============================] - 1s 3ms/step - loss: 0.6644 - binary_accuracy: 0.6053 - val_loss: 0.6298 - val_binary_accuracy: 0.6552\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6279 - val_loss: 0.6199 - val_binary_accuracy: 0.6685\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6483 - val_loss: 0.6157 - val_binary_accuracy: 0.6748\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6496 - val_loss: 0.6120 - val_binary_accuracy: 0.6748\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6540 - val_loss: 0.6104 - val_binary_accuracy: 0.6756\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6571 - val_loss: 0.6091 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6590 - val_loss: 0.6063 - val_binary_accuracy: 0.6782\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6643 - val_loss: 0.6070 - val_binary_accuracy: 0.6785\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6633 - val_loss: 0.6071 - val_binary_accuracy: 0.6793\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6653 - val_loss: 0.6048 - val_binary_accuracy: 0.6789\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6613 - val_loss: 0.6052 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6687 - val_loss: 0.6049 - val_binary_accuracy: 0.6737\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6694 - val_loss: 0.6048 - val_binary_accuracy: 0.6756\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6711 - val_loss: 0.6044 - val_binary_accuracy: 0.6759\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6747 - val_loss: 0.6043 - val_binary_accuracy: 0.6767\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6768 - val_loss: 0.6044 - val_binary_accuracy: 0.6730\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6727 - val_loss: 0.6034 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6748 - val_loss: 0.6034 - val_binary_accuracy: 0.6767\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6705 - val_loss: 0.6030 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6782 - val_loss: 0.6029 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6741 - val_loss: 0.6032 - val_binary_accuracy: 0.6745\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6741 - val_loss: 0.6030 - val_binary_accuracy: 0.6748\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6760 - val_loss: 0.6027 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6730 - val_loss: 0.6030 - val_binary_accuracy: 0.6719\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6765 - val_loss: 0.6026 - val_binary_accuracy: 0.6759\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6725 - val_loss: 0.6031 - val_binary_accuracy: 0.6778\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5975 - binary_accuracy: 0.6741 - val_loss: 0.6030 - val_binary_accuracy: 0.6767\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6740 - val_loss: 0.6034 - val_binary_accuracy: 0.6756\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6785 - val_loss: 0.6029 - val_binary_accuracy: 0.6733\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6757 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6790 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6771 - val_loss: 0.6031 - val_binary_accuracy: 0.6763\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6745 - val_loss: 0.6030 - val_binary_accuracy: 0.6770\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5958 - binary_accuracy: 0.6765 - val_loss: 0.6033 - val_binary_accuracy: 0.6759\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5929 - binary_accuracy: 0.6784 - val_loss: 0.6030 - val_binary_accuracy: 0.6759\n",
            "Epoch 00035: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:27,370]\u001b[0m Trial 45 finished with value: 0.6693847179412842 and parameters: {'batch size': 105, 'optimizer': 'Adagrad', 'lr': 0.048799913270082894, 'minimum_learning_rate': 0.020851052978452862}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 1s 4ms/step - loss: 0.7132 - binary_accuracy: 0.5562 - val_loss: 0.6543 - val_binary_accuracy: 0.6125\n",
            "Epoch 2/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6694 - binary_accuracy: 0.5926 - val_loss: 0.6432 - val_binary_accuracy: 0.6329\n",
            "Epoch 3/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6607 - binary_accuracy: 0.6012 - val_loss: 0.6378 - val_binary_accuracy: 0.6433\n",
            "Epoch 4/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6514 - binary_accuracy: 0.6140 - val_loss: 0.6322 - val_binary_accuracy: 0.6507\n",
            "Epoch 5/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6437 - binary_accuracy: 0.6226 - val_loss: 0.6297 - val_binary_accuracy: 0.6600\n",
            "Epoch 6/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6247 - val_loss: 0.6252 - val_binary_accuracy: 0.6630\n",
            "Epoch 7/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6371 - binary_accuracy: 0.6300 - val_loss: 0.6246 - val_binary_accuracy: 0.6593\n",
            "Epoch 8/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6352 - binary_accuracy: 0.6321 - val_loss: 0.6173 - val_binary_accuracy: 0.6730\n",
            "Epoch 9/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6346 - val_loss: 0.6146 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6276 - binary_accuracy: 0.6406 - val_loss: 0.6131 - val_binary_accuracy: 0.6715\n",
            "Epoch 11/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6408 - val_loss: 0.6117 - val_binary_accuracy: 0.6778\n",
            "Epoch 12/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6460 - val_loss: 0.6096 - val_binary_accuracy: 0.6785\n",
            "Epoch 13/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6445 - val_loss: 0.6087 - val_binary_accuracy: 0.6852\n",
            "Epoch 14/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6440 - val_loss: 0.6077 - val_binary_accuracy: 0.6804\n",
            "Epoch 15/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6513 - val_loss: 0.6066 - val_binary_accuracy: 0.6863\n",
            "Epoch 16/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6489 - val_loss: 0.6058 - val_binary_accuracy: 0.6867\n",
            "Epoch 17/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6505 - val_loss: 0.6050 - val_binary_accuracy: 0.6878\n",
            "Epoch 18/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6513 - val_loss: 0.6048 - val_binary_accuracy: 0.6811\n",
            "Epoch 19/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6509 - val_loss: 0.6043 - val_binary_accuracy: 0.6834\n",
            "Epoch 20/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6536 - val_loss: 0.6043 - val_binary_accuracy: 0.6867\n",
            "Epoch 21/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6636 - val_loss: 0.6030 - val_binary_accuracy: 0.6859\n",
            "Epoch 22/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6592 - val_loss: 0.6021 - val_binary_accuracy: 0.6863\n",
            "Epoch 23/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6598 - val_loss: 0.6022 - val_binary_accuracy: 0.6852\n",
            "Epoch 24/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6567 - val_loss: 0.6025 - val_binary_accuracy: 0.6808\n",
            "Epoch 25/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6582 - val_loss: 0.6032 - val_binary_accuracy: 0.6852\n",
            "Epoch 26/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6565 - val_loss: 0.6021 - val_binary_accuracy: 0.6859\n",
            "Epoch 27/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6625 - val_loss: 0.6019 - val_binary_accuracy: 0.6834\n",
            "Epoch 28/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6621 - val_loss: 0.6021 - val_binary_accuracy: 0.6804\n",
            "Epoch 29/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6602 - val_loss: 0.6020 - val_binary_accuracy: 0.6841\n",
            "Epoch 30/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6621 - val_loss: 0.6021 - val_binary_accuracy: 0.6837\n",
            "Epoch 31/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6611 - val_loss: 0.6021 - val_binary_accuracy: 0.6837\n",
            "Epoch 32/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6080 - binary_accuracy: 0.6623 - val_loss: 0.6016 - val_binary_accuracy: 0.6845\n",
            "Epoch 33/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6621 - val_loss: 0.6012 - val_binary_accuracy: 0.6830\n",
            "Epoch 34/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6622 - val_loss: 0.6012 - val_binary_accuracy: 0.6834\n",
            "Epoch 35/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6682 - val_loss: 0.6012 - val_binary_accuracy: 0.6822\n",
            "Epoch 36/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6629 - val_loss: 0.6010 - val_binary_accuracy: 0.6834\n",
            "Epoch 37/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6641 - val_loss: 0.6005 - val_binary_accuracy: 0.6845\n",
            "Epoch 38/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6699 - val_loss: 0.6005 - val_binary_accuracy: 0.6822\n",
            "Epoch 39/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6598 - val_loss: 0.6005 - val_binary_accuracy: 0.6826\n",
            "Epoch 40/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6650 - val_loss: 0.6005 - val_binary_accuracy: 0.6822\n",
            "Epoch 41/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6658 - val_loss: 0.6007 - val_binary_accuracy: 0.6800\n",
            "Epoch 42/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6659 - val_loss: 0.6007 - val_binary_accuracy: 0.6819\n",
            "Epoch 43/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6673 - val_loss: 0.6010 - val_binary_accuracy: 0.6793\n",
            "Epoch 44/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6646 - val_loss: 0.6006 - val_binary_accuracy: 0.6826\n",
            "Epoch 45/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6666 - val_loss: 0.6008 - val_binary_accuracy: 0.6815\n",
            "Epoch 46/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6690 - val_loss: 0.6005 - val_binary_accuracy: 0.6808\n",
            "Epoch 47/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6663 - val_loss: 0.6005 - val_binary_accuracy: 0.6796\n",
            "Epoch 48/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6639 - val_loss: 0.6010 - val_binary_accuracy: 0.6845\n",
            "Epoch 00048: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:38,111]\u001b[0m Trial 46 finished with value: 0.6645663380622864 and parameters: {'batch size': 177, 'optimizer': 'Adagrad', 'lr': 0.020318770966964578, 'minimum_learning_rate': 0.0144828368780999}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "98/98 [==============================] - 1s 3ms/step - loss: 0.6709 - binary_accuracy: 0.5960 - val_loss: 0.6292 - val_binary_accuracy: 0.6418\n",
            "Epoch 2/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6438 - binary_accuracy: 0.6211 - val_loss: 0.6216 - val_binary_accuracy: 0.6570\n",
            "Epoch 3/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6362 - val_loss: 0.6156 - val_binary_accuracy: 0.6589\n",
            "Epoch 4/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6397 - val_loss: 0.6117 - val_binary_accuracy: 0.6667\n",
            "Epoch 5/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6474 - val_loss: 0.6101 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6532 - val_loss: 0.6104 - val_binary_accuracy: 0.6663\n",
            "Epoch 7/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6563 - val_loss: 0.6061 - val_binary_accuracy: 0.6719\n",
            "Epoch 8/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6539 - val_loss: 0.6066 - val_binary_accuracy: 0.6756\n",
            "Epoch 9/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6582 - val_loss: 0.6060 - val_binary_accuracy: 0.6737\n",
            "Epoch 10/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6636 - val_loss: 0.6042 - val_binary_accuracy: 0.6748\n",
            "Epoch 11/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6578 - val_loss: 0.6050 - val_binary_accuracy: 0.6737\n",
            "Epoch 12/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6617 - val_loss: 0.6045 - val_binary_accuracy: 0.6748\n",
            "Epoch 13/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6661 - val_loss: 0.6034 - val_binary_accuracy: 0.6763\n",
            "Epoch 14/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6679 - val_loss: 0.6038 - val_binary_accuracy: 0.6711\n",
            "Epoch 15/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6632 - val_loss: 0.6035 - val_binary_accuracy: 0.6763\n",
            "Epoch 16/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6653 - val_loss: 0.6028 - val_binary_accuracy: 0.6778\n",
            "Epoch 17/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6633 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 18/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6687 - val_loss: 0.6028 - val_binary_accuracy: 0.6748\n",
            "Epoch 19/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6684 - val_loss: 0.6026 - val_binary_accuracy: 0.6767\n",
            "Epoch 20/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6714 - val_loss: 0.6020 - val_binary_accuracy: 0.6730\n",
            "Epoch 21/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6690 - val_loss: 0.6010 - val_binary_accuracy: 0.6770\n",
            "Epoch 22/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6725 - val_loss: 0.6019 - val_binary_accuracy: 0.6715\n",
            "Epoch 23/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6720 - val_loss: 0.6009 - val_binary_accuracy: 0.6789\n",
            "Epoch 24/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6739 - val_loss: 0.6009 - val_binary_accuracy: 0.6796\n",
            "Epoch 25/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6722 - val_loss: 0.6009 - val_binary_accuracy: 0.6759\n",
            "Epoch 26/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6710 - val_loss: 0.6017 - val_binary_accuracy: 0.6741\n",
            "Epoch 27/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6731 - val_loss: 0.6012 - val_binary_accuracy: 0.6759\n",
            "Epoch 28/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6722 - val_loss: 0.6013 - val_binary_accuracy: 0.6733\n",
            "Epoch 29/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6719 - val_loss: 0.6007 - val_binary_accuracy: 0.6770\n",
            "Epoch 30/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6726 - val_loss: 0.6011 - val_binary_accuracy: 0.6759\n",
            "Epoch 31/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6716 - val_loss: 0.6007 - val_binary_accuracy: 0.6756\n",
            "Epoch 32/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6715 - val_loss: 0.6007 - val_binary_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6749 - val_loss: 0.6008 - val_binary_accuracy: 0.6774\n",
            "Epoch 34/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6737 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 35/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6727 - val_loss: 0.6004 - val_binary_accuracy: 0.6763\n",
            "Epoch 36/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6767 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 37/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6764 - val_loss: 0.6004 - val_binary_accuracy: 0.6767\n",
            "Epoch 38/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6782 - val_loss: 0.6004 - val_binary_accuracy: 0.6767\n",
            "Epoch 39/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6744 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 40/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6760 - val_loss: 0.6005 - val_binary_accuracy: 0.6752\n",
            "Epoch 41/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6720 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 42/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6748 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 43/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6760 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 44/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6783 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 45/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6746 - val_loss: 0.6008 - val_binary_accuracy: 0.6756\n",
            "Epoch 46/200\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6765 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 47/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6771 - val_loss: 0.6008 - val_binary_accuracy: 0.6756\n",
            "Epoch 48/200\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6740 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 00048: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:48,826]\u001b[0m Trial 47 finished with value: 0.6675314903259277 and parameters: {'batch size': 129, 'optimizer': 'Adagrad', 'lr': 0.04068399694860104, 'minimum_learning_rate': 0.012077783107610467}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "126/126 [==============================] - 1s 3ms/step - loss: 0.6599 - binary_accuracy: 0.6041 - val_loss: 0.6273 - val_binary_accuracy: 0.6429\n",
            "Epoch 2/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6445 - val_loss: 0.6165 - val_binary_accuracy: 0.6652\n",
            "Epoch 3/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6490 - val_loss: 0.6073 - val_binary_accuracy: 0.6685\n",
            "Epoch 4/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6598 - val_loss: 0.6071 - val_binary_accuracy: 0.6689\n",
            "Epoch 5/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6623 - val_loss: 0.6042 - val_binary_accuracy: 0.6726\n",
            "Epoch 6/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6604 - val_loss: 0.6034 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6651 - val_loss: 0.6026 - val_binary_accuracy: 0.6719\n",
            "Epoch 8/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6650 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 9/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6677 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 10/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6001 - binary_accuracy: 0.6753 - val_loss: 0.6023 - val_binary_accuracy: 0.6674\n",
            "Epoch 11/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6661 - val_loss: 0.6037 - val_binary_accuracy: 0.6681\n",
            "Epoch 12/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6747 - val_loss: 0.6014 - val_binary_accuracy: 0.6748\n",
            "Epoch 13/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6746 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6763 - val_loss: 0.6005 - val_binary_accuracy: 0.6707\n",
            "Epoch 15/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5981 - binary_accuracy: 0.6742 - val_loss: 0.6022 - val_binary_accuracy: 0.6689\n",
            "Epoch 16/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6787 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 17/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6772 - val_loss: 0.6000 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6765 - val_loss: 0.6011 - val_binary_accuracy: 0.6693\n",
            "Epoch 19/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5969 - binary_accuracy: 0.6809 - val_loss: 0.6000 - val_binary_accuracy: 0.6719\n",
            "Epoch 20/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6789 - val_loss: 0.6009 - val_binary_accuracy: 0.6726\n",
            "Epoch 21/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6799 - val_loss: 0.6032 - val_binary_accuracy: 0.6707\n",
            "Epoch 22/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6806 - val_loss: 0.6010 - val_binary_accuracy: 0.6785\n",
            "Epoch 23/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6783 - val_loss: 0.6015 - val_binary_accuracy: 0.6737\n",
            "Epoch 24/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5915 - binary_accuracy: 0.6757 - val_loss: 0.6025 - val_binary_accuracy: 0.6719\n",
            "Epoch 25/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5906 - binary_accuracy: 0.6820 - val_loss: 0.6036 - val_binary_accuracy: 0.6700\n",
            "Epoch 26/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.6811 - val_loss: 0.6030 - val_binary_accuracy: 0.6678\n",
            "Epoch 27/200\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5933 - binary_accuracy: 0.6833 - val_loss: 0.6026 - val_binary_accuracy: 0.6793\n",
            "Epoch 00027: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:29:56,135]\u001b[0m Trial 48 finished with value: 0.6701260209083557 and parameters: {'batch size': 100, 'optimizer': 'Adagrad', 'lr': 0.08703488657354605, 'minimum_learning_rate': 0.06959679024149529}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "56/56 [==============================] - 1s 5ms/step - loss: 0.6769 - binary_accuracy: 0.5826 - val_loss: 0.6339 - val_binary_accuracy: 0.6363\n",
            "Epoch 2/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6421 - binary_accuracy: 0.6212 - val_loss: 0.6250 - val_binary_accuracy: 0.6518\n",
            "Epoch 3/200\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6437 - val_loss: 0.6148 - val_binary_accuracy: 0.6600\n",
            "Epoch 4/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6474 - val_loss: 0.6104 - val_binary_accuracy: 0.6722\n",
            "Epoch 5/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6199 - binary_accuracy: 0.6479 - val_loss: 0.6075 - val_binary_accuracy: 0.6756\n",
            "Epoch 6/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6177 - binary_accuracy: 0.6523 - val_loss: 0.6072 - val_binary_accuracy: 0.6667\n",
            "Epoch 7/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6597 - val_loss: 0.6059 - val_binary_accuracy: 0.6737\n",
            "Epoch 8/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6575 - val_loss: 0.6044 - val_binary_accuracy: 0.6733\n",
            "Epoch 9/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6666 - val_loss: 0.6019 - val_binary_accuracy: 0.6726\n",
            "Epoch 10/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6627 - val_loss: 0.6025 - val_binary_accuracy: 0.6730\n",
            "Epoch 11/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6685 - val_loss: 0.6028 - val_binary_accuracy: 0.6756\n",
            "Epoch 12/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6667 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 13/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6652 - val_loss: 0.6025 - val_binary_accuracy: 0.6752\n",
            "Epoch 14/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6617 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6707 - val_loss: 0.6011 - val_binary_accuracy: 0.6715\n",
            "Epoch 16/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6743 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6712 - val_loss: 0.6012 - val_binary_accuracy: 0.6685\n",
            "Epoch 18/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6725 - val_loss: 0.6020 - val_binary_accuracy: 0.6685\n",
            "Epoch 19/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6739 - val_loss: 0.6006 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6686 - val_loss: 0.6014 - val_binary_accuracy: 0.6707\n",
            "Epoch 21/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6747 - val_loss: 0.6011 - val_binary_accuracy: 0.6700\n",
            "Epoch 22/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6688 - val_loss: 0.6006 - val_binary_accuracy: 0.6689\n",
            "Epoch 23/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6713 - val_loss: 0.6002 - val_binary_accuracy: 0.6715\n",
            "Epoch 24/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6753 - val_loss: 0.5999 - val_binary_accuracy: 0.6730\n",
            "Epoch 25/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6779 - val_loss: 0.6001 - val_binary_accuracy: 0.6730\n",
            "Epoch 26/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6713 - val_loss: 0.6010 - val_binary_accuracy: 0.6763\n",
            "Epoch 27/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6794 - val_loss: 0.5999 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6776 - val_loss: 0.5998 - val_binary_accuracy: 0.6733\n",
            "Epoch 29/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6743 - val_loss: 0.6003 - val_binary_accuracy: 0.6715\n",
            "Epoch 30/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6760 - val_loss: 0.6003 - val_binary_accuracy: 0.6726\n",
            "Epoch 31/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6781 - val_loss: 0.5991 - val_binary_accuracy: 0.6670\n",
            "Epoch 32/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5952 - binary_accuracy: 0.6837 - val_loss: 0.5999 - val_binary_accuracy: 0.6763\n",
            "Epoch 33/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6784 - val_loss: 0.5995 - val_binary_accuracy: 0.6737\n",
            "Epoch 34/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6818 - val_loss: 0.5993 - val_binary_accuracy: 0.6722\n",
            "Epoch 35/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5944 - binary_accuracy: 0.6810 - val_loss: 0.6005 - val_binary_accuracy: 0.6737\n",
            "Epoch 36/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6788 - val_loss: 0.5996 - val_binary_accuracy: 0.6711\n",
            "Epoch 37/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6789 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 38/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6776 - val_loss: 0.5997 - val_binary_accuracy: 0.6722\n",
            "Epoch 39/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6778 - val_loss: 0.6001 - val_binary_accuracy: 0.6719\n",
            "Epoch 40/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5909 - binary_accuracy: 0.6823 - val_loss: 0.5985 - val_binary_accuracy: 0.6782\n",
            "Epoch 41/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5926 - binary_accuracy: 0.6865 - val_loss: 0.5987 - val_binary_accuracy: 0.6759\n",
            "Epoch 42/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6813 - val_loss: 0.5998 - val_binary_accuracy: 0.6763\n",
            "Epoch 43/200\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5924 - binary_accuracy: 0.6822 - val_loss: 0.5990 - val_binary_accuracy: 0.6767\n",
            "Epoch 44/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6803 - val_loss: 0.5989 - val_binary_accuracy: 0.6767\n",
            "Epoch 45/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5897 - binary_accuracy: 0.6835 - val_loss: 0.5994 - val_binary_accuracy: 0.6737\n",
            "Epoch 46/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5920 - binary_accuracy: 0.6833 - val_loss: 0.6006 - val_binary_accuracy: 0.6726\n",
            "Epoch 47/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5917 - binary_accuracy: 0.6807 - val_loss: 0.6008 - val_binary_accuracy: 0.6730\n",
            "Epoch 48/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6785 - val_loss: 0.6003 - val_binary_accuracy: 0.6711\n",
            "Epoch 49/200\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5906 - binary_accuracy: 0.6835 - val_loss: 0.6001 - val_binary_accuracy: 0.6719\n",
            "Epoch 50/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5923 - binary_accuracy: 0.6809 - val_loss: 0.6011 - val_binary_accuracy: 0.6689\n",
            "Epoch 00050: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:05,502]\u001b[0m Trial 49 finished with value: 0.6645663380622864 and parameters: {'batch size': 225, 'optimizer': 'Adagrad', 'lr': 0.09299454102880292, 'minimum_learning_rate': 0.08729725368999539}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "72/72 [==============================] - 1s 4ms/step - loss: 0.6719 - binary_accuracy: 0.5904 - val_loss: 0.6397 - val_binary_accuracy: 0.6174\n",
            "Epoch 2/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6386 - binary_accuracy: 0.6275 - val_loss: 0.6214 - val_binary_accuracy: 0.6455\n",
            "Epoch 3/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6296 - binary_accuracy: 0.6361 - val_loss: 0.6137 - val_binary_accuracy: 0.6626\n",
            "Epoch 4/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6182 - binary_accuracy: 0.6484 - val_loss: 0.6086 - val_binary_accuracy: 0.6670\n",
            "Epoch 5/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6536 - val_loss: 0.6087 - val_binary_accuracy: 0.6626\n",
            "Epoch 6/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6587 - val_loss: 0.6049 - val_binary_accuracy: 0.6678\n",
            "Epoch 7/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6608 - val_loss: 0.6043 - val_binary_accuracy: 0.6700\n",
            "Epoch 8/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6630 - val_loss: 0.6055 - val_binary_accuracy: 0.6663\n",
            "Epoch 9/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6592 - val_loss: 0.6059 - val_binary_accuracy: 0.6693\n",
            "Epoch 10/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6648 - val_loss: 0.6037 - val_binary_accuracy: 0.6722\n",
            "Epoch 11/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6659 - val_loss: 0.6024 - val_binary_accuracy: 0.6678\n",
            "Epoch 12/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6656 - val_loss: 0.6044 - val_binary_accuracy: 0.6674\n",
            "Epoch 13/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6724 - val_loss: 0.6027 - val_binary_accuracy: 0.6681\n",
            "Epoch 14/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6654 - val_loss: 0.6042 - val_binary_accuracy: 0.6674\n",
            "Epoch 15/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6703 - val_loss: 0.6034 - val_binary_accuracy: 0.6685\n",
            "Epoch 16/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6725 - val_loss: 0.6030 - val_binary_accuracy: 0.6711\n",
            "Epoch 17/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6729 - val_loss: 0.6050 - val_binary_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6738 - val_loss: 0.6032 - val_binary_accuracy: 0.6681\n",
            "Epoch 19/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6735 - val_loss: 0.6023 - val_binary_accuracy: 0.6730\n",
            "Epoch 20/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6767 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 21/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6799 - val_loss: 0.6012 - val_binary_accuracy: 0.6745\n",
            "Epoch 22/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6760 - val_loss: 0.6016 - val_binary_accuracy: 0.6733\n",
            "Epoch 23/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6702 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6798 - val_loss: 0.6021 - val_binary_accuracy: 0.6707\n",
            "Epoch 25/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6754 - val_loss: 0.6032 - val_binary_accuracy: 0.6696\n",
            "Epoch 26/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6752 - val_loss: 0.6027 - val_binary_accuracy: 0.6678\n",
            "Epoch 27/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6837 - val_loss: 0.6033 - val_binary_accuracy: 0.6648\n",
            "Epoch 28/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6806 - val_loss: 0.6026 - val_binary_accuracy: 0.6678\n",
            "Epoch 29/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6747 - val_loss: 0.6051 - val_binary_accuracy: 0.6644\n",
            "Epoch 30/200\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6769 - val_loss: 0.6029 - val_binary_accuracy: 0.6674\n",
            "Epoch 31/200\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6803 - val_loss: 0.6026 - val_binary_accuracy: 0.6667\n",
            "Epoch 00031: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:12,052]\u001b[0m Trial 50 finished with value: 0.6653076410293579 and parameters: {'batch size': 177, 'optimizer': 'Adagrad', 'lr': 0.08955592983525004, 'minimum_learning_rate': 0.07892232473964836}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "79/79 [==============================] - 1s 4ms/step - loss: 0.6608 - binary_accuracy: 0.6088 - val_loss: 0.6224 - val_binary_accuracy: 0.6633\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6283 - val_loss: 0.6135 - val_binary_accuracy: 0.6578\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6532 - val_loss: 0.6065 - val_binary_accuracy: 0.6704\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6493 - val_loss: 0.6059 - val_binary_accuracy: 0.6726\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6603 - val_loss: 0.6074 - val_binary_accuracy: 0.6789\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6607 - val_loss: 0.6057 - val_binary_accuracy: 0.6711\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6617 - val_loss: 0.6041 - val_binary_accuracy: 0.6785\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.6598 - val_loss: 0.6051 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6689 - val_loss: 0.6048 - val_binary_accuracy: 0.6756\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6679 - val_loss: 0.6053 - val_binary_accuracy: 0.6752\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6067 - binary_accuracy: 0.6736 - val_loss: 0.6038 - val_binary_accuracy: 0.6763\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6722 - val_loss: 0.6037 - val_binary_accuracy: 0.6782\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6729 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6717 - val_loss: 0.6025 - val_binary_accuracy: 0.6767\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6728 - val_loss: 0.6036 - val_binary_accuracy: 0.6759\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6725 - val_loss: 0.6028 - val_binary_accuracy: 0.6770\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6746 - val_loss: 0.6030 - val_binary_accuracy: 0.6782\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6704 - val_loss: 0.6024 - val_binary_accuracy: 0.6741\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6792 - val_loss: 0.6020 - val_binary_accuracy: 0.6782\n",
            "Epoch 20/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6770 - val_loss: 0.6030 - val_binary_accuracy: 0.6796\n",
            "Epoch 21/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6768 - val_loss: 0.6017 - val_binary_accuracy: 0.6752\n",
            "Epoch 22/200\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6796 - val_loss: 0.6024 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6768 - val_loss: 0.6018 - val_binary_accuracy: 0.6748\n",
            "Epoch 00023: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:17,152]\u001b[0m Trial 51 finished with value: 0.6593773365020752 and parameters: {'batch size': 160, 'optimizer': 'Adagrad', 'lr': 0.09885780992493133, 'minimum_learning_rate': 0.09153523510319299}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.6647 - binary_accuracy: 0.5967 - val_loss: 0.6297 - val_binary_accuracy: 0.6533\n",
            "Epoch 2/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6389 - binary_accuracy: 0.6296 - val_loss: 0.6197 - val_binary_accuracy: 0.6574\n",
            "Epoch 3/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6434 - val_loss: 0.6106 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6516 - val_loss: 0.6079 - val_binary_accuracy: 0.6644\n",
            "Epoch 5/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6534 - val_loss: 0.6058 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6571 - val_loss: 0.6059 - val_binary_accuracy: 0.6730\n",
            "Epoch 7/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6591 - val_loss: 0.6064 - val_binary_accuracy: 0.6704\n",
            "Epoch 8/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6602 - val_loss: 0.6045 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6651 - val_loss: 0.6026 - val_binary_accuracy: 0.6659\n",
            "Epoch 10/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6079 - binary_accuracy: 0.6640 - val_loss: 0.6028 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6713 - val_loss: 0.6011 - val_binary_accuracy: 0.6711\n",
            "Epoch 12/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6701 - val_loss: 0.6028 - val_binary_accuracy: 0.6737\n",
            "Epoch 13/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6678 - val_loss: 0.6012 - val_binary_accuracy: 0.6789\n",
            "Epoch 14/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6669 - val_loss: 0.6027 - val_binary_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6683 - val_loss: 0.6023 - val_binary_accuracy: 0.6689\n",
            "Epoch 16/200\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6696 - val_loss: 0.6020 - val_binary_accuracy: 0.6681\n",
            "Epoch 17/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.6728 - val_loss: 0.6013 - val_binary_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6712 - val_loss: 0.6013 - val_binary_accuracy: 0.6752\n",
            "Epoch 19/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6718 - val_loss: 0.6026 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6702 - val_loss: 0.6019 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6729 - val_loss: 0.6023 - val_binary_accuracy: 0.6722\n",
            "Epoch 00021: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:22,801]\u001b[0m Trial 52 finished with value: 0.664195716381073 and parameters: {'batch size': 150, 'optimizer': 'Adagrad', 'lr': 0.0698708118232093, 'minimum_learning_rate': 0.053523958587681573}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "94/94 [==============================] - 1s 3ms/step - loss: 0.6634 - binary_accuracy: 0.5971 - val_loss: 0.6257 - val_binary_accuracy: 0.6496\n",
            "Epoch 2/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6355 - val_loss: 0.6115 - val_binary_accuracy: 0.6678\n",
            "Epoch 3/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6485 - val_loss: 0.6071 - val_binary_accuracy: 0.6715\n",
            "Epoch 4/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6577 - val_loss: 0.6057 - val_binary_accuracy: 0.6767\n",
            "Epoch 5/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6612 - val_loss: 0.6065 - val_binary_accuracy: 0.6715\n",
            "Epoch 6/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6632 - val_loss: 0.6050 - val_binary_accuracy: 0.6763\n",
            "Epoch 7/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6637 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 8/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6667 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 9/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6650 - val_loss: 0.6018 - val_binary_accuracy: 0.6722\n",
            "Epoch 10/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6643 - val_loss: 0.6001 - val_binary_accuracy: 0.6770\n",
            "Epoch 11/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6703 - val_loss: 0.6007 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6714 - val_loss: 0.5997 - val_binary_accuracy: 0.6767\n",
            "Epoch 13/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6762 - val_loss: 0.6001 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6678 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 15/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6716 - val_loss: 0.6006 - val_binary_accuracy: 0.6733\n",
            "Epoch 16/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6725 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 17/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6733 - val_loss: 0.5999 - val_binary_accuracy: 0.6756\n",
            "Epoch 18/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6748 - val_loss: 0.6009 - val_binary_accuracy: 0.6767\n",
            "Epoch 19/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5977 - binary_accuracy: 0.6756 - val_loss: 0.6010 - val_binary_accuracy: 0.6778\n",
            "Epoch 20/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6745 - val_loss: 0.5999 - val_binary_accuracy: 0.6745\n",
            "Epoch 21/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6699 - val_loss: 0.6009 - val_binary_accuracy: 0.6722\n",
            "Epoch 22/200\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6768 - val_loss: 0.6018 - val_binary_accuracy: 0.6707\n",
            "Epoch 00022: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:28,039]\u001b[0m Trial 53 finished with value: 0.6682727932929993 and parameters: {'batch size': 134, 'optimizer': 'Adagrad', 'lr': 0.08464217590391679, 'minimum_learning_rate': 0.07027697478518845}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "108/108 [==============================] - 1s 3ms/step - loss: 0.7037 - binary_accuracy: 0.5624 - val_loss: 0.6539 - val_binary_accuracy: 0.6125\n",
            "Epoch 2/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6740 - binary_accuracy: 0.5817 - val_loss: 0.6465 - val_binary_accuracy: 0.6196\n",
            "Epoch 3/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6615 - binary_accuracy: 0.5975 - val_loss: 0.6404 - val_binary_accuracy: 0.6307\n",
            "Epoch 4/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6549 - binary_accuracy: 0.6093 - val_loss: 0.6367 - val_binary_accuracy: 0.6337\n",
            "Epoch 5/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6512 - binary_accuracy: 0.6105 - val_loss: 0.6334 - val_binary_accuracy: 0.6403\n",
            "Epoch 6/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6447 - binary_accuracy: 0.6192 - val_loss: 0.6302 - val_binary_accuracy: 0.6485\n",
            "Epoch 7/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6450 - binary_accuracy: 0.6225 - val_loss: 0.6277 - val_binary_accuracy: 0.6518\n",
            "Epoch 8/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6423 - binary_accuracy: 0.6274 - val_loss: 0.6250 - val_binary_accuracy: 0.6570\n",
            "Epoch 9/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6299 - val_loss: 0.6232 - val_binary_accuracy: 0.6581\n",
            "Epoch 10/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6322 - val_loss: 0.6211 - val_binary_accuracy: 0.6622\n",
            "Epoch 11/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6378 - val_loss: 0.6188 - val_binary_accuracy: 0.6659\n",
            "Epoch 12/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6336 - binary_accuracy: 0.6365 - val_loss: 0.6177 - val_binary_accuracy: 0.6652\n",
            "Epoch 13/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6408 - val_loss: 0.6172 - val_binary_accuracy: 0.6678\n",
            "Epoch 14/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6366 - val_loss: 0.6152 - val_binary_accuracy: 0.6670\n",
            "Epoch 15/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6425 - val_loss: 0.6140 - val_binary_accuracy: 0.6674\n",
            "Epoch 16/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6479 - val_loss: 0.6123 - val_binary_accuracy: 0.6704\n",
            "Epoch 17/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6455 - val_loss: 0.6124 - val_binary_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6444 - val_loss: 0.6112 - val_binary_accuracy: 0.6726\n",
            "Epoch 19/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6532 - val_loss: 0.6107 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6481 - val_loss: 0.6095 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6466 - val_loss: 0.6089 - val_binary_accuracy: 0.6752\n",
            "Epoch 22/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6493 - val_loss: 0.6081 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6470 - val_loss: 0.6074 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6552 - val_loss: 0.6074 - val_binary_accuracy: 0.6730\n",
            "Epoch 25/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6536 - val_loss: 0.6071 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6563 - val_loss: 0.6069 - val_binary_accuracy: 0.6756\n",
            "Epoch 27/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6576 - val_loss: 0.6065 - val_binary_accuracy: 0.6767\n",
            "Epoch 28/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6597 - val_loss: 0.6064 - val_binary_accuracy: 0.6763\n",
            "Epoch 29/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6555 - val_loss: 0.6057 - val_binary_accuracy: 0.6756\n",
            "Epoch 30/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6576 - val_loss: 0.6058 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6609 - val_loss: 0.6055 - val_binary_accuracy: 0.6756\n",
            "Epoch 32/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6592 - val_loss: 0.6051 - val_binary_accuracy: 0.6778\n",
            "Epoch 33/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6532 - val_loss: 0.6053 - val_binary_accuracy: 0.6774\n",
            "Epoch 34/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6570 - val_loss: 0.6056 - val_binary_accuracy: 0.6759\n",
            "Epoch 35/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6608 - val_loss: 0.6057 - val_binary_accuracy: 0.6748\n",
            "Epoch 36/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6613 - val_loss: 0.6057 - val_binary_accuracy: 0.6752\n",
            "Epoch 37/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6598 - val_loss: 0.6052 - val_binary_accuracy: 0.6748\n",
            "Epoch 38/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6588 - val_loss: 0.6050 - val_binary_accuracy: 0.6759\n",
            "Epoch 39/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6602 - val_loss: 0.6050 - val_binary_accuracy: 0.6774\n",
            "Epoch 40/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6602 - val_loss: 0.6044 - val_binary_accuracy: 0.6737\n",
            "Epoch 41/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6602 - val_loss: 0.6047 - val_binary_accuracy: 0.6763\n",
            "Epoch 42/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6648 - val_loss: 0.6042 - val_binary_accuracy: 0.6745\n",
            "Epoch 43/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6651 - val_loss: 0.6046 - val_binary_accuracy: 0.6748\n",
            "Epoch 44/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6600 - val_loss: 0.6047 - val_binary_accuracy: 0.6745\n",
            "Epoch 45/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6579 - val_loss: 0.6049 - val_binary_accuracy: 0.6748\n",
            "Epoch 46/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6643 - val_loss: 0.6045 - val_binary_accuracy: 0.6748\n",
            "Epoch 47/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6099 - binary_accuracy: 0.6646 - val_loss: 0.6045 - val_binary_accuracy: 0.6767\n",
            "Epoch 48/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6683 - val_loss: 0.6041 - val_binary_accuracy: 0.6770\n",
            "Epoch 49/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6618 - val_loss: 0.6041 - val_binary_accuracy: 0.6759\n",
            "Epoch 50/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6663 - val_loss: 0.6043 - val_binary_accuracy: 0.6759\n",
            "Epoch 51/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6690 - val_loss: 0.6041 - val_binary_accuracy: 0.6748\n",
            "Epoch 52/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6674 - val_loss: 0.6042 - val_binary_accuracy: 0.6770\n",
            "Epoch 53/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6707 - val_loss: 0.6041 - val_binary_accuracy: 0.6770\n",
            "Epoch 54/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6670 - val_loss: 0.6040 - val_binary_accuracy: 0.6759\n",
            "Epoch 55/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6704 - val_loss: 0.6040 - val_binary_accuracy: 0.6756\n",
            "Epoch 56/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6070 - binary_accuracy: 0.6637 - val_loss: 0.6042 - val_binary_accuracy: 0.6741\n",
            "Epoch 57/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6675 - val_loss: 0.6041 - val_binary_accuracy: 0.6748\n",
            "Epoch 58/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6645 - val_loss: 0.6040 - val_binary_accuracy: 0.6748\n",
            "Epoch 59/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6683 - val_loss: 0.6040 - val_binary_accuracy: 0.6763\n",
            "Epoch 60/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6076 - binary_accuracy: 0.6649 - val_loss: 0.6041 - val_binary_accuracy: 0.6770\n",
            "Epoch 61/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6677 - val_loss: 0.6042 - val_binary_accuracy: 0.6745\n",
            "Epoch 62/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.6656 - val_loss: 0.6039 - val_binary_accuracy: 0.6756\n",
            "Epoch 63/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6644 - val_loss: 0.6041 - val_binary_accuracy: 0.6767\n",
            "Epoch 64/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6679 - val_loss: 0.6042 - val_binary_accuracy: 0.6756\n",
            "Epoch 65/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6678 - val_loss: 0.6040 - val_binary_accuracy: 0.6763\n",
            "Epoch 66/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6700 - val_loss: 0.6041 - val_binary_accuracy: 0.6770\n",
            "Epoch 67/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6713 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 68/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6660 - val_loss: 0.6041 - val_binary_accuracy: 0.6756\n",
            "Epoch 69/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6729 - val_loss: 0.6039 - val_binary_accuracy: 0.6756\n",
            "Epoch 70/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6679 - val_loss: 0.6038 - val_binary_accuracy: 0.6745\n",
            "Epoch 71/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6687 - val_loss: 0.6040 - val_binary_accuracy: 0.6752\n",
            "Epoch 72/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6674 - val_loss: 0.6038 - val_binary_accuracy: 0.6752\n",
            "Epoch 73/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6666 - val_loss: 0.6040 - val_binary_accuracy: 0.6745\n",
            "Epoch 74/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6718 - val_loss: 0.6041 - val_binary_accuracy: 0.6745\n",
            "Epoch 75/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.6697 - val_loss: 0.6042 - val_binary_accuracy: 0.6748\n",
            "Epoch 76/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6663 - val_loss: 0.6039 - val_binary_accuracy: 0.6745\n",
            "Epoch 77/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6708 - val_loss: 0.6037 - val_binary_accuracy: 0.6748\n",
            "Epoch 78/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.6718 - val_loss: 0.6039 - val_binary_accuracy: 0.6748\n",
            "Epoch 79/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.6688 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 80/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6639 - val_loss: 0.6039 - val_binary_accuracy: 0.6726\n",
            "Epoch 81/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6715 - val_loss: 0.6040 - val_binary_accuracy: 0.6733\n",
            "Epoch 82/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6673 - val_loss: 0.6042 - val_binary_accuracy: 0.6741\n",
            "Epoch 83/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6697 - val_loss: 0.6043 - val_binary_accuracy: 0.6730\n",
            "Epoch 84/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6675 - val_loss: 0.6043 - val_binary_accuracy: 0.6730\n",
            "Epoch 85/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6690 - val_loss: 0.6042 - val_binary_accuracy: 0.6722\n",
            "Epoch 86/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6714 - val_loss: 0.6040 - val_binary_accuracy: 0.6726\n",
            "Epoch 87/200\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6751 - val_loss: 0.6039 - val_binary_accuracy: 0.6737\n",
            "Epoch 00087: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:48,359]\u001b[0m Trial 54 finished with value: 0.6675314903259277 and parameters: {'batch size': 117, 'optimizer': 'Adagrad', 'lr': 0.011170374843414922, 'minimum_learning_rate': 0.010380097651287883}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "64/64 [==============================] - 1s 4ms/step - loss: 0.6636 - binary_accuracy: 0.5997 - val_loss: 0.6311 - val_binary_accuracy: 0.6526\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6355 - binary_accuracy: 0.6328 - val_loss: 0.6198 - val_binary_accuracy: 0.6618\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6435 - val_loss: 0.6134 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6517 - val_loss: 0.6138 - val_binary_accuracy: 0.6611\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6532 - val_loss: 0.6106 - val_binary_accuracy: 0.6626\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6567 - val_loss: 0.6083 - val_binary_accuracy: 0.6637\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6612 - val_loss: 0.6082 - val_binary_accuracy: 0.6689\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6627 - val_loss: 0.6068 - val_binary_accuracy: 0.6696\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6625 - val_loss: 0.6061 - val_binary_accuracy: 0.6667\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6643 - val_loss: 0.6040 - val_binary_accuracy: 0.6745\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6642 - val_loss: 0.6033 - val_binary_accuracy: 0.6707\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6706 - val_loss: 0.6047 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6725 - val_loss: 0.6029 - val_binary_accuracy: 0.6696\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6682 - val_loss: 0.6043 - val_binary_accuracy: 0.6681\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6722 - val_loss: 0.6038 - val_binary_accuracy: 0.6681\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6692 - val_loss: 0.6027 - val_binary_accuracy: 0.6704\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6729 - val_loss: 0.6033 - val_binary_accuracy: 0.6737\n",
            "Epoch 18/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6748 - val_loss: 0.6028 - val_binary_accuracy: 0.6711\n",
            "Epoch 19/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6725 - val_loss: 0.6039 - val_binary_accuracy: 0.6711\n",
            "Epoch 20/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.6006 - binary_accuracy: 0.6746 - val_loss: 0.6034 - val_binary_accuracy: 0.6711\n",
            "Epoch 21/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6787 - val_loss: 0.6032 - val_binary_accuracy: 0.6730\n",
            "Epoch 22/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6720 - val_loss: 0.6024 - val_binary_accuracy: 0.6726\n",
            "Epoch 23/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6752 - val_loss: 0.6021 - val_binary_accuracy: 0.6722\n",
            "Epoch 24/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5987 - binary_accuracy: 0.6765 - val_loss: 0.6037 - val_binary_accuracy: 0.6726\n",
            "Epoch 25/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6754 - val_loss: 0.6026 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6770 - val_loss: 0.6030 - val_binary_accuracy: 0.6741\n",
            "Epoch 27/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5963 - binary_accuracy: 0.6779 - val_loss: 0.6024 - val_binary_accuracy: 0.6719\n",
            "Epoch 28/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6807 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 29/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6752 - val_loss: 0.6032 - val_binary_accuracy: 0.6696\n",
            "Epoch 30/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6775 - val_loss: 0.6041 - val_binary_accuracy: 0.6626\n",
            "Epoch 31/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6741 - val_loss: 0.6034 - val_binary_accuracy: 0.6693\n",
            "Epoch 32/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5937 - binary_accuracy: 0.6787 - val_loss: 0.6033 - val_binary_accuracy: 0.6670\n",
            "Epoch 33/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6779 - val_loss: 0.6023 - val_binary_accuracy: 0.6700\n",
            "Epoch 34/200\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6773 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 35/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6778 - val_loss: 0.6049 - val_binary_accuracy: 0.6663\n",
            "Epoch 36/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5941 - binary_accuracy: 0.6810 - val_loss: 0.6037 - val_binary_accuracy: 0.6674\n",
            "Epoch 37/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5925 - binary_accuracy: 0.6865 - val_loss: 0.6032 - val_binary_accuracy: 0.6693\n",
            "Epoch 38/200\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6766 - val_loss: 0.6021 - val_binary_accuracy: 0.6704\n",
            "Epoch 00038: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:30:55,681]\u001b[0m Trial 55 finished with value: 0.6664195656776428 and parameters: {'batch size': 197, 'optimizer': 'Adagrad', 'lr': 0.09478994855411174, 'minimum_learning_rate': 0.07612681566930443}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "92/92 [==============================] - 1s 3ms/step - loss: 0.6896 - binary_accuracy: 0.5806 - val_loss: 0.6367 - val_binary_accuracy: 0.6370\n",
            "Epoch 2/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6539 - binary_accuracy: 0.6092 - val_loss: 0.6296 - val_binary_accuracy: 0.6492\n",
            "Epoch 3/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6203 - val_loss: 0.6220 - val_binary_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6324 - binary_accuracy: 0.6339 - val_loss: 0.6167 - val_binary_accuracy: 0.6678\n",
            "Epoch 5/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6317 - binary_accuracy: 0.6352 - val_loss: 0.6154 - val_binary_accuracy: 0.6681\n",
            "Epoch 6/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6423 - val_loss: 0.6110 - val_binary_accuracy: 0.6763\n",
            "Epoch 7/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6446 - val_loss: 0.6105 - val_binary_accuracy: 0.6785\n",
            "Epoch 8/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6464 - val_loss: 0.6091 - val_binary_accuracy: 0.6770\n",
            "Epoch 9/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6517 - val_loss: 0.6074 - val_binary_accuracy: 0.6804\n",
            "Epoch 10/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6588 - val_loss: 0.6047 - val_binary_accuracy: 0.6745\n",
            "Epoch 11/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6533 - val_loss: 0.6055 - val_binary_accuracy: 0.6763\n",
            "Epoch 12/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6557 - val_loss: 0.6045 - val_binary_accuracy: 0.6767\n",
            "Epoch 13/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6592 - val_loss: 0.6044 - val_binary_accuracy: 0.6752\n",
            "Epoch 14/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6614 - val_loss: 0.6039 - val_binary_accuracy: 0.6763\n",
            "Epoch 15/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6628 - val_loss: 0.6037 - val_binary_accuracy: 0.6782\n",
            "Epoch 16/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6593 - val_loss: 0.6030 - val_binary_accuracy: 0.6796\n",
            "Epoch 17/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6665 - val_loss: 0.6028 - val_binary_accuracy: 0.6789\n",
            "Epoch 18/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6098 - binary_accuracy: 0.6677 - val_loss: 0.6027 - val_binary_accuracy: 0.6811\n",
            "Epoch 19/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6662 - val_loss: 0.6024 - val_binary_accuracy: 0.6785\n",
            "Epoch 20/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6642 - val_loss: 0.6015 - val_binary_accuracy: 0.6778\n",
            "Epoch 21/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6637 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6690 - val_loss: 0.6012 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6719 - val_loss: 0.6007 - val_binary_accuracy: 0.6748\n",
            "Epoch 24/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6712 - val_loss: 0.6012 - val_binary_accuracy: 0.6763\n",
            "Epoch 25/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6663 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 26/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.6690 - val_loss: 0.6012 - val_binary_accuracy: 0.6759\n",
            "Epoch 27/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6740 - val_loss: 0.6010 - val_binary_accuracy: 0.6774\n",
            "Epoch 28/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6669 - val_loss: 0.6011 - val_binary_accuracy: 0.6778\n",
            "Epoch 29/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6694 - val_loss: 0.6006 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6742 - val_loss: 0.6006 - val_binary_accuracy: 0.6756\n",
            "Epoch 31/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6750 - val_loss: 0.6006 - val_binary_accuracy: 0.6752\n",
            "Epoch 32/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.6694 - val_loss: 0.6006 - val_binary_accuracy: 0.6759\n",
            "Epoch 33/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6710 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 34/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6731 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 35/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6687 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 36/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6739 - val_loss: 0.6007 - val_binary_accuracy: 0.6767\n",
            "Epoch 37/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6662 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 38/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6009 - binary_accuracy: 0.6705 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 39/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6737 - val_loss: 0.6007 - val_binary_accuracy: 0.6770\n",
            "Epoch 40/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6716 - val_loss: 0.6007 - val_binary_accuracy: 0.6767\n",
            "Epoch 41/200\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6671 - val_loss: 0.6007 - val_binary_accuracy: 0.6767\n",
            "Epoch 00041: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:31:04,864]\u001b[0m Trial 56 finished with value: 0.6664195656776428 and parameters: {'batch size': 138, 'optimizer': 'Adagrad', 'lr': 0.029385601514428265, 'minimum_learning_rate': 0.0007938556743747067}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "59/59 [==============================] - 1s 4ms/step - loss: 0.6739 - binary_accuracy: 0.5831 - val_loss: 0.6346 - val_binary_accuracy: 0.6466\n",
            "Epoch 2/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6407 - binary_accuracy: 0.6234 - val_loss: 0.6209 - val_binary_accuracy: 0.6626\n",
            "Epoch 3/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.6376 - val_loss: 0.6195 - val_binary_accuracy: 0.6715\n",
            "Epoch 4/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6223 - binary_accuracy: 0.6442 - val_loss: 0.6126 - val_binary_accuracy: 0.6696\n",
            "Epoch 5/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6213 - binary_accuracy: 0.6443 - val_loss: 0.6102 - val_binary_accuracy: 0.6704\n",
            "Epoch 6/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6594 - val_loss: 0.6091 - val_binary_accuracy: 0.6711\n",
            "Epoch 7/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6517 - val_loss: 0.6103 - val_binary_accuracy: 0.6722\n",
            "Epoch 8/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6629 - val_loss: 0.6076 - val_binary_accuracy: 0.6770\n",
            "Epoch 9/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6616 - val_loss: 0.6058 - val_binary_accuracy: 0.6745\n",
            "Epoch 10/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6629 - val_loss: 0.6048 - val_binary_accuracy: 0.6774\n",
            "Epoch 11/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6706 - val_loss: 0.6043 - val_binary_accuracy: 0.6719\n",
            "Epoch 12/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6621 - val_loss: 0.6039 - val_binary_accuracy: 0.6693\n",
            "Epoch 13/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6650 - val_loss: 0.6048 - val_binary_accuracy: 0.6726\n",
            "Epoch 14/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6702 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 15/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6722 - val_loss: 0.6039 - val_binary_accuracy: 0.6693\n",
            "Epoch 16/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6681 - val_loss: 0.6049 - val_binary_accuracy: 0.6711\n",
            "Epoch 17/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6729 - val_loss: 0.6023 - val_binary_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6690 - val_loss: 0.6031 - val_binary_accuracy: 0.6696\n",
            "Epoch 19/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6670 - val_loss: 0.6032 - val_binary_accuracy: 0.6715\n",
            "Epoch 20/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6723 - val_loss: 0.6022 - val_binary_accuracy: 0.6741\n",
            "Epoch 21/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6716 - val_loss: 0.6017 - val_binary_accuracy: 0.6715\n",
            "Epoch 22/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6708 - val_loss: 0.6029 - val_binary_accuracy: 0.6670\n",
            "Epoch 23/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6745 - val_loss: 0.6018 - val_binary_accuracy: 0.6711\n",
            "Epoch 24/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6724 - val_loss: 0.6014 - val_binary_accuracy: 0.6693\n",
            "Epoch 25/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6714 - val_loss: 0.6023 - val_binary_accuracy: 0.6707\n",
            "Epoch 26/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6758 - val_loss: 0.6023 - val_binary_accuracy: 0.6719\n",
            "Epoch 27/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6745 - val_loss: 0.6040 - val_binary_accuracy: 0.6693\n",
            "Epoch 28/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6777 - val_loss: 0.6026 - val_binary_accuracy: 0.6700\n",
            "Epoch 29/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6767 - val_loss: 0.6023 - val_binary_accuracy: 0.6711\n",
            "Epoch 30/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6789 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 31/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6787 - val_loss: 0.6014 - val_binary_accuracy: 0.6741\n",
            "Epoch 32/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6732 - val_loss: 0.6017 - val_binary_accuracy: 0.6726\n",
            "Epoch 33/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6759 - val_loss: 0.6027 - val_binary_accuracy: 0.6704\n",
            "Epoch 34/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6787 - val_loss: 0.6021 - val_binary_accuracy: 0.6696\n",
            "Epoch 35/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5952 - binary_accuracy: 0.6796 - val_loss: 0.6018 - val_binary_accuracy: 0.6726\n",
            "Epoch 36/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6797 - val_loss: 0.6022 - val_binary_accuracy: 0.6670\n",
            "Epoch 37/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6776 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 38/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6787 - val_loss: 0.6021 - val_binary_accuracy: 0.6693\n",
            "Epoch 39/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5933 - binary_accuracy: 0.6812 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 40/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6731 - val_loss: 0.6012 - val_binary_accuracy: 0.6756\n",
            "Epoch 41/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5940 - binary_accuracy: 0.6760 - val_loss: 0.6007 - val_binary_accuracy: 0.6722\n",
            "Epoch 42/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6766 - val_loss: 0.6008 - val_binary_accuracy: 0.6756\n",
            "Epoch 43/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6749 - val_loss: 0.6008 - val_binary_accuracy: 0.6748\n",
            "Epoch 44/200\n",
            "59/59 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6793 - val_loss: 0.6011 - val_binary_accuracy: 0.6700\n",
            "Epoch 45/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5915 - binary_accuracy: 0.6785 - val_loss: 0.6017 - val_binary_accuracy: 0.6711\n",
            "Epoch 46/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6779 - val_loss: 0.6014 - val_binary_accuracy: 0.6733\n",
            "Epoch 47/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6818 - val_loss: 0.6022 - val_binary_accuracy: 0.6704\n",
            "Epoch 48/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6804 - val_loss: 0.6017 - val_binary_accuracy: 0.6722\n",
            "Epoch 49/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5903 - binary_accuracy: 0.6799 - val_loss: 0.6015 - val_binary_accuracy: 0.6722\n",
            "Epoch 50/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5916 - binary_accuracy: 0.6791 - val_loss: 0.6019 - val_binary_accuracy: 0.6719\n",
            "Epoch 51/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5927 - binary_accuracy: 0.6828 - val_loss: 0.6026 - val_binary_accuracy: 0.6696\n",
            "Epoch 00051: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:31:15,641]\u001b[0m Trial 57 finished with value: 0.6745737791061401 and parameters: {'batch size': 215, 'optimizer': 'Adagrad', 'lr': 0.09186514619586106, 'minimum_learning_rate': 0.08474346448954577}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "60/60 [==============================] - 1s 5ms/step - loss: 0.6721 - binary_accuracy: 0.5941 - val_loss: 0.6259 - val_binary_accuracy: 0.6474\n",
            "Epoch 2/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6381 - binary_accuracy: 0.6309 - val_loss: 0.6164 - val_binary_accuracy: 0.6626\n",
            "Epoch 3/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6282 - binary_accuracy: 0.6388 - val_loss: 0.6085 - val_binary_accuracy: 0.6767\n",
            "Epoch 4/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6228 - binary_accuracy: 0.6449 - val_loss: 0.6079 - val_binary_accuracy: 0.6733\n",
            "Epoch 5/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6202 - binary_accuracy: 0.6491 - val_loss: 0.6071 - val_binary_accuracy: 0.6730\n",
            "Epoch 6/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6555 - val_loss: 0.6050 - val_binary_accuracy: 0.6752\n",
            "Epoch 7/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6571 - val_loss: 0.6049 - val_binary_accuracy: 0.6730\n",
            "Epoch 8/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6578 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6625 - val_loss: 0.6009 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6634 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 11/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6620 - val_loss: 0.6025 - val_binary_accuracy: 0.6808\n",
            "Epoch 12/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6668 - val_loss: 0.6009 - val_binary_accuracy: 0.6782\n",
            "Epoch 13/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6656 - val_loss: 0.6009 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6686 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 15/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6670 - val_loss: 0.5996 - val_binary_accuracy: 0.6767\n",
            "Epoch 16/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6700 - val_loss: 0.6007 - val_binary_accuracy: 0.6796\n",
            "Epoch 17/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6722 - val_loss: 0.5996 - val_binary_accuracy: 0.6796\n",
            "Epoch 18/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6707 - val_loss: 0.5994 - val_binary_accuracy: 0.6796\n",
            "Epoch 19/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6733 - val_loss: 0.6000 - val_binary_accuracy: 0.6707\n",
            "Epoch 20/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6735 - val_loss: 0.5998 - val_binary_accuracy: 0.6737\n",
            "Epoch 21/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6720 - val_loss: 0.5998 - val_binary_accuracy: 0.6756\n",
            "Epoch 22/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6721 - val_loss: 0.6000 - val_binary_accuracy: 0.6774\n",
            "Epoch 23/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6744 - val_loss: 0.5994 - val_binary_accuracy: 0.6759\n",
            "Epoch 24/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6760 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 25/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6719 - val_loss: 0.5997 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6721 - val_loss: 0.6015 - val_binary_accuracy: 0.6689\n",
            "Epoch 27/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6783 - val_loss: 0.6001 - val_binary_accuracy: 0.6774\n",
            "Epoch 28/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6810 - val_loss: 0.6002 - val_binary_accuracy: 0.6733\n",
            "Epoch 29/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6783 - val_loss: 0.5996 - val_binary_accuracy: 0.6719\n",
            "Epoch 30/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6747 - val_loss: 0.6003 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6774 - val_loss: 0.5999 - val_binary_accuracy: 0.6726\n",
            "Epoch 32/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6826 - val_loss: 0.6000 - val_binary_accuracy: 0.6711\n",
            "Epoch 33/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.6741 - val_loss: 0.6005 - val_binary_accuracy: 0.6715\n",
            "Epoch 00033: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:31:26,409]\u001b[0m Trial 58 finished with value: 0.6645663380622864 and parameters: {'batch size': 211, 'optimizer': 'Adagrad', 'lr': 0.0937532105177368, 'minimum_learning_rate': 0.08502598786998525}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "54/54 [==============================] - 1s 5ms/step - loss: 0.7125 - binary_accuracy: 0.5558 - val_loss: 0.6430 - val_binary_accuracy: 0.6170\n",
            "Epoch 2/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6718 - binary_accuracy: 0.5924 - val_loss: 0.6354 - val_binary_accuracy: 0.6314\n",
            "Epoch 3/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6559 - binary_accuracy: 0.6065 - val_loss: 0.6307 - val_binary_accuracy: 0.6370\n",
            "Epoch 4/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6503 - binary_accuracy: 0.6123 - val_loss: 0.6272 - val_binary_accuracy: 0.6470\n",
            "Epoch 5/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6443 - binary_accuracy: 0.6162 - val_loss: 0.6242 - val_binary_accuracy: 0.6485\n",
            "Epoch 6/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6407 - binary_accuracy: 0.6260 - val_loss: 0.6223 - val_binary_accuracy: 0.6522\n",
            "Epoch 7/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6323 - val_loss: 0.6198 - val_binary_accuracy: 0.6559\n",
            "Epoch 8/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6297 - val_loss: 0.6182 - val_binary_accuracy: 0.6563\n",
            "Epoch 9/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6320 - binary_accuracy: 0.6291 - val_loss: 0.6162 - val_binary_accuracy: 0.6581\n",
            "Epoch 10/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6313 - binary_accuracy: 0.6372 - val_loss: 0.6149 - val_binary_accuracy: 0.6611\n",
            "Epoch 11/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6379 - val_loss: 0.6129 - val_binary_accuracy: 0.6652\n",
            "Epoch 12/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6280 - binary_accuracy: 0.6390 - val_loss: 0.6113 - val_binary_accuracy: 0.6674\n",
            "Epoch 13/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6267 - binary_accuracy: 0.6460 - val_loss: 0.6104 - val_binary_accuracy: 0.6704\n",
            "Epoch 14/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_accuracy: 0.6477 - val_loss: 0.6095 - val_binary_accuracy: 0.6704\n",
            "Epoch 15/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6453 - val_loss: 0.6094 - val_binary_accuracy: 0.6726\n",
            "Epoch 16/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6484 - val_loss: 0.6078 - val_binary_accuracy: 0.6737\n",
            "Epoch 17/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6494 - val_loss: 0.6073 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6211 - binary_accuracy: 0.6397 - val_loss: 0.6070 - val_binary_accuracy: 0.6737\n",
            "Epoch 19/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6172 - binary_accuracy: 0.6537 - val_loss: 0.6057 - val_binary_accuracy: 0.6767\n",
            "Epoch 20/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6171 - binary_accuracy: 0.6578 - val_loss: 0.6056 - val_binary_accuracy: 0.6778\n",
            "Epoch 21/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6175 - binary_accuracy: 0.6589 - val_loss: 0.6059 - val_binary_accuracy: 0.6767\n",
            "Epoch 22/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6528 - val_loss: 0.6053 - val_binary_accuracy: 0.6785\n",
            "Epoch 23/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.6571 - val_loss: 0.6051 - val_binary_accuracy: 0.6782\n",
            "Epoch 24/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6575 - val_loss: 0.6049 - val_binary_accuracy: 0.6778\n",
            "Epoch 25/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6561 - val_loss: 0.6047 - val_binary_accuracy: 0.6774\n",
            "Epoch 26/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6540 - val_loss: 0.6042 - val_binary_accuracy: 0.6785\n",
            "Epoch 27/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6540 - val_loss: 0.6040 - val_binary_accuracy: 0.6759\n",
            "Epoch 28/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6143 - binary_accuracy: 0.6593 - val_loss: 0.6040 - val_binary_accuracy: 0.6774\n",
            "Epoch 29/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6591 - val_loss: 0.6032 - val_binary_accuracy: 0.6782\n",
            "Epoch 30/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6623 - val_loss: 0.6035 - val_binary_accuracy: 0.6789\n",
            "Epoch 31/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6585 - val_loss: 0.6033 - val_binary_accuracy: 0.6774\n",
            "Epoch 32/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6607 - val_loss: 0.6031 - val_binary_accuracy: 0.6782\n",
            "Epoch 33/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6642 - val_loss: 0.6029 - val_binary_accuracy: 0.6785\n",
            "Epoch 34/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6623 - val_loss: 0.6023 - val_binary_accuracy: 0.6767\n",
            "Epoch 35/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6583 - val_loss: 0.6023 - val_binary_accuracy: 0.6774\n",
            "Epoch 36/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6645 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 37/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6592 - val_loss: 0.6023 - val_binary_accuracy: 0.6752\n",
            "Epoch 38/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6667 - val_loss: 0.6020 - val_binary_accuracy: 0.6774\n",
            "Epoch 39/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6667 - val_loss: 0.6018 - val_binary_accuracy: 0.6756\n",
            "Epoch 40/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6660 - val_loss: 0.6016 - val_binary_accuracy: 0.6778\n",
            "Epoch 41/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6640 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 42/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6621 - val_loss: 0.6015 - val_binary_accuracy: 0.6763\n",
            "Epoch 43/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6640 - val_loss: 0.6015 - val_binary_accuracy: 0.6796\n",
            "Epoch 44/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6645 - val_loss: 0.6013 - val_binary_accuracy: 0.6778\n",
            "Epoch 45/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6650 - val_loss: 0.6012 - val_binary_accuracy: 0.6789\n",
            "Epoch 46/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6679 - val_loss: 0.6010 - val_binary_accuracy: 0.6782\n",
            "Epoch 47/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6636 - val_loss: 0.6011 - val_binary_accuracy: 0.6767\n",
            "Epoch 48/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6671 - val_loss: 0.6009 - val_binary_accuracy: 0.6763\n",
            "Epoch 49/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6723 - val_loss: 0.6008 - val_binary_accuracy: 0.6778\n",
            "Epoch 50/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6698 - val_loss: 0.6004 - val_binary_accuracy: 0.6785\n",
            "Epoch 51/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6648 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 52/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6718 - val_loss: 0.6005 - val_binary_accuracy: 0.6785\n",
            "Epoch 53/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6698 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 54/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6661 - val_loss: 0.6006 - val_binary_accuracy: 0.6774\n",
            "Epoch 55/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6705 - val_loss: 0.6005 - val_binary_accuracy: 0.6778\n",
            "Epoch 56/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6694 - val_loss: 0.6007 - val_binary_accuracy: 0.6785\n",
            "Epoch 57/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6699 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 58/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6726 - val_loss: 0.6007 - val_binary_accuracy: 0.6778\n",
            "Epoch 59/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6729 - val_loss: 0.6007 - val_binary_accuracy: 0.6782\n",
            "Epoch 60/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6683 - val_loss: 0.6008 - val_binary_accuracy: 0.6770\n",
            "Epoch 00060: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:31:37,212]\u001b[0m Trial 59 finished with value: 0.6653076410293579 and parameters: {'batch size': 234, 'optimizer': 'Adagrad', 'lr': 0.022861314900668034, 'minimum_learning_rate': 0.007399603535528712}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 1s 5ms/step - loss: 0.7122 - binary_accuracy: 0.5634 - val_loss: 0.6444 - val_binary_accuracy: 0.6233\n",
            "Epoch 2/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6643 - binary_accuracy: 0.5990 - val_loss: 0.6370 - val_binary_accuracy: 0.6418\n",
            "Epoch 3/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.6071 - val_loss: 0.6362 - val_binary_accuracy: 0.6396\n",
            "Epoch 4/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6448 - binary_accuracy: 0.6228 - val_loss: 0.6287 - val_binary_accuracy: 0.6507\n",
            "Epoch 5/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6390 - binary_accuracy: 0.6241 - val_loss: 0.6256 - val_binary_accuracy: 0.6589\n",
            "Epoch 6/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6341 - binary_accuracy: 0.6296 - val_loss: 0.6215 - val_binary_accuracy: 0.6600\n",
            "Epoch 7/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6307 - binary_accuracy: 0.6324 - val_loss: 0.6202 - val_binary_accuracy: 0.6626\n",
            "Epoch 8/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6282 - binary_accuracy: 0.6392 - val_loss: 0.6167 - val_binary_accuracy: 0.6667\n",
            "Epoch 9/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6444 - val_loss: 0.6157 - val_binary_accuracy: 0.6618\n",
            "Epoch 10/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6410 - val_loss: 0.6150 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6247 - binary_accuracy: 0.6459 - val_loss: 0.6125 - val_binary_accuracy: 0.6685\n",
            "Epoch 12/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6212 - binary_accuracy: 0.6468 - val_loss: 0.6116 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6449 - val_loss: 0.6115 - val_binary_accuracy: 0.6681\n",
            "Epoch 14/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6490 - val_loss: 0.6100 - val_binary_accuracy: 0.6715\n",
            "Epoch 15/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6505 - val_loss: 0.6114 - val_binary_accuracy: 0.6637\n",
            "Epoch 16/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6570 - val_loss: 0.6098 - val_binary_accuracy: 0.6693\n",
            "Epoch 17/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6534 - val_loss: 0.6088 - val_binary_accuracy: 0.6693\n",
            "Epoch 18/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6141 - binary_accuracy: 0.6513 - val_loss: 0.6070 - val_binary_accuracy: 0.6752\n",
            "Epoch 19/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6519 - val_loss: 0.6075 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6541 - val_loss: 0.6068 - val_binary_accuracy: 0.6696\n",
            "Epoch 21/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6617 - val_loss: 0.6068 - val_binary_accuracy: 0.6711\n",
            "Epoch 22/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6605 - val_loss: 0.6068 - val_binary_accuracy: 0.6726\n",
            "Epoch 23/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6607 - val_loss: 0.6052 - val_binary_accuracy: 0.6711\n",
            "Epoch 24/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6605 - val_loss: 0.6050 - val_binary_accuracy: 0.6685\n",
            "Epoch 25/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6629 - val_loss: 0.6063 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6572 - val_loss: 0.6055 - val_binary_accuracy: 0.6700\n",
            "Epoch 27/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6603 - val_loss: 0.6054 - val_binary_accuracy: 0.6704\n",
            "Epoch 28/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6620 - val_loss: 0.6053 - val_binary_accuracy: 0.6707\n",
            "Epoch 29/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6580 - val_loss: 0.6053 - val_binary_accuracy: 0.6715\n",
            "Epoch 30/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6669 - val_loss: 0.6051 - val_binary_accuracy: 0.6685\n",
            "Epoch 31/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6631 - val_loss: 0.6049 - val_binary_accuracy: 0.6696\n",
            "Epoch 32/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6654 - val_loss: 0.6048 - val_binary_accuracy: 0.6693\n",
            "Epoch 33/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6655 - val_loss: 0.6046 - val_binary_accuracy: 0.6696\n",
            "Epoch 34/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6642 - val_loss: 0.6046 - val_binary_accuracy: 0.6685\n",
            "Epoch 35/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6671 - val_loss: 0.6047 - val_binary_accuracy: 0.6704\n",
            "Epoch 36/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6630 - val_loss: 0.6046 - val_binary_accuracy: 0.6696\n",
            "Epoch 37/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6638 - val_loss: 0.6046 - val_binary_accuracy: 0.6707\n",
            "Epoch 38/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6669 - val_loss: 0.6046 - val_binary_accuracy: 0.6707\n",
            "Epoch 39/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6662 - val_loss: 0.6046 - val_binary_accuracy: 0.6704\n",
            "Epoch 40/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6666 - val_loss: 0.6046 - val_binary_accuracy: 0.6700\n",
            "Epoch 41/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6644 - val_loss: 0.6046 - val_binary_accuracy: 0.6704\n",
            "Epoch 42/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6607 - val_loss: 0.6046 - val_binary_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6673 - val_loss: 0.6045 - val_binary_accuracy: 0.6696\n",
            "Epoch 44/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6633 - val_loss: 0.6046 - val_binary_accuracy: 0.6696\n",
            "Epoch 45/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6725 - val_loss: 0.6044 - val_binary_accuracy: 0.6693\n",
            "Epoch 46/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6648 - val_loss: 0.6044 - val_binary_accuracy: 0.6696\n",
            "Epoch 47/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6630 - val_loss: 0.6043 - val_binary_accuracy: 0.6689\n",
            "Epoch 48/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6619 - val_loss: 0.6043 - val_binary_accuracy: 0.6693\n",
            "Epoch 49/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6652 - val_loss: 0.6044 - val_binary_accuracy: 0.6689\n",
            "Epoch 50/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6674 - val_loss: 0.6043 - val_binary_accuracy: 0.6689\n",
            "Epoch 51/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6659 - val_loss: 0.6043 - val_binary_accuracy: 0.6693\n",
            "Epoch 52/200\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.6064 - binary_accuracy: 0.6605 - val_loss: 0.6043 - val_binary_accuracy: 0.6696\n",
            "Epoch 53/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6670 - val_loss: 0.6043 - val_binary_accuracy: 0.6681\n",
            "Epoch 54/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6656 - val_loss: 0.6042 - val_binary_accuracy: 0.6696\n",
            "Epoch 55/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6626 - val_loss: 0.6042 - val_binary_accuracy: 0.6693\n",
            "Epoch 56/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6640 - val_loss: 0.6042 - val_binary_accuracy: 0.6696\n",
            "Epoch 57/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6669 - val_loss: 0.6042 - val_binary_accuracy: 0.6693\n",
            "Epoch 58/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6649 - val_loss: 0.6042 - val_binary_accuracy: 0.6700\n",
            "Epoch 59/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6662 - val_loss: 0.6042 - val_binary_accuracy: 0.6704\n",
            "Epoch 60/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6719 - val_loss: 0.6041 - val_binary_accuracy: 0.6704\n",
            "Epoch 61/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6654 - val_loss: 0.6041 - val_binary_accuracy: 0.6707\n",
            "Epoch 62/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6616 - val_loss: 0.6041 - val_binary_accuracy: 0.6700\n",
            "Epoch 63/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6625 - val_loss: 0.6040 - val_binary_accuracy: 0.6704\n",
            "Epoch 64/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6673 - val_loss: 0.6040 - val_binary_accuracy: 0.6704\n",
            "Epoch 65/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6654 - val_loss: 0.6040 - val_binary_accuracy: 0.6707\n",
            "Epoch 66/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6720 - val_loss: 0.6039 - val_binary_accuracy: 0.6707\n",
            "Epoch 67/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6660 - val_loss: 0.6039 - val_binary_accuracy: 0.6700\n",
            "Epoch 68/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6724 - val_loss: 0.6039 - val_binary_accuracy: 0.6696\n",
            "Epoch 69/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6629 - val_loss: 0.6039 - val_binary_accuracy: 0.6700\n",
            "Epoch 70/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6681 - val_loss: 0.6038 - val_binary_accuracy: 0.6693\n",
            "Epoch 71/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6662 - val_loss: 0.6038 - val_binary_accuracy: 0.6700\n",
            "Epoch 72/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6618 - val_loss: 0.6038 - val_binary_accuracy: 0.6711\n",
            "Epoch 73/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6632 - val_loss: 0.6038 - val_binary_accuracy: 0.6711\n",
            "Epoch 74/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6646 - val_loss: 0.6038 - val_binary_accuracy: 0.6715\n",
            "Epoch 75/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6670 - val_loss: 0.6037 - val_binary_accuracy: 0.6719\n",
            "Epoch 76/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6712 - val_loss: 0.6037 - val_binary_accuracy: 0.6719\n",
            "Epoch 77/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6679 - val_loss: 0.6037 - val_binary_accuracy: 0.6722\n",
            "Epoch 78/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6642 - val_loss: 0.6036 - val_binary_accuracy: 0.6719\n",
            "Epoch 79/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6684 - val_loss: 0.6037 - val_binary_accuracy: 0.6715\n",
            "Epoch 80/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6698 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 81/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6687 - val_loss: 0.6036 - val_binary_accuracy: 0.6715\n",
            "Epoch 82/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6679 - val_loss: 0.6035 - val_binary_accuracy: 0.6711\n",
            "Epoch 83/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6700 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 84/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6690 - val_loss: 0.6035 - val_binary_accuracy: 0.6700\n",
            "Epoch 85/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6639 - val_loss: 0.6035 - val_binary_accuracy: 0.6715\n",
            "Epoch 86/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6671 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 87/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6648 - val_loss: 0.6035 - val_binary_accuracy: 0.6711\n",
            "Epoch 88/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6702 - val_loss: 0.6035 - val_binary_accuracy: 0.6719\n",
            "Epoch 89/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6633 - val_loss: 0.6035 - val_binary_accuracy: 0.6726\n",
            "Epoch 90/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6671 - val_loss: 0.6036 - val_binary_accuracy: 0.6730\n",
            "Epoch 91/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6618 - val_loss: 0.6035 - val_binary_accuracy: 0.6726\n",
            "Epoch 92/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6685 - val_loss: 0.6035 - val_binary_accuracy: 0.6726\n",
            "Epoch 93/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6709 - val_loss: 0.6034 - val_binary_accuracy: 0.6722\n",
            "Epoch 94/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6700 - val_loss: 0.6034 - val_binary_accuracy: 0.6730\n",
            "Epoch 95/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6654 - val_loss: 0.6034 - val_binary_accuracy: 0.6726\n",
            "Epoch 96/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6709 - val_loss: 0.6034 - val_binary_accuracy: 0.6726\n",
            "Epoch 97/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6668 - val_loss: 0.6033 - val_binary_accuracy: 0.6730\n",
            "Epoch 98/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6667 - val_loss: 0.6033 - val_binary_accuracy: 0.6730\n",
            "Epoch 99/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6660 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 100/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6700 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 101/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6683 - val_loss: 0.6033 - val_binary_accuracy: 0.6726\n",
            "Epoch 102/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6713 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 103/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6732 - val_loss: 0.6032 - val_binary_accuracy: 0.6715\n",
            "Epoch 104/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6698 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 105/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6711 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 106/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6685 - val_loss: 0.6032 - val_binary_accuracy: 0.6722\n",
            "Epoch 107/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6655 - val_loss: 0.6032 - val_binary_accuracy: 0.6726\n",
            "Epoch 108/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6629 - val_loss: 0.6032 - val_binary_accuracy: 0.6730\n",
            "Epoch 109/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6692 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 110/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6686 - val_loss: 0.6031 - val_binary_accuracy: 0.6730\n",
            "Epoch 111/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6651 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 112/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6694 - val_loss: 0.6031 - val_binary_accuracy: 0.6730\n",
            "Epoch 113/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6687 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 114/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6702 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 115/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6672 - val_loss: 0.6031 - val_binary_accuracy: 0.6715\n",
            "Epoch 116/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6685 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 117/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6683 - val_loss: 0.6031 - val_binary_accuracy: 0.6726\n",
            "Epoch 118/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6688 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 119/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6706 - val_loss: 0.6030 - val_binary_accuracy: 0.6722\n",
            "Epoch 120/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6717 - val_loss: 0.6030 - val_binary_accuracy: 0.6722\n",
            "Epoch 121/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6687 - val_loss: 0.6030 - val_binary_accuracy: 0.6722\n",
            "Epoch 122/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6677 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 123/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6671 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 124/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6672 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 125/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6703 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 126/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6663 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 127/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6737 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 128/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6692 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 129/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6708 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 130/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6702 - val_loss: 0.6031 - val_binary_accuracy: 0.6715\n",
            "Epoch 131/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6714 - val_loss: 0.6031 - val_binary_accuracy: 0.6711\n",
            "Epoch 132/200\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6717 - val_loss: 0.6030 - val_binary_accuracy: 0.6711\n",
            "Epoch 00132: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:32:18,706]\u001b[0m Trial 60 finished with value: 0.6571534276008606 and parameters: {'batch size': 228, 'optimizer': 'Adagrad', 'lr': 0.026435830551631873, 'minimum_learning_rate': 0.0031684543612021778}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "59/59 [==============================] - 1s 5ms/step - loss: 0.6747 - binary_accuracy: 0.5861 - val_loss: 0.6458 - val_binary_accuracy: 0.6292\n",
            "Epoch 2/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.6184 - val_loss: 0.6716 - val_binary_accuracy: 0.6081\n",
            "Epoch 3/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6391 - binary_accuracy: 0.6289 - val_loss: 0.6157 - val_binary_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6272 - binary_accuracy: 0.6428 - val_loss: 0.6237 - val_binary_accuracy: 0.6478\n",
            "Epoch 5/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6250 - binary_accuracy: 0.6470 - val_loss: 0.6316 - val_binary_accuracy: 0.6474\n",
            "Epoch 6/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6509 - val_loss: 0.6192 - val_binary_accuracy: 0.6455\n",
            "Epoch 7/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6569 - val_loss: 0.6075 - val_binary_accuracy: 0.6707\n",
            "Epoch 8/200\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.6168 - binary_accuracy: 0.6608 - val_loss: 0.6023 - val_binary_accuracy: 0.6804\n",
            "Epoch 9/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6621 - val_loss: 0.6124 - val_binary_accuracy: 0.6674\n",
            "Epoch 10/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.6586 - val_loss: 0.6226 - val_binary_accuracy: 0.6522\n",
            "Epoch 11/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6597 - val_loss: 0.6070 - val_binary_accuracy: 0.6752\n",
            "Epoch 12/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6627 - val_loss: 0.6109 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6656 - val_loss: 0.6064 - val_binary_accuracy: 0.6667\n",
            "Epoch 14/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6673 - val_loss: 0.6018 - val_binary_accuracy: 0.6782\n",
            "Epoch 15/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6715 - val_loss: 0.6039 - val_binary_accuracy: 0.6726\n",
            "Epoch 16/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6681 - val_loss: 0.6070 - val_binary_accuracy: 0.6704\n",
            "Epoch 17/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6710 - val_loss: 0.6125 - val_binary_accuracy: 0.6700\n",
            "Epoch 18/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6698 - val_loss: 0.6009 - val_binary_accuracy: 0.6796\n",
            "Epoch 19/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6717 - val_loss: 0.6026 - val_binary_accuracy: 0.6745\n",
            "Epoch 20/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6710 - val_loss: 0.6274 - val_binary_accuracy: 0.6548\n",
            "Epoch 21/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6663 - val_loss: 0.6053 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6715 - val_loss: 0.6092 - val_binary_accuracy: 0.6737\n",
            "Epoch 23/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6721 - val_loss: 0.6163 - val_binary_accuracy: 0.6678\n",
            "Epoch 24/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6679 - val_loss: 0.6106 - val_binary_accuracy: 0.6759\n",
            "Epoch 25/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6712 - val_loss: 0.6095 - val_binary_accuracy: 0.6696\n",
            "Epoch 26/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6704 - val_loss: 0.6063 - val_binary_accuracy: 0.6696\n",
            "Epoch 27/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6716 - val_loss: 0.6092 - val_binary_accuracy: 0.6707\n",
            "Epoch 28/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6740 - val_loss: 0.6096 - val_binary_accuracy: 0.6659\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:32:24,498]\u001b[0m Trial 61 finished with value: 0.6564121842384338 and parameters: {'batch size': 217, 'optimizer': 'Adagrad', 'lr': 0.0966268760124246, 'minimum_learning_rate': 0.0962488885396083}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "53/53 [==============================] - 1s 5ms/step - loss: 0.6728 - binary_accuracy: 0.5890 - val_loss: 0.6334 - val_binary_accuracy: 0.6433\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6409 - binary_accuracy: 0.6254 - val_loss: 0.6216 - val_binary_accuracy: 0.6552\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6382 - val_loss: 0.6169 - val_binary_accuracy: 0.6674\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6436 - val_loss: 0.6136 - val_binary_accuracy: 0.6626\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_accuracy: 0.6516 - val_loss: 0.6096 - val_binary_accuracy: 0.6644\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6519 - val_loss: 0.6071 - val_binary_accuracy: 0.6644\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.6581 - val_loss: 0.6082 - val_binary_accuracy: 0.6659\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6567 - val_loss: 0.6107 - val_binary_accuracy: 0.6681\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6632 - val_loss: 0.6085 - val_binary_accuracy: 0.6678\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6607 - val_loss: 0.6058 - val_binary_accuracy: 0.6648\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6605 - val_loss: 0.6057 - val_binary_accuracy: 0.6681\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6629 - val_loss: 0.6039 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6702 - val_loss: 0.6051 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6652 - val_loss: 0.6083 - val_binary_accuracy: 0.6707\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6673 - val_loss: 0.6035 - val_binary_accuracy: 0.6685\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6667 - val_loss: 0.6038 - val_binary_accuracy: 0.6648\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6690 - val_loss: 0.6034 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6654 - val_loss: 0.6031 - val_binary_accuracy: 0.6652\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6694 - val_loss: 0.6028 - val_binary_accuracy: 0.6707\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6746 - val_loss: 0.6029 - val_binary_accuracy: 0.6745\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6695 - val_loss: 0.6024 - val_binary_accuracy: 0.6681\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6729 - val_loss: 0.6016 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6686 - val_loss: 0.6021 - val_binary_accuracy: 0.6741\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6755 - val_loss: 0.6025 - val_binary_accuracy: 0.6722\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6719 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6724 - val_loss: 0.6030 - val_binary_accuracy: 0.6693\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6709 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6753 - val_loss: 0.6030 - val_binary_accuracy: 0.6704\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6760 - val_loss: 0.6024 - val_binary_accuracy: 0.6670\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6764 - val_loss: 0.6015 - val_binary_accuracy: 0.6678\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6794 - val_loss: 0.6022 - val_binary_accuracy: 0.6652\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6783 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6737 - val_loss: 0.6027 - val_binary_accuracy: 0.6659\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6737 - val_loss: 0.6011 - val_binary_accuracy: 0.6704\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6721 - val_loss: 0.6026 - val_binary_accuracy: 0.6659\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6746 - val_loss: 0.6021 - val_binary_accuracy: 0.6711\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6779 - val_loss: 0.6007 - val_binary_accuracy: 0.6696\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6734 - val_loss: 0.6018 - val_binary_accuracy: 0.6626\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6782 - val_loss: 0.6022 - val_binary_accuracy: 0.6685\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6733 - val_loss: 0.6026 - val_binary_accuracy: 0.6693\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6814 - val_loss: 0.6037 - val_binary_accuracy: 0.6667\n",
            "Epoch 42/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6734 - val_loss: 0.6040 - val_binary_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6748 - val_loss: 0.6037 - val_binary_accuracy: 0.6674\n",
            "Epoch 44/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.6796 - val_loss: 0.6032 - val_binary_accuracy: 0.6700\n",
            "Epoch 45/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6799 - val_loss: 0.6031 - val_binary_accuracy: 0.6730\n",
            "Epoch 46/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5932 - binary_accuracy: 0.6808 - val_loss: 0.6020 - val_binary_accuracy: 0.6722\n",
            "Epoch 47/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5942 - binary_accuracy: 0.6787 - val_loss: 0.6032 - val_binary_accuracy: 0.6659\n",
            "Epoch 00047: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:32:35,300]\u001b[0m Trial 62 finished with value: 0.6679021716117859 and parameters: {'batch size': 241, 'optimizer': 'Adagrad', 'lr': 0.08888703626164998, 'minimum_learning_rate': 0.07504119319189112}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "66/66 [==============================] - 1s 4ms/step - loss: 0.6812 - binary_accuracy: 0.5815 - val_loss: 0.6400 - val_binary_accuracy: 0.6311\n",
            "Epoch 2/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6238 - val_loss: 0.6240 - val_binary_accuracy: 0.6593\n",
            "Epoch 3/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6327 - val_loss: 0.6180 - val_binary_accuracy: 0.6585\n",
            "Epoch 4/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6499 - val_loss: 0.6132 - val_binary_accuracy: 0.6652\n",
            "Epoch 5/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6212 - binary_accuracy: 0.6508 - val_loss: 0.6104 - val_binary_accuracy: 0.6681\n",
            "Epoch 6/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6578 - val_loss: 0.6117 - val_binary_accuracy: 0.6659\n",
            "Epoch 7/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6171 - binary_accuracy: 0.6594 - val_loss: 0.6088 - val_binary_accuracy: 0.6626\n",
            "Epoch 8/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6161 - binary_accuracy: 0.6534 - val_loss: 0.6059 - val_binary_accuracy: 0.6685\n",
            "Epoch 9/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6577 - val_loss: 0.6066 - val_binary_accuracy: 0.6689\n",
            "Epoch 10/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6641 - val_loss: 0.6044 - val_binary_accuracy: 0.6689\n",
            "Epoch 11/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6615 - val_loss: 0.6050 - val_binary_accuracy: 0.6685\n",
            "Epoch 12/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6706 - val_loss: 0.6036 - val_binary_accuracy: 0.6719\n",
            "Epoch 13/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6694 - val_loss: 0.6042 - val_binary_accuracy: 0.6704\n",
            "Epoch 14/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6718 - val_loss: 0.6045 - val_binary_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6713 - val_loss: 0.6055 - val_binary_accuracy: 0.6726\n",
            "Epoch 16/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6698 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 17/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.6073 - binary_accuracy: 0.6685 - val_loss: 0.6040 - val_binary_accuracy: 0.6745\n",
            "Epoch 18/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6749 - val_loss: 0.6025 - val_binary_accuracy: 0.6763\n",
            "Epoch 19/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6718 - val_loss: 0.6013 - val_binary_accuracy: 0.6759\n",
            "Epoch 20/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6712 - val_loss: 0.6018 - val_binary_accuracy: 0.6759\n",
            "Epoch 21/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6753 - val_loss: 0.6017 - val_binary_accuracy: 0.6730\n",
            "Epoch 22/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6741 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 23/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6733 - val_loss: 0.6020 - val_binary_accuracy: 0.6778\n",
            "Epoch 24/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6746 - val_loss: 0.6016 - val_binary_accuracy: 0.6741\n",
            "Epoch 25/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6778 - val_loss: 0.6018 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6760 - val_loss: 0.6014 - val_binary_accuracy: 0.6770\n",
            "Epoch 27/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6729 - val_loss: 0.6027 - val_binary_accuracy: 0.6730\n",
            "Epoch 28/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6741 - val_loss: 0.6026 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6790 - val_loss: 0.6012 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6783 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 31/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6787 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 32/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6782 - val_loss: 0.6007 - val_binary_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6711 - val_loss: 0.6000 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6762 - val_loss: 0.6019 - val_binary_accuracy: 0.6774\n",
            "Epoch 35/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6760 - val_loss: 0.6019 - val_binary_accuracy: 0.6752\n",
            "Epoch 36/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.5957 - binary_accuracy: 0.6811 - val_loss: 0.6004 - val_binary_accuracy: 0.6763\n",
            "Epoch 37/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6733 - val_loss: 0.6005 - val_binary_accuracy: 0.6774\n",
            "Epoch 38/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6799 - val_loss: 0.6017 - val_binary_accuracy: 0.6730\n",
            "Epoch 39/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5942 - binary_accuracy: 0.6797 - val_loss: 0.6005 - val_binary_accuracy: 0.6748\n",
            "Epoch 40/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6745 - val_loss: 0.6011 - val_binary_accuracy: 0.6752\n",
            "Epoch 41/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.5962 - binary_accuracy: 0.6787 - val_loss: 0.6001 - val_binary_accuracy: 0.6752\n",
            "Epoch 42/200\n",
            "66/66 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6784 - val_loss: 0.6017 - val_binary_accuracy: 0.6704\n",
            "Epoch 43/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5951 - binary_accuracy: 0.6822 - val_loss: 0.6004 - val_binary_accuracy: 0.6763\n",
            "Epoch 00043: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:32:46,057]\u001b[0m Trial 63 finished with value: 0.6682727932929993 and parameters: {'batch size': 191, 'optimizer': 'Adagrad', 'lr': 0.0792856360730135, 'minimum_learning_rate': 0.051474597969041164}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 1s 5ms/step - loss: 0.6927 - binary_accuracy: 0.5718 - val_loss: 0.6433 - val_binary_accuracy: 0.6411\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6624 - binary_accuracy: 0.6001 - val_loss: 0.6374 - val_binary_accuracy: 0.6355\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6507 - binary_accuracy: 0.6115 - val_loss: 0.6313 - val_binary_accuracy: 0.6504\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6426 - binary_accuracy: 0.6243 - val_loss: 0.6255 - val_binary_accuracy: 0.6544\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6370 - binary_accuracy: 0.6311 - val_loss: 0.6223 - val_binary_accuracy: 0.6644\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6333 - val_loss: 0.6208 - val_binary_accuracy: 0.6574\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6416 - val_loss: 0.6153 - val_binary_accuracy: 0.6670\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.6397 - val_loss: 0.6156 - val_binary_accuracy: 0.6674\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6210 - binary_accuracy: 0.6490 - val_loss: 0.6133 - val_binary_accuracy: 0.6685\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6224 - binary_accuracy: 0.6466 - val_loss: 0.6134 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_accuracy: 0.6528 - val_loss: 0.6110 - val_binary_accuracy: 0.6696\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6192 - binary_accuracy: 0.6496 - val_loss: 0.6089 - val_binary_accuracy: 0.6704\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6488 - val_loss: 0.6081 - val_binary_accuracy: 0.6696\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6550 - val_loss: 0.6084 - val_binary_accuracy: 0.6681\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6561 - val_loss: 0.6062 - val_binary_accuracy: 0.6707\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6539 - val_loss: 0.6075 - val_binary_accuracy: 0.6659\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6658 - val_loss: 0.6060 - val_binary_accuracy: 0.6667\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6602 - val_loss: 0.6047 - val_binary_accuracy: 0.6689\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6563 - val_loss: 0.6058 - val_binary_accuracy: 0.6696\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6640 - val_loss: 0.6058 - val_binary_accuracy: 0.6693\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6652 - val_loss: 0.6047 - val_binary_accuracy: 0.6696\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6660 - val_loss: 0.6056 - val_binary_accuracy: 0.6700\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6651 - val_loss: 0.6053 - val_binary_accuracy: 0.6685\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6694 - val_loss: 0.6045 - val_binary_accuracy: 0.6674\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6623 - val_loss: 0.6044 - val_binary_accuracy: 0.6685\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6660 - val_loss: 0.6043 - val_binary_accuracy: 0.6670\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6662 - val_loss: 0.6043 - val_binary_accuracy: 0.6670\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6675 - val_loss: 0.6038 - val_binary_accuracy: 0.6685\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6647 - val_loss: 0.6043 - val_binary_accuracy: 0.6674\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6680 - val_loss: 0.6038 - val_binary_accuracy: 0.6667\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6674 - val_loss: 0.6038 - val_binary_accuracy: 0.6678\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6683 - val_loss: 0.6039 - val_binary_accuracy: 0.6685\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6668 - val_loss: 0.6040 - val_binary_accuracy: 0.6681\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6650 - val_loss: 0.6038 - val_binary_accuracy: 0.6674\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6686 - val_loss: 0.6037 - val_binary_accuracy: 0.6685\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6698 - val_loss: 0.6037 - val_binary_accuracy: 0.6670\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6691 - val_loss: 0.6039 - val_binary_accuracy: 0.6667\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6058 - binary_accuracy: 0.6687 - val_loss: 0.6040 - val_binary_accuracy: 0.6663\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6710 - val_loss: 0.6039 - val_binary_accuracy: 0.6670\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6728 - val_loss: 0.6040 - val_binary_accuracy: 0.6678\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6714 - val_loss: 0.6037 - val_binary_accuracy: 0.6681\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6690 - val_loss: 0.6036 - val_binary_accuracy: 0.6670\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6712 - val_loss: 0.6039 - val_binary_accuracy: 0.6681\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6721 - val_loss: 0.6035 - val_binary_accuracy: 0.6681\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6698 - val_loss: 0.6035 - val_binary_accuracy: 0.6693\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6721 - val_loss: 0.6034 - val_binary_accuracy: 0.6689\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6728 - val_loss: 0.6035 - val_binary_accuracy: 0.6704\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6705 - val_loss: 0.6035 - val_binary_accuracy: 0.6700\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6688 - val_loss: 0.6034 - val_binary_accuracy: 0.6700\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6682 - val_loss: 0.6032 - val_binary_accuracy: 0.6704\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6725 - val_loss: 0.6032 - val_binary_accuracy: 0.6711\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6678 - val_loss: 0.6033 - val_binary_accuracy: 0.6700\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6730 - val_loss: 0.6032 - val_binary_accuracy: 0.6700\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6679 - val_loss: 0.6034 - val_binary_accuracy: 0.6663\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6764 - val_loss: 0.6033 - val_binary_accuracy: 0.6659\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6719 - val_loss: 0.6031 - val_binary_accuracy: 0.6670\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6745 - val_loss: 0.6030 - val_binary_accuracy: 0.6667\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6041 - binary_accuracy: 0.6697 - val_loss: 0.6031 - val_binary_accuracy: 0.6685\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6679 - val_loss: 0.6031 - val_binary_accuracy: 0.6704\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6720 - val_loss: 0.6032 - val_binary_accuracy: 0.6678\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6662 - val_loss: 0.6031 - val_binary_accuracy: 0.6696\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6711 - val_loss: 0.6030 - val_binary_accuracy: 0.6704\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6701 - val_loss: 0.6031 - val_binary_accuracy: 0.6681\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6008 - binary_accuracy: 0.6714 - val_loss: 0.6030 - val_binary_accuracy: 0.6681\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6747 - val_loss: 0.6030 - val_binary_accuracy: 0.6681\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6720 - val_loss: 0.6031 - val_binary_accuracy: 0.6670\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6725 - val_loss: 0.6030 - val_binary_accuracy: 0.6700\n",
            "Epoch 00067: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:07,063]\u001b[0m Trial 64 finished with value: 0.6701260209083557 and parameters: {'batch size': 205, 'optimizer': 'Adagrad', 'lr': 0.036932297591784645, 'minimum_learning_rate': 0.011209401256674304}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "70/70 [==============================] - 1s 4ms/step - loss: 0.6711 - binary_accuracy: 0.5980 - val_loss: 0.6264 - val_binary_accuracy: 0.6507\n",
            "Epoch 2/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6363 - binary_accuracy: 0.6341 - val_loss: 0.6152 - val_binary_accuracy: 0.6667\n",
            "Epoch 3/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6455 - val_loss: 0.6096 - val_binary_accuracy: 0.6748\n",
            "Epoch 4/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6478 - val_loss: 0.6082 - val_binary_accuracy: 0.6704\n",
            "Epoch 5/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6542 - val_loss: 0.6040 - val_binary_accuracy: 0.6733\n",
            "Epoch 6/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6511 - val_loss: 0.6040 - val_binary_accuracy: 0.6763\n",
            "Epoch 7/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6594 - val_loss: 0.6027 - val_binary_accuracy: 0.6696\n",
            "Epoch 8/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6617 - val_loss: 0.6025 - val_binary_accuracy: 0.6793\n",
            "Epoch 9/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6093 - binary_accuracy: 0.6656 - val_loss: 0.6006 - val_binary_accuracy: 0.6778\n",
            "Epoch 10/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6629 - val_loss: 0.6027 - val_binary_accuracy: 0.6726\n",
            "Epoch 11/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6678 - val_loss: 0.6039 - val_binary_accuracy: 0.6733\n",
            "Epoch 12/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6667 - val_loss: 0.6001 - val_binary_accuracy: 0.6774\n",
            "Epoch 13/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6711 - val_loss: 0.5991 - val_binary_accuracy: 0.6752\n",
            "Epoch 14/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6684 - val_loss: 0.6001 - val_binary_accuracy: 0.6796\n",
            "Epoch 15/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6711 - val_loss: 0.6007 - val_binary_accuracy: 0.6822\n",
            "Epoch 16/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6027 - binary_accuracy: 0.6729 - val_loss: 0.6002 - val_binary_accuracy: 0.6782\n",
            "Epoch 17/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6698 - val_loss: 0.6010 - val_binary_accuracy: 0.6793\n",
            "Epoch 18/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6772 - val_loss: 0.6006 - val_binary_accuracy: 0.6767\n",
            "Epoch 19/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6694 - val_loss: 0.5997 - val_binary_accuracy: 0.6789\n",
            "Epoch 20/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6734 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 21/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6752 - val_loss: 0.6007 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6709 - val_loss: 0.6022 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6741 - val_loss: 0.6003 - val_binary_accuracy: 0.6759\n",
            "Epoch 00023: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:12,504]\u001b[0m Trial 65 finished with value: 0.6645663380622864 and parameters: {'batch size': 181, 'optimizer': 'Adagrad', 'lr': 0.0902218235795412, 'minimum_learning_rate': 0.061607407262029075}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "76/76 [==============================] - 1s 4ms/step - loss: 0.6694 - binary_accuracy: 0.5864 - val_loss: 0.6339 - val_binary_accuracy: 0.6429\n",
            "Epoch 2/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6264 - val_loss: 0.6226 - val_binary_accuracy: 0.6663\n",
            "Epoch 3/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6374 - val_loss: 0.6130 - val_binary_accuracy: 0.6726\n",
            "Epoch 4/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6489 - val_loss: 0.6087 - val_binary_accuracy: 0.6704\n",
            "Epoch 5/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6588 - val_loss: 0.6084 - val_binary_accuracy: 0.6770\n",
            "Epoch 6/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6160 - binary_accuracy: 0.6544 - val_loss: 0.6065 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6608 - val_loss: 0.6048 - val_binary_accuracy: 0.6752\n",
            "Epoch 8/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6580 - val_loss: 0.6031 - val_binary_accuracy: 0.6767\n",
            "Epoch 9/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6690 - val_loss: 0.6030 - val_binary_accuracy: 0.6689\n",
            "Epoch 10/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6641 - val_loss: 0.6021 - val_binary_accuracy: 0.6778\n",
            "Epoch 11/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6702 - val_loss: 0.6029 - val_binary_accuracy: 0.6815\n",
            "Epoch 12/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6666 - val_loss: 0.6018 - val_binary_accuracy: 0.6789\n",
            "Epoch 13/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6679 - val_loss: 0.6023 - val_binary_accuracy: 0.6759\n",
            "Epoch 14/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6726 - val_loss: 0.6007 - val_binary_accuracy: 0.6774\n",
            "Epoch 15/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6693 - val_loss: 0.5999 - val_binary_accuracy: 0.6767\n",
            "Epoch 16/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6721 - val_loss: 0.6010 - val_binary_accuracy: 0.6767\n",
            "Epoch 17/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6733 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 18/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6686 - val_loss: 0.6030 - val_binary_accuracy: 0.6748\n",
            "Epoch 19/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6749 - val_loss: 0.6020 - val_binary_accuracy: 0.6763\n",
            "Epoch 20/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6755 - val_loss: 0.6001 - val_binary_accuracy: 0.6770\n",
            "Epoch 21/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6765 - val_loss: 0.5998 - val_binary_accuracy: 0.6756\n",
            "Epoch 22/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5990 - binary_accuracy: 0.6710 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.6772 - val_loss: 0.6007 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.6002 - binary_accuracy: 0.6754 - val_loss: 0.6005 - val_binary_accuracy: 0.6815\n",
            "Epoch 25/200\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6766 - val_loss: 0.6019 - val_binary_accuracy: 0.6715\n",
            "Epoch 26/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6759 - val_loss: 0.6015 - val_binary_accuracy: 0.6745\n",
            "Epoch 27/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6824 - val_loss: 0.6013 - val_binary_accuracy: 0.6800\n",
            "Epoch 28/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6745 - val_loss: 0.6015 - val_binary_accuracy: 0.6774\n",
            "Epoch 29/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6782 - val_loss: 0.6021 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5956 - binary_accuracy: 0.6811 - val_loss: 0.6010 - val_binary_accuracy: 0.6748\n",
            "Epoch 31/200\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6795 - val_loss: 0.6022 - val_binary_accuracy: 0.6748\n",
            "Epoch 00031: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:19,553]\u001b[0m Trial 66 finished with value: 0.6649370193481445 and parameters: {'batch size': 167, 'optimizer': 'Adagrad', 'lr': 0.08399415264127782, 'minimum_learning_rate': 0.07556153559657336}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 1s 3ms/step - loss: 0.6682 - binary_accuracy: 0.6083 - val_loss: 0.6268 - val_binary_accuracy: 0.6489\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6331 - binary_accuracy: 0.6358 - val_loss: 0.6179 - val_binary_accuracy: 0.6581\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6514 - val_loss: 0.6099 - val_binary_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6533 - val_loss: 0.6059 - val_binary_accuracy: 0.6745\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6555 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6628 - val_loss: 0.6013 - val_binary_accuracy: 0.6778\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6646 - val_loss: 0.6020 - val_binary_accuracy: 0.6748\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6658 - val_loss: 0.6017 - val_binary_accuracy: 0.6785\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6066 - binary_accuracy: 0.6672 - val_loss: 0.6018 - val_binary_accuracy: 0.6715\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6043 - binary_accuracy: 0.6689 - val_loss: 0.5999 - val_binary_accuracy: 0.6785\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6671 - val_loss: 0.6020 - val_binary_accuracy: 0.6715\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.6670 - val_loss: 0.6018 - val_binary_accuracy: 0.6789\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6011 - binary_accuracy: 0.6737 - val_loss: 0.5997 - val_binary_accuracy: 0.6778\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6720 - val_loss: 0.6018 - val_binary_accuracy: 0.6748\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6016 - binary_accuracy: 0.6742 - val_loss: 0.5998 - val_binary_accuracy: 0.6763\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6751 - val_loss: 0.6010 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6739 - val_loss: 0.5994 - val_binary_accuracy: 0.6741\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5982 - binary_accuracy: 0.6755 - val_loss: 0.5987 - val_binary_accuracy: 0.6793\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5974 - binary_accuracy: 0.6783 - val_loss: 0.5993 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6737 - val_loss: 0.5993 - val_binary_accuracy: 0.6778\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5948 - binary_accuracy: 0.6780 - val_loss: 0.6010 - val_binary_accuracy: 0.6774\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6817 - val_loss: 0.6009 - val_binary_accuracy: 0.6741\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5954 - binary_accuracy: 0.6798 - val_loss: 0.6016 - val_binary_accuracy: 0.6774\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5961 - binary_accuracy: 0.6783 - val_loss: 0.6004 - val_binary_accuracy: 0.6778\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.6803 - val_loss: 0.6010 - val_binary_accuracy: 0.6726\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6810 - val_loss: 0.5998 - val_binary_accuracy: 0.6822\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5935 - binary_accuracy: 0.6828 - val_loss: 0.6010 - val_binary_accuracy: 0.6793\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 0.5899 - binary_accuracy: 0.6872 - val_loss: 0.6015 - val_binary_accuracy: 0.6808\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:30,343]\u001b[0m Trial 67 finished with value: 0.6682727932929993 and parameters: {'batch size': 141, 'optimizer': 'Adagrad', 'lr': 0.09248278973065292, 'minimum_learning_rate': 0.0838443254480177}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.6637 - binary_accuracy: 0.6030 - val_loss: 0.6268 - val_binary_accuracy: 0.6504\n",
            "Epoch 2/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6343 - val_loss: 0.6127 - val_binary_accuracy: 0.6659\n",
            "Epoch 3/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6455 - val_loss: 0.6091 - val_binary_accuracy: 0.6689\n",
            "Epoch 4/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6508 - val_loss: 0.6072 - val_binary_accuracy: 0.6719\n",
            "Epoch 5/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6559 - val_loss: 0.6054 - val_binary_accuracy: 0.6726\n",
            "Epoch 6/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6596 - val_loss: 0.6052 - val_binary_accuracy: 0.6730\n",
            "Epoch 7/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6614 - val_loss: 0.6024 - val_binary_accuracy: 0.6745\n",
            "Epoch 8/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6675 - val_loss: 0.6027 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6662 - val_loss: 0.6025 - val_binary_accuracy: 0.6715\n",
            "Epoch 10/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6685 - val_loss: 0.6019 - val_binary_accuracy: 0.6733\n",
            "Epoch 11/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.6698 - val_loss: 0.6019 - val_binary_accuracy: 0.6770\n",
            "Epoch 12/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6663 - val_loss: 0.6007 - val_binary_accuracy: 0.6759\n",
            "Epoch 13/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6658 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - binary_accuracy: 0.6717 - val_loss: 0.5999 - val_binary_accuracy: 0.6741\n",
            "Epoch 15/200\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6694 - val_loss: 0.5997 - val_binary_accuracy: 0.6752\n",
            "Epoch 16/200\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6751 - val_loss: 0.6011 - val_binary_accuracy: 0.6715\n",
            "Epoch 17/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6756 - val_loss: 0.5998 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6689 - val_loss: 0.5990 - val_binary_accuracy: 0.6759\n",
            "Epoch 19/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6710 - val_loss: 0.6009 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6772 - val_loss: 0.6002 - val_binary_accuracy: 0.6745\n",
            "Epoch 21/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6782 - val_loss: 0.6004 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6736 - val_loss: 0.5999 - val_binary_accuracy: 0.6793\n",
            "Epoch 23/200\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6807 - val_loss: 0.6009 - val_binary_accuracy: 0.6778\n",
            "Epoch 24/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6734 - val_loss: 0.5999 - val_binary_accuracy: 0.6785\n",
            "Epoch 25/200\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6723 - val_loss: 0.5998 - val_binary_accuracy: 0.6752\n",
            "Epoch 26/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.5953 - binary_accuracy: 0.6760 - val_loss: 0.5992 - val_binary_accuracy: 0.6804\n",
            "Epoch 27/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6830 - val_loss: 0.5997 - val_binary_accuracy: 0.6756\n",
            "Epoch 28/200\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.5935 - binary_accuracy: 0.6836 - val_loss: 0.5998 - val_binary_accuracy: 0.6759\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:36,598]\u001b[0m Trial 68 finished with value: 0.6701260209083557 and parameters: {'batch size': 152, 'optimizer': 'Adagrad', 'lr': 0.08641476451606019, 'minimum_learning_rate': 0.06454304908961889}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 1s 4ms/step - loss: 0.7035 - binary_accuracy: 0.5636 - val_loss: 0.6441 - val_binary_accuracy: 0.6340\n",
            "Epoch 2/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6582 - binary_accuracy: 0.6043 - val_loss: 0.6356 - val_binary_accuracy: 0.6426\n",
            "Epoch 3/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6218 - val_loss: 0.6280 - val_binary_accuracy: 0.6589\n",
            "Epoch 4/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6356 - binary_accuracy: 0.6291 - val_loss: 0.6229 - val_binary_accuracy: 0.6663\n",
            "Epoch 5/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6329 - val_loss: 0.6190 - val_binary_accuracy: 0.6700\n",
            "Epoch 6/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6367 - val_loss: 0.6168 - val_binary_accuracy: 0.6656\n",
            "Epoch 7/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6253 - binary_accuracy: 0.6395 - val_loss: 0.6138 - val_binary_accuracy: 0.6644\n",
            "Epoch 8/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6250 - binary_accuracy: 0.6439 - val_loss: 0.6126 - val_binary_accuracy: 0.6678\n",
            "Epoch 9/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_accuracy: 0.6493 - val_loss: 0.6116 - val_binary_accuracy: 0.6696\n",
            "Epoch 10/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6220 - binary_accuracy: 0.6470 - val_loss: 0.6098 - val_binary_accuracy: 0.6678\n",
            "Epoch 11/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6527 - val_loss: 0.6092 - val_binary_accuracy: 0.6693\n",
            "Epoch 12/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6512 - val_loss: 0.6090 - val_binary_accuracy: 0.6696\n",
            "Epoch 13/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.6503 - val_loss: 0.6087 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6559 - val_loss: 0.6070 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_accuracy: 0.6561 - val_loss: 0.6063 - val_binary_accuracy: 0.6704\n",
            "Epoch 16/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6593 - val_loss: 0.6055 - val_binary_accuracy: 0.6711\n",
            "Epoch 17/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6626 - val_loss: 0.6046 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6601 - val_loss: 0.6044 - val_binary_accuracy: 0.6745\n",
            "Epoch 19/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6631 - val_loss: 0.6046 - val_binary_accuracy: 0.6730\n",
            "Epoch 20/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6597 - val_loss: 0.6046 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6615 - val_loss: 0.6042 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6634 - val_loss: 0.6039 - val_binary_accuracy: 0.6774\n",
            "Epoch 23/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6647 - val_loss: 0.6033 - val_binary_accuracy: 0.6737\n",
            "Epoch 24/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6636 - val_loss: 0.6033 - val_binary_accuracy: 0.6719\n",
            "Epoch 25/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6597 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 26/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6683 - val_loss: 0.6035 - val_binary_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6687 - val_loss: 0.6033 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6683 - val_loss: 0.6031 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6704 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 30/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6686 - val_loss: 0.6030 - val_binary_accuracy: 0.6737\n",
            "Epoch 31/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6705 - val_loss: 0.6029 - val_binary_accuracy: 0.6741\n",
            "Epoch 32/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6662 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 33/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6683 - val_loss: 0.6031 - val_binary_accuracy: 0.6733\n",
            "Epoch 34/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6646 - val_loss: 0.6031 - val_binary_accuracy: 0.6715\n",
            "Epoch 35/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6667 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6675 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 37/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6706 - val_loss: 0.6027 - val_binary_accuracy: 0.6704\n",
            "Epoch 38/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6663 - val_loss: 0.6027 - val_binary_accuracy: 0.6719\n",
            "Epoch 39/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6694 - val_loss: 0.6026 - val_binary_accuracy: 0.6711\n",
            "Epoch 40/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6718 - val_loss: 0.6025 - val_binary_accuracy: 0.6722\n",
            "Epoch 41/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6670 - val_loss: 0.6025 - val_binary_accuracy: 0.6707\n",
            "Epoch 42/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6675 - val_loss: 0.6024 - val_binary_accuracy: 0.6715\n",
            "Epoch 43/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6693 - val_loss: 0.6026 - val_binary_accuracy: 0.6707\n",
            "Epoch 44/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6692 - val_loss: 0.6027 - val_binary_accuracy: 0.6711\n",
            "Epoch 45/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6048 - binary_accuracy: 0.6698 - val_loss: 0.6028 - val_binary_accuracy: 0.6719\n",
            "Epoch 46/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6701 - val_loss: 0.6027 - val_binary_accuracy: 0.6715\n",
            "Epoch 47/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6714 - val_loss: 0.6027 - val_binary_accuracy: 0.6719\n",
            "Epoch 48/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6727 - val_loss: 0.6027 - val_binary_accuracy: 0.6707\n",
            "Epoch 49/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6676 - val_loss: 0.6026 - val_binary_accuracy: 0.6715\n",
            "Epoch 50/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6692 - val_loss: 0.6026 - val_binary_accuracy: 0.6707\n",
            "Epoch 51/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6723 - val_loss: 0.6028 - val_binary_accuracy: 0.6711\n",
            "Epoch 52/200\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6710 - val_loss: 0.6027 - val_binary_accuracy: 0.6726\n",
            "Epoch 00052: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:47,370]\u001b[0m Trial 69 finished with value: 0.6645663380622864 and parameters: {'batch size': 210, 'optimizer': 'Adagrad', 'lr': 0.03197651162136269, 'minimum_learning_rate': 0.012174921051298604}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.6778 - binary_accuracy: 0.5897 - val_loss: 0.6302 - val_binary_accuracy: 0.6500\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6482 - binary_accuracy: 0.6142 - val_loss: 0.6254 - val_binary_accuracy: 0.6544\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6383 - binary_accuracy: 0.6286 - val_loss: 0.6204 - val_binary_accuracy: 0.6626\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6348 - val_loss: 0.6174 - val_binary_accuracy: 0.6593\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6254 - binary_accuracy: 0.6467 - val_loss: 0.6129 - val_binary_accuracy: 0.6685\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6234 - binary_accuracy: 0.6463 - val_loss: 0.6098 - val_binary_accuracy: 0.6711\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6197 - binary_accuracy: 0.6493 - val_loss: 0.6085 - val_binary_accuracy: 0.6730\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6167 - binary_accuracy: 0.6544 - val_loss: 0.6083 - val_binary_accuracy: 0.6626\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6173 - binary_accuracy: 0.6558 - val_loss: 0.6062 - val_binary_accuracy: 0.6722\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6590 - val_loss: 0.6041 - val_binary_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6649 - val_loss: 0.6043 - val_binary_accuracy: 0.6711\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6565 - val_loss: 0.6041 - val_binary_accuracy: 0.6737\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6586 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6621 - val_loss: 0.6037 - val_binary_accuracy: 0.6741\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6646 - val_loss: 0.6041 - val_binary_accuracy: 0.6722\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6608 - val_loss: 0.6040 - val_binary_accuracy: 0.6730\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6658 - val_loss: 0.6036 - val_binary_accuracy: 0.6748\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6685 - val_loss: 0.6031 - val_binary_accuracy: 0.6722\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6703 - val_loss: 0.6029 - val_binary_accuracy: 0.6756\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6668 - val_loss: 0.6028 - val_binary_accuracy: 0.6745\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6657 - val_loss: 0.6028 - val_binary_accuracy: 0.6767\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6706 - val_loss: 0.6027 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6667 - val_loss: 0.6028 - val_binary_accuracy: 0.6745\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6640 - val_loss: 0.6028 - val_binary_accuracy: 0.6789\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6679 - val_loss: 0.6027 - val_binary_accuracy: 0.6767\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6666 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6717 - val_loss: 0.6025 - val_binary_accuracy: 0.6741\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6684 - val_loss: 0.6024 - val_binary_accuracy: 0.6756\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6666 - val_loss: 0.6023 - val_binary_accuracy: 0.6767\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6698 - val_loss: 0.6022 - val_binary_accuracy: 0.6767\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6725 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6694 - val_loss: 0.6020 - val_binary_accuracy: 0.6756\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6731 - val_loss: 0.6022 - val_binary_accuracy: 0.6756\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6034 - binary_accuracy: 0.6711 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6704 - val_loss: 0.6021 - val_binary_accuracy: 0.6752\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6720 - val_loss: 0.6020 - val_binary_accuracy: 0.6748\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6710 - val_loss: 0.6023 - val_binary_accuracy: 0.6748\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6699 - val_loss: 0.6022 - val_binary_accuracy: 0.6763\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6737 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6699 - val_loss: 0.6022 - val_binary_accuracy: 0.6763\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6014 - binary_accuracy: 0.6711 - val_loss: 0.6022 - val_binary_accuracy: 0.6759\n",
            "Epoch 00041: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:33:55,445]\u001b[0m Trial 70 finished with value: 0.660118579864502 and parameters: {'batch size': 223, 'optimizer': 'Adagrad', 'lr': 0.05293186684582607, 'minimum_learning_rate': 0.013731028561146885}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 1s 3ms/step - loss: 0.6661 - binary_accuracy: 0.5986 - val_loss: 0.6316 - val_binary_accuracy: 0.6433\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6339 - val_loss: 0.6108 - val_binary_accuracy: 0.6622\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6449 - val_loss: 0.6099 - val_binary_accuracy: 0.6644\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6536 - val_loss: 0.6024 - val_binary_accuracy: 0.6700\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6574 - val_loss: 0.6049 - val_binary_accuracy: 0.6696\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6619 - val_loss: 0.6053 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6582 - val_loss: 0.6047 - val_binary_accuracy: 0.6763\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6607 - val_loss: 0.6031 - val_binary_accuracy: 0.6719\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6691 - val_loss: 0.6028 - val_binary_accuracy: 0.6737\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.6677 - val_loss: 0.6030 - val_binary_accuracy: 0.6711\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6671 - val_loss: 0.6025 - val_binary_accuracy: 0.6722\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.6690 - val_loss: 0.6013 - val_binary_accuracy: 0.6730\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6665 - val_loss: 0.6024 - val_binary_accuracy: 0.6659\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6685 - val_loss: 0.6009 - val_binary_accuracy: 0.6733\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6743 - val_loss: 0.6018 - val_binary_accuracy: 0.6696\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6042 - binary_accuracy: 0.6712 - val_loss: 0.6020 - val_binary_accuracy: 0.6696\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6048 - binary_accuracy: 0.6676 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6049 - binary_accuracy: 0.6705 - val_loss: 0.6016 - val_binary_accuracy: 0.6730\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6716 - val_loss: 0.6021 - val_binary_accuracy: 0.6719\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6661 - val_loss: 0.6026 - val_binary_accuracy: 0.6726\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6667 - val_loss: 0.6014 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6007 - binary_accuracy: 0.6709 - val_loss: 0.6033 - val_binary_accuracy: 0.6652\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6714 - val_loss: 0.6008 - val_binary_accuracy: 0.6733\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5994 - binary_accuracy: 0.6744 - val_loss: 0.6005 - val_binary_accuracy: 0.6756\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6694 - val_loss: 0.6012 - val_binary_accuracy: 0.6748\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.6776 - val_loss: 0.6010 - val_binary_accuracy: 0.6767\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6736 - val_loss: 0.6026 - val_binary_accuracy: 0.6685\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5971 - binary_accuracy: 0.6764 - val_loss: 0.6013 - val_binary_accuracy: 0.6689\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6791 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5946 - binary_accuracy: 0.6755 - val_loss: 0.6012 - val_binary_accuracy: 0.6693\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6740 - val_loss: 0.6008 - val_binary_accuracy: 0.6778\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5983 - binary_accuracy: 0.6728 - val_loss: 0.6006 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6781 - val_loss: 0.6007 - val_binary_accuracy: 0.6726\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.6818 - val_loss: 0.6007 - val_binary_accuracy: 0.6752\n",
            "Epoch 00034: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:06,178]\u001b[0m Trial 71 finished with value: 0.6679021716117859 and parameters: {'batch size': 127, 'optimizer': 'Adagrad', 'lr': 0.07423921861608675, 'minimum_learning_rate': 0.03907654301555174}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "113/113 [==============================] - 1s 3ms/step - loss: 0.6551 - binary_accuracy: 0.6139 - val_loss: 0.6196 - val_binary_accuracy: 0.6611\n",
            "Epoch 2/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6422 - val_loss: 0.6124 - val_binary_accuracy: 0.6748\n",
            "Epoch 3/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6523 - val_loss: 0.6068 - val_binary_accuracy: 0.6793\n",
            "Epoch 4/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6590 - val_loss: 0.6063 - val_binary_accuracy: 0.6767\n",
            "Epoch 5/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6628 - val_loss: 0.6076 - val_binary_accuracy: 0.6696\n",
            "Epoch 6/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.6630 - val_loss: 0.6037 - val_binary_accuracy: 0.6774\n",
            "Epoch 7/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6687 - val_loss: 0.6044 - val_binary_accuracy: 0.6715\n",
            "Epoch 8/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6657 - val_loss: 0.6055 - val_binary_accuracy: 0.6667\n",
            "Epoch 9/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6077 - binary_accuracy: 0.6710 - val_loss: 0.6049 - val_binary_accuracy: 0.6774\n",
            "Epoch 10/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6712 - val_loss: 0.6005 - val_binary_accuracy: 0.6804\n",
            "Epoch 11/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6030 - binary_accuracy: 0.6741 - val_loss: 0.6031 - val_binary_accuracy: 0.6774\n",
            "Epoch 12/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6721 - val_loss: 0.6020 - val_binary_accuracy: 0.6770\n",
            "Epoch 13/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6783 - val_loss: 0.6024 - val_binary_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5989 - binary_accuracy: 0.6747 - val_loss: 0.6046 - val_binary_accuracy: 0.6774\n",
            "Epoch 15/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6702 - val_loss: 0.6011 - val_binary_accuracy: 0.6748\n",
            "Epoch 16/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5967 - binary_accuracy: 0.6758 - val_loss: 0.5990 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.6788 - val_loss: 0.6018 - val_binary_accuracy: 0.6745\n",
            "Epoch 18/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5984 - binary_accuracy: 0.6754 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 19/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5996 - binary_accuracy: 0.6759 - val_loss: 0.6033 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5973 - binary_accuracy: 0.6757 - val_loss: 0.6008 - val_binary_accuracy: 0.6767\n",
            "Epoch 21/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6746 - val_loss: 0.6013 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5955 - binary_accuracy: 0.6796 - val_loss: 0.6011 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.6795 - val_loss: 0.6019 - val_binary_accuracy: 0.6767\n",
            "Epoch 24/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5933 - binary_accuracy: 0.6806 - val_loss: 0.6021 - val_binary_accuracy: 0.6770\n",
            "Epoch 25/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.6814 - val_loss: 0.6022 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5932 - binary_accuracy: 0.6835 - val_loss: 0.6038 - val_binary_accuracy: 0.6756\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:16,944]\u001b[0m Trial 72 finished with value: 0.6682727932929993 and parameters: {'batch size': 112, 'optimizer': 'Adagrad', 'lr': 0.09730224842368117, 'minimum_learning_rate': 0.0920587150467094}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6655 - binary_accuracy: 0.5959 - val_loss: 0.6304 - val_binary_accuracy: 0.6452\n",
            "Epoch 2/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6331 - val_loss: 0.6186 - val_binary_accuracy: 0.6581\n",
            "Epoch 3/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6466 - val_loss: 0.6092 - val_binary_accuracy: 0.6689\n",
            "Epoch 4/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6551 - val_loss: 0.6078 - val_binary_accuracy: 0.6737\n",
            "Epoch 5/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6605 - val_loss: 0.6060 - val_binary_accuracy: 0.6685\n",
            "Epoch 6/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6605 - val_loss: 0.6049 - val_binary_accuracy: 0.6756\n",
            "Epoch 7/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6630 - val_loss: 0.6054 - val_binary_accuracy: 0.6652\n",
            "Epoch 8/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6707 - val_loss: 0.6021 - val_binary_accuracy: 0.6656\n",
            "Epoch 9/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6687 - val_loss: 0.6024 - val_binary_accuracy: 0.6704\n",
            "Epoch 10/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6660 - val_loss: 0.6035 - val_binary_accuracy: 0.6693\n",
            "Epoch 11/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6054 - binary_accuracy: 0.6719 - val_loss: 0.6035 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6014 - binary_accuracy: 0.6722 - val_loss: 0.6032 - val_binary_accuracy: 0.6678\n",
            "Epoch 13/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6752 - val_loss: 0.6025 - val_binary_accuracy: 0.6726\n",
            "Epoch 14/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6003 - binary_accuracy: 0.6756 - val_loss: 0.6020 - val_binary_accuracy: 0.6711\n",
            "Epoch 15/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5988 - binary_accuracy: 0.6749 - val_loss: 0.6023 - val_binary_accuracy: 0.6737\n",
            "Epoch 16/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6737 - val_loss: 0.6018 - val_binary_accuracy: 0.6704\n",
            "Epoch 17/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6755 - val_loss: 0.6029 - val_binary_accuracy: 0.6685\n",
            "Epoch 18/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5993 - binary_accuracy: 0.6742 - val_loss: 0.6010 - val_binary_accuracy: 0.6693\n",
            "Epoch 19/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5968 - binary_accuracy: 0.6763 - val_loss: 0.6020 - val_binary_accuracy: 0.6696\n",
            "Epoch 20/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6753 - val_loss: 0.6010 - val_binary_accuracy: 0.6693\n",
            "Epoch 21/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6785 - val_loss: 0.5998 - val_binary_accuracy: 0.6670\n",
            "Epoch 22/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5949 - binary_accuracy: 0.6768 - val_loss: 0.5998 - val_binary_accuracy: 0.6685\n",
            "Epoch 23/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5946 - binary_accuracy: 0.6807 - val_loss: 0.6006 - val_binary_accuracy: 0.6685\n",
            "Epoch 24/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5980 - binary_accuracy: 0.6773 - val_loss: 0.6017 - val_binary_accuracy: 0.6678\n",
            "Epoch 25/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.6802 - val_loss: 0.6015 - val_binary_accuracy: 0.6693\n",
            "Epoch 26/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6816 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 27/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.6825 - val_loss: 0.6033 - val_binary_accuracy: 0.6678\n",
            "Epoch 28/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.6800 - val_loss: 0.6020 - val_binary_accuracy: 0.6693\n",
            "Epoch 29/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6837 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 30/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.6837 - val_loss: 0.6033 - val_binary_accuracy: 0.6741\n",
            "Epoch 31/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5939 - binary_accuracy: 0.6791 - val_loss: 0.6033 - val_binary_accuracy: 0.6704\n",
            "Epoch 32/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5936 - binary_accuracy: 0.6835 - val_loss: 0.6037 - val_binary_accuracy: 0.6711\n",
            "Epoch 00032: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:24,864]\u001b[0m Trial 73 finished with value: 0.6708673238754272 and parameters: {'batch size': 120, 'optimizer': 'Adagrad', 'lr': 0.08142759073395199, 'minimum_learning_rate': 0.07283371382385072}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6590 - binary_accuracy: 0.6103 - val_loss: 0.6237 - val_binary_accuracy: 0.6555\n",
            "Epoch 2/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6332 - val_loss: 0.6233 - val_binary_accuracy: 0.6459\n",
            "Epoch 3/200\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6229 - binary_accuracy: 0.6482 - val_loss: 0.6301 - val_binary_accuracy: 0.6492\n",
            "Epoch 4/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6479 - val_loss: 0.6057 - val_binary_accuracy: 0.6770\n",
            "Epoch 5/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6548 - val_loss: 0.6073 - val_binary_accuracy: 0.6715\n",
            "Epoch 6/200\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6556 - val_loss: 0.6064 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6667 - val_loss: 0.6039 - val_binary_accuracy: 0.6752\n",
            "Epoch 8/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6625 - val_loss: 0.6084 - val_binary_accuracy: 0.6719\n",
            "Epoch 9/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6096 - binary_accuracy: 0.6588 - val_loss: 0.6029 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6075 - binary_accuracy: 0.6666 - val_loss: 0.6005 - val_binary_accuracy: 0.6804\n",
            "Epoch 11/200\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6629 - val_loss: 0.6041 - val_binary_accuracy: 0.6767\n",
            "Epoch 12/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6036 - binary_accuracy: 0.6673 - val_loss: 0.6031 - val_binary_accuracy: 0.6711\n",
            "Epoch 13/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6662 - val_loss: 0.6072 - val_binary_accuracy: 0.6693\n",
            "Epoch 14/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6698 - val_loss: 0.6013 - val_binary_accuracy: 0.6707\n",
            "Epoch 15/200\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6714 - val_loss: 0.6037 - val_binary_accuracy: 0.6707\n",
            "Epoch 16/200\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6703 - val_loss: 0.6021 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6736 - val_loss: 0.6017 - val_binary_accuracy: 0.6722\n",
            "Epoch 18/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6020 - binary_accuracy: 0.6718 - val_loss: 0.6019 - val_binary_accuracy: 0.6704\n",
            "Epoch 19/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.6726 - val_loss: 0.6014 - val_binary_accuracy: 0.6756\n",
            "Epoch 20/200\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6751 - val_loss: 0.6025 - val_binary_accuracy: 0.6752\n",
            "Epoch 00020: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:30,548]\u001b[0m Trial 74 finished with value: 0.6660489439964294 and parameters: {'batch size': 121, 'optimizer': 'Adagrad', 'lr': 0.06918611473176116, 'minimum_learning_rate': 0.04129133903900435}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "103/103 [==============================] - 1s 3ms/step - loss: 0.6647 - binary_accuracy: 0.5949 - val_loss: 0.6354 - val_binary_accuracy: 0.6255\n",
            "Epoch 2/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6291 - val_loss: 0.6186 - val_binary_accuracy: 0.6567\n",
            "Epoch 3/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6435 - val_loss: 0.6133 - val_binary_accuracy: 0.6656\n",
            "Epoch 4/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6461 - val_loss: 0.6083 - val_binary_accuracy: 0.6748\n",
            "Epoch 5/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6558 - val_loss: 0.6060 - val_binary_accuracy: 0.6711\n",
            "Epoch 6/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6601 - val_loss: 0.6078 - val_binary_accuracy: 0.6745\n",
            "Epoch 7/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6599 - val_loss: 0.6067 - val_binary_accuracy: 0.6763\n",
            "Epoch 8/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6628 - val_loss: 0.6034 - val_binary_accuracy: 0.6737\n",
            "Epoch 9/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.6654 - val_loss: 0.6034 - val_binary_accuracy: 0.6733\n",
            "Epoch 10/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6687 - val_loss: 0.6032 - val_binary_accuracy: 0.6767\n",
            "Epoch 11/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6641 - val_loss: 0.6019 - val_binary_accuracy: 0.6733\n",
            "Epoch 12/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6057 - binary_accuracy: 0.6680 - val_loss: 0.6014 - val_binary_accuracy: 0.6756\n",
            "Epoch 13/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.6698 - val_loss: 0.6018 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6019 - binary_accuracy: 0.6764 - val_loss: 0.6006 - val_binary_accuracy: 0.6678\n",
            "Epoch 15/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6706 - val_loss: 0.6003 - val_binary_accuracy: 0.6711\n",
            "Epoch 16/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6021 - binary_accuracy: 0.6753 - val_loss: 0.5992 - val_binary_accuracy: 0.6759\n",
            "Epoch 17/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6687 - val_loss: 0.6001 - val_binary_accuracy: 0.6763\n",
            "Epoch 18/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6721 - val_loss: 0.6005 - val_binary_accuracy: 0.6756\n",
            "Epoch 19/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6683 - val_loss: 0.6018 - val_binary_accuracy: 0.6782\n",
            "Epoch 20/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5979 - binary_accuracy: 0.6787 - val_loss: 0.6003 - val_binary_accuracy: 0.6778\n",
            "Epoch 21/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6729 - val_loss: 0.6000 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5998 - binary_accuracy: 0.6761 - val_loss: 0.6013 - val_binary_accuracy: 0.6719\n",
            "Epoch 23/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5991 - binary_accuracy: 0.6733 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 24/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6760 - val_loss: 0.6014 - val_binary_accuracy: 0.6700\n",
            "Epoch 25/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5965 - binary_accuracy: 0.6801 - val_loss: 0.6009 - val_binary_accuracy: 0.6756\n",
            "Epoch 26/200\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5945 - binary_accuracy: 0.6803 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:41,288]\u001b[0m Trial 75 finished with value: 0.6693847179412842 and parameters: {'batch size': 123, 'optimizer': 'Adagrad', 'lr': 0.0756227830631965, 'minimum_learning_rate': 0.07070476951288315}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "51/51 [==============================] - 1s 5ms/step - loss: 0.6764 - binary_accuracy: 0.5922 - val_loss: 0.6398 - val_binary_accuracy: 0.6329\n",
            "Epoch 2/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6277 - val_loss: 0.6235 - val_binary_accuracy: 0.6570\n",
            "Epoch 3/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6314 - binary_accuracy: 0.6385 - val_loss: 0.6191 - val_binary_accuracy: 0.6600\n",
            "Epoch 4/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6476 - val_loss: 0.6151 - val_binary_accuracy: 0.6633\n",
            "Epoch 5/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6227 - binary_accuracy: 0.6466 - val_loss: 0.6132 - val_binary_accuracy: 0.6637\n",
            "Epoch 6/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6182 - binary_accuracy: 0.6559 - val_loss: 0.6121 - val_binary_accuracy: 0.6707\n",
            "Epoch 7/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6590 - val_loss: 0.6085 - val_binary_accuracy: 0.6696\n",
            "Epoch 8/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6520 - val_loss: 0.6087 - val_binary_accuracy: 0.6659\n",
            "Epoch 9/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6595 - val_loss: 0.6080 - val_binary_accuracy: 0.6633\n",
            "Epoch 10/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6625 - val_loss: 0.6051 - val_binary_accuracy: 0.6674\n",
            "Epoch 11/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6693 - val_loss: 0.6064 - val_binary_accuracy: 0.6678\n",
            "Epoch 12/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6685 - val_loss: 0.6050 - val_binary_accuracy: 0.6700\n",
            "Epoch 13/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6643 - val_loss: 0.6041 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6694 - val_loss: 0.6038 - val_binary_accuracy: 0.6678\n",
            "Epoch 15/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6722 - val_loss: 0.6028 - val_binary_accuracy: 0.6696\n",
            "Epoch 16/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6018 - binary_accuracy: 0.6717 - val_loss: 0.6035 - val_binary_accuracy: 0.6748\n",
            "Epoch 17/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6702 - val_loss: 0.6024 - val_binary_accuracy: 0.6641\n",
            "Epoch 18/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6725 - val_loss: 0.6019 - val_binary_accuracy: 0.6644\n",
            "Epoch 19/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6702 - val_loss: 0.6020 - val_binary_accuracy: 0.6696\n",
            "Epoch 20/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6702 - val_loss: 0.6033 - val_binary_accuracy: 0.6670\n",
            "Epoch 21/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6008 - binary_accuracy: 0.6752 - val_loss: 0.6028 - val_binary_accuracy: 0.6711\n",
            "Epoch 22/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6767 - val_loss: 0.6021 - val_binary_accuracy: 0.6659\n",
            "Epoch 23/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6744 - val_loss: 0.6027 - val_binary_accuracy: 0.6678\n",
            "Epoch 24/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6748 - val_loss: 0.6023 - val_binary_accuracy: 0.6696\n",
            "Epoch 25/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6775 - val_loss: 0.6022 - val_binary_accuracy: 0.6678\n",
            "Epoch 26/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6716 - val_loss: 0.6024 - val_binary_accuracy: 0.6678\n",
            "Epoch 27/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6706 - val_loss: 0.6023 - val_binary_accuracy: 0.6663\n",
            "Epoch 28/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.6780 - val_loss: 0.6020 - val_binary_accuracy: 0.6652\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:46,847]\u001b[0m Trial 76 finished with value: 0.6712379455566406 and parameters: {'batch size': 247, 'optimizer': 'Adagrad', 'lr': 0.0915008840931798, 'minimum_learning_rate': 0.034973616469962096}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 1s 6ms/step - loss: 0.6762 - binary_accuracy: 0.5889 - val_loss: 0.6350 - val_binary_accuracy: 0.6403\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6432 - binary_accuracy: 0.6219 - val_loss: 0.6215 - val_binary_accuracy: 0.6622\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6313 - binary_accuracy: 0.6342 - val_loss: 0.6129 - val_binary_accuracy: 0.6618\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.6477 - val_loss: 0.6123 - val_binary_accuracy: 0.6667\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6215 - binary_accuracy: 0.6463 - val_loss: 0.6091 - val_binary_accuracy: 0.6719\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.6517 - val_loss: 0.6069 - val_binary_accuracy: 0.6737\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6575 - val_loss: 0.6064 - val_binary_accuracy: 0.6681\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6537 - val_loss: 0.6058 - val_binary_accuracy: 0.6689\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6641 - val_loss: 0.6033 - val_binary_accuracy: 0.6715\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6153 - binary_accuracy: 0.6565 - val_loss: 0.6039 - val_binary_accuracy: 0.6704\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6652 - val_loss: 0.6056 - val_binary_accuracy: 0.6704\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6629 - val_loss: 0.6047 - val_binary_accuracy: 0.6726\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6678 - val_loss: 0.6039 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6652 - val_loss: 0.6043 - val_binary_accuracy: 0.6715\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6068 - binary_accuracy: 0.6683 - val_loss: 0.6031 - val_binary_accuracy: 0.6730\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6699 - val_loss: 0.6031 - val_binary_accuracy: 0.6741\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6718 - val_loss: 0.6027 - val_binary_accuracy: 0.6704\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6748 - val_loss: 0.6025 - val_binary_accuracy: 0.6733\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6054 - binary_accuracy: 0.6720 - val_loss: 0.6026 - val_binary_accuracy: 0.6707\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6725 - val_loss: 0.6023 - val_binary_accuracy: 0.6730\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6725 - val_loss: 0.6015 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6725 - val_loss: 0.6015 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6706 - val_loss: 0.6017 - val_binary_accuracy: 0.6704\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6692 - val_loss: 0.6008 - val_binary_accuracy: 0.6752\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6748 - val_loss: 0.6014 - val_binary_accuracy: 0.6748\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6025 - binary_accuracy: 0.6679 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6763 - val_loss: 0.6020 - val_binary_accuracy: 0.6741\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6753 - val_loss: 0.6011 - val_binary_accuracy: 0.6745\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6705 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6011 - binary_accuracy: 0.6691 - val_loss: 0.6018 - val_binary_accuracy: 0.6745\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6772 - val_loss: 0.6020 - val_binary_accuracy: 0.6733\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6751 - val_loss: 0.6021 - val_binary_accuracy: 0.6707\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6737 - val_loss: 0.6021 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6737 - val_loss: 0.6021 - val_binary_accuracy: 0.6733\n",
            "Epoch 00034: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:34:58,011]\u001b[0m Trial 77 finished with value: 0.6716086268424988 and parameters: {'batch size': 252, 'optimizer': 'Adagrad', 'lr': 0.09055749762439522, 'minimum_learning_rate': 0.03236485612722968}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 1s 5ms/step - loss: 0.6768 - binary_accuracy: 0.5871 - val_loss: 0.6299 - val_binary_accuracy: 0.6314\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6460 - binary_accuracy: 0.6225 - val_loss: 0.6202 - val_binary_accuracy: 0.6485\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6342 - binary_accuracy: 0.6334 - val_loss: 0.6131 - val_binary_accuracy: 0.6578\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6395 - val_loss: 0.6096 - val_binary_accuracy: 0.6678\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6214 - binary_accuracy: 0.6534 - val_loss: 0.6057 - val_binary_accuracy: 0.6711\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6216 - binary_accuracy: 0.6536 - val_loss: 0.6038 - val_binary_accuracy: 0.6670\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6184 - binary_accuracy: 0.6540 - val_loss: 0.6048 - val_binary_accuracy: 0.6733\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6165 - binary_accuracy: 0.6608 - val_loss: 0.6026 - val_binary_accuracy: 0.6711\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6581 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6607 - val_loss: 0.6009 - val_binary_accuracy: 0.6726\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6604 - val_loss: 0.5990 - val_binary_accuracy: 0.6752\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6645 - val_loss: 0.5984 - val_binary_accuracy: 0.6752\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6689 - val_loss: 0.5987 - val_binary_accuracy: 0.6756\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6675 - val_loss: 0.5986 - val_binary_accuracy: 0.6726\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6704 - val_loss: 0.6006 - val_binary_accuracy: 0.6748\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6686 - val_loss: 0.5989 - val_binary_accuracy: 0.6770\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6647 - val_loss: 0.5991 - val_binary_accuracy: 0.6756\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6052 - binary_accuracy: 0.6706 - val_loss: 0.5991 - val_binary_accuracy: 0.6759\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6067 - binary_accuracy: 0.6662 - val_loss: 0.5987 - val_binary_accuracy: 0.6793\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6037 - binary_accuracy: 0.6734 - val_loss: 0.5987 - val_binary_accuracy: 0.6767\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6712 - val_loss: 0.5987 - val_binary_accuracy: 0.6752\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6725 - val_loss: 0.5995 - val_binary_accuracy: 0.6748\n",
            "Epoch 00022: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:03,635]\u001b[0m Trial 78 finished with value: 0.6597479581832886 and parameters: {'batch size': 255, 'optimizer': 'Adagrad', 'lr': 0.08135044281330768, 'minimum_learning_rate': 0.03222338246291333}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "51/51 [==============================] - 1s 5ms/step - loss: 0.6766 - binary_accuracy: 0.5991 - val_loss: 0.6473 - val_binary_accuracy: 0.6303\n",
            "Epoch 2/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.6228 - val_loss: 0.6303 - val_binary_accuracy: 0.6444\n",
            "Epoch 3/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6313 - binary_accuracy: 0.6328 - val_loss: 0.6150 - val_binary_accuracy: 0.6589\n",
            "Epoch 4/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6253 - binary_accuracy: 0.6429 - val_loss: 0.6121 - val_binary_accuracy: 0.6641\n",
            "Epoch 5/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6209 - binary_accuracy: 0.6484 - val_loss: 0.6109 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6509 - val_loss: 0.6083 - val_binary_accuracy: 0.6667\n",
            "Epoch 7/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6604 - val_loss: 0.6071 - val_binary_accuracy: 0.6707\n",
            "Epoch 8/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6586 - val_loss: 0.6059 - val_binary_accuracy: 0.6696\n",
            "Epoch 9/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.6609 - val_loss: 0.6073 - val_binary_accuracy: 0.6741\n",
            "Epoch 10/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6620 - val_loss: 0.6033 - val_binary_accuracy: 0.6700\n",
            "Epoch 11/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.6595 - val_loss: 0.6033 - val_binary_accuracy: 0.6696\n",
            "Epoch 12/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6640 - val_loss: 0.6021 - val_binary_accuracy: 0.6674\n",
            "Epoch 13/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6675 - val_loss: 0.6032 - val_binary_accuracy: 0.6689\n",
            "Epoch 14/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6602 - val_loss: 0.6035 - val_binary_accuracy: 0.6711\n",
            "Epoch 15/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6678 - val_loss: 0.6013 - val_binary_accuracy: 0.6700\n",
            "Epoch 16/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6675 - val_loss: 0.6019 - val_binary_accuracy: 0.6722\n",
            "Epoch 17/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6693 - val_loss: 0.6011 - val_binary_accuracy: 0.6704\n",
            "Epoch 18/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6694 - val_loss: 0.6019 - val_binary_accuracy: 0.6745\n",
            "Epoch 19/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6049 - binary_accuracy: 0.6705 - val_loss: 0.6010 - val_binary_accuracy: 0.6733\n",
            "Epoch 20/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6697 - val_loss: 0.6009 - val_binary_accuracy: 0.6730\n",
            "Epoch 21/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6705 - val_loss: 0.6028 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6745 - val_loss: 0.6017 - val_binary_accuracy: 0.6696\n",
            "Epoch 23/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6743 - val_loss: 0.6006 - val_binary_accuracy: 0.6737\n",
            "Epoch 24/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6732 - val_loss: 0.6004 - val_binary_accuracy: 0.6696\n",
            "Epoch 25/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6697 - val_loss: 0.6002 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6726 - val_loss: 0.6002 - val_binary_accuracy: 0.6719\n",
            "Epoch 27/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6764 - val_loss: 0.6001 - val_binary_accuracy: 0.6726\n",
            "Epoch 28/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6775 - val_loss: 0.6008 - val_binary_accuracy: 0.6707\n",
            "Epoch 29/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6779 - val_loss: 0.6005 - val_binary_accuracy: 0.6711\n",
            "Epoch 30/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6761 - val_loss: 0.6003 - val_binary_accuracy: 0.6719\n",
            "Epoch 31/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6736 - val_loss: 0.6004 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6752 - val_loss: 0.6003 - val_binary_accuracy: 0.6700\n",
            "Epoch 33/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6763 - val_loss: 0.6004 - val_binary_accuracy: 0.6722\n",
            "Epoch 34/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6729 - val_loss: 0.6004 - val_binary_accuracy: 0.6722\n",
            "Epoch 35/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5945 - binary_accuracy: 0.6764 - val_loss: 0.5999 - val_binary_accuracy: 0.6719\n",
            "Epoch 36/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6803 - val_loss: 0.6001 - val_binary_accuracy: 0.6700\n",
            "Epoch 37/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5996 - binary_accuracy: 0.6760 - val_loss: 0.6002 - val_binary_accuracy: 0.6715\n",
            "Epoch 38/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6781 - val_loss: 0.6002 - val_binary_accuracy: 0.6726\n",
            "Epoch 39/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6788 - val_loss: 0.6002 - val_binary_accuracy: 0.6745\n",
            "Epoch 40/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6782 - val_loss: 0.6000 - val_binary_accuracy: 0.6730\n",
            "Epoch 41/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6744 - val_loss: 0.5999 - val_binary_accuracy: 0.6711\n",
            "Epoch 42/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6726 - val_loss: 0.5998 - val_binary_accuracy: 0.6715\n",
            "Epoch 43/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6799 - val_loss: 0.6002 - val_binary_accuracy: 0.6715\n",
            "Epoch 44/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6765 - val_loss: 0.6002 - val_binary_accuracy: 0.6722\n",
            "Epoch 45/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6749 - val_loss: 0.6005 - val_binary_accuracy: 0.6689\n",
            "Epoch 46/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6764 - val_loss: 0.6002 - val_binary_accuracy: 0.6767\n",
            "Epoch 47/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6825 - val_loss: 0.5999 - val_binary_accuracy: 0.6767\n",
            "Epoch 48/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6807 - val_loss: 0.5997 - val_binary_accuracy: 0.6730\n",
            "Epoch 49/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6785 - val_loss: 0.5999 - val_binary_accuracy: 0.6745\n",
            "Epoch 50/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6768 - val_loss: 0.6001 - val_binary_accuracy: 0.6722\n",
            "Epoch 51/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6772 - val_loss: 0.6000 - val_binary_accuracy: 0.6756\n",
            "Epoch 52/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6761 - val_loss: 0.6000 - val_binary_accuracy: 0.6748\n",
            "Epoch 53/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6822 - val_loss: 0.6003 - val_binary_accuracy: 0.6737\n",
            "Epoch 54/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5972 - binary_accuracy: 0.6776 - val_loss: 0.6000 - val_binary_accuracy: 0.6737\n",
            "Epoch 55/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6810 - val_loss: 0.6001 - val_binary_accuracy: 0.6752\n",
            "Epoch 56/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6772 - val_loss: 0.6002 - val_binary_accuracy: 0.6741\n",
            "Epoch 57/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6752 - val_loss: 0.5998 - val_binary_accuracy: 0.6741\n",
            "Epoch 58/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5942 - binary_accuracy: 0.6829 - val_loss: 0.5997 - val_binary_accuracy: 0.6741\n",
            "Epoch 59/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6762 - val_loss: 0.5996 - val_binary_accuracy: 0.6785\n",
            "Epoch 60/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6801 - val_loss: 0.5996 - val_binary_accuracy: 0.6741\n",
            "Epoch 61/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5941 - binary_accuracy: 0.6768 - val_loss: 0.5995 - val_binary_accuracy: 0.6741\n",
            "Epoch 62/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6784 - val_loss: 0.5997 - val_binary_accuracy: 0.6741\n",
            "Epoch 63/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5917 - binary_accuracy: 0.6808 - val_loss: 0.5996 - val_binary_accuracy: 0.6711\n",
            "Epoch 64/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6787 - val_loss: 0.5998 - val_binary_accuracy: 0.6733\n",
            "Epoch 65/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5941 - binary_accuracy: 0.6815 - val_loss: 0.5998 - val_binary_accuracy: 0.6730\n",
            "Epoch 66/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6784 - val_loss: 0.6000 - val_binary_accuracy: 0.6733\n",
            "Epoch 67/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5925 - binary_accuracy: 0.6832 - val_loss: 0.5999 - val_binary_accuracy: 0.6737\n",
            "Epoch 68/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6808 - val_loss: 0.6000 - val_binary_accuracy: 0.6715\n",
            "Epoch 69/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6810 - val_loss: 0.6003 - val_binary_accuracy: 0.6722\n",
            "Epoch 70/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6762 - val_loss: 0.6003 - val_binary_accuracy: 0.6715\n",
            "Epoch 71/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5923 - binary_accuracy: 0.6789 - val_loss: 0.6002 - val_binary_accuracy: 0.6722\n",
            "Epoch 00071: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:16,483]\u001b[0m Trial 79 finished with value: 0.6653076410293579 and parameters: {'batch size': 250, 'optimizer': 'Adagrad', 'lr': 0.09052805401215666, 'minimum_learning_rate': 0.025900051425112515}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "52/52 [==============================] - 1s 5ms/step - loss: 0.6734 - binary_accuracy: 0.5865 - val_loss: 0.6427 - val_binary_accuracy: 0.6326\n",
            "Epoch 2/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6454 - binary_accuracy: 0.6220 - val_loss: 0.6294 - val_binary_accuracy: 0.6422\n",
            "Epoch 3/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6328 - val_loss: 0.6220 - val_binary_accuracy: 0.6518\n",
            "Epoch 4/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6236 - binary_accuracy: 0.6447 - val_loss: 0.6168 - val_binary_accuracy: 0.6563\n",
            "Epoch 5/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6228 - binary_accuracy: 0.6418 - val_loss: 0.6105 - val_binary_accuracy: 0.6633\n",
            "Epoch 6/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6516 - val_loss: 0.6110 - val_binary_accuracy: 0.6618\n",
            "Epoch 7/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6567 - val_loss: 0.6076 - val_binary_accuracy: 0.6741\n",
            "Epoch 8/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6613 - val_loss: 0.6058 - val_binary_accuracy: 0.6696\n",
            "Epoch 9/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6602 - val_loss: 0.6049 - val_binary_accuracy: 0.6737\n",
            "Epoch 10/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6641 - val_loss: 0.6051 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6659 - val_loss: 0.6040 - val_binary_accuracy: 0.6700\n",
            "Epoch 12/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6079 - binary_accuracy: 0.6694 - val_loss: 0.6038 - val_binary_accuracy: 0.6681\n",
            "Epoch 13/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6682 - val_loss: 0.6052 - val_binary_accuracy: 0.6696\n",
            "Epoch 14/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6671 - val_loss: 0.6027 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6629 - val_loss: 0.6029 - val_binary_accuracy: 0.6726\n",
            "Epoch 16/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6667 - val_loss: 0.6018 - val_binary_accuracy: 0.6741\n",
            "Epoch 17/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6690 - val_loss: 0.6017 - val_binary_accuracy: 0.6748\n",
            "Epoch 18/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6065 - binary_accuracy: 0.6648 - val_loss: 0.6017 - val_binary_accuracy: 0.6700\n",
            "Epoch 19/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6010 - binary_accuracy: 0.6712 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6717 - val_loss: 0.6024 - val_binary_accuracy: 0.6745\n",
            "Epoch 21/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6726 - val_loss: 0.6015 - val_binary_accuracy: 0.6737\n",
            "Epoch 22/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6718 - val_loss: 0.6015 - val_binary_accuracy: 0.6778\n",
            "Epoch 23/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5993 - binary_accuracy: 0.6726 - val_loss: 0.6015 - val_binary_accuracy: 0.6696\n",
            "Epoch 24/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6748 - val_loss: 0.6016 - val_binary_accuracy: 0.6759\n",
            "Epoch 25/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6716 - val_loss: 0.6016 - val_binary_accuracy: 0.6719\n",
            "Epoch 26/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6723 - val_loss: 0.6011 - val_binary_accuracy: 0.6737\n",
            "Epoch 27/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6667 - val_loss: 0.6019 - val_binary_accuracy: 0.6711\n",
            "Epoch 28/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6000 - binary_accuracy: 0.6766 - val_loss: 0.6014 - val_binary_accuracy: 0.6689\n",
            "Epoch 29/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6735 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 30/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6779 - val_loss: 0.6011 - val_binary_accuracy: 0.6748\n",
            "Epoch 31/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6733 - val_loss: 0.6018 - val_binary_accuracy: 0.6707\n",
            "Epoch 32/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6815 - val_loss: 0.6013 - val_binary_accuracy: 0.6715\n",
            "Epoch 33/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6796 - val_loss: 0.6016 - val_binary_accuracy: 0.6741\n",
            "Epoch 34/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5979 - binary_accuracy: 0.6783 - val_loss: 0.6009 - val_binary_accuracy: 0.6737\n",
            "Epoch 35/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6769 - val_loss: 0.6002 - val_binary_accuracy: 0.6748\n",
            "Epoch 36/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6800 - val_loss: 0.6006 - val_binary_accuracy: 0.6737\n",
            "Epoch 37/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6752 - val_loss: 0.6009 - val_binary_accuracy: 0.6745\n",
            "Epoch 38/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6758 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 39/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6769 - val_loss: 0.6002 - val_binary_accuracy: 0.6778\n",
            "Epoch 40/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5962 - binary_accuracy: 0.6781 - val_loss: 0.6001 - val_binary_accuracy: 0.6752\n",
            "Epoch 41/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6782 - val_loss: 0.6006 - val_binary_accuracy: 0.6752\n",
            "Epoch 42/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6760 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 43/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6734 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 44/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.6760 - val_loss: 0.6007 - val_binary_accuracy: 0.6756\n",
            "Epoch 45/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6816 - val_loss: 0.6006 - val_binary_accuracy: 0.6737\n",
            "Epoch 46/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5955 - binary_accuracy: 0.6815 - val_loss: 0.6008 - val_binary_accuracy: 0.6767\n",
            "Epoch 47/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5953 - binary_accuracy: 0.6805 - val_loss: 0.6005 - val_binary_accuracy: 0.6774\n",
            "Epoch 48/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6791 - val_loss: 0.6008 - val_binary_accuracy: 0.6767\n",
            "Epoch 49/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5961 - binary_accuracy: 0.6768 - val_loss: 0.6010 - val_binary_accuracy: 0.6752\n",
            "Epoch 50/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6800 - val_loss: 0.6003 - val_binary_accuracy: 0.6778\n",
            "Epoch 00050: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:25,951]\u001b[0m Trial 80 finished with value: 0.6716086268424988 and parameters: {'batch size': 244, 'optimizer': 'Adagrad', 'lr': 0.08725986677239335, 'minimum_learning_rate': 0.056896581371154754}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "52/52 [==============================] - 1s 5ms/step - loss: 0.6683 - binary_accuracy: 0.5997 - val_loss: 0.6329 - val_binary_accuracy: 0.6437\n",
            "Epoch 2/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6363 - binary_accuracy: 0.6308 - val_loss: 0.6203 - val_binary_accuracy: 0.6585\n",
            "Epoch 3/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6389 - val_loss: 0.6166 - val_binary_accuracy: 0.6678\n",
            "Epoch 4/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6266 - binary_accuracy: 0.6439 - val_loss: 0.6112 - val_binary_accuracy: 0.6696\n",
            "Epoch 5/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6200 - binary_accuracy: 0.6541 - val_loss: 0.6070 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6575 - val_loss: 0.6054 - val_binary_accuracy: 0.6696\n",
            "Epoch 7/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_accuracy: 0.6530 - val_loss: 0.6070 - val_binary_accuracy: 0.6704\n",
            "Epoch 8/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6605 - val_loss: 0.6064 - val_binary_accuracy: 0.6730\n",
            "Epoch 9/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6613 - val_loss: 0.6040 - val_binary_accuracy: 0.6678\n",
            "Epoch 10/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6640 - val_loss: 0.6040 - val_binary_accuracy: 0.6685\n",
            "Epoch 11/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6619 - val_loss: 0.6038 - val_binary_accuracy: 0.6707\n",
            "Epoch 12/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6604 - val_loss: 0.6031 - val_binary_accuracy: 0.6681\n",
            "Epoch 13/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6710 - val_loss: 0.6024 - val_binary_accuracy: 0.6745\n",
            "Epoch 14/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6774 - val_loss: 0.6033 - val_binary_accuracy: 0.6711\n",
            "Epoch 15/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6677 - val_loss: 0.6010 - val_binary_accuracy: 0.6719\n",
            "Epoch 16/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6684 - val_loss: 0.6026 - val_binary_accuracy: 0.6763\n",
            "Epoch 17/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6698 - val_loss: 0.6024 - val_binary_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6683 - val_loss: 0.6005 - val_binary_accuracy: 0.6719\n",
            "Epoch 19/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6710 - val_loss: 0.6007 - val_binary_accuracy: 0.6685\n",
            "Epoch 20/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6729 - val_loss: 0.6011 - val_binary_accuracy: 0.6685\n",
            "Epoch 21/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6733 - val_loss: 0.6009 - val_binary_accuracy: 0.6700\n",
            "Epoch 22/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6744 - val_loss: 0.6006 - val_binary_accuracy: 0.6670\n",
            "Epoch 23/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6779 - val_loss: 0.6008 - val_binary_accuracy: 0.6700\n",
            "Epoch 24/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6733 - val_loss: 0.6006 - val_binary_accuracy: 0.6711\n",
            "Epoch 25/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6728 - val_loss: 0.6011 - val_binary_accuracy: 0.6685\n",
            "Epoch 26/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6752 - val_loss: 0.6006 - val_binary_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6766 - val_loss: 0.6008 - val_binary_accuracy: 0.6707\n",
            "Epoch 28/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6752 - val_loss: 0.6010 - val_binary_accuracy: 0.6711\n",
            "Epoch 00028: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:31,603]\u001b[0m Trial 81 finished with value: 0.6686434149742126 and parameters: {'batch size': 243, 'optimizer': 'Adagrad', 'lr': 0.08697402076855813, 'minimum_learning_rate': 0.059188139835042744}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "51/51 [==============================] - 1s 6ms/step - loss: 0.6649 - binary_accuracy: 0.6041 - val_loss: 0.6319 - val_binary_accuracy: 0.6415\n",
            "Epoch 2/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6296 - val_loss: 0.6207 - val_binary_accuracy: 0.6555\n",
            "Epoch 3/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6293 - binary_accuracy: 0.6312 - val_loss: 0.6154 - val_binary_accuracy: 0.6637\n",
            "Epoch 4/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.6459 - val_loss: 0.6127 - val_binary_accuracy: 0.6615\n",
            "Epoch 5/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6555 - val_loss: 0.6089 - val_binary_accuracy: 0.6622\n",
            "Epoch 6/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.6513 - val_loss: 0.6095 - val_binary_accuracy: 0.6689\n",
            "Epoch 7/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6604 - val_loss: 0.6053 - val_binary_accuracy: 0.6696\n",
            "Epoch 8/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.6605 - val_loss: 0.6061 - val_binary_accuracy: 0.6674\n",
            "Epoch 9/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6107 - binary_accuracy: 0.6628 - val_loss: 0.6063 - val_binary_accuracy: 0.6707\n",
            "Epoch 10/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6571 - val_loss: 0.6057 - val_binary_accuracy: 0.6707\n",
            "Epoch 11/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6647 - val_loss: 0.6044 - val_binary_accuracy: 0.6685\n",
            "Epoch 12/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6663 - val_loss: 0.6046 - val_binary_accuracy: 0.6696\n",
            "Epoch 13/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6656 - val_loss: 0.6032 - val_binary_accuracy: 0.6719\n",
            "Epoch 14/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6656 - val_loss: 0.6024 - val_binary_accuracy: 0.6752\n",
            "Epoch 15/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6737 - val_loss: 0.6022 - val_binary_accuracy: 0.6733\n",
            "Epoch 16/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.6069 - binary_accuracy: 0.6697 - val_loss: 0.6028 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6700 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 18/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6753 - val_loss: 0.6027 - val_binary_accuracy: 0.6759\n",
            "Epoch 19/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6760 - val_loss: 0.6027 - val_binary_accuracy: 0.6752\n",
            "Epoch 20/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6744 - val_loss: 0.6021 - val_binary_accuracy: 0.6711\n",
            "Epoch 21/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6729 - val_loss: 0.6023 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6730 - val_loss: 0.6023 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6711 - val_loss: 0.6022 - val_binary_accuracy: 0.6759\n",
            "Epoch 24/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6708 - val_loss: 0.6023 - val_binary_accuracy: 0.6793\n",
            "Epoch 25/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6715 - val_loss: 0.6021 - val_binary_accuracy: 0.6774\n",
            "Epoch 26/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6690 - val_loss: 0.6022 - val_binary_accuracy: 0.6782\n",
            "Epoch 27/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6721 - val_loss: 0.6015 - val_binary_accuracy: 0.6752\n",
            "Epoch 28/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5994 - binary_accuracy: 0.6766 - val_loss: 0.6014 - val_binary_accuracy: 0.6770\n",
            "Epoch 29/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6715 - val_loss: 0.6012 - val_binary_accuracy: 0.6793\n",
            "Epoch 30/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6716 - val_loss: 0.6011 - val_binary_accuracy: 0.6770\n",
            "Epoch 31/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6766 - val_loss: 0.6014 - val_binary_accuracy: 0.6778\n",
            "Epoch 32/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6745 - val_loss: 0.6014 - val_binary_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6764 - val_loss: 0.6015 - val_binary_accuracy: 0.6774\n",
            "Epoch 34/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6811 - val_loss: 0.6011 - val_binary_accuracy: 0.6763\n",
            "Epoch 35/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6767 - val_loss: 0.6017 - val_binary_accuracy: 0.6785\n",
            "Epoch 36/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6801 - val_loss: 0.6014 - val_binary_accuracy: 0.6733\n",
            "Epoch 37/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6731 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 38/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6750 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 39/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6739 - val_loss: 0.6022 - val_binary_accuracy: 0.6770\n",
            "Epoch 40/200\n",
            "51/51 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6771 - val_loss: 0.6016 - val_binary_accuracy: 0.6770\n",
            "Epoch 41/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5964 - binary_accuracy: 0.6777 - val_loss: 0.6016 - val_binary_accuracy: 0.6767\n",
            "Epoch 42/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5919 - binary_accuracy: 0.6803 - val_loss: 0.6022 - val_binary_accuracy: 0.6763\n",
            "Epoch 43/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_accuracy: 0.6782 - val_loss: 0.6018 - val_binary_accuracy: 0.6774\n",
            "Epoch 44/200\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6748 - val_loss: 0.6025 - val_binary_accuracy: 0.6804\n",
            "Epoch 00044: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:39,870]\u001b[0m Trial 82 finished with value: 0.6660489439964294 and parameters: {'batch size': 249, 'optimizer': 'Adagrad', 'lr': 0.0956341581411656, 'minimum_learning_rate': 0.057518565558919155}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "52/52 [==============================] - 1s 5ms/step - loss: 0.6715 - binary_accuracy: 0.5871 - val_loss: 0.6389 - val_binary_accuracy: 0.6277\n",
            "Epoch 2/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.6216 - val_loss: 0.6231 - val_binary_accuracy: 0.6504\n",
            "Epoch 3/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6326 - binary_accuracy: 0.6331 - val_loss: 0.6158 - val_binary_accuracy: 0.6570\n",
            "Epoch 4/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6248 - binary_accuracy: 0.6481 - val_loss: 0.6114 - val_binary_accuracy: 0.6663\n",
            "Epoch 5/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6207 - binary_accuracy: 0.6519 - val_loss: 0.6093 - val_binary_accuracy: 0.6681\n",
            "Epoch 6/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6175 - binary_accuracy: 0.6566 - val_loss: 0.6064 - val_binary_accuracy: 0.6726\n",
            "Epoch 7/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6604 - val_loss: 0.6042 - val_binary_accuracy: 0.6745\n",
            "Epoch 8/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6585 - val_loss: 0.6047 - val_binary_accuracy: 0.6774\n",
            "Epoch 9/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6653 - val_loss: 0.6055 - val_binary_accuracy: 0.6670\n",
            "Epoch 10/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6121 - binary_accuracy: 0.6656 - val_loss: 0.6036 - val_binary_accuracy: 0.6763\n",
            "Epoch 11/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6617 - val_loss: 0.6045 - val_binary_accuracy: 0.6733\n",
            "Epoch 12/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6703 - val_loss: 0.6024 - val_binary_accuracy: 0.6737\n",
            "Epoch 13/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6684 - val_loss: 0.6036 - val_binary_accuracy: 0.6685\n",
            "Epoch 14/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6665 - val_loss: 0.6041 - val_binary_accuracy: 0.6652\n",
            "Epoch 15/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6686 - val_loss: 0.6030 - val_binary_accuracy: 0.6774\n",
            "Epoch 16/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6049 - binary_accuracy: 0.6706 - val_loss: 0.6030 - val_binary_accuracy: 0.6726\n",
            "Epoch 17/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6710 - val_loss: 0.6030 - val_binary_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6059 - binary_accuracy: 0.6669 - val_loss: 0.6028 - val_binary_accuracy: 0.6770\n",
            "Epoch 19/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6714 - val_loss: 0.6022 - val_binary_accuracy: 0.6748\n",
            "Epoch 20/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6032 - binary_accuracy: 0.6726 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 21/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6724 - val_loss: 0.6017 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6739 - val_loss: 0.6018 - val_binary_accuracy: 0.6700\n",
            "Epoch 23/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6710 - val_loss: 0.6020 - val_binary_accuracy: 0.6652\n",
            "Epoch 24/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6756 - val_loss: 0.6020 - val_binary_accuracy: 0.6685\n",
            "Epoch 25/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6728 - val_loss: 0.6021 - val_binary_accuracy: 0.6711\n",
            "Epoch 26/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6659 - val_loss: 0.6021 - val_binary_accuracy: 0.6707\n",
            "Epoch 27/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5997 - binary_accuracy: 0.6768 - val_loss: 0.6020 - val_binary_accuracy: 0.6707\n",
            "Epoch 28/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6716 - val_loss: 0.6020 - val_binary_accuracy: 0.6767\n",
            "Epoch 29/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6762 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 30/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6737 - val_loss: 0.6024 - val_binary_accuracy: 0.6700\n",
            "Epoch 31/200\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6018 - binary_accuracy: 0.6727 - val_loss: 0.6028 - val_binary_accuracy: 0.6685\n",
            "Epoch 00031: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:35:50,656]\u001b[0m Trial 83 finished with value: 0.6667901873588562 and parameters: {'batch size': 246, 'optimizer': 'Adagrad', 'lr': 0.09167604397815075, 'minimum_learning_rate': 0.03257436215897075}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "53/53 [==============================] - 1s 5ms/step - loss: 0.7196 - binary_accuracy: 0.5457 - val_loss: 0.6527 - val_binary_accuracy: 0.6096\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6792 - binary_accuracy: 0.5803 - val_loss: 0.6439 - val_binary_accuracy: 0.6196\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6680 - binary_accuracy: 0.5909 - val_loss: 0.6379 - val_binary_accuracy: 0.6377\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6573 - binary_accuracy: 0.6050 - val_loss: 0.6339 - val_binary_accuracy: 0.6400\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.6110 - val_loss: 0.6317 - val_binary_accuracy: 0.6448\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6493 - binary_accuracy: 0.6148 - val_loss: 0.6287 - val_binary_accuracy: 0.6470\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.6202 - val_loss: 0.6259 - val_binary_accuracy: 0.6529\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.6250 - val_loss: 0.6231 - val_binary_accuracy: 0.6559\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6394 - binary_accuracy: 0.6262 - val_loss: 0.6215 - val_binary_accuracy: 0.6570\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6375 - binary_accuracy: 0.6278 - val_loss: 0.6193 - val_binary_accuracy: 0.6596\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6297 - val_loss: 0.6176 - val_binary_accuracy: 0.6585\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6312 - val_loss: 0.6156 - val_binary_accuracy: 0.6641\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6311 - val_loss: 0.6135 - val_binary_accuracy: 0.6630\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6405 - val_loss: 0.6127 - val_binary_accuracy: 0.6667\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6283 - binary_accuracy: 0.6379 - val_loss: 0.6117 - val_binary_accuracy: 0.6656\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6267 - binary_accuracy: 0.6402 - val_loss: 0.6105 - val_binary_accuracy: 0.6707\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6458 - val_loss: 0.6086 - val_binary_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_accuracy: 0.6480 - val_loss: 0.6083 - val_binary_accuracy: 0.6741\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6467 - val_loss: 0.6078 - val_binary_accuracy: 0.6770\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6223 - binary_accuracy: 0.6432 - val_loss: 0.6066 - val_binary_accuracy: 0.6763\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6199 - binary_accuracy: 0.6469 - val_loss: 0.6057 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6524 - val_loss: 0.6054 - val_binary_accuracy: 0.6785\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6522 - val_loss: 0.6050 - val_binary_accuracy: 0.6770\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6156 - binary_accuracy: 0.6555 - val_loss: 0.6047 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6491 - val_loss: 0.6049 - val_binary_accuracy: 0.6770\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6507 - val_loss: 0.6041 - val_binary_accuracy: 0.6774\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6174 - binary_accuracy: 0.6527 - val_loss: 0.6040 - val_binary_accuracy: 0.6759\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6602 - val_loss: 0.6033 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6166 - binary_accuracy: 0.6578 - val_loss: 0.6035 - val_binary_accuracy: 0.6796\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6596 - val_loss: 0.6032 - val_binary_accuracy: 0.6767\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6569 - val_loss: 0.6029 - val_binary_accuracy: 0.6745\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6533 - val_loss: 0.6027 - val_binary_accuracy: 0.6759\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6570 - val_loss: 0.6021 - val_binary_accuracy: 0.6748\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.6581 - val_loss: 0.6025 - val_binary_accuracy: 0.6745\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6101 - binary_accuracy: 0.6604 - val_loss: 0.6024 - val_binary_accuracy: 0.6756\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6648 - val_loss: 0.6022 - val_binary_accuracy: 0.6778\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6629 - val_loss: 0.6018 - val_binary_accuracy: 0.6785\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6598 - val_loss: 0.6017 - val_binary_accuracy: 0.6733\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6637 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6618 - val_loss: 0.6012 - val_binary_accuracy: 0.6748\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6616 - val_loss: 0.6009 - val_binary_accuracy: 0.6741\n",
            "Epoch 42/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6628 - val_loss: 0.6007 - val_binary_accuracy: 0.6745\n",
            "Epoch 43/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6611 - val_loss: 0.6011 - val_binary_accuracy: 0.6745\n",
            "Epoch 44/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6636 - val_loss: 0.6008 - val_binary_accuracy: 0.6745\n",
            "Epoch 45/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6647 - val_loss: 0.6009 - val_binary_accuracy: 0.6733\n",
            "Epoch 46/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6614 - val_loss: 0.6008 - val_binary_accuracy: 0.6737\n",
            "Epoch 47/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6625 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 48/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6704 - val_loss: 0.6006 - val_binary_accuracy: 0.6719\n",
            "Epoch 49/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6068 - binary_accuracy: 0.6678 - val_loss: 0.6005 - val_binary_accuracy: 0.6759\n",
            "Epoch 50/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6643 - val_loss: 0.6005 - val_binary_accuracy: 0.6752\n",
            "Epoch 51/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6641 - val_loss: 0.6002 - val_binary_accuracy: 0.6759\n",
            "Epoch 52/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6633 - val_loss: 0.6004 - val_binary_accuracy: 0.6752\n",
            "Epoch 53/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6088 - binary_accuracy: 0.6674 - val_loss: 0.6006 - val_binary_accuracy: 0.6763\n",
            "Epoch 54/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6636 - val_loss: 0.6007 - val_binary_accuracy: 0.6782\n",
            "Epoch 55/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6663 - val_loss: 0.6006 - val_binary_accuracy: 0.6770\n",
            "Epoch 56/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6075 - binary_accuracy: 0.6641 - val_loss: 0.6005 - val_binary_accuracy: 0.6763\n",
            "Epoch 57/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6621 - val_loss: 0.6002 - val_binary_accuracy: 0.6778\n",
            "Epoch 58/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6637 - val_loss: 0.6001 - val_binary_accuracy: 0.6763\n",
            "Epoch 59/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6667 - val_loss: 0.6002 - val_binary_accuracy: 0.6767\n",
            "Epoch 60/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6669 - val_loss: 0.6003 - val_binary_accuracy: 0.6782\n",
            "Epoch 61/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6055 - binary_accuracy: 0.6694 - val_loss: 0.6002 - val_binary_accuracy: 0.6782\n",
            "Epoch 62/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6069 - binary_accuracy: 0.6669 - val_loss: 0.6002 - val_binary_accuracy: 0.6774\n",
            "Epoch 63/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6046 - binary_accuracy: 0.6670 - val_loss: 0.5999 - val_binary_accuracy: 0.6770\n",
            "Epoch 64/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6096 - binary_accuracy: 0.6648 - val_loss: 0.6003 - val_binary_accuracy: 0.6785\n",
            "Epoch 65/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6652 - val_loss: 0.6004 - val_binary_accuracy: 0.6774\n",
            "Epoch 66/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6644 - val_loss: 0.6003 - val_binary_accuracy: 0.6793\n",
            "Epoch 67/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6654 - val_loss: 0.6003 - val_binary_accuracy: 0.6770\n",
            "Epoch 68/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6660 - val_loss: 0.6005 - val_binary_accuracy: 0.6770\n",
            "Epoch 69/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6708 - val_loss: 0.6004 - val_binary_accuracy: 0.6748\n",
            "Epoch 70/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6713 - val_loss: 0.6006 - val_binary_accuracy: 0.6741\n",
            "Epoch 71/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6677 - val_loss: 0.6003 - val_binary_accuracy: 0.6748\n",
            "Epoch 72/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6690 - val_loss: 0.6002 - val_binary_accuracy: 0.6752\n",
            "Epoch 73/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6041 - binary_accuracy: 0.6695 - val_loss: 0.6002 - val_binary_accuracy: 0.6759\n",
            "Epoch 00073: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:36:04,133]\u001b[0m Trial 84 finished with value: 0.6586360335350037 and parameters: {'batch size': 241, 'optimizer': 'Adagrad', 'lr': 0.017219588090261122, 'minimum_learning_rate': 0.014068378382039034}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 1s 6ms/step - loss: 0.6700 - binary_accuracy: 0.5911 - val_loss: 0.6360 - val_binary_accuracy: 0.6400\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6216 - val_loss: 0.6269 - val_binary_accuracy: 0.6552\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6326 - binary_accuracy: 0.6330 - val_loss: 0.6182 - val_binary_accuracy: 0.6633\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6302 - binary_accuracy: 0.6386 - val_loss: 0.6206 - val_binary_accuracy: 0.6637\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6206 - binary_accuracy: 0.6428 - val_loss: 0.6097 - val_binary_accuracy: 0.6722\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6507 - val_loss: 0.6105 - val_binary_accuracy: 0.6707\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6196 - binary_accuracy: 0.6527 - val_loss: 0.6090 - val_binary_accuracy: 0.6785\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6157 - binary_accuracy: 0.6552 - val_loss: 0.6039 - val_binary_accuracy: 0.6756\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6154 - binary_accuracy: 0.6562 - val_loss: 0.6061 - val_binary_accuracy: 0.6707\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6115 - binary_accuracy: 0.6628 - val_loss: 0.6028 - val_binary_accuracy: 0.6778\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6611 - val_loss: 0.6037 - val_binary_accuracy: 0.6793\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6076 - binary_accuracy: 0.6617 - val_loss: 0.6028 - val_binary_accuracy: 0.6722\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6102 - binary_accuracy: 0.6650 - val_loss: 0.6032 - val_binary_accuracy: 0.6748\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6643 - val_loss: 0.6022 - val_binary_accuracy: 0.6745\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6624 - val_loss: 0.6012 - val_binary_accuracy: 0.6752\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6689 - val_loss: 0.6014 - val_binary_accuracy: 0.6745\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6635 - val_loss: 0.6010 - val_binary_accuracy: 0.6730\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6644 - val_loss: 0.6013 - val_binary_accuracy: 0.6726\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6636 - val_loss: 0.6015 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6047 - binary_accuracy: 0.6653 - val_loss: 0.6009 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6684 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6685 - val_loss: 0.6013 - val_binary_accuracy: 0.6715\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6674 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6679 - val_loss: 0.6006 - val_binary_accuracy: 0.6700\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6016 - binary_accuracy: 0.6718 - val_loss: 0.6007 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5994 - binary_accuracy: 0.6763 - val_loss: 0.6009 - val_binary_accuracy: 0.6685\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6693 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6740 - val_loss: 0.6011 - val_binary_accuracy: 0.6737\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6687 - val_loss: 0.6004 - val_binary_accuracy: 0.6681\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6726 - val_loss: 0.6006 - val_binary_accuracy: 0.6711\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6720 - val_loss: 0.6002 - val_binary_accuracy: 0.6707\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6662 - val_loss: 0.6007 - val_binary_accuracy: 0.6696\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6694 - val_loss: 0.6008 - val_binary_accuracy: 0.6704\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6727 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6012 - binary_accuracy: 0.6721 - val_loss: 0.6009 - val_binary_accuracy: 0.6663\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5998 - binary_accuracy: 0.6708 - val_loss: 0.6003 - val_binary_accuracy: 0.6681\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.6716 - val_loss: 0.6008 - val_binary_accuracy: 0.6648\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6721 - val_loss: 0.6006 - val_binary_accuracy: 0.6678\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5985 - binary_accuracy: 0.6699 - val_loss: 0.6008 - val_binary_accuracy: 0.6700\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6765 - val_loss: 0.6004 - val_binary_accuracy: 0.6670\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6778 - val_loss: 0.5998 - val_binary_accuracy: 0.6663\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6773 - val_loss: 0.6002 - val_binary_accuracy: 0.6696\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5989 - binary_accuracy: 0.6752 - val_loss: 0.5995 - val_binary_accuracy: 0.6681\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6738 - val_loss: 0.5997 - val_binary_accuracy: 0.6689\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6734 - val_loss: 0.5991 - val_binary_accuracy: 0.6681\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6787 - val_loss: 0.5993 - val_binary_accuracy: 0.6700\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6781 - val_loss: 0.5992 - val_binary_accuracy: 0.6696\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5945 - binary_accuracy: 0.6805 - val_loss: 0.5992 - val_binary_accuracy: 0.6693\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6741 - val_loss: 0.5994 - val_binary_accuracy: 0.6678\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6786 - val_loss: 0.5996 - val_binary_accuracy: 0.6693\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6772 - val_loss: 0.5999 - val_binary_accuracy: 0.6707\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6740 - val_loss: 0.6001 - val_binary_accuracy: 0.6715\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6783 - val_loss: 0.5993 - val_binary_accuracy: 0.6700\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6742 - val_loss: 0.5994 - val_binary_accuracy: 0.6678\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5953 - binary_accuracy: 0.6783 - val_loss: 0.5995 - val_binary_accuracy: 0.6707\n",
            "Epoch 00055: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:36:14,908]\u001b[0m Trial 85 finished with value: 0.6656782627105713 and parameters: {'batch size': 254, 'optimizer': 'Adagrad', 'lr': 0.08185091121281118, 'minimum_learning_rate': 0.04859338215097217}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "54/54 [==============================] - 1s 5ms/step - loss: 0.6815 - binary_accuracy: 0.5900 - val_loss: 0.6462 - val_binary_accuracy: 0.6266\n",
            "Epoch 2/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.6233 - val_loss: 0.6257 - val_binary_accuracy: 0.6548\n",
            "Epoch 3/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6338 - binary_accuracy: 0.6366 - val_loss: 0.6187 - val_binary_accuracy: 0.6548\n",
            "Epoch 4/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6284 - binary_accuracy: 0.6443 - val_loss: 0.6165 - val_binary_accuracy: 0.6622\n",
            "Epoch 5/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6244 - binary_accuracy: 0.6455 - val_loss: 0.6111 - val_binary_accuracy: 0.6589\n",
            "Epoch 6/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6202 - binary_accuracy: 0.6475 - val_loss: 0.6098 - val_binary_accuracy: 0.6593\n",
            "Epoch 7/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6200 - binary_accuracy: 0.6525 - val_loss: 0.6085 - val_binary_accuracy: 0.6652\n",
            "Epoch 8/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6598 - val_loss: 0.6047 - val_binary_accuracy: 0.6704\n",
            "Epoch 9/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6605 - val_loss: 0.6073 - val_binary_accuracy: 0.6745\n",
            "Epoch 10/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6581 - val_loss: 0.6068 - val_binary_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6637 - val_loss: 0.6026 - val_binary_accuracy: 0.6785\n",
            "Epoch 12/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6710 - val_loss: 0.6068 - val_binary_accuracy: 0.6752\n",
            "Epoch 13/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6639 - val_loss: 0.6044 - val_binary_accuracy: 0.6759\n",
            "Epoch 14/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6626 - val_loss: 0.6040 - val_binary_accuracy: 0.6726\n",
            "Epoch 15/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6702 - val_loss: 0.6022 - val_binary_accuracy: 0.6756\n",
            "Epoch 16/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6679 - val_loss: 0.6026 - val_binary_accuracy: 0.6715\n",
            "Epoch 17/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6740 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 18/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6675 - val_loss: 0.6028 - val_binary_accuracy: 0.6763\n",
            "Epoch 19/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6672 - val_loss: 0.6027 - val_binary_accuracy: 0.6737\n",
            "Epoch 20/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6683 - val_loss: 0.6024 - val_binary_accuracy: 0.6756\n",
            "Epoch 21/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6717 - val_loss: 0.6024 - val_binary_accuracy: 0.6763\n",
            "Epoch 22/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6757 - val_loss: 0.6019 - val_binary_accuracy: 0.6763\n",
            "Epoch 23/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6729 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 24/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6024 - binary_accuracy: 0.6717 - val_loss: 0.6016 - val_binary_accuracy: 0.6759\n",
            "Epoch 25/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6691 - val_loss: 0.6014 - val_binary_accuracy: 0.6752\n",
            "Epoch 26/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6014 - binary_accuracy: 0.6754 - val_loss: 0.6015 - val_binary_accuracy: 0.6748\n",
            "Epoch 27/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6017 - binary_accuracy: 0.6756 - val_loss: 0.6014 - val_binary_accuracy: 0.6752\n",
            "Epoch 28/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.5985 - binary_accuracy: 0.6780 - val_loss: 0.6014 - val_binary_accuracy: 0.6759\n",
            "Epoch 29/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6720 - val_loss: 0.6016 - val_binary_accuracy: 0.6759\n",
            "Epoch 30/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6746 - val_loss: 0.6015 - val_binary_accuracy: 0.6770\n",
            "Epoch 31/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6739 - val_loss: 0.6013 - val_binary_accuracy: 0.6774\n",
            "Epoch 32/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6751 - val_loss: 0.6014 - val_binary_accuracy: 0.6778\n",
            "Epoch 33/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6779 - val_loss: 0.6014 - val_binary_accuracy: 0.6763\n",
            "Epoch 34/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6785 - val_loss: 0.6014 - val_binary_accuracy: 0.6759\n",
            "Epoch 35/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6015 - binary_accuracy: 0.6734 - val_loss: 0.6017 - val_binary_accuracy: 0.6741\n",
            "Epoch 36/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6748 - val_loss: 0.6019 - val_binary_accuracy: 0.6745\n",
            "Epoch 37/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.5970 - binary_accuracy: 0.6756 - val_loss: 0.6016 - val_binary_accuracy: 0.6737\n",
            "Epoch 38/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.5997 - binary_accuracy: 0.6714 - val_loss: 0.6017 - val_binary_accuracy: 0.6756\n",
            "Epoch 39/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6764 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 40/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6714 - val_loss: 0.6015 - val_binary_accuracy: 0.6741\n",
            "Epoch 41/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6735 - val_loss: 0.6016 - val_binary_accuracy: 0.6752\n",
            "Epoch 00041: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:36:23,158]\u001b[0m Trial 86 finished with value: 0.660118579864502 and parameters: {'batch size': 237, 'optimizer': 'Adagrad', 'lr': 0.08867568987228432, 'minimum_learning_rate': 0.017523340619459676}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "55/55 [==============================] - 1s 5ms/step - loss: 0.6777 - binary_accuracy: 0.5921 - val_loss: 0.6342 - val_binary_accuracy: 0.6374\n",
            "Epoch 2/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6272 - val_loss: 0.6210 - val_binary_accuracy: 0.6555\n",
            "Epoch 3/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6309 - binary_accuracy: 0.6374 - val_loss: 0.6153 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6238 - binary_accuracy: 0.6484 - val_loss: 0.6106 - val_binary_accuracy: 0.6711\n",
            "Epoch 5/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6188 - binary_accuracy: 0.6538 - val_loss: 0.6057 - val_binary_accuracy: 0.6733\n",
            "Epoch 6/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6588 - val_loss: 0.6037 - val_binary_accuracy: 0.6763\n",
            "Epoch 7/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6154 - binary_accuracy: 0.6540 - val_loss: 0.6047 - val_binary_accuracy: 0.6756\n",
            "Epoch 8/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6568 - val_loss: 0.6025 - val_binary_accuracy: 0.6804\n",
            "Epoch 9/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6627 - val_loss: 0.6007 - val_binary_accuracy: 0.6785\n",
            "Epoch 10/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6629 - val_loss: 0.6035 - val_binary_accuracy: 0.6733\n",
            "Epoch 11/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6701 - val_loss: 0.6013 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6630 - val_loss: 0.6019 - val_binary_accuracy: 0.6822\n",
            "Epoch 13/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6671 - val_loss: 0.6007 - val_binary_accuracy: 0.6796\n",
            "Epoch 14/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.6679 - val_loss: 0.6000 - val_binary_accuracy: 0.6796\n",
            "Epoch 15/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6067 - binary_accuracy: 0.6703 - val_loss: 0.6002 - val_binary_accuracy: 0.6804\n",
            "Epoch 16/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6703 - val_loss: 0.5991 - val_binary_accuracy: 0.6767\n",
            "Epoch 17/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6710 - val_loss: 0.5988 - val_binary_accuracy: 0.6800\n",
            "Epoch 18/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6734 - val_loss: 0.5985 - val_binary_accuracy: 0.6785\n",
            "Epoch 19/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6722 - val_loss: 0.5994 - val_binary_accuracy: 0.6804\n",
            "Epoch 20/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6715 - val_loss: 0.5990 - val_binary_accuracy: 0.6811\n",
            "Epoch 21/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6743 - val_loss: 0.5979 - val_binary_accuracy: 0.6811\n",
            "Epoch 22/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6732 - val_loss: 0.5982 - val_binary_accuracy: 0.6793\n",
            "Epoch 23/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6004 - binary_accuracy: 0.6741 - val_loss: 0.5988 - val_binary_accuracy: 0.6822\n",
            "Epoch 24/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6764 - val_loss: 0.5998 - val_binary_accuracy: 0.6826\n",
            "Epoch 25/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6772 - val_loss: 0.5980 - val_binary_accuracy: 0.6800\n",
            "Epoch 26/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6718 - val_loss: 0.6005 - val_binary_accuracy: 0.6796\n",
            "Epoch 27/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5965 - binary_accuracy: 0.6795 - val_loss: 0.5988 - val_binary_accuracy: 0.6789\n",
            "Epoch 28/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6792 - val_loss: 0.5987 - val_binary_accuracy: 0.6782\n",
            "Epoch 29/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6746 - val_loss: 0.5980 - val_binary_accuracy: 0.6789\n",
            "Epoch 30/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6758 - val_loss: 0.5985 - val_binary_accuracy: 0.6800\n",
            "Epoch 31/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6822 - val_loss: 0.5976 - val_binary_accuracy: 0.6793\n",
            "Epoch 32/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6767 - val_loss: 0.5979 - val_binary_accuracy: 0.6815\n",
            "Epoch 33/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6779 - val_loss: 0.5975 - val_binary_accuracy: 0.6759\n",
            "Epoch 34/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6777 - val_loss: 0.5995 - val_binary_accuracy: 0.6778\n",
            "Epoch 35/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6818 - val_loss: 0.5986 - val_binary_accuracy: 0.6778\n",
            "Epoch 36/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6763 - val_loss: 0.5980 - val_binary_accuracy: 0.6774\n",
            "Epoch 37/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5939 - binary_accuracy: 0.6812 - val_loss: 0.5978 - val_binary_accuracy: 0.6782\n",
            "Epoch 38/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6780 - val_loss: 0.5979 - val_binary_accuracy: 0.6759\n",
            "Epoch 39/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5938 - binary_accuracy: 0.6799 - val_loss: 0.5992 - val_binary_accuracy: 0.6752\n",
            "Epoch 40/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.5932 - binary_accuracy: 0.6745 - val_loss: 0.5981 - val_binary_accuracy: 0.6770\n",
            "Epoch 41/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6813 - val_loss: 0.5997 - val_binary_accuracy: 0.6800\n",
            "Epoch 42/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.5959 - binary_accuracy: 0.6815 - val_loss: 0.5979 - val_binary_accuracy: 0.6800\n",
            "Epoch 43/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.5946 - binary_accuracy: 0.6812 - val_loss: 0.5982 - val_binary_accuracy: 0.6778\n",
            "Epoch 00043: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:36:31,755]\u001b[0m Trial 87 finished with value: 0.6697553992271423 and parameters: {'batch size': 230, 'optimizer': 'Adagrad', 'lr': 0.09953345442171396, 'minimum_learning_rate': 0.0799313621928376}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "58/58 [==============================] - 1s 5ms/step - loss: 0.6724 - binary_accuracy: 0.5944 - val_loss: 0.6462 - val_binary_accuracy: 0.6281\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6429 - binary_accuracy: 0.6192 - val_loss: 0.6255 - val_binary_accuracy: 0.6589\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6350 - val_loss: 0.6191 - val_binary_accuracy: 0.6633\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.6432 - val_loss: 0.6137 - val_binary_accuracy: 0.6656\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6437 - val_loss: 0.6116 - val_binary_accuracy: 0.6722\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6204 - binary_accuracy: 0.6477 - val_loss: 0.6119 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.6579 - val_loss: 0.6074 - val_binary_accuracy: 0.6726\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6567 - val_loss: 0.6078 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6609 - val_loss: 0.6057 - val_binary_accuracy: 0.6745\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6605 - val_loss: 0.6093 - val_binary_accuracy: 0.6696\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6605 - val_loss: 0.6058 - val_binary_accuracy: 0.6730\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6084 - binary_accuracy: 0.6602 - val_loss: 0.6059 - val_binary_accuracy: 0.6748\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6709 - val_loss: 0.6039 - val_binary_accuracy: 0.6715\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6656 - val_loss: 0.6039 - val_binary_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6663 - val_loss: 0.6031 - val_binary_accuracy: 0.6748\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6658 - val_loss: 0.6030 - val_binary_accuracy: 0.6741\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6690 - val_loss: 0.6028 - val_binary_accuracy: 0.6685\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6710 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6682 - val_loss: 0.6028 - val_binary_accuracy: 0.6748\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6064 - binary_accuracy: 0.6647 - val_loss: 0.6027 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6616 - val_loss: 0.6028 - val_binary_accuracy: 0.6693\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6698 - val_loss: 0.6031 - val_binary_accuracy: 0.6752\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6668 - val_loss: 0.6029 - val_binary_accuracy: 0.6759\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6718 - val_loss: 0.6024 - val_binary_accuracy: 0.6759\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6679 - val_loss: 0.6028 - val_binary_accuracy: 0.6745\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6681 - val_loss: 0.6028 - val_binary_accuracy: 0.6730\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.6723 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6688 - val_loss: 0.6026 - val_binary_accuracy: 0.6733\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6702 - val_loss: 0.6029 - val_binary_accuracy: 0.6730\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6706 - val_loss: 0.6030 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6713 - val_loss: 0.6024 - val_binary_accuracy: 0.6719\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6722 - val_loss: 0.6031 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6780 - val_loss: 0.6029 - val_binary_accuracy: 0.6715\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6743 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 00034: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:36:42,555]\u001b[0m Trial 88 finished with value: 0.6719792485237122 and parameters: {'batch size': 220, 'optimizer': 'Adagrad', 'lr': 0.07645710448490328, 'minimum_learning_rate': 0.029053233393750884}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.7188 - binary_accuracy: 0.5470 - val_loss: 0.6612 - val_binary_accuracy: 0.6066\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6786 - binary_accuracy: 0.5852 - val_loss: 0.6492 - val_binary_accuracy: 0.6166\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5976 - val_loss: 0.6443 - val_binary_accuracy: 0.6251\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6589 - binary_accuracy: 0.6090 - val_loss: 0.6407 - val_binary_accuracy: 0.6285\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6543 - binary_accuracy: 0.6072 - val_loss: 0.6381 - val_binary_accuracy: 0.6355\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6169 - val_loss: 0.6355 - val_binary_accuracy: 0.6370\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6493 - binary_accuracy: 0.6143 - val_loss: 0.6339 - val_binary_accuracy: 0.6407\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6469 - binary_accuracy: 0.6142 - val_loss: 0.6323 - val_binary_accuracy: 0.6433\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6293 - val_loss: 0.6298 - val_binary_accuracy: 0.6470\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6323 - val_loss: 0.6281 - val_binary_accuracy: 0.6515\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6287 - val_loss: 0.6266 - val_binary_accuracy: 0.6500\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6279 - val_loss: 0.6246 - val_binary_accuracy: 0.6504\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6360 - binary_accuracy: 0.6287 - val_loss: 0.6229 - val_binary_accuracy: 0.6555\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6332 - val_loss: 0.6217 - val_binary_accuracy: 0.6585\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6342 - val_loss: 0.6209 - val_binary_accuracy: 0.6596\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6311 - binary_accuracy: 0.6369 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6289 - binary_accuracy: 0.6388 - val_loss: 0.6183 - val_binary_accuracy: 0.6626\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6273 - binary_accuracy: 0.6417 - val_loss: 0.6170 - val_binary_accuracy: 0.6630\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6395 - val_loss: 0.6158 - val_binary_accuracy: 0.6630\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.6369 - val_loss: 0.6153 - val_binary_accuracy: 0.6648\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6231 - binary_accuracy: 0.6489 - val_loss: 0.6142 - val_binary_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6457 - val_loss: 0.6135 - val_binary_accuracy: 0.6659\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6229 - binary_accuracy: 0.6484 - val_loss: 0.6131 - val_binary_accuracy: 0.6670\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6215 - binary_accuracy: 0.6510 - val_loss: 0.6124 - val_binary_accuracy: 0.6633\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6201 - binary_accuracy: 0.6511 - val_loss: 0.6119 - val_binary_accuracy: 0.6637\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6166 - binary_accuracy: 0.6528 - val_loss: 0.6113 - val_binary_accuracy: 0.6633\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6538 - val_loss: 0.6107 - val_binary_accuracy: 0.6670\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6152 - binary_accuracy: 0.6548 - val_loss: 0.6102 - val_binary_accuracy: 0.6644\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6199 - binary_accuracy: 0.6540 - val_loss: 0.6106 - val_binary_accuracy: 0.6656\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6549 - val_loss: 0.6098 - val_binary_accuracy: 0.6670\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6198 - binary_accuracy: 0.6543 - val_loss: 0.6100 - val_binary_accuracy: 0.6667\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6168 - binary_accuracy: 0.6532 - val_loss: 0.6097 - val_binary_accuracy: 0.6663\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6185 - binary_accuracy: 0.6532 - val_loss: 0.6094 - val_binary_accuracy: 0.6656\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6548 - val_loss: 0.6091 - val_binary_accuracy: 0.6678\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6190 - binary_accuracy: 0.6468 - val_loss: 0.6087 - val_binary_accuracy: 0.6674\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6130 - binary_accuracy: 0.6606 - val_loss: 0.6085 - val_binary_accuracy: 0.6689\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6152 - binary_accuracy: 0.6542 - val_loss: 0.6079 - val_binary_accuracy: 0.6696\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6629 - val_loss: 0.6078 - val_binary_accuracy: 0.6700\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6119 - binary_accuracy: 0.6578 - val_loss: 0.6075 - val_binary_accuracy: 0.6696\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6581 - val_loss: 0.6073 - val_binary_accuracy: 0.6696\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6128 - binary_accuracy: 0.6561 - val_loss: 0.6070 - val_binary_accuracy: 0.6730\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6604 - val_loss: 0.6064 - val_binary_accuracy: 0.6741\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6564 - val_loss: 0.6066 - val_binary_accuracy: 0.6715\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6555 - val_loss: 0.6064 - val_binary_accuracy: 0.6726\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6600 - val_loss: 0.6062 - val_binary_accuracy: 0.6726\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.6579 - val_loss: 0.6061 - val_binary_accuracy: 0.6722\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6594 - val_loss: 0.6063 - val_binary_accuracy: 0.6719\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6110 - binary_accuracy: 0.6641 - val_loss: 0.6062 - val_binary_accuracy: 0.6730\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6090 - binary_accuracy: 0.6626 - val_loss: 0.6059 - val_binary_accuracy: 0.6737\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6605 - val_loss: 0.6057 - val_binary_accuracy: 0.6730\n",
            "Epoch 51/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6561 - val_loss: 0.6060 - val_binary_accuracy: 0.6730\n",
            "Epoch 52/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6640 - val_loss: 0.6059 - val_binary_accuracy: 0.6745\n",
            "Epoch 53/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6084 - binary_accuracy: 0.6582 - val_loss: 0.6057 - val_binary_accuracy: 0.6726\n",
            "Epoch 54/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6625 - val_loss: 0.6057 - val_binary_accuracy: 0.6730\n",
            "Epoch 55/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6629 - val_loss: 0.6056 - val_binary_accuracy: 0.6726\n",
            "Epoch 56/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6667 - val_loss: 0.6056 - val_binary_accuracy: 0.6733\n",
            "Epoch 57/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6081 - binary_accuracy: 0.6651 - val_loss: 0.6056 - val_binary_accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6599 - val_loss: 0.6056 - val_binary_accuracy: 0.6730\n",
            "Epoch 59/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6599 - val_loss: 0.6056 - val_binary_accuracy: 0.6730\n",
            "Epoch 60/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6652 - val_loss: 0.6055 - val_binary_accuracy: 0.6722\n",
            "Epoch 61/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6643 - val_loss: 0.6055 - val_binary_accuracy: 0.6719\n",
            "Epoch 62/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6644 - val_loss: 0.6055 - val_binary_accuracy: 0.6722\n",
            "Epoch 63/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6610 - val_loss: 0.6055 - val_binary_accuracy: 0.6722\n",
            "Epoch 64/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6609 - val_loss: 0.6054 - val_binary_accuracy: 0.6726\n",
            "Epoch 65/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6674 - val_loss: 0.6054 - val_binary_accuracy: 0.6733\n",
            "Epoch 66/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6640 - val_loss: 0.6054 - val_binary_accuracy: 0.6726\n",
            "Epoch 67/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6648 - val_loss: 0.6054 - val_binary_accuracy: 0.6722\n",
            "Epoch 68/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6639 - val_loss: 0.6053 - val_binary_accuracy: 0.6722\n",
            "Epoch 69/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6556 - val_loss: 0.6054 - val_binary_accuracy: 0.6722\n",
            "Epoch 70/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6110 - binary_accuracy: 0.6638 - val_loss: 0.6054 - val_binary_accuracy: 0.6722\n",
            "Epoch 71/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6643 - val_loss: 0.6053 - val_binary_accuracy: 0.6715\n",
            "Epoch 72/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6696 - val_loss: 0.6053 - val_binary_accuracy: 0.6719\n",
            "Epoch 73/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6671 - val_loss: 0.6052 - val_binary_accuracy: 0.6707\n",
            "Epoch 74/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6687 - val_loss: 0.6052 - val_binary_accuracy: 0.6715\n",
            "Epoch 75/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6685 - val_loss: 0.6051 - val_binary_accuracy: 0.6722\n",
            "Epoch 76/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.6633 - val_loss: 0.6052 - val_binary_accuracy: 0.6726\n",
            "Epoch 77/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6641 - val_loss: 0.6051 - val_binary_accuracy: 0.6726\n",
            "Epoch 78/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6698 - val_loss: 0.6051 - val_binary_accuracy: 0.6730\n",
            "Epoch 79/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6636 - val_loss: 0.6050 - val_binary_accuracy: 0.6733\n",
            "Epoch 80/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6657 - val_loss: 0.6051 - val_binary_accuracy: 0.6715\n",
            "Epoch 81/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6650 - val_loss: 0.6050 - val_binary_accuracy: 0.6722\n",
            "Epoch 82/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6575 - val_loss: 0.6051 - val_binary_accuracy: 0.6726\n",
            "Epoch 83/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6652 - val_loss: 0.6051 - val_binary_accuracy: 0.6730\n",
            "Epoch 84/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6645 - val_loss: 0.6050 - val_binary_accuracy: 0.6730\n",
            "Epoch 85/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6070 - binary_accuracy: 0.6667 - val_loss: 0.6050 - val_binary_accuracy: 0.6733\n",
            "Epoch 86/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6638 - val_loss: 0.6049 - val_binary_accuracy: 0.6730\n",
            "Epoch 87/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6681 - val_loss: 0.6049 - val_binary_accuracy: 0.6733\n",
            "Epoch 88/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6069 - binary_accuracy: 0.6671 - val_loss: 0.6049 - val_binary_accuracy: 0.6733\n",
            "Epoch 89/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.6700 - val_loss: 0.6048 - val_binary_accuracy: 0.6726\n",
            "Epoch 90/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6617 - val_loss: 0.6048 - val_binary_accuracy: 0.6722\n",
            "Epoch 91/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6660 - val_loss: 0.6049 - val_binary_accuracy: 0.6730\n",
            "Epoch 92/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6618 - val_loss: 0.6049 - val_binary_accuracy: 0.6726\n",
            "Epoch 93/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6612 - val_loss: 0.6049 - val_binary_accuracy: 0.6726\n",
            "Epoch 94/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6679 - val_loss: 0.6049 - val_binary_accuracy: 0.6715\n",
            "Epoch 95/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6702 - val_loss: 0.6048 - val_binary_accuracy: 0.6722\n",
            "Epoch 96/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6658 - val_loss: 0.6048 - val_binary_accuracy: 0.6719\n",
            "Epoch 97/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6047 - binary_accuracy: 0.6666 - val_loss: 0.6047 - val_binary_accuracy: 0.6719\n",
            "Epoch 98/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6675 - val_loss: 0.6047 - val_binary_accuracy: 0.6730\n",
            "Epoch 99/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6624 - val_loss: 0.6047 - val_binary_accuracy: 0.6730\n",
            "Epoch 100/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6648 - val_loss: 0.6047 - val_binary_accuracy: 0.6737\n",
            "Epoch 101/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6670 - val_loss: 0.6047 - val_binary_accuracy: 0.6733\n",
            "Epoch 102/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6657 - val_loss: 0.6047 - val_binary_accuracy: 0.6733\n",
            "Epoch 103/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6633 - val_loss: 0.6047 - val_binary_accuracy: 0.6730\n",
            "Epoch 104/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6073 - binary_accuracy: 0.6644 - val_loss: 0.6047 - val_binary_accuracy: 0.6733\n",
            "Epoch 105/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6680 - val_loss: 0.6046 - val_binary_accuracy: 0.6733\n",
            "Epoch 106/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6618 - val_loss: 0.6046 - val_binary_accuracy: 0.6733\n",
            "Epoch 107/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6053 - binary_accuracy: 0.6674 - val_loss: 0.6045 - val_binary_accuracy: 0.6733\n",
            "Epoch 108/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6026 - binary_accuracy: 0.6688 - val_loss: 0.6045 - val_binary_accuracy: 0.6737\n",
            "Epoch 109/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6687 - val_loss: 0.6045 - val_binary_accuracy: 0.6741\n",
            "Epoch 110/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6668 - val_loss: 0.6044 - val_binary_accuracy: 0.6745\n",
            "Epoch 111/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6644 - val_loss: 0.6045 - val_binary_accuracy: 0.6745\n",
            "Epoch 112/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6671 - val_loss: 0.6044 - val_binary_accuracy: 0.6748\n",
            "Epoch 113/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6684 - val_loss: 0.6044 - val_binary_accuracy: 0.6745\n",
            "Epoch 114/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6691 - val_loss: 0.6044 - val_binary_accuracy: 0.6745\n",
            "Epoch 115/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6654 - val_loss: 0.6044 - val_binary_accuracy: 0.6741\n",
            "Epoch 116/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6636 - val_loss: 0.6044 - val_binary_accuracy: 0.6745\n",
            "Epoch 117/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6075 - binary_accuracy: 0.6662 - val_loss: 0.6045 - val_binary_accuracy: 0.6737\n",
            "Epoch 118/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6648 - val_loss: 0.6045 - val_binary_accuracy: 0.6733\n",
            "Epoch 119/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6696 - val_loss: 0.6045 - val_binary_accuracy: 0.6741\n",
            "Epoch 120/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6675 - val_loss: 0.6045 - val_binary_accuracy: 0.6737\n",
            "Epoch 00120: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:05,506]\u001b[0m Trial 89 finished with value: 0.6578947305679321 and parameters: {'batch size': 223, 'optimizer': 'Adagrad', 'lr': 0.014760107819706183, 'minimum_learning_rate': 0.0036927181759905565}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "58/58 [==============================] - 1s 5ms/step - loss: 0.6687 - binary_accuracy: 0.5978 - val_loss: 0.6333 - val_binary_accuracy: 0.6385\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6256 - val_loss: 0.6257 - val_binary_accuracy: 0.6466\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6285 - binary_accuracy: 0.6419 - val_loss: 0.6188 - val_binary_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6207 - binary_accuracy: 0.6483 - val_loss: 0.6173 - val_binary_accuracy: 0.6674\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6191 - binary_accuracy: 0.6509 - val_loss: 0.6112 - val_binary_accuracy: 0.6715\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.6180 - binary_accuracy: 0.6528 - val_loss: 0.6110 - val_binary_accuracy: 0.6733\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6571 - val_loss: 0.6087 - val_binary_accuracy: 0.6707\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6610 - val_loss: 0.6086 - val_binary_accuracy: 0.6696\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6621 - val_loss: 0.6077 - val_binary_accuracy: 0.6700\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6652 - val_loss: 0.6068 - val_binary_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6092 - binary_accuracy: 0.6652 - val_loss: 0.6039 - val_binary_accuracy: 0.6715\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6617 - val_loss: 0.6038 - val_binary_accuracy: 0.6730\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6624 - val_loss: 0.6032 - val_binary_accuracy: 0.6715\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6686 - val_loss: 0.6040 - val_binary_accuracy: 0.6670\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6674 - val_loss: 0.6043 - val_binary_accuracy: 0.6733\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6618 - val_loss: 0.6063 - val_binary_accuracy: 0.6715\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6749 - val_loss: 0.6034 - val_binary_accuracy: 0.6704\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6741 - val_loss: 0.6035 - val_binary_accuracy: 0.6700\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.6682 - val_loss: 0.6038 - val_binary_accuracy: 0.6730\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6700 - val_loss: 0.6036 - val_binary_accuracy: 0.6711\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6719 - val_loss: 0.6035 - val_binary_accuracy: 0.6730\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6734 - val_loss: 0.6036 - val_binary_accuracy: 0.6704\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6679 - val_loss: 0.6035 - val_binary_accuracy: 0.6722\n",
            "Epoch 00023: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:10,457]\u001b[0m Trial 90 finished with value: 0.6753150224685669 and parameters: {'batch size': 219, 'optimizer': 'Adagrad', 'lr': 0.08663064637509481, 'minimum_learning_rate': 0.03493096206024444}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "58/58 [==============================] - 1s 5ms/step - loss: 0.6727 - binary_accuracy: 0.5872 - val_loss: 0.6351 - val_binary_accuracy: 0.6326\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6305 - val_loss: 0.6218 - val_binary_accuracy: 0.6504\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6363 - val_loss: 0.6164 - val_binary_accuracy: 0.6626\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6241 - binary_accuracy: 0.6462 - val_loss: 0.6099 - val_binary_accuracy: 0.6674\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.6189 - binary_accuracy: 0.6516 - val_loss: 0.6091 - val_binary_accuracy: 0.6644\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6201 - binary_accuracy: 0.6476 - val_loss: 0.6064 - val_binary_accuracy: 0.6759\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6555 - val_loss: 0.6049 - val_binary_accuracy: 0.6674\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6534 - val_loss: 0.6043 - val_binary_accuracy: 0.6748\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6563 - val_loss: 0.6044 - val_binary_accuracy: 0.6782\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6636 - val_loss: 0.6028 - val_binary_accuracy: 0.6752\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6607 - val_loss: 0.6025 - val_binary_accuracy: 0.6763\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6631 - val_loss: 0.6023 - val_binary_accuracy: 0.6815\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6654 - val_loss: 0.6031 - val_binary_accuracy: 0.6796\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6687 - val_loss: 0.6024 - val_binary_accuracy: 0.6759\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6646 - val_loss: 0.6016 - val_binary_accuracy: 0.6789\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6690 - val_loss: 0.6019 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6719 - val_loss: 0.6013 - val_binary_accuracy: 0.6770\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6702 - val_loss: 0.6024 - val_binary_accuracy: 0.6722\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6686 - val_loss: 0.6026 - val_binary_accuracy: 0.6730\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6030 - binary_accuracy: 0.6718 - val_loss: 0.6023 - val_binary_accuracy: 0.6774\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6737 - val_loss: 0.6008 - val_binary_accuracy: 0.6759\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6741 - val_loss: 0.6012 - val_binary_accuracy: 0.6745\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6729 - val_loss: 0.6014 - val_binary_accuracy: 0.6774\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6697 - val_loss: 0.6016 - val_binary_accuracy: 0.6741\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6736 - val_loss: 0.6014 - val_binary_accuracy: 0.6759\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6745 - val_loss: 0.6012 - val_binary_accuracy: 0.6756\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6726 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6757 - val_loss: 0.6008 - val_binary_accuracy: 0.6767\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5983 - binary_accuracy: 0.6760 - val_loss: 0.6006 - val_binary_accuracy: 0.6726\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6707 - val_loss: 0.6007 - val_binary_accuracy: 0.6707\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6788 - val_loss: 0.6009 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6774 - val_loss: 0.6002 - val_binary_accuracy: 0.6722\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6769 - val_loss: 0.6003 - val_binary_accuracy: 0.6730\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6756 - val_loss: 0.6005 - val_binary_accuracy: 0.6767\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6763 - val_loss: 0.6005 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.6818 - val_loss: 0.6007 - val_binary_accuracy: 0.6722\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6775 - val_loss: 0.6006 - val_binary_accuracy: 0.6745\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6792 - val_loss: 0.6006 - val_binary_accuracy: 0.6726\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5915 - binary_accuracy: 0.6831 - val_loss: 0.6004 - val_binary_accuracy: 0.6733\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6737 - val_loss: 0.6004 - val_binary_accuracy: 0.6726\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5957 - binary_accuracy: 0.6741 - val_loss: 0.6007 - val_binary_accuracy: 0.6733\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5943 - binary_accuracy: 0.6841 - val_loss: 0.6010 - val_binary_accuracy: 0.6737\n",
            "Epoch 00042: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:21,219]\u001b[0m Trial 91 finished with value: 0.6667901873588562 and parameters: {'batch size': 219, 'optimizer': 'Adagrad', 'lr': 0.08698818853235978, 'minimum_learning_rate': 0.034284078694982956}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 1s 4ms/step - loss: 0.6798 - binary_accuracy: 0.6004 - val_loss: 0.6300 - val_binary_accuracy: 0.6411\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6362 - binary_accuracy: 0.6371 - val_loss: 0.6183 - val_binary_accuracy: 0.6548\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6268 - binary_accuracy: 0.6435 - val_loss: 0.6116 - val_binary_accuracy: 0.6604\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_accuracy: 0.6486 - val_loss: 0.6096 - val_binary_accuracy: 0.6652\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6191 - binary_accuracy: 0.6522 - val_loss: 0.6114 - val_binary_accuracy: 0.6663\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6544 - val_loss: 0.6082 - val_binary_accuracy: 0.6730\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6619 - val_loss: 0.6060 - val_binary_accuracy: 0.6770\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6575 - val_loss: 0.6047 - val_binary_accuracy: 0.6789\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6626 - val_loss: 0.6059 - val_binary_accuracy: 0.6752\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6651 - val_loss: 0.6050 - val_binary_accuracy: 0.6722\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6605 - val_loss: 0.6028 - val_binary_accuracy: 0.6719\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_accuracy: 0.6629 - val_loss: 0.6027 - val_binary_accuracy: 0.6730\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6088 - binary_accuracy: 0.6663 - val_loss: 0.6027 - val_binary_accuracy: 0.6741\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.6662 - val_loss: 0.6020 - val_binary_accuracy: 0.6733\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6672 - val_loss: 0.6013 - val_binary_accuracy: 0.6704\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6688 - val_loss: 0.6011 - val_binary_accuracy: 0.6722\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6688 - val_loss: 0.6025 - val_binary_accuracy: 0.6737\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6748 - val_loss: 0.6017 - val_binary_accuracy: 0.6667\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6698 - val_loss: 0.6000 - val_binary_accuracy: 0.6726\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6720 - val_loss: 0.6001 - val_binary_accuracy: 0.6719\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6706 - val_loss: 0.5999 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6723 - val_loss: 0.5996 - val_binary_accuracy: 0.6778\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6749 - val_loss: 0.6021 - val_binary_accuracy: 0.6767\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6698 - val_loss: 0.6010 - val_binary_accuracy: 0.6763\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6711 - val_loss: 0.6008 - val_binary_accuracy: 0.6741\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6776 - val_loss: 0.6007 - val_binary_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5980 - binary_accuracy: 0.6733 - val_loss: 0.5999 - val_binary_accuracy: 0.6733\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6765 - val_loss: 0.5993 - val_binary_accuracy: 0.6767\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5996 - binary_accuracy: 0.6723 - val_loss: 0.5998 - val_binary_accuracy: 0.6752\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6731 - val_loss: 0.6007 - val_binary_accuracy: 0.6770\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6760 - val_loss: 0.5997 - val_binary_accuracy: 0.6748\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6786 - val_loss: 0.6009 - val_binary_accuracy: 0.6763\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5979 - binary_accuracy: 0.6759 - val_loss: 0.6005 - val_binary_accuracy: 0.6722\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6763 - val_loss: 0.6019 - val_binary_accuracy: 0.6707\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6774 - val_loss: 0.6002 - val_binary_accuracy: 0.6756\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6770 - val_loss: 0.6000 - val_binary_accuracy: 0.6741\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6767 - val_loss: 0.5997 - val_binary_accuracy: 0.6730\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6781 - val_loss: 0.6001 - val_binary_accuracy: 0.6730\n",
            "Epoch 00038: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:31,964]\u001b[0m Trial 92 finished with value: 0.6690140962600708 and parameters: {'batch size': 206, 'optimizer': 'Adagrad', 'lr': 0.07800801296361765, 'minimum_learning_rate': 0.036851479010871345}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/samplers/_tpe/parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 1s 4ms/step - loss: 0.6776 - binary_accuracy: 0.5867 - val_loss: 0.6337 - val_binary_accuracy: 0.6429\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6445 - binary_accuracy: 0.6232 - val_loss: 0.6257 - val_binary_accuracy: 0.6489\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6361 - binary_accuracy: 0.6347 - val_loss: 0.6197 - val_binary_accuracy: 0.6585\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6299 - binary_accuracy: 0.6397 - val_loss: 0.6154 - val_binary_accuracy: 0.6648\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6237 - binary_accuracy: 0.6456 - val_loss: 0.6120 - val_binary_accuracy: 0.6656\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6183 - binary_accuracy: 0.6540 - val_loss: 0.6104 - val_binary_accuracy: 0.6674\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6511 - val_loss: 0.6082 - val_binary_accuracy: 0.6667\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6166 - binary_accuracy: 0.6551 - val_loss: 0.6079 - val_binary_accuracy: 0.6726\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6143 - binary_accuracy: 0.6615 - val_loss: 0.6069 - val_binary_accuracy: 0.6707\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6590 - val_loss: 0.6053 - val_binary_accuracy: 0.6659\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6622 - val_loss: 0.6054 - val_binary_accuracy: 0.6652\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6679 - val_loss: 0.6048 - val_binary_accuracy: 0.6652\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6687 - val_loss: 0.6036 - val_binary_accuracy: 0.6670\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6645 - val_loss: 0.6038 - val_binary_accuracy: 0.6681\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6079 - binary_accuracy: 0.6649 - val_loss: 0.6029 - val_binary_accuracy: 0.6670\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6640 - val_loss: 0.6033 - val_binary_accuracy: 0.6670\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6055 - binary_accuracy: 0.6662 - val_loss: 0.6035 - val_binary_accuracy: 0.6681\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6673 - val_loss: 0.6030 - val_binary_accuracy: 0.6678\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6712 - val_loss: 0.6033 - val_binary_accuracy: 0.6670\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6683 - val_loss: 0.6032 - val_binary_accuracy: 0.6663\n",
            "Epoch 21/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.6716 - val_loss: 0.6027 - val_binary_accuracy: 0.6670\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6664 - val_loss: 0.6030 - val_binary_accuracy: 0.6652\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6733 - val_loss: 0.6027 - val_binary_accuracy: 0.6681\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6700 - val_loss: 0.6026 - val_binary_accuracy: 0.6670\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6687 - val_loss: 0.6027 - val_binary_accuracy: 0.6685\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6676 - val_loss: 0.6023 - val_binary_accuracy: 0.6704\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.6745 - val_loss: 0.6026 - val_binary_accuracy: 0.6681\n",
            "Epoch 28/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6037 - binary_accuracy: 0.6721 - val_loss: 0.6035 - val_binary_accuracy: 0.6659\n",
            "Epoch 29/200\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6750 - val_loss: 0.6026 - val_binary_accuracy: 0.6663\n",
            "Epoch 30/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6749 - val_loss: 0.6028 - val_binary_accuracy: 0.6678\n",
            "Epoch 31/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6708 - val_loss: 0.6026 - val_binary_accuracy: 0.6670\n",
            "Epoch 32/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6779 - val_loss: 0.6025 - val_binary_accuracy: 0.6667\n",
            "Epoch 33/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6658 - val_loss: 0.6021 - val_binary_accuracy: 0.6674\n",
            "Epoch 34/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6764 - val_loss: 0.6019 - val_binary_accuracy: 0.6696\n",
            "Epoch 35/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6703 - val_loss: 0.6020 - val_binary_accuracy: 0.6715\n",
            "Epoch 36/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6776 - val_loss: 0.6019 - val_binary_accuracy: 0.6704\n",
            "Epoch 37/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6782 - val_loss: 0.6016 - val_binary_accuracy: 0.6711\n",
            "Epoch 38/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6767 - val_loss: 0.6016 - val_binary_accuracy: 0.6674\n",
            "Epoch 39/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6700 - val_loss: 0.6019 - val_binary_accuracy: 0.6685\n",
            "Epoch 40/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6807 - val_loss: 0.6014 - val_binary_accuracy: 0.6700\n",
            "Epoch 41/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5993 - binary_accuracy: 0.6736 - val_loss: 0.6020 - val_binary_accuracy: 0.6659\n",
            "Epoch 42/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6772 - val_loss: 0.6018 - val_binary_accuracy: 0.6685\n",
            "Epoch 43/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6772 - val_loss: 0.6020 - val_binary_accuracy: 0.6663\n",
            "Epoch 44/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5975 - binary_accuracy: 0.6768 - val_loss: 0.6014 - val_binary_accuracy: 0.6700\n",
            "Epoch 45/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6762 - val_loss: 0.6015 - val_binary_accuracy: 0.6707\n",
            "Epoch 46/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6768 - val_loss: 0.6017 - val_binary_accuracy: 0.6704\n",
            "Epoch 47/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6718 - val_loss: 0.6018 - val_binary_accuracy: 0.6693\n",
            "Epoch 48/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6814 - val_loss: 0.6014 - val_binary_accuracy: 0.6719\n",
            "Epoch 49/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6768 - val_loss: 0.6018 - val_binary_accuracy: 0.6693\n",
            "Epoch 50/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6763 - val_loss: 0.6016 - val_binary_accuracy: 0.6693\n",
            "Epoch 51/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6748 - val_loss: 0.6020 - val_binary_accuracy: 0.6700\n",
            "Epoch 52/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6791 - val_loss: 0.6017 - val_binary_accuracy: 0.6704\n",
            "Epoch 53/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6756 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 54/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6770 - val_loss: 0.6014 - val_binary_accuracy: 0.6715\n",
            "Epoch 55/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6777 - val_loss: 0.6011 - val_binary_accuracy: 0.6707\n",
            "Epoch 56/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.6803 - val_loss: 0.6010 - val_binary_accuracy: 0.6719\n",
            "Epoch 57/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5967 - binary_accuracy: 0.6767 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 58/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5922 - binary_accuracy: 0.6798 - val_loss: 0.6012 - val_binary_accuracy: 0.6733\n",
            "Epoch 59/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6747 - val_loss: 0.6016 - val_binary_accuracy: 0.6704\n",
            "Epoch 60/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5971 - binary_accuracy: 0.6742 - val_loss: 0.6022 - val_binary_accuracy: 0.6711\n",
            "Epoch 61/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5935 - binary_accuracy: 0.6841 - val_loss: 0.6017 - val_binary_accuracy: 0.6715\n",
            "Epoch 62/200\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5956 - binary_accuracy: 0.6787 - val_loss: 0.6014 - val_binary_accuracy: 0.6722\n",
            "Epoch 63/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.6813 - val_loss: 0.6015 - val_binary_accuracy: 0.6715\n",
            "Epoch 64/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5928 - binary_accuracy: 0.6820 - val_loss: 0.6014 - val_binary_accuracy: 0.6693\n",
            "Epoch 65/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5930 - binary_accuracy: 0.6813 - val_loss: 0.6011 - val_binary_accuracy: 0.6711\n",
            "Epoch 66/200\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5954 - binary_accuracy: 0.6795 - val_loss: 0.6015 - val_binary_accuracy: 0.6719\n",
            "Epoch 00066: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:45,404]\u001b[0m Trial 93 finished with value: 0.6679021716117859 and parameters: {'batch size': 200, 'optimizer': 'Adagrad', 'lr': 0.060443406144387216, 'minimum_learning_rate': 0.03646532490962026}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "53/53 [==============================] - 1s 5ms/step - loss: 0.6667 - binary_accuracy: 0.5943 - val_loss: 0.6330 - val_binary_accuracy: 0.6422\n",
            "Epoch 2/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6422 - binary_accuracy: 0.6196 - val_loss: 0.6242 - val_binary_accuracy: 0.6526\n",
            "Epoch 3/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6323 - binary_accuracy: 0.6351 - val_loss: 0.6174 - val_binary_accuracy: 0.6656\n",
            "Epoch 4/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6416 - val_loss: 0.6109 - val_binary_accuracy: 0.6745\n",
            "Epoch 5/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6213 - binary_accuracy: 0.6497 - val_loss: 0.6099 - val_binary_accuracy: 0.6741\n",
            "Epoch 6/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6193 - binary_accuracy: 0.6524 - val_loss: 0.6078 - val_binary_accuracy: 0.6689\n",
            "Epoch 7/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6556 - val_loss: 0.6061 - val_binary_accuracy: 0.6700\n",
            "Epoch 8/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6160 - binary_accuracy: 0.6524 - val_loss: 0.6056 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6124 - binary_accuracy: 0.6564 - val_loss: 0.6064 - val_binary_accuracy: 0.6700\n",
            "Epoch 10/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6088 - binary_accuracy: 0.6671 - val_loss: 0.6053 - val_binary_accuracy: 0.6733\n",
            "Epoch 11/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6610 - val_loss: 0.6044 - val_binary_accuracy: 0.6696\n",
            "Epoch 12/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.6667 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 13/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6060 - binary_accuracy: 0.6721 - val_loss: 0.6025 - val_binary_accuracy: 0.6715\n",
            "Epoch 14/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6681 - val_loss: 0.6023 - val_binary_accuracy: 0.6719\n",
            "Epoch 15/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6696 - val_loss: 0.6016 - val_binary_accuracy: 0.6763\n",
            "Epoch 16/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.6712 - val_loss: 0.6015 - val_binary_accuracy: 0.6730\n",
            "Epoch 17/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6755 - val_loss: 0.6018 - val_binary_accuracy: 0.6707\n",
            "Epoch 18/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6694 - val_loss: 0.6018 - val_binary_accuracy: 0.6726\n",
            "Epoch 19/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6683 - val_loss: 0.6019 - val_binary_accuracy: 0.6774\n",
            "Epoch 20/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6721 - val_loss: 0.6014 - val_binary_accuracy: 0.6782\n",
            "Epoch 21/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6759 - val_loss: 0.6021 - val_binary_accuracy: 0.6756\n",
            "Epoch 22/200\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5987 - binary_accuracy: 0.6755 - val_loss: 0.6019 - val_binary_accuracy: 0.6704\n",
            "Epoch 23/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5998 - binary_accuracy: 0.6739 - val_loss: 0.6017 - val_binary_accuracy: 0.6719\n",
            "Epoch 24/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5969 - binary_accuracy: 0.6753 - val_loss: 0.6013 - val_binary_accuracy: 0.6711\n",
            "Epoch 25/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6755 - val_loss: 0.6012 - val_binary_accuracy: 0.6700\n",
            "Epoch 26/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6005 - binary_accuracy: 0.6771 - val_loss: 0.6013 - val_binary_accuracy: 0.6733\n",
            "Epoch 27/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6772 - val_loss: 0.6015 - val_binary_accuracy: 0.6704\n",
            "Epoch 28/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6773 - val_loss: 0.6011 - val_binary_accuracy: 0.6752\n",
            "Epoch 29/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6699 - val_loss: 0.6011 - val_binary_accuracy: 0.6681\n",
            "Epoch 30/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6750 - val_loss: 0.6009 - val_binary_accuracy: 0.6719\n",
            "Epoch 31/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6749 - val_loss: 0.6008 - val_binary_accuracy: 0.6733\n",
            "Epoch 32/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6709 - val_loss: 0.6014 - val_binary_accuracy: 0.6704\n",
            "Epoch 33/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6742 - val_loss: 0.6013 - val_binary_accuracy: 0.6700\n",
            "Epoch 34/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6729 - val_loss: 0.6014 - val_binary_accuracy: 0.6689\n",
            "Epoch 35/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6762 - val_loss: 0.6015 - val_binary_accuracy: 0.6678\n",
            "Epoch 36/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6699 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 37/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6736 - val_loss: 0.6015 - val_binary_accuracy: 0.6707\n",
            "Epoch 38/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6758 - val_loss: 0.6016 - val_binary_accuracy: 0.6700\n",
            "Epoch 39/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5941 - binary_accuracy: 0.6774 - val_loss: 0.6013 - val_binary_accuracy: 0.6722\n",
            "Epoch 40/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5987 - binary_accuracy: 0.6795 - val_loss: 0.6012 - val_binary_accuracy: 0.6730\n",
            "Epoch 41/200\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6764 - val_loss: 0.6013 - val_binary_accuracy: 0.6715\n",
            "Epoch 00041: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:37:53,322]\u001b[0m Trial 94 finished with value: 0.6764270067214966 and parameters: {'batch size': 238, 'optimizer': 'Adagrad', 'lr': 0.0910130338559842, 'minimum_learning_rate': 0.02884752012890941}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "59/59 [==============================] - 1s 5ms/step - loss: 0.6784 - binary_accuracy: 0.5883 - val_loss: 0.6408 - val_binary_accuracy: 0.6359\n",
            "Epoch 2/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6362 - binary_accuracy: 0.6317 - val_loss: 0.6207 - val_binary_accuracy: 0.6548\n",
            "Epoch 3/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6394 - val_loss: 0.6175 - val_binary_accuracy: 0.6593\n",
            "Epoch 4/200\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.6242 - binary_accuracy: 0.6416 - val_loss: 0.6118 - val_binary_accuracy: 0.6637\n",
            "Epoch 5/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6179 - binary_accuracy: 0.6509 - val_loss: 0.6098 - val_binary_accuracy: 0.6711\n",
            "Epoch 6/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.6563 - val_loss: 0.6082 - val_binary_accuracy: 0.6722\n",
            "Epoch 7/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.6600 - val_loss: 0.6068 - val_binary_accuracy: 0.6737\n",
            "Epoch 8/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6615 - val_loss: 0.6049 - val_binary_accuracy: 0.6741\n",
            "Epoch 9/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6097 - binary_accuracy: 0.6620 - val_loss: 0.6066 - val_binary_accuracy: 0.6707\n",
            "Epoch 10/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6605 - val_loss: 0.6041 - val_binary_accuracy: 0.6741\n",
            "Epoch 11/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_accuracy: 0.6637 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 12/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6685 - val_loss: 0.6038 - val_binary_accuracy: 0.6704\n",
            "Epoch 13/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6076 - binary_accuracy: 0.6597 - val_loss: 0.6049 - val_binary_accuracy: 0.6737\n",
            "Epoch 14/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6697 - val_loss: 0.6012 - val_binary_accuracy: 0.6722\n",
            "Epoch 15/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6721 - val_loss: 0.6020 - val_binary_accuracy: 0.6726\n",
            "Epoch 16/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6035 - binary_accuracy: 0.6726 - val_loss: 0.6016 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6715 - val_loss: 0.6018 - val_binary_accuracy: 0.6681\n",
            "Epoch 18/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6711 - val_loss: 0.6008 - val_binary_accuracy: 0.6730\n",
            "Epoch 19/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6711 - val_loss: 0.6011 - val_binary_accuracy: 0.6719\n",
            "Epoch 20/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6729 - val_loss: 0.6015 - val_binary_accuracy: 0.6733\n",
            "Epoch 21/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6736 - val_loss: 0.6016 - val_binary_accuracy: 0.6707\n",
            "Epoch 22/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6723 - val_loss: 0.6013 - val_binary_accuracy: 0.6711\n",
            "Epoch 23/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.6762 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 24/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.6731 - val_loss: 0.6009 - val_binary_accuracy: 0.6704\n",
            "Epoch 25/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6730 - val_loss: 0.6008 - val_binary_accuracy: 0.6722\n",
            "Epoch 26/200\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.5987 - binary_accuracy: 0.6777 - val_loss: 0.6010 - val_binary_accuracy: 0.6726\n",
            "Epoch 27/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6774 - val_loss: 0.6011 - val_binary_accuracy: 0.6741\n",
            "Epoch 28/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5977 - binary_accuracy: 0.6747 - val_loss: 0.6006 - val_binary_accuracy: 0.6730\n",
            "Epoch 29/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6743 - val_loss: 0.6010 - val_binary_accuracy: 0.6782\n",
            "Epoch 30/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6710 - val_loss: 0.6012 - val_binary_accuracy: 0.6752\n",
            "Epoch 31/200\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.6008 - binary_accuracy: 0.6754 - val_loss: 0.6009 - val_binary_accuracy: 0.6752\n",
            "Epoch 32/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6760 - val_loss: 0.6006 - val_binary_accuracy: 0.6745\n",
            "Epoch 33/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6767 - val_loss: 0.6006 - val_binary_accuracy: 0.6711\n",
            "Epoch 34/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6780 - val_loss: 0.6003 - val_binary_accuracy: 0.6719\n",
            "Epoch 35/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.6780 - val_loss: 0.6004 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6766 - val_loss: 0.6002 - val_binary_accuracy: 0.6748\n",
            "Epoch 37/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6747 - val_loss: 0.6003 - val_binary_accuracy: 0.6745\n",
            "Epoch 38/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6745 - val_loss: 0.6005 - val_binary_accuracy: 0.6707\n",
            "Epoch 39/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5944 - binary_accuracy: 0.6792 - val_loss: 0.6001 - val_binary_accuracy: 0.6748\n",
            "Epoch 40/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5960 - binary_accuracy: 0.6752 - val_loss: 0.5999 - val_binary_accuracy: 0.6722\n",
            "Epoch 41/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.6732 - val_loss: 0.6002 - val_binary_accuracy: 0.6711\n",
            "Epoch 42/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.6773 - val_loss: 0.6003 - val_binary_accuracy: 0.6722\n",
            "Epoch 43/200\n",
            "59/59 [==============================] - 0s 4ms/step - loss: 0.5949 - binary_accuracy: 0.6787 - val_loss: 0.6001 - val_binary_accuracy: 0.6726\n",
            "Epoch 44/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5966 - binary_accuracy: 0.6770 - val_loss: 0.6002 - val_binary_accuracy: 0.6715\n",
            "Epoch 45/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6732 - val_loss: 0.6007 - val_binary_accuracy: 0.6711\n",
            "Epoch 46/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5948 - binary_accuracy: 0.6752 - val_loss: 0.6007 - val_binary_accuracy: 0.6696\n",
            "Epoch 47/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5973 - binary_accuracy: 0.6748 - val_loss: 0.6008 - val_binary_accuracy: 0.6715\n",
            "Epoch 48/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5909 - binary_accuracy: 0.6773 - val_loss: 0.6005 - val_binary_accuracy: 0.6730\n",
            "Epoch 49/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5934 - binary_accuracy: 0.6778 - val_loss: 0.6003 - val_binary_accuracy: 0.6711\n",
            "Epoch 50/200\n",
            "59/59 [==============================] - 0s 3ms/step - loss: 0.5924 - binary_accuracy: 0.6776 - val_loss: 0.6004 - val_binary_accuracy: 0.6730\n",
            "Epoch 00050: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:38:03,337]\u001b[0m Trial 95 finished with value: 0.6623424887657166 and parameters: {'batch size': 215, 'optimizer': 'Adagrad', 'lr': 0.08424799824053938, 'minimum_learning_rate': 0.029327175799527934}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "54/54 [==============================] - 1s 5ms/step - loss: 0.6727 - binary_accuracy: 0.5909 - val_loss: 0.6344 - val_binary_accuracy: 0.6511\n",
            "Epoch 2/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6240 - val_loss: 0.6215 - val_binary_accuracy: 0.6529\n",
            "Epoch 3/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6366 - val_loss: 0.6247 - val_binary_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_accuracy: 0.6421 - val_loss: 0.6138 - val_binary_accuracy: 0.6652\n",
            "Epoch 5/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6212 - binary_accuracy: 0.6509 - val_loss: 0.6097 - val_binary_accuracy: 0.6707\n",
            "Epoch 6/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6183 - binary_accuracy: 0.6539 - val_loss: 0.6056 - val_binary_accuracy: 0.6715\n",
            "Epoch 7/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6599 - val_loss: 0.6071 - val_binary_accuracy: 0.6782\n",
            "Epoch 8/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.6604 - val_loss: 0.6067 - val_binary_accuracy: 0.6752\n",
            "Epoch 9/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6606 - val_loss: 0.6032 - val_binary_accuracy: 0.6748\n",
            "Epoch 10/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6089 - binary_accuracy: 0.6641 - val_loss: 0.6037 - val_binary_accuracy: 0.6704\n",
            "Epoch 11/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6645 - val_loss: 0.6053 - val_binary_accuracy: 0.6659\n",
            "Epoch 12/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.6724 - val_loss: 0.6051 - val_binary_accuracy: 0.6652\n",
            "Epoch 13/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.6724 - val_loss: 0.6020 - val_binary_accuracy: 0.6648\n",
            "Epoch 14/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6702 - val_loss: 0.6020 - val_binary_accuracy: 0.6745\n",
            "Epoch 15/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6694 - val_loss: 0.6012 - val_binary_accuracy: 0.6722\n",
            "Epoch 16/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6695 - val_loss: 0.6004 - val_binary_accuracy: 0.6707\n",
            "Epoch 17/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6702 - val_loss: 0.6014 - val_binary_accuracy: 0.6704\n",
            "Epoch 18/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6031 - binary_accuracy: 0.6683 - val_loss: 0.6005 - val_binary_accuracy: 0.6752\n",
            "Epoch 19/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6688 - val_loss: 0.6017 - val_binary_accuracy: 0.6763\n",
            "Epoch 20/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6718 - val_loss: 0.6012 - val_binary_accuracy: 0.6726\n",
            "Epoch 21/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6695 - val_loss: 0.6014 - val_binary_accuracy: 0.6693\n",
            "Epoch 22/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6007 - binary_accuracy: 0.6728 - val_loss: 0.6011 - val_binary_accuracy: 0.6733\n",
            "Epoch 23/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6019 - binary_accuracy: 0.6738 - val_loss: 0.6010 - val_binary_accuracy: 0.6730\n",
            "Epoch 24/200\n",
            "54/54 [==============================] - 0s 4ms/step - loss: 0.6005 - binary_accuracy: 0.6737 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 25/200\n",
            "54/54 [==============================] - 0s 5ms/step - loss: 0.6013 - binary_accuracy: 0.6730 - val_loss: 0.6017 - val_binary_accuracy: 0.6763\n",
            "Epoch 26/200\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6733 - val_loss: 0.6010 - val_binary_accuracy: 0.6719\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:38:08,682]\u001b[0m Trial 96 finished with value: 0.6660489439964294 and parameters: {'batch size': 237, 'optimizer': 'Adagrad', 'lr': 0.08864202900820924, 'minimum_learning_rate': 0.02737304205331209}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "55/55 [==============================] - 1s 5ms/step - loss: 0.6746 - binary_accuracy: 0.5974 - val_loss: 0.6332 - val_binary_accuracy: 0.6385\n",
            "Epoch 2/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.6246 - val_loss: 0.6217 - val_binary_accuracy: 0.6574\n",
            "Epoch 3/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6304 - binary_accuracy: 0.6401 - val_loss: 0.6138 - val_binary_accuracy: 0.6589\n",
            "Epoch 4/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6233 - binary_accuracy: 0.6414 - val_loss: 0.6108 - val_binary_accuracy: 0.6685\n",
            "Epoch 5/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6234 - binary_accuracy: 0.6491 - val_loss: 0.6089 - val_binary_accuracy: 0.6622\n",
            "Epoch 6/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.6532 - val_loss: 0.6083 - val_binary_accuracy: 0.6656\n",
            "Epoch 7/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6550 - val_loss: 0.6043 - val_binary_accuracy: 0.6722\n",
            "Epoch 8/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.6663 - val_loss: 0.6047 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6609 - val_loss: 0.6047 - val_binary_accuracy: 0.6696\n",
            "Epoch 10/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6090 - binary_accuracy: 0.6594 - val_loss: 0.6038 - val_binary_accuracy: 0.6689\n",
            "Epoch 11/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6708 - val_loss: 0.6037 - val_binary_accuracy: 0.6689\n",
            "Epoch 12/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.6649 - val_loss: 0.6031 - val_binary_accuracy: 0.6685\n",
            "Epoch 13/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6710 - val_loss: 0.6029 - val_binary_accuracy: 0.6704\n",
            "Epoch 14/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6027 - binary_accuracy: 0.6694 - val_loss: 0.6010 - val_binary_accuracy: 0.6700\n",
            "Epoch 15/200\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 0.6031 - binary_accuracy: 0.6726 - val_loss: 0.6003 - val_binary_accuracy: 0.6667\n",
            "Epoch 16/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6677 - val_loss: 0.6015 - val_binary_accuracy: 0.6693\n",
            "Epoch 17/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6042 - binary_accuracy: 0.6721 - val_loss: 0.6011 - val_binary_accuracy: 0.6715\n",
            "Epoch 18/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6702 - val_loss: 0.6019 - val_binary_accuracy: 0.6681\n",
            "Epoch 19/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6693 - val_loss: 0.6006 - val_binary_accuracy: 0.6693\n",
            "Epoch 20/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6727 - val_loss: 0.6003 - val_binary_accuracy: 0.6715\n",
            "Epoch 21/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6683 - val_loss: 0.6006 - val_binary_accuracy: 0.6733\n",
            "Epoch 22/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6737 - val_loss: 0.6002 - val_binary_accuracy: 0.6711\n",
            "Epoch 23/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6685 - val_loss: 0.6005 - val_binary_accuracy: 0.6733\n",
            "Epoch 24/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5981 - binary_accuracy: 0.6797 - val_loss: 0.6006 - val_binary_accuracy: 0.6700\n",
            "Epoch 25/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6741 - val_loss: 0.6002 - val_binary_accuracy: 0.6730\n",
            "Epoch 26/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6758 - val_loss: 0.6005 - val_binary_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6776 - val_loss: 0.6001 - val_binary_accuracy: 0.6730\n",
            "Epoch 28/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5991 - binary_accuracy: 0.6714 - val_loss: 0.6001 - val_binary_accuracy: 0.6715\n",
            "Epoch 29/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6008 - binary_accuracy: 0.6735 - val_loss: 0.6003 - val_binary_accuracy: 0.6726\n",
            "Epoch 30/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6742 - val_loss: 0.6003 - val_binary_accuracy: 0.6726\n",
            "Epoch 31/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6791 - val_loss: 0.6004 - val_binary_accuracy: 0.6711\n",
            "Epoch 32/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6794 - val_loss: 0.6003 - val_binary_accuracy: 0.6748\n",
            "Epoch 33/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5976 - binary_accuracy: 0.6724 - val_loss: 0.6002 - val_binary_accuracy: 0.6726\n",
            "Epoch 34/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6707 - val_loss: 0.6005 - val_binary_accuracy: 0.6707\n",
            "Epoch 35/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6760 - val_loss: 0.6003 - val_binary_accuracy: 0.6707\n",
            "Epoch 36/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6704 - val_loss: 0.6004 - val_binary_accuracy: 0.6733\n",
            "Epoch 37/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6741 - val_loss: 0.6001 - val_binary_accuracy: 0.6741\n",
            "Epoch 00037: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:38:15,962]\u001b[0m Trial 97 finished with value: 0.6749444007873535 and parameters: {'batch size': 230, 'optimizer': 'Adagrad', 'lr': 0.09498796179241432, 'minimum_learning_rate': 0.023007770774624507}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "55/55 [==============================] - 1s 5ms/step - loss: 0.6722 - binary_accuracy: 0.5915 - val_loss: 0.6317 - val_binary_accuracy: 0.6496\n",
            "Epoch 2/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.6250 - val_loss: 0.6233 - val_binary_accuracy: 0.6570\n",
            "Epoch 3/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6306 - binary_accuracy: 0.6316 - val_loss: 0.6151 - val_binary_accuracy: 0.6644\n",
            "Epoch 4/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_accuracy: 0.6481 - val_loss: 0.6150 - val_binary_accuracy: 0.6670\n",
            "Epoch 5/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6197 - binary_accuracy: 0.6518 - val_loss: 0.6072 - val_binary_accuracy: 0.6696\n",
            "Epoch 6/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6159 - binary_accuracy: 0.6537 - val_loss: 0.6072 - val_binary_accuracy: 0.6696\n",
            "Epoch 7/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6643 - val_loss: 0.6038 - val_binary_accuracy: 0.6737\n",
            "Epoch 8/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6614 - val_loss: 0.6054 - val_binary_accuracy: 0.6726\n",
            "Epoch 9/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6109 - binary_accuracy: 0.6573 - val_loss: 0.6037 - val_binary_accuracy: 0.6767\n",
            "Epoch 10/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6639 - val_loss: 0.6013 - val_binary_accuracy: 0.6778\n",
            "Epoch 11/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6668 - val_loss: 0.6029 - val_binary_accuracy: 0.6741\n",
            "Epoch 12/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6065 - binary_accuracy: 0.6675 - val_loss: 0.6032 - val_binary_accuracy: 0.6785\n",
            "Epoch 13/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.6670 - val_loss: 0.6002 - val_binary_accuracy: 0.6767\n",
            "Epoch 14/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6675 - val_loss: 0.6011 - val_binary_accuracy: 0.6733\n",
            "Epoch 15/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6043 - binary_accuracy: 0.6708 - val_loss: 0.6023 - val_binary_accuracy: 0.6767\n",
            "Epoch 16/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.6698 - val_loss: 0.6001 - val_binary_accuracy: 0.6789\n",
            "Epoch 17/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6033 - binary_accuracy: 0.6714 - val_loss: 0.6018 - val_binary_accuracy: 0.6770\n",
            "Epoch 18/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6688 - val_loss: 0.6010 - val_binary_accuracy: 0.6770\n",
            "Epoch 19/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6066 - binary_accuracy: 0.6671 - val_loss: 0.6027 - val_binary_accuracy: 0.6767\n",
            "Epoch 20/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.6751 - val_loss: 0.6013 - val_binary_accuracy: 0.6808\n",
            "Epoch 21/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6012 - binary_accuracy: 0.6760 - val_loss: 0.6015 - val_binary_accuracy: 0.6782\n",
            "Epoch 22/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6013 - binary_accuracy: 0.6722 - val_loss: 0.6015 - val_binary_accuracy: 0.6756\n",
            "Epoch 23/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6000 - binary_accuracy: 0.6768 - val_loss: 0.6013 - val_binary_accuracy: 0.6800\n",
            "Epoch 24/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5970 - binary_accuracy: 0.6799 - val_loss: 0.6008 - val_binary_accuracy: 0.6796\n",
            "Epoch 25/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.6015 - binary_accuracy: 0.6717 - val_loss: 0.6010 - val_binary_accuracy: 0.6793\n",
            "Epoch 26/200\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 0.5949 - binary_accuracy: 0.6766 - val_loss: 0.6007 - val_binary_accuracy: 0.6804\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:38:21,597]\u001b[0m Trial 98 finished with value: 0.6738324761390686 and parameters: {'batch size': 230, 'optimizer': 'Adagrad', 'lr': 0.09730973570582721, 'minimum_learning_rate': 0.018564010595486055}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "57/57 [==============================] - 1s 5ms/step - loss: 0.6657 - binary_accuracy: 0.6072 - val_loss: 0.6264 - val_binary_accuracy: 0.6604\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6308 - val_loss: 0.6133 - val_binary_accuracy: 0.6696\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6269 - binary_accuracy: 0.6408 - val_loss: 0.6112 - val_binary_accuracy: 0.6745\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6227 - binary_accuracy: 0.6499 - val_loss: 0.6089 - val_binary_accuracy: 0.6733\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6158 - binary_accuracy: 0.6563 - val_loss: 0.6049 - val_binary_accuracy: 0.6719\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6135 - binary_accuracy: 0.6598 - val_loss: 0.6028 - val_binary_accuracy: 0.6737\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.6549 - val_loss: 0.6042 - val_binary_accuracy: 0.6715\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6122 - binary_accuracy: 0.6590 - val_loss: 0.6044 - val_binary_accuracy: 0.6722\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_accuracy: 0.6663 - val_loss: 0.6041 - val_binary_accuracy: 0.6752\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6078 - binary_accuracy: 0.6656 - val_loss: 0.6035 - val_binary_accuracy: 0.6722\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6058 - binary_accuracy: 0.6619 - val_loss: 0.6027 - val_binary_accuracy: 0.6711\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6046 - binary_accuracy: 0.6706 - val_loss: 0.6028 - val_binary_accuracy: 0.6715\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.6695 - val_loss: 0.6029 - val_binary_accuracy: 0.6711\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6072 - binary_accuracy: 0.6677 - val_loss: 0.6031 - val_binary_accuracy: 0.6756\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6050 - binary_accuracy: 0.6705 - val_loss: 0.6020 - val_binary_accuracy: 0.6752\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6036 - binary_accuracy: 0.6693 - val_loss: 0.6019 - val_binary_accuracy: 0.6756\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.6669 - val_loss: 0.6022 - val_binary_accuracy: 0.6726\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6057 - binary_accuracy: 0.6689 - val_loss: 0.6021 - val_binary_accuracy: 0.6737\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6698 - val_loss: 0.6017 - val_binary_accuracy: 0.6733\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6028 - binary_accuracy: 0.6715 - val_loss: 0.6016 - val_binary_accuracy: 0.6719\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6745 - val_loss: 0.6016 - val_binary_accuracy: 0.6741\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_accuracy: 0.6685 - val_loss: 0.6018 - val_binary_accuracy: 0.6707\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6038 - binary_accuracy: 0.6725 - val_loss: 0.6016 - val_binary_accuracy: 0.6722\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6044 - binary_accuracy: 0.6711 - val_loss: 0.6015 - val_binary_accuracy: 0.6745\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6023 - binary_accuracy: 0.6748 - val_loss: 0.6015 - val_binary_accuracy: 0.6715\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6014 - binary_accuracy: 0.6705 - val_loss: 0.6014 - val_binary_accuracy: 0.6696\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6020 - binary_accuracy: 0.6719 - val_loss: 0.6010 - val_binary_accuracy: 0.6733\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6026 - binary_accuracy: 0.6748 - val_loss: 0.6013 - val_binary_accuracy: 0.6711\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.6698 - val_loss: 0.6012 - val_binary_accuracy: 0.6719\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 0.6722 - val_loss: 0.6011 - val_binary_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.6733 - val_loss: 0.6013 - val_binary_accuracy: 0.6737\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.6729 - val_loss: 0.6014 - val_binary_accuracy: 0.6715\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.6777 - val_loss: 0.6011 - val_binary_accuracy: 0.6722\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.6768 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.6756 - val_loss: 0.6011 - val_binary_accuracy: 0.6730\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5988 - binary_accuracy: 0.6754 - val_loss: 0.6007 - val_binary_accuracy: 0.6733\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6002 - binary_accuracy: 0.6751 - val_loss: 0.6007 - val_binary_accuracy: 0.6726\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6756 - val_loss: 0.6007 - val_binary_accuracy: 0.6745\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5995 - binary_accuracy: 0.6760 - val_loss: 0.6007 - val_binary_accuracy: 0.6748\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5974 - binary_accuracy: 0.6759 - val_loss: 0.6006 - val_binary_accuracy: 0.6730\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.6776 - val_loss: 0.6006 - val_binary_accuracy: 0.6737\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6018 - binary_accuracy: 0.6717 - val_loss: 0.6009 - val_binary_accuracy: 0.6726\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6017 - binary_accuracy: 0.6745 - val_loss: 0.6011 - val_binary_accuracy: 0.6730\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5978 - binary_accuracy: 0.6773 - val_loss: 0.6008 - val_binary_accuracy: 0.6726\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.6745 - val_loss: 0.6009 - val_binary_accuracy: 0.6722\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.6775 - val_loss: 0.6007 - val_binary_accuracy: 0.6737\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5992 - binary_accuracy: 0.6738 - val_loss: 0.6007 - val_binary_accuracy: 0.6730\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5990 - binary_accuracy: 0.6721 - val_loss: 0.6009 - val_binary_accuracy: 0.6715\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5996 - binary_accuracy: 0.6752 - val_loss: 0.6012 - val_binary_accuracy: 0.6711\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6003 - binary_accuracy: 0.6720 - val_loss: 0.6013 - val_binary_accuracy: 0.6719\n",
            "Epoch 00050: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-19 20:38:31,117]\u001b[0m Trial 99 finished with value: 0.6734617948532104 and parameters: {'batch size': 221, 'optimizer': 'Adagrad', 'lr': 0.09804537512932607, 'minimum_learning_rate': 0.02055737140821968}. Best is trial 25 with value: 0.678280234336853.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'batch size': 118, 'optimizer': 'Adagrad', 'lr': 0.032214580661926416, 'minimum_learning_rate': 0.004712080335294012}\n",
            "best accuracy: 0.678280234336853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ESASyy2MyHku",
        "outputId": "8418493a-c686-4086-92d9-44678c17ca7f"
      },
      "source": [
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(keras.layers.Dropout(rate=0.2)) \n",
        "model.add(keras.layers.Dense(64,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(32,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.032), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0047,verbose=1)\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint('current_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)#patience-kolik epoch se nezmění val_loss pak stop\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=200, shuffle=True,batch_size=118,validation_data=(X_val, y_val), \n",
        "                    callbacks=[reduce_lr_callback,checkpoint_callback,early_stopping_callback])#steps\n",
        "train_predictions= model.predict(X_train)\n",
        "train_accuracy_score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {:.2%} \\n Error on training data: {:.2%}'.format(train_accuracy_score[1],  1 - train_accuracy_score[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "test_predictions= model.predict(X_test)\n",
        "test_accuracy_score= model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {:.2%} \\n Error on test data: {:.2%}'.format(test_accuracy_score[1], 1 - test_accuracy_score[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "107/107 [==============================] - 1s 3ms/step - loss: 0.6804 - binary_accuracy: 0.5875 - val_loss: 0.6360 - val_binary_accuracy: 0.6426\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.63596, saving model to current_model.h5\n",
            "Epoch 2/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6479 - binary_accuracy: 0.6122 - val_loss: 0.6253 - val_binary_accuracy: 0.6589\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.63596 to 0.62530, saving model to current_model.h5\n",
            "Epoch 3/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6351 - val_loss: 0.6146 - val_binary_accuracy: 0.6696\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.62530 to 0.61459, saving model to current_model.h5\n",
            "Epoch 4/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6412 - val_loss: 0.6101 - val_binary_accuracy: 0.6726\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.61459 to 0.61007, saving model to current_model.h5\n",
            "Epoch 5/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6451 - val_loss: 0.6083 - val_binary_accuracy: 0.6681\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.61007 to 0.60825, saving model to current_model.h5\n",
            "Epoch 6/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6520 - val_loss: 0.6058 - val_binary_accuracy: 0.6689\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.60825 to 0.60576, saving model to current_model.h5\n",
            "Epoch 7/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6540 - val_loss: 0.6041 - val_binary_accuracy: 0.6715\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.60576 to 0.60411, saving model to current_model.h5\n",
            "Epoch 8/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6555 - val_loss: 0.6037 - val_binary_accuracy: 0.6700\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.60411 to 0.60369, saving model to current_model.h5\n",
            "Epoch 9/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6569 - val_loss: 0.6012 - val_binary_accuracy: 0.6770\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.60369 to 0.60118, saving model to current_model.h5\n",
            "Epoch 10/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6602 - val_loss: 0.6012 - val_binary_accuracy: 0.6704\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.60118\n",
            "Epoch 11/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6624 - val_loss: 0.6001 - val_binary_accuracy: 0.6730\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.60118 to 0.60007, saving model to current_model.h5\n",
            "Epoch 12/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6088 - binary_accuracy: 0.6610 - val_loss: 0.5999 - val_binary_accuracy: 0.6704\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.60007 to 0.59994, saving model to current_model.h5\n",
            "Epoch 13/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6568 - val_loss: 0.6012 - val_binary_accuracy: 0.6748\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.59994\n",
            "Epoch 14/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6068 - binary_accuracy: 0.6618 - val_loss: 0.5998 - val_binary_accuracy: 0.6759\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.59994 to 0.59985, saving model to current_model.h5\n",
            "Epoch 15/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6078 - binary_accuracy: 0.6626 - val_loss: 0.5994 - val_binary_accuracy: 0.6767\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.59985 to 0.59940, saving model to current_model.h5\n",
            "Epoch 16/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6675 - val_loss: 0.5996 - val_binary_accuracy: 0.6782\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.59940\n",
            "Epoch 17/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6690 - val_loss: 0.5998 - val_binary_accuracy: 0.6759\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.59940\n",
            "Epoch 18/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6052 - binary_accuracy: 0.6675 - val_loss: 0.6001 - val_binary_accuracy: 0.6748\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.01600000075995922.\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.59940\n",
            "Epoch 19/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6633 - val_loss: 0.5999 - val_binary_accuracy: 0.6804\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.59940\n",
            "Epoch 20/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.6717 - val_loss: 0.5994 - val_binary_accuracy: 0.6752\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.59940\n",
            "Epoch 21/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6053 - binary_accuracy: 0.6682 - val_loss: 0.5996 - val_binary_accuracy: 0.6782\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00800000037997961.\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.59940\n",
            "Epoch 22/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6046 - binary_accuracy: 0.6655 - val_loss: 0.5995 - val_binary_accuracy: 0.6774\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.59940\n",
            "Epoch 23/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6690 - val_loss: 0.5994 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.59940 to 0.59938, saving model to current_model.h5\n",
            "Epoch 24/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6025 - binary_accuracy: 0.6696 - val_loss: 0.5993 - val_binary_accuracy: 0.6782\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.59938 to 0.59927, saving model to current_model.h5\n",
            "Epoch 25/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6026 - binary_accuracy: 0.6687 - val_loss: 0.5992 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.59927 to 0.59925, saving model to current_model.h5\n",
            "Epoch 26/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6028 - binary_accuracy: 0.6701 - val_loss: 0.5990 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.59925 to 0.59901, saving model to current_model.h5\n",
            "Epoch 27/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6034 - binary_accuracy: 0.6695 - val_loss: 0.5990 - val_binary_accuracy: 0.6793\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.59901\n",
            "Epoch 28/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.6681 - val_loss: 0.5991 - val_binary_accuracy: 0.6800\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.59901\n",
            "Epoch 29/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6044 - binary_accuracy: 0.6697 - val_loss: 0.5991 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0047.\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.59901\n",
            "Epoch 30/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6029 - binary_accuracy: 0.6716 - val_loss: 0.5992 - val_binary_accuracy: 0.6782\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.59901\n",
            "Epoch 31/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6013 - binary_accuracy: 0.6709 - val_loss: 0.5991 - val_binary_accuracy: 0.6778\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.59901\n",
            "Epoch 32/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6063 - binary_accuracy: 0.6672 - val_loss: 0.5992 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.59901\n",
            "Epoch 33/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6689 - val_loss: 0.5991 - val_binary_accuracy: 0.6778\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.59901\n",
            "Epoch 34/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5972 - binary_accuracy: 0.6741 - val_loss: 0.5990 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.59901 to 0.59898, saving model to current_model.h5\n",
            "Epoch 35/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6012 - binary_accuracy: 0.6718 - val_loss: 0.5989 - val_binary_accuracy: 0.6778\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.59898 to 0.59892, saving model to current_model.h5\n",
            "Epoch 36/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.6700 - val_loss: 0.5989 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.59892 to 0.59891, saving model to current_model.h5\n",
            "Epoch 37/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.6710 - val_loss: 0.5990 - val_binary_accuracy: 0.6778\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.59891\n",
            "Epoch 38/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6757 - val_loss: 0.5990 - val_binary_accuracy: 0.6800\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.59891\n",
            "Epoch 39/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6015 - binary_accuracy: 0.6710 - val_loss: 0.5990 - val_binary_accuracy: 0.6796\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.59891\n",
            "Epoch 40/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6022 - binary_accuracy: 0.6719 - val_loss: 0.5990 - val_binary_accuracy: 0.6800\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.59891\n",
            "Epoch 41/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6684 - val_loss: 0.5990 - val_binary_accuracy: 0.6808\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.59891\n",
            "Epoch 42/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6039 - binary_accuracy: 0.6711 - val_loss: 0.5992 - val_binary_accuracy: 0.6782\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.59891\n",
            "Epoch 43/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.5970 - binary_accuracy: 0.6745 - val_loss: 0.5990 - val_binary_accuracy: 0.6789\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.59891\n",
            "Epoch 44/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6023 - binary_accuracy: 0.6689 - val_loss: 0.5991 - val_binary_accuracy: 0.6793\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.59891\n",
            "Epoch 45/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6000 - binary_accuracy: 0.6711 - val_loss: 0.5991 - val_binary_accuracy: 0.6789\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.59891\n",
            "Epoch 46/200\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.6709 - val_loss: 0.5991 - val_binary_accuracy: 0.6789\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.59891\n",
            "Epoch 00046: early stopping\n",
            "Accuracy on training data: 69.33% \n",
            " Error on training data: 30.67%\n",
            "Accuracy on test data: 66.86% \n",
            " Error on test data: 33.14%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "1e3187c7-4076-49f7-f9bf-c73f56a7d301"
      },
      "source": [
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(keras.layers.Dropout(rate=0.2)) \n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(256,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(128,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(64,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(32,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(16,activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.0725), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.004,verbose=1)\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint('current_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)#patience-kolik epoch se nezmění val_loss pak stop\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=200, shuffle=True,batch_size=227,validation_data=(X_val, y_val), \n",
        "                    callbacks=[reduce_lr_callback,checkpoint_callback,early_stopping_callback])#steps\n",
        "train_predictions= model.predict(X_train)\n",
        "train_accuracy_score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {:.2%} \\n Error on training data: {:.2%}'.format(train_accuracy_score[1],  1 - train_accuracy_score[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "test_predictions= model.predict(X_test)\n",
        "test_accuracy_score= model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {:.2%} \\n Error on test data: {:.2%}'.format(test_accuracy_score[1], 1 - test_accuracy_score[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "56/56 [==============================] - 1s 14ms/step - loss: 0.6735 - binary_accuracy: 0.5771 - val_loss: 0.6516 - val_binary_accuracy: 0.6355\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.65156, saving model to current_model.h5\n",
            "Epoch 2/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6557 - binary_accuracy: 0.6102 - val_loss: 0.6322 - val_binary_accuracy: 0.6437\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.65156 to 0.63221, saving model to current_model.h5\n",
            "Epoch 3/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6391 - binary_accuracy: 0.6256 - val_loss: 0.6269 - val_binary_accuracy: 0.6670\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.63221 to 0.62688, saving model to current_model.h5\n",
            "Epoch 4/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6291 - binary_accuracy: 0.6497 - val_loss: 0.6131 - val_binary_accuracy: 0.6670\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.62688 to 0.61305, saving model to current_model.h5\n",
            "Epoch 5/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6234 - binary_accuracy: 0.6513 - val_loss: 0.6045 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.61305 to 0.60452, saving model to current_model.h5\n",
            "Epoch 6/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6226 - binary_accuracy: 0.6524 - val_loss: 0.6075 - val_binary_accuracy: 0.6719\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.60452\n",
            "Epoch 7/200\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.6185 - binary_accuracy: 0.6629 - val_loss: 0.6041 - val_binary_accuracy: 0.6763\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.60452 to 0.60413, saving model to current_model.h5\n",
            "Epoch 8/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6133 - binary_accuracy: 0.6700 - val_loss: 0.6049 - val_binary_accuracy: 0.6774\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.60413\n",
            "Epoch 9/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6117 - binary_accuracy: 0.6640 - val_loss: 0.6091 - val_binary_accuracy: 0.6796\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.60413\n",
            "Epoch 10/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6109 - binary_accuracy: 0.6682 - val_loss: 0.6012 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.60413 to 0.60117, saving model to current_model.h5\n",
            "Epoch 11/200\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.6082 - binary_accuracy: 0.6718 - val_loss: 0.6058 - val_binary_accuracy: 0.6774\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.60117\n",
            "Epoch 12/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6088 - binary_accuracy: 0.6714 - val_loss: 0.6042 - val_binary_accuracy: 0.6726\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.60117\n",
            "Epoch 13/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6058 - binary_accuracy: 0.6781 - val_loss: 0.6011 - val_binary_accuracy: 0.6785\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.036249998956918716.\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.60117 to 0.60108, saving model to current_model.h5\n",
            "Epoch 14/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6042 - binary_accuracy: 0.6750 - val_loss: 0.6044 - val_binary_accuracy: 0.6730\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.60108\n",
            "Epoch 15/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6046 - binary_accuracy: 0.6804 - val_loss: 0.6037 - val_binary_accuracy: 0.6674\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.60108\n",
            "Epoch 16/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6027 - binary_accuracy: 0.6770 - val_loss: 0.6033 - val_binary_accuracy: 0.6700\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.018124999478459358.\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.60108\n",
            "Epoch 17/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.5989 - binary_accuracy: 0.6841 - val_loss: 0.6019 - val_binary_accuracy: 0.6696\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.60108\n",
            "Epoch 18/200\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.5982 - binary_accuracy: 0.6836 - val_loss: 0.6022 - val_binary_accuracy: 0.6674\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.60108\n",
            "Epoch 19/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.6021 - binary_accuracy: 0.6787 - val_loss: 0.6049 - val_binary_accuracy: 0.6674\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.009062499739229679.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.60108\n",
            "Epoch 20/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.5986 - binary_accuracy: 0.6787 - val_loss: 0.6031 - val_binary_accuracy: 0.6696\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.60108\n",
            "Epoch 21/200\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.6001 - binary_accuracy: 0.6794 - val_loss: 0.6028 - val_binary_accuracy: 0.6689\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.60108\n",
            "Epoch 22/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.5980 - binary_accuracy: 0.6839 - val_loss: 0.6029 - val_binary_accuracy: 0.6678\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0045312498696148396.\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.60108\n",
            "Epoch 23/200\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.5990 - binary_accuracy: 0.6799 - val_loss: 0.6027 - val_binary_accuracy: 0.6696\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.60108\n",
            "Epoch 00023: early stopping\n",
            "Accuracy on training data: 70.83% \n",
            " Error on training data: 29.17%\n",
            "Accuracy on test data: 66.75% \n",
            " Error on test data: 33.25%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBS6OOAJNxv",
        "outputId": "7f8c8298-a46f-46c5-9991-3f1264334991"
      },
      "source": [
        "#model.save('/content/save/model707.h5')\n",
        "model= keras.models.load_model(\"current_model.h5\")\n",
        "\n",
        "scaledData=main_scaler.transform(X)\n",
        "pred_test= model.predict(scaledData)\n",
        "scores2 = model.evaluate(scaledData, y, verbose=1)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on the whole dataset: {:.2%} \\n Error on the whole dataset: {:.2%}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "#pickle.dump(main_scaler, open(\"/content/save/scaler707.pkl\", 'wb'))#save the scaler "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "562/562 [==============================] - 1s 1ms/step - loss: 0.5875 - binary_accuracy: 0.6929\n",
            "Accuracy on the whole dataset: 69.29% \n",
            " Error on the whole dataset: 30.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWKcVOt9eBe7"
      },
      "source": [
        "main_scaler = pickle.load(open(\"scaler707.pkl\", 'rb'))\n",
        "Xnew=np.array([[1.6,2.25,26,44,0.63,0.64,0.464,0.578,1.18,0.76,0.72,1.28,88.3,0.82,0.66,1.08,5.2,1.14,0.58,0.73,1.09,73.2,0.71,0.3,1.23,3.0,1.08,0.63,0.74,0.97,75.1,0.65,0.45,1.03,5.9,1.07,0.64,0.72,1.0,74.7,0.67,0.45,1.05,3.3,0.99,0.64,0.72,0.89,67.3,0.59,0.53,0.92,7.0,1.2,0.66,0.73,1.29,85.5,0.76,0.49,1.17,7.6,1.08,0.59,0.72,1.07,66.6,0.67,0.29,1.12,2.5,1.07,0.63,0.72,1.02,72.1,0.67,0.57,1.05,5.1,1.06,0.61,0.74,0.93,72.3,0.67,0.53,1.08,5.4,1.02,0.67,0.72,0.99,74.0,0.62,0.46,0.93,9.4],\n",
        "               [2.62,1.47,165,129,0.47,0.67,0.5,0.5,1.24,0.68,0.76,1.24,86.3,0.83,0.58,1.23,4.6,1.09,0.67,0.71,1.11,74.9,0.68,0.41,1.01,5.2,1.03,0.68,0.72,0.99,71.8,0.67,0.56,0.99,2.6,0.98,0.72,0.68,0.95,73.2,0.65,0.4,0.90,3.4,0.96,0.67,0.69,0.9,65.9,0.61,0.48,0.91,2.3,1.2,0.68,0.73,1.23,87.0,0.78,0.55,1.15,6.7,1.14,0.58,0.74,1.14,68.7,0.68,0.38,1.17,3.4,1.13,0.67,0.71,1.28,76.3,0.71,0.59,1.05,4.0,1.06,0.63,0.72,0.9,73.9,0.7,0.61,1.10,5.1,1.04,0.69,0.71,1.01,74.2,0.68,0.6,0.99,3.9],\n",
        "               [2.3,1.52,91,72,0.53,0.67,0.5,0.5,1.11,0.62,0.71,1.08,73.1,0.7,0.3,1.13,2.9,1.08,0.66,0.69,1.16,72.6,0.71,0.62,1.09,3.6,1.06,0.68,0.73,0.95,77.2,0.66,0.51,0.98,3.9,1.03,0.66,0.69,0.95,74.8,0.67,0.68,1.01,3.0,0.96,0.64,0.71,0.87,65.7,0.57,0.5,0.89,5.2,1.13,0.6,0.74,1.0,77.5,0.71,0.57,1.20,5.7,1.18,0.57,0.74,1.17,74.4,0.71,0.27,1.25,3.1,1.15,0.66,0.74,1.11,79.8,0.73,0.52,1.11,4.3,1.04,0.67,0.7,1.03,74.4,0.66,0.62,0.98,3.0,0.95,0.68,0.7,0.85,67.0,0.58,0.5,0.85,4.9],\n",
        "               [1.6,2.27,43,60,0.55,0.5,0.5,0.51,1.06,0.69,0.69,1.1,75.7,0.7,0.55,1.02,4.5,1.13,0.67,0.68,1.26,77.6,0.76,0.32,1.13,1.8,0.97,0.69,0.68,0.93,71.2,0.64,0.54,0.94,4.2,1.05,0.68,0.68,1.1,74.83,0.7,0.47,1.03,3.5,1.05,0.68,0.68,1.1,74.83,0.7,0.47,1.03,3.5,1.14,0.7,0.72,1.17,83.8,0.74,0.53,1.05,4.5,1.03,0.64,0.68,1.04,69.9,0.66,0.3,1.03,3.3,1.0,0.7,0.68,1.06,71.6,0.64,0.59,0.92,2.8,0.95,0.66,0.69,0.84,65.4,0.62,0.64,0.94,2.4,0.95,0.7,0.68,0.86,69.4,0.62,0.55,0.88,2.5],\n",
        "               [1.74,2.04,65,78,0.67,0.45,0.569,0.5,1.35,0.51,0.78,1.34,82.4,0.84,0.34,1.66,2.8,1.14,0.61,0.72,1.16,77.0,0.7,0.49,1.16,4.5,1.14,0.63,0.72,1.13,80.0,0.7,0.52,1.11,4.6,1.09,0.63,0.71,1.03,76.0,0.7,0.54,1.11,3.7,1.01,0.62,0.72,0.87,68.7,0.61,0.6,0.98,4.2,1.08,0.68,0.71,1.11,77.7,0.7,0.53,1.04,5.0,1.04,0.68,0.68,1.1,75.5,0.69,0.51,1.01,3.6,1.0,0.63,0.69,0.9,67.8,0.63,0.3,1.00,4.4,0.96,0.74,0.64,1.07,74.4,0.64,0.55,0.86,5.8,0.95,0.63,0.71,0.69,67.2,0.6,0.54,0.96,4.3],\n",
        "               [1.43,2.6,17,36,0.42,0.8,0.595,0.535,1.3,0.6,0.74,1.35,89.4,0.85,0.46,1.41,5.0,1.07,0.64,0.71,0.98,77.0,0.67,0.44,1.06,5.3,1.07,0.7,0.69,1.2,74.4,0.67,0.29,0.97,3.3,0.98,0.66,0.71,0.84,71.3,0.62,0.45,0.94,4.8,0.71,0.65,0.63,0.5,45.6,0.4,0.46,0.62,1.9,1.29,0.57,0.79,1.13,87.2,0.82,0.53,1.44,3.2,1.28,0.56,0.77,1.3,79.6,0.8,0.26,1.43,3.1,1.23,0.62,0.75,1.27,84.0,0.77,0.51,1.23,6.1,1.06,0.65,0.71,1.08,73.0,0.68,0.52,1.04,5.6,1.06,0.6,0.75,0.88,72.2,0.63,0.46,1.04,3.5],\n",
        "               [2.91,1.39,128,68,0.6,0.75,0.5,0.516,1.12,0.63,0.69,1.2,75.9,0.73,0.27,1.16,4.6,1.08,0.67,0.69,1.1,76.1,0.71,0.47,1.06,4.5,1.03,0.68,0.71,0.92,75.7,0.68,0.53,1.01,2.6,1.0,0.72,0.71,0.99,76.1,0.64,0.39,0.89,4.7,0.9,0.71,0.69,0.81,64.5,0.59,0.46,0.83,3.1,1.17,0.62,0.71,1.2,78.1,0.76,0.25,1.24,2.6,1.08,0.65,0.71,1.08,76.4,0.67,0.55,1.03,5.5,1.07,0.63,0.73,0.93,72.3,0.68,0.55,1.08,3.4,1.05,0.71,0.68,1.2,76.3,0.68,0.43,0.96,3.8,1.04,0.67,0.72,0.98,72.5,0.67,0.55,1.00,3.7]\n",
        "])\n",
        "\n",
        "pokus=main_scaler.transform(Xnew)\n",
        "model= keras.models.load_model(\"model707.h5\")\n",
        "ynew=(model.predict([pokus]))\n",
        "print(ynew)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-0x3EQ37uB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 2 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = sklearn.model_selection.GridSearchCV(sklearn.neighbors.KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)\n",
        "#pro 300 nabízí 153"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhmwsYYngDG0"
      },
      "source": [
        "\n",
        "poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky!!\n",
        "\n",
        "optimální batch_size je 128 zjištěno zkoušením\n",
        "\n",
        "kernel inity\n",
        "he_uniform>he_normal\n",
        "lecun uniform>lecun normal \n",
        "orthogonal a variance scaling použitelné\n",
        "\n",
        "bias inity\n",
        "lecun normal >he normal, variance_scaling\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/initializers\n",
        "val loss u callbacků nebo val_accuracy?\n",
        "model.add(Dense(512, kernel_initializer=tf.initializers.lecun_uniform,bias_initializer=tf.initializers.lecun_normal))\n",
        "\n",
        "nejlepší model měl zatím 512,256,128 i když to není doporučováno"
      ]
    }
  ]
}