{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2g/iz58iok9tEAVQvRO1r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbSeoWpB3mO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCY-aVPMK1aO"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "94fc4594-8d7a-4429-96ab-a38d385d24e3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import keras\n",
        "\n",
        "\n",
        "#CSV_COLUMN_NAMES označuje nadpisy sloupců v csv soubour\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "print(train.shape)#vypíše nám dimenzionalitu našeho dataframu (2, 3) 2 řádky 3 sloupce\n",
        "\n",
        "#následující 2 řádky nám upraví dva sloupce z textových na číselné formáty (category datatype)\n",
        "train['team_one_name']=pd.Categorical(train['team_one_name']).codes #sníží využití paměti z 1.2MB na 0.03 MB viz: https://towardsdatascience.com/staying-sane-while-adopting-pandas-categorical-datatypes-78dbd19dcd8a\n",
        "train['team_two_name']=pd.Categorical(train['team_two_name']).codes\n",
        "\n",
        "#Odstraním z dataframu následující sloupce (odkaz na zápas a jména týmů), jelikož jsem je využíval pouze při sběru dat\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "\n",
        "'''\n",
        "train.pop('playerAAGrenadeDmg')\n",
        "train.pop('playerABGrenadeDmg')\n",
        "train.pop('playerACGrenadeDmg')\n",
        "train.pop('playerADGrenadeDmg')\n",
        "train.pop('playerAEGrenadeDmg')\n",
        "train.pop('playerBAGrenadeDmg')\n",
        "train.pop('playerBBGrenadeDmg')\n",
        "train.pop('playerBCGrenadeDmg')\n",
        "train.pop('playerBDGrenadeDmg')\n",
        "train.pop('playerBEGrenadeDmg')\n",
        "\n",
        "train.pop('playerAAKast')\n",
        "train.pop('playerABKast')\n",
        "train.pop('playerACKast')\n",
        "train.pop('playerADKast')\n",
        "train.pop('playerAEKast')\n",
        "train.pop('playerBAKast')\n",
        "train.pop('playerBBKast')\n",
        "train.pop('playerBCKast')\n",
        "train.pop('playerBDKast')\n",
        "train.pop('playerBEKast')\n",
        "\n",
        "train.pop('playerAAKD')\n",
        "train.pop('playerABKD')\n",
        "train.pop('playerACKD')\n",
        "train.pop('playerADKD')\n",
        "train.pop('playerAEKD')\n",
        "train.pop('playerBAKD')\n",
        "train.pop('playerBBKD')\n",
        "train.pop('playerBCKD')\n",
        "train.pop('playerBDKD')\n",
        "train.pop('playerBEKD')\n",
        "\n",
        "train.pop('playerAAAdr')\n",
        "train.pop('playerABAdr')\n",
        "train.pop('playerACAdr')\n",
        "train.pop('playerADAdr')\n",
        "train.pop('playerAEAdr')\n",
        "train.pop('playerBAAdr')\n",
        "train.pop('playerBBAdr')\n",
        "train.pop('playerBCAdr')\n",
        "train.pop('playerBDAdr')\n",
        "train.pop('playerBEAdr')\n",
        "\n",
        "train.pop('playerAADpr')\n",
        "train.pop('playerABDpr')\n",
        "train.pop('playerACDpr')\n",
        "train.pop('playerADDpr')\n",
        "train.pop('playerAEDpr')\n",
        "train.pop('playerBADpr')\n",
        "train.pop('playerBBDpr')\n",
        "train.pop('playerBCDpr')\n",
        "train.pop('playerBDDpr')\n",
        "train.pop('playerBEDpr')\n",
        "\n",
        "train.pop('playerAAKpr')\n",
        "train.pop('playerABKpr')\n",
        "train.pop('playerACKpr')\n",
        "train.pop('playerADKpr')\n",
        "train.pop('playerAEKpr')\n",
        "train.pop('playerBAKpr')\n",
        "train.pop('playerBBKpr')\n",
        "train.pop('playerBCKpr')\n",
        "train.pop('playerBDKpr')\n",
        "train.pop('playerBEKpr')\n",
        "\n",
        "train.pop('playerAAImpact')\n",
        "train.pop('playerABImpact')\n",
        "train.pop('playerACImpact')\n",
        "train.pop('playerADImpact')\n",
        "train.pop('playerAEImpact')\n",
        "train.pop('playerBAImpact')\n",
        "train.pop('playerBBImpact')\n",
        "train.pop('playerBCImpact')\n",
        "train.pop('playerBDImpact')\n",
        "train.pop('playerBEImpact')\n",
        "\n",
        "train.pop('playerAAHs')\n",
        "train.pop('playerABHs')\n",
        "train.pop('playerACHs')\n",
        "train.pop('playerADHs')\n",
        "train.pop('playerAEHs')\n",
        "train.pop('playerBAHs')\n",
        "train.pop('playerBBHs')\n",
        "train.pop('playerBCHs')\n",
        "train.pop('playerBDHs')\n",
        "train.pop('playerBEHs')\n",
        "\n",
        "train.pop('playerAARating')\n",
        "train.pop('playerABRating')\n",
        "train.pop('playerACRating')\n",
        "train.pop('playerADRating')\n",
        "train.pop('playerAERating')\n",
        "train.pop('playerBARating')\n",
        "train.pop('playerBBRating')\n",
        "train.pop('playerBCRating')\n",
        "train.pop('playerBDRating')\n",
        "train.pop('playerBERating')\n",
        "'''\n",
        "#predictors nám vybere všechny sloupce, které jsou využity pro predikování výsledků neboli target_column\n",
        "target_column = ['Result'] \n",
        "predictors = list(set(list(train.columns))-set(target_column))\n",
        "\n",
        "scalerData=train.copy()\n",
        "scalerData.pop('Result')\n",
        "\n",
        "predictionScaler=MinMaxScaler(feature_range=(0,2))\n",
        "X = train[predictors].values\n",
        "y = train[target_column].values\n",
        "predictionScaler.fit(scalerData)\n",
        "\n",
        "#n = 100 # Max number of neighbours you want to consider\n",
        "#param_grid = {'n_neighbors': np.arange(n)}\n",
        "#grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "#grid.fit(X,y)\n",
        "#print(grid.best_params_)\n",
        "\n",
        "\n",
        "#určíme outliers (odlehlé hodnoty, které by mohly být při tréninku pro model škodlivé)\n",
        "#zkráceně řečeno zjistíme odlehlou hodnotu tak, že ve svém okolí má oproti jiným hodnotám o dost méně \"sousedů\"\n",
        "#15% dat \n",
        "lof = LocalOutlierFactor(contamination=0.15,n_neighbors=96)\n",
        "yhat = lof.fit_predict(X)\n",
        "mask = yhat != -1\n",
        "X, y= X[mask, :], y[mask]\n",
        "print(X.shape)\n",
        "\n",
        "#rozdělíme náš dataframe na trénovací, testovací a validační dataset\n",
        "#testovací dataset bude 15% random_state=98\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,random_state=3332)#32 #888 887\n",
        "\n",
        "#validační set bude 15% random_state=75\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1765,random_state=7215) # 0.1765 x 0.85 = 0.15 podívat se na cross-validation\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(X_test.shape)\n",
        "print(X_val.shape) #součet odpovídá X.shape\n",
        "\n",
        "#vytvoříme scaler, který nám data přetransformuje na formát lepší pro model ?\n",
        "#scalujeme data aby si model nemyslel, že větší číselný řád indikuje větší důležitost atributu\n",
        "#https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
        "#https://datascience.stackexchange.com/questions/43972/when-should-i-use-standardscaler-and-when-minmaxscaler\n",
        "\n",
        "#nepoužíváme minmaxscaler, protože naše data by měly být \"normálně\" distribuovány\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=CSV_COLUMN_NAMES2)\n",
        "X_test=pd.DataFrame(X_test, columns=CSV_COLUMN_NAMES2)\n",
        "X_val=pd.DataFrame(X_val, columns=CSV_COLUMN_NAMES2)\n",
        "\n",
        "X_train=predictionScaler.transform(X_train)\n",
        "X_test=predictionScaler.transform(X_test)\n",
        "X_val=predictionScaler.transform(X_val)\n",
        "\n",
        "\n",
        "#64 32\n",
        "#data máme připravena, tak vytvoříme sequential model, jelikož potřebujeme mít více vrstev, ale máme pouze 1 input (zápas) a output 0;1\n",
        "model = Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(98)))#https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af\n",
        "model.add(Dense(64, activation='relu'))#input layer je už v modelu defaultně\n",
        "model.add(keras.layers.Dropout(0.5))#50% inputů dropne abz se příliš nespoléhala na vybrané inputy\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))#jelikož děláme binární klasifikaci, tak aktivační funkce bude sigmoid popř. softmax, zde by mezi těmito dvěmi neměl být výkonově rozdíl viz:https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#tady jsem skončil s vysvětlováním!!!\n",
        "#model zkompilujeme s parametry:\n",
        "#optimizer bude ? optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9\n",
        "#loss funkce bude BinaryCrossentropy, jelikož máme binární klasifikátor\n",
        "model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.07), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), #https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "              metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None))#metrics=['accuracy'] je to jedno accuracy se vnitřně přetransformuje na binary accuracy, kvůli binary crossentropy loss funkci\n",
        "\n",
        "#[tf.keras.metrics.BinaryAccuracy()]\n",
        "\n",
        "#Adagrad(learning_rate=0.01) kolem 100 epochs a 32 batch_size je kolem 0.67\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1500,batch_size=32,validation_data=(X_val, y_val))#validační data pro změny při tréninku sítě\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))#úspěšnost na trénovacím setu   \n",
        "\n",
        "\n",
        "pred_test= model.predict(X_test)\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)# zkusit změnit verbose zde a nahoře na 1 a 2 mělo by to zobrazovat více údajů při tréninku\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))#úspěšnost na testovacím setu\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('binary_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#poznatky-vypadá to, že grenade damage každého hráče je nadbytečná a síť bez této informace vykazuje lepší výsledky\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18775, 102)\n",
            "(15958, 98)\n",
            "(11169, 98)\n",
            "(2394, 98)\n",
            "(2395, 98)\n",
            "Epoch 1/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 19.7970 - binary_accuracy: 0.5200 - val_loss: 1.6292 - val_binary_accuracy: 0.6113\n",
            "Epoch 2/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 11.2209 - binary_accuracy: 0.5105 - val_loss: 1.2812 - val_binary_accuracy: 0.5766\n",
            "Epoch 3/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 6.7813 - binary_accuracy: 0.5148 - val_loss: 1.1777 - val_binary_accuracy: 0.5549\n",
            "Epoch 4/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 3.9843 - binary_accuracy: 0.5241 - val_loss: 0.9387 - val_binary_accuracy: 0.5349\n",
            "Epoch 5/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 2.6037 - binary_accuracy: 0.5248 - val_loss: 0.7790 - val_binary_accuracy: 0.5253\n",
            "Epoch 6/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.9105 - binary_accuracy: 0.5177 - val_loss: 0.7221 - val_binary_accuracy: 0.5541\n",
            "Epoch 7/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.3961 - binary_accuracy: 0.5330 - val_loss: 0.7019 - val_binary_accuracy: 0.5603\n",
            "Epoch 8/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.1566 - binary_accuracy: 0.5352 - val_loss: 0.6829 - val_binary_accuracy: 0.5708\n",
            "Epoch 9/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 1.0149 - binary_accuracy: 0.5314 - val_loss: 0.6734 - val_binary_accuracy: 0.5754\n",
            "Epoch 10/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.8894 - binary_accuracy: 0.5438 - val_loss: 0.6691 - val_binary_accuracy: 0.5812\n",
            "Epoch 11/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.8264 - binary_accuracy: 0.5433 - val_loss: 0.6671 - val_binary_accuracy: 0.5900\n",
            "Epoch 12/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7763 - binary_accuracy: 0.5522 - val_loss: 0.6676 - val_binary_accuracy: 0.5921\n",
            "Epoch 13/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7422 - binary_accuracy: 0.5461 - val_loss: 0.6659 - val_binary_accuracy: 0.6013\n",
            "Epoch 14/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7261 - binary_accuracy: 0.5534 - val_loss: 0.6696 - val_binary_accuracy: 0.5879\n",
            "Epoch 15/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7135 - binary_accuracy: 0.5609 - val_loss: 0.6655 - val_binary_accuracy: 0.6033\n",
            "Epoch 16/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.7040 - binary_accuracy: 0.5700 - val_loss: 0.6613 - val_binary_accuracy: 0.6213\n",
            "Epoch 17/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6990 - binary_accuracy: 0.5646 - val_loss: 0.6652 - val_binary_accuracy: 0.6025\n",
            "Epoch 18/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6904 - binary_accuracy: 0.5718 - val_loss: 0.6626 - val_binary_accuracy: 0.6046\n",
            "Epoch 19/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6901 - binary_accuracy: 0.5740 - val_loss: 0.6641 - val_binary_accuracy: 0.5983\n",
            "Epoch 20/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6898 - binary_accuracy: 0.5642 - val_loss: 0.6637 - val_binary_accuracy: 0.5971\n",
            "Epoch 21/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6841 - binary_accuracy: 0.5729 - val_loss: 0.6631 - val_binary_accuracy: 0.6021\n",
            "Epoch 22/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6846 - binary_accuracy: 0.5698 - val_loss: 0.6643 - val_binary_accuracy: 0.6000\n",
            "Epoch 23/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6815 - binary_accuracy: 0.5727 - val_loss: 0.6592 - val_binary_accuracy: 0.6021\n",
            "Epoch 24/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6804 - binary_accuracy: 0.5782 - val_loss: 0.6585 - val_binary_accuracy: 0.6017\n",
            "Epoch 25/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6776 - binary_accuracy: 0.5845 - val_loss: 0.6600 - val_binary_accuracy: 0.6054\n",
            "Epoch 26/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6739 - binary_accuracy: 0.5815 - val_loss: 0.6585 - val_binary_accuracy: 0.6054\n",
            "Epoch 27/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6785 - binary_accuracy: 0.5760 - val_loss: 0.6591 - val_binary_accuracy: 0.5962\n",
            "Epoch 28/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6736 - binary_accuracy: 0.5836 - val_loss: 0.6564 - val_binary_accuracy: 0.6104\n",
            "Epoch 29/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6742 - binary_accuracy: 0.5875 - val_loss: 0.6580 - val_binary_accuracy: 0.6054\n",
            "Epoch 30/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6755 - binary_accuracy: 0.5811 - val_loss: 0.6604 - val_binary_accuracy: 0.5996\n",
            "Epoch 31/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6758 - binary_accuracy: 0.5826 - val_loss: 0.6603 - val_binary_accuracy: 0.6000\n",
            "Epoch 32/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6742 - binary_accuracy: 0.5869 - val_loss: 0.6585 - val_binary_accuracy: 0.6025\n",
            "Epoch 33/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6740 - binary_accuracy: 0.5876 - val_loss: 0.6575 - val_binary_accuracy: 0.6042\n",
            "Epoch 34/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6713 - binary_accuracy: 0.5923 - val_loss: 0.6568 - val_binary_accuracy: 0.6042\n",
            "Epoch 35/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6712 - binary_accuracy: 0.5824 - val_loss: 0.6572 - val_binary_accuracy: 0.6071\n",
            "Epoch 36/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6715 - binary_accuracy: 0.5857 - val_loss: 0.6582 - val_binary_accuracy: 0.6092\n",
            "Epoch 37/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6700 - binary_accuracy: 0.5890 - val_loss: 0.6558 - val_binary_accuracy: 0.6109\n",
            "Epoch 38/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6673 - binary_accuracy: 0.5932 - val_loss: 0.6567 - val_binary_accuracy: 0.6092\n",
            "Epoch 39/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6654 - binary_accuracy: 0.5975 - val_loss: 0.6552 - val_binary_accuracy: 0.6142\n",
            "Epoch 40/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6670 - binary_accuracy: 0.5953 - val_loss: 0.6533 - val_binary_accuracy: 0.6221\n",
            "Epoch 41/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6629 - binary_accuracy: 0.6044 - val_loss: 0.6567 - val_binary_accuracy: 0.6188\n",
            "Epoch 42/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6654 - binary_accuracy: 0.5988 - val_loss: 0.6530 - val_binary_accuracy: 0.6221\n",
            "Epoch 43/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6645 - binary_accuracy: 0.5964 - val_loss: 0.6533 - val_binary_accuracy: 0.6221\n",
            "Epoch 44/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6662 - binary_accuracy: 0.5984 - val_loss: 0.6524 - val_binary_accuracy: 0.6142\n",
            "Epoch 45/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6657 - binary_accuracy: 0.5987 - val_loss: 0.6509 - val_binary_accuracy: 0.6230\n",
            "Epoch 46/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6594 - binary_accuracy: 0.6036 - val_loss: 0.6501 - val_binary_accuracy: 0.6355\n",
            "Epoch 47/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6611 - binary_accuracy: 0.6044 - val_loss: 0.6520 - val_binary_accuracy: 0.6280\n",
            "Epoch 48/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6634 - binary_accuracy: 0.6039 - val_loss: 0.6539 - val_binary_accuracy: 0.6238\n",
            "Epoch 49/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6623 - binary_accuracy: 0.6061 - val_loss: 0.6508 - val_binary_accuracy: 0.6200\n",
            "Epoch 50/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6635 - binary_accuracy: 0.6018 - val_loss: 0.6526 - val_binary_accuracy: 0.6225\n",
            "Epoch 51/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6586 - binary_accuracy: 0.6035 - val_loss: 0.6521 - val_binary_accuracy: 0.6263\n",
            "Epoch 52/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6583 - binary_accuracy: 0.6126 - val_loss: 0.6530 - val_binary_accuracy: 0.6255\n",
            "Epoch 53/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6605 - binary_accuracy: 0.6065 - val_loss: 0.6519 - val_binary_accuracy: 0.6271\n",
            "Epoch 54/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6583 - binary_accuracy: 0.6126 - val_loss: 0.6508 - val_binary_accuracy: 0.6280\n",
            "Epoch 55/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6608 - binary_accuracy: 0.6047 - val_loss: 0.6535 - val_binary_accuracy: 0.6288\n",
            "Epoch 56/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6572 - binary_accuracy: 0.6046 - val_loss: 0.6533 - val_binary_accuracy: 0.6288\n",
            "Epoch 57/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6565 - binary_accuracy: 0.6105 - val_loss: 0.6540 - val_binary_accuracy: 0.6259\n",
            "Epoch 58/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6578 - binary_accuracy: 0.6128 - val_loss: 0.6526 - val_binary_accuracy: 0.6301\n",
            "Epoch 59/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6567 - binary_accuracy: 0.6140 - val_loss: 0.6503 - val_binary_accuracy: 0.6301\n",
            "Epoch 60/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6555 - binary_accuracy: 0.6160 - val_loss: 0.6524 - val_binary_accuracy: 0.6322\n",
            "Epoch 61/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6603 - binary_accuracy: 0.6109 - val_loss: 0.6512 - val_binary_accuracy: 0.6292\n",
            "Epoch 62/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6563 - binary_accuracy: 0.6104 - val_loss: 0.6522 - val_binary_accuracy: 0.6338\n",
            "Epoch 63/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6552 - binary_accuracy: 0.6090 - val_loss: 0.6525 - val_binary_accuracy: 0.6280\n",
            "Epoch 64/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6565 - binary_accuracy: 0.6150 - val_loss: 0.6520 - val_binary_accuracy: 0.6347\n",
            "Epoch 65/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6535 - binary_accuracy: 0.6160 - val_loss: 0.6488 - val_binary_accuracy: 0.6367\n",
            "Epoch 66/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6576 - binary_accuracy: 0.6140 - val_loss: 0.6511 - val_binary_accuracy: 0.6271\n",
            "Epoch 67/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6543 - binary_accuracy: 0.6155 - val_loss: 0.6502 - val_binary_accuracy: 0.6267\n",
            "Epoch 68/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6590 - binary_accuracy: 0.6149 - val_loss: 0.6524 - val_binary_accuracy: 0.6313\n",
            "Epoch 69/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6541 - binary_accuracy: 0.6182 - val_loss: 0.6512 - val_binary_accuracy: 0.6351\n",
            "Epoch 70/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6523 - binary_accuracy: 0.6147 - val_loss: 0.6509 - val_binary_accuracy: 0.6426\n",
            "Epoch 71/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6557 - binary_accuracy: 0.6189 - val_loss: 0.6503 - val_binary_accuracy: 0.6309\n",
            "Epoch 72/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6542 - binary_accuracy: 0.6139 - val_loss: 0.6510 - val_binary_accuracy: 0.6330\n",
            "Epoch 73/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6528 - binary_accuracy: 0.6181 - val_loss: 0.6504 - val_binary_accuracy: 0.6397\n",
            "Epoch 74/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6536 - binary_accuracy: 0.6162 - val_loss: 0.6520 - val_binary_accuracy: 0.6301\n",
            "Epoch 75/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6571 - binary_accuracy: 0.6094 - val_loss: 0.6515 - val_binary_accuracy: 0.6292\n",
            "Epoch 76/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6231 - val_loss: 0.6489 - val_binary_accuracy: 0.6355\n",
            "Epoch 77/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6531 - binary_accuracy: 0.6199 - val_loss: 0.6500 - val_binary_accuracy: 0.6372\n",
            "Epoch 78/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6531 - binary_accuracy: 0.6199 - val_loss: 0.6497 - val_binary_accuracy: 0.6355\n",
            "Epoch 79/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6230 - val_loss: 0.6492 - val_binary_accuracy: 0.6342\n",
            "Epoch 80/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6538 - binary_accuracy: 0.6216 - val_loss: 0.6497 - val_binary_accuracy: 0.6376\n",
            "Epoch 81/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6489 - binary_accuracy: 0.6163 - val_loss: 0.6483 - val_binary_accuracy: 0.6322\n",
            "Epoch 82/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6537 - binary_accuracy: 0.6235 - val_loss: 0.6491 - val_binary_accuracy: 0.6342\n",
            "Epoch 83/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6459 - binary_accuracy: 0.6287 - val_loss: 0.6492 - val_binary_accuracy: 0.6376\n",
            "Epoch 84/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6222 - val_loss: 0.6467 - val_binary_accuracy: 0.6326\n",
            "Epoch 85/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6488 - binary_accuracy: 0.6186 - val_loss: 0.6482 - val_binary_accuracy: 0.6334\n",
            "Epoch 86/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6470 - binary_accuracy: 0.6201 - val_loss: 0.6480 - val_binary_accuracy: 0.6317\n",
            "Epoch 87/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6247 - val_loss: 0.6473 - val_binary_accuracy: 0.6313\n",
            "Epoch 88/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6495 - binary_accuracy: 0.6206 - val_loss: 0.6472 - val_binary_accuracy: 0.6401\n",
            "Epoch 89/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6543 - binary_accuracy: 0.6205 - val_loss: 0.6496 - val_binary_accuracy: 0.6359\n",
            "Epoch 90/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6476 - binary_accuracy: 0.6204 - val_loss: 0.6472 - val_binary_accuracy: 0.6338\n",
            "Epoch 91/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6505 - binary_accuracy: 0.6184 - val_loss: 0.6477 - val_binary_accuracy: 0.6280\n",
            "Epoch 92/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6465 - binary_accuracy: 0.6246 - val_loss: 0.6473 - val_binary_accuracy: 0.6426\n",
            "Epoch 93/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6239 - val_loss: 0.6464 - val_binary_accuracy: 0.6347\n",
            "Epoch 94/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6487 - binary_accuracy: 0.6275 - val_loss: 0.6466 - val_binary_accuracy: 0.6334\n",
            "Epoch 95/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6473 - binary_accuracy: 0.6302 - val_loss: 0.6462 - val_binary_accuracy: 0.6497\n",
            "Epoch 96/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6465 - binary_accuracy: 0.6223 - val_loss: 0.6454 - val_binary_accuracy: 0.6413\n",
            "Epoch 97/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6499 - binary_accuracy: 0.6245 - val_loss: 0.6470 - val_binary_accuracy: 0.6359\n",
            "Epoch 98/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6453 - binary_accuracy: 0.6274 - val_loss: 0.6459 - val_binary_accuracy: 0.6438\n",
            "Epoch 99/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6479 - binary_accuracy: 0.6292 - val_loss: 0.6459 - val_binary_accuracy: 0.6372\n",
            "Epoch 100/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6437 - binary_accuracy: 0.6275 - val_loss: 0.6444 - val_binary_accuracy: 0.6438\n",
            "Epoch 101/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6486 - binary_accuracy: 0.6218 - val_loss: 0.6455 - val_binary_accuracy: 0.6380\n",
            "Epoch 102/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6491 - binary_accuracy: 0.6273 - val_loss: 0.6465 - val_binary_accuracy: 0.6367\n",
            "Epoch 103/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6488 - binary_accuracy: 0.6248 - val_loss: 0.6455 - val_binary_accuracy: 0.6363\n",
            "Epoch 104/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6478 - binary_accuracy: 0.6299 - val_loss: 0.6449 - val_binary_accuracy: 0.6422\n",
            "Epoch 105/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6420 - binary_accuracy: 0.6296 - val_loss: 0.6437 - val_binary_accuracy: 0.6455\n",
            "Epoch 106/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6513 - binary_accuracy: 0.6291 - val_loss: 0.6451 - val_binary_accuracy: 0.6330\n",
            "Epoch 107/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6462 - binary_accuracy: 0.6287 - val_loss: 0.6437 - val_binary_accuracy: 0.6455\n",
            "Epoch 108/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6465 - binary_accuracy: 0.6314 - val_loss: 0.6441 - val_binary_accuracy: 0.6447\n",
            "Epoch 109/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6281 - val_loss: 0.6431 - val_binary_accuracy: 0.6443\n",
            "Epoch 110/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6458 - binary_accuracy: 0.6275 - val_loss: 0.6423 - val_binary_accuracy: 0.6451\n",
            "Epoch 111/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6455 - binary_accuracy: 0.6298 - val_loss: 0.6447 - val_binary_accuracy: 0.6430\n",
            "Epoch 112/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6330 - val_loss: 0.6433 - val_binary_accuracy: 0.6409\n",
            "Epoch 113/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6444 - binary_accuracy: 0.6285 - val_loss: 0.6443 - val_binary_accuracy: 0.6447\n",
            "Epoch 114/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6480 - binary_accuracy: 0.6260 - val_loss: 0.6444 - val_binary_accuracy: 0.6363\n",
            "Epoch 115/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6447 - binary_accuracy: 0.6340 - val_loss: 0.6439 - val_binary_accuracy: 0.6443\n",
            "Epoch 116/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6466 - binary_accuracy: 0.6263 - val_loss: 0.6463 - val_binary_accuracy: 0.6476\n",
            "Epoch 117/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6330 - val_loss: 0.6433 - val_binary_accuracy: 0.6472\n",
            "Epoch 118/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6297 - val_loss: 0.6430 - val_binary_accuracy: 0.6422\n",
            "Epoch 119/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6401 - binary_accuracy: 0.6368 - val_loss: 0.6427 - val_binary_accuracy: 0.6476\n",
            "Epoch 120/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6452 - binary_accuracy: 0.6252 - val_loss: 0.6447 - val_binary_accuracy: 0.6463\n",
            "Epoch 121/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6404 - binary_accuracy: 0.6322 - val_loss: 0.6430 - val_binary_accuracy: 0.6472\n",
            "Epoch 122/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6407 - binary_accuracy: 0.6383 - val_loss: 0.6445 - val_binary_accuracy: 0.6451\n",
            "Epoch 123/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6311 - val_loss: 0.6422 - val_binary_accuracy: 0.6459\n",
            "Epoch 124/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6413 - binary_accuracy: 0.6302 - val_loss: 0.6436 - val_binary_accuracy: 0.6463\n",
            "Epoch 125/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6432 - binary_accuracy: 0.6334 - val_loss: 0.6435 - val_binary_accuracy: 0.6480\n",
            "Epoch 126/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6438 - binary_accuracy: 0.6327 - val_loss: 0.6423 - val_binary_accuracy: 0.6484\n",
            "Epoch 127/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6417 - binary_accuracy: 0.6346 - val_loss: 0.6421 - val_binary_accuracy: 0.6534\n",
            "Epoch 128/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6306 - val_loss: 0.6421 - val_binary_accuracy: 0.6501\n",
            "Epoch 129/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6344 - val_loss: 0.6420 - val_binary_accuracy: 0.6476\n",
            "Epoch 130/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6309 - val_loss: 0.6431 - val_binary_accuracy: 0.6484\n",
            "Epoch 131/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6439 - binary_accuracy: 0.6377 - val_loss: 0.6427 - val_binary_accuracy: 0.6505\n",
            "Epoch 132/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6435 - binary_accuracy: 0.6308 - val_loss: 0.6427 - val_binary_accuracy: 0.6476\n",
            "Epoch 133/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6400 - binary_accuracy: 0.6333 - val_loss: 0.6416 - val_binary_accuracy: 0.6489\n",
            "Epoch 134/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6337 - val_loss: 0.6448 - val_binary_accuracy: 0.6501\n",
            "Epoch 135/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6375 - val_loss: 0.6424 - val_binary_accuracy: 0.6501\n",
            "Epoch 136/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6336 - val_loss: 0.6424 - val_binary_accuracy: 0.6480\n",
            "Epoch 137/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6358 - val_loss: 0.6431 - val_binary_accuracy: 0.6463\n",
            "Epoch 138/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6425 - binary_accuracy: 0.6361 - val_loss: 0.6425 - val_binary_accuracy: 0.6451\n",
            "Epoch 139/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6413 - binary_accuracy: 0.6314 - val_loss: 0.6425 - val_binary_accuracy: 0.6472\n",
            "Epoch 140/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6342 - val_loss: 0.6419 - val_binary_accuracy: 0.6426\n",
            "Epoch 141/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6352 - val_loss: 0.6425 - val_binary_accuracy: 0.6514\n",
            "Epoch 142/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6405 - val_loss: 0.6415 - val_binary_accuracy: 0.6497\n",
            "Epoch 143/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6432 - binary_accuracy: 0.6342 - val_loss: 0.6426 - val_binary_accuracy: 0.6526\n",
            "Epoch 144/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6429 - binary_accuracy: 0.6354 - val_loss: 0.6418 - val_binary_accuracy: 0.6526\n",
            "Epoch 145/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6330 - val_loss: 0.6428 - val_binary_accuracy: 0.6501\n",
            "Epoch 146/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6320 - val_loss: 0.6421 - val_binary_accuracy: 0.6443\n",
            "Epoch 147/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6353 - val_loss: 0.6427 - val_binary_accuracy: 0.6484\n",
            "Epoch 148/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6453 - binary_accuracy: 0.6364 - val_loss: 0.6416 - val_binary_accuracy: 0.6476\n",
            "Epoch 149/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6400 - binary_accuracy: 0.6382 - val_loss: 0.6402 - val_binary_accuracy: 0.6463\n",
            "Epoch 150/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6404 - binary_accuracy: 0.6335 - val_loss: 0.6408 - val_binary_accuracy: 0.6493\n",
            "Epoch 151/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6381 - binary_accuracy: 0.6390 - val_loss: 0.6407 - val_binary_accuracy: 0.6576\n",
            "Epoch 152/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6347 - val_loss: 0.6425 - val_binary_accuracy: 0.6422\n",
            "Epoch 153/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6404 - binary_accuracy: 0.6367 - val_loss: 0.6417 - val_binary_accuracy: 0.6480\n",
            "Epoch 154/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6417 - binary_accuracy: 0.6370 - val_loss: 0.6404 - val_binary_accuracy: 0.6543\n",
            "Epoch 155/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6387 - val_loss: 0.6414 - val_binary_accuracy: 0.6472\n",
            "Epoch 156/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6405 - binary_accuracy: 0.6345 - val_loss: 0.6412 - val_binary_accuracy: 0.6405\n",
            "Epoch 157/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6413 - binary_accuracy: 0.6334 - val_loss: 0.6407 - val_binary_accuracy: 0.6564\n",
            "Epoch 158/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6395 - val_loss: 0.6412 - val_binary_accuracy: 0.6392\n",
            "Epoch 159/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6390 - binary_accuracy: 0.6360 - val_loss: 0.6405 - val_binary_accuracy: 0.6476\n",
            "Epoch 160/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6381 - binary_accuracy: 0.6391 - val_loss: 0.6405 - val_binary_accuracy: 0.6489\n",
            "Epoch 161/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6375 - binary_accuracy: 0.6404 - val_loss: 0.6395 - val_binary_accuracy: 0.6489\n",
            "Epoch 162/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6377 - val_loss: 0.6397 - val_binary_accuracy: 0.6530\n",
            "Epoch 163/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6386 - binary_accuracy: 0.6377 - val_loss: 0.6388 - val_binary_accuracy: 0.6459\n",
            "Epoch 164/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6411 - binary_accuracy: 0.6319 - val_loss: 0.6402 - val_binary_accuracy: 0.6459\n",
            "Epoch 165/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6394 - binary_accuracy: 0.6374 - val_loss: 0.6374 - val_binary_accuracy: 0.6468\n",
            "Epoch 166/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6360 - binary_accuracy: 0.6453 - val_loss: 0.6380 - val_binary_accuracy: 0.6468\n",
            "Epoch 167/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6320 - val_loss: 0.6392 - val_binary_accuracy: 0.6505\n",
            "Epoch 168/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6383 - val_loss: 0.6412 - val_binary_accuracy: 0.6480\n",
            "Epoch 169/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6427 - val_loss: 0.6390 - val_binary_accuracy: 0.6530\n",
            "Epoch 170/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6406 - binary_accuracy: 0.6390 - val_loss: 0.6397 - val_binary_accuracy: 0.6539\n",
            "Epoch 171/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6380 - binary_accuracy: 0.6333 - val_loss: 0.6379 - val_binary_accuracy: 0.6447\n",
            "Epoch 172/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6382 - val_loss: 0.6380 - val_binary_accuracy: 0.6472\n",
            "Epoch 173/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6413 - binary_accuracy: 0.6370 - val_loss: 0.6396 - val_binary_accuracy: 0.6539\n",
            "Epoch 174/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6371 - binary_accuracy: 0.6386 - val_loss: 0.6388 - val_binary_accuracy: 0.6434\n",
            "Epoch 175/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6376 - binary_accuracy: 0.6371 - val_loss: 0.6377 - val_binary_accuracy: 0.6514\n",
            "Epoch 176/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6396 - val_loss: 0.6371 - val_binary_accuracy: 0.6476\n",
            "Epoch 177/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6388 - binary_accuracy: 0.6379 - val_loss: 0.6382 - val_binary_accuracy: 0.6522\n",
            "Epoch 178/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6365 - val_loss: 0.6380 - val_binary_accuracy: 0.6434\n",
            "Epoch 179/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6429 - val_loss: 0.6395 - val_binary_accuracy: 0.6505\n",
            "Epoch 180/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6388 - binary_accuracy: 0.6426 - val_loss: 0.6380 - val_binary_accuracy: 0.6551\n",
            "Epoch 181/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6376 - val_loss: 0.6366 - val_binary_accuracy: 0.6601\n",
            "Epoch 182/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6418 - val_loss: 0.6373 - val_binary_accuracy: 0.6593\n",
            "Epoch 183/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6384 - binary_accuracy: 0.6391 - val_loss: 0.6400 - val_binary_accuracy: 0.6593\n",
            "Epoch 184/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6379 - binary_accuracy: 0.6419 - val_loss: 0.6376 - val_binary_accuracy: 0.6539\n",
            "Epoch 185/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6451 - val_loss: 0.6369 - val_binary_accuracy: 0.6526\n",
            "Epoch 186/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6369 - val_loss: 0.6381 - val_binary_accuracy: 0.6472\n",
            "Epoch 187/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6356 - binary_accuracy: 0.6375 - val_loss: 0.6387 - val_binary_accuracy: 0.6576\n",
            "Epoch 188/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6352 - binary_accuracy: 0.6435 - val_loss: 0.6346 - val_binary_accuracy: 0.6526\n",
            "Epoch 189/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6398 - val_loss: 0.6358 - val_binary_accuracy: 0.6526\n",
            "Epoch 190/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6342 - binary_accuracy: 0.6372 - val_loss: 0.6396 - val_binary_accuracy: 0.6551\n",
            "Epoch 191/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6421 - val_loss: 0.6358 - val_binary_accuracy: 0.6530\n",
            "Epoch 192/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6431 - val_loss: 0.6361 - val_binary_accuracy: 0.6505\n",
            "Epoch 193/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6355 - binary_accuracy: 0.6388 - val_loss: 0.6385 - val_binary_accuracy: 0.6551\n",
            "Epoch 194/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6389 - binary_accuracy: 0.6470 - val_loss: 0.6364 - val_binary_accuracy: 0.6530\n",
            "Epoch 195/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6502 - val_loss: 0.6346 - val_binary_accuracy: 0.6526\n",
            "Epoch 196/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6370 - binary_accuracy: 0.6383 - val_loss: 0.6367 - val_binary_accuracy: 0.6405\n",
            "Epoch 197/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6372 - binary_accuracy: 0.6395 - val_loss: 0.6356 - val_binary_accuracy: 0.6539\n",
            "Epoch 198/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6332 - binary_accuracy: 0.6406 - val_loss: 0.6352 - val_binary_accuracy: 0.6568\n",
            "Epoch 199/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6364 - binary_accuracy: 0.6427 - val_loss: 0.6364 - val_binary_accuracy: 0.6626\n",
            "Epoch 200/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6364 - binary_accuracy: 0.6427 - val_loss: 0.6362 - val_binary_accuracy: 0.6614\n",
            "Epoch 201/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6362 - binary_accuracy: 0.6357 - val_loss: 0.6373 - val_binary_accuracy: 0.6509\n",
            "Epoch 202/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6315 - binary_accuracy: 0.6446 - val_loss: 0.6358 - val_binary_accuracy: 0.6493\n",
            "Epoch 203/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6351 - binary_accuracy: 0.6380 - val_loss: 0.6366 - val_binary_accuracy: 0.6493\n",
            "Epoch 204/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6435 - val_loss: 0.6354 - val_binary_accuracy: 0.6572\n",
            "Epoch 205/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6347 - binary_accuracy: 0.6402 - val_loss: 0.6354 - val_binary_accuracy: 0.6605\n",
            "Epoch 206/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6378 - binary_accuracy: 0.6385 - val_loss: 0.6391 - val_binary_accuracy: 0.6580\n",
            "Epoch 207/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6316 - binary_accuracy: 0.6425 - val_loss: 0.6343 - val_binary_accuracy: 0.6472\n",
            "Epoch 208/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6431 - val_loss: 0.6362 - val_binary_accuracy: 0.6522\n",
            "Epoch 209/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6368 - binary_accuracy: 0.6420 - val_loss: 0.6374 - val_binary_accuracy: 0.6576\n",
            "Epoch 210/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6348 - binary_accuracy: 0.6394 - val_loss: 0.6360 - val_binary_accuracy: 0.6509\n",
            "Epoch 211/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6439 - val_loss: 0.6367 - val_binary_accuracy: 0.6593\n",
            "Epoch 212/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6359 - binary_accuracy: 0.6438 - val_loss: 0.6362 - val_binary_accuracy: 0.6551\n",
            "Epoch 213/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6391 - val_loss: 0.6370 - val_binary_accuracy: 0.6530\n",
            "Epoch 214/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6321 - binary_accuracy: 0.6457 - val_loss: 0.6346 - val_binary_accuracy: 0.6530\n",
            "Epoch 215/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6353 - binary_accuracy: 0.6445 - val_loss: 0.6368 - val_binary_accuracy: 0.6568\n",
            "Epoch 216/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6321 - binary_accuracy: 0.6435 - val_loss: 0.6352 - val_binary_accuracy: 0.6476\n",
            "Epoch 217/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6424 - val_loss: 0.6358 - val_binary_accuracy: 0.6551\n",
            "Epoch 218/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6328 - binary_accuracy: 0.6464 - val_loss: 0.6373 - val_binary_accuracy: 0.6518\n",
            "Epoch 219/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6354 - binary_accuracy: 0.6449 - val_loss: 0.6354 - val_binary_accuracy: 0.6593\n",
            "Epoch 220/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6343 - binary_accuracy: 0.6389 - val_loss: 0.6368 - val_binary_accuracy: 0.6514\n",
            "Epoch 221/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6403 - val_loss: 0.6355 - val_binary_accuracy: 0.6539\n",
            "Epoch 222/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6340 - binary_accuracy: 0.6449 - val_loss: 0.6338 - val_binary_accuracy: 0.6610\n",
            "Epoch 223/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6428 - val_loss: 0.6343 - val_binary_accuracy: 0.6605\n",
            "Epoch 224/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6445 - val_loss: 0.6353 - val_binary_accuracy: 0.6543\n",
            "Epoch 225/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6354 - binary_accuracy: 0.6427 - val_loss: 0.6350 - val_binary_accuracy: 0.6614\n",
            "Epoch 226/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6341 - binary_accuracy: 0.6456 - val_loss: 0.6337 - val_binary_accuracy: 0.6610\n",
            "Epoch 227/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6502 - val_loss: 0.6347 - val_binary_accuracy: 0.6547\n",
            "Epoch 228/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6350 - binary_accuracy: 0.6452 - val_loss: 0.6362 - val_binary_accuracy: 0.6555\n",
            "Epoch 229/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6395 - val_loss: 0.6344 - val_binary_accuracy: 0.6605\n",
            "Epoch 230/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6312 - binary_accuracy: 0.6441 - val_loss: 0.6354 - val_binary_accuracy: 0.6618\n",
            "Epoch 231/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6464 - val_loss: 0.6339 - val_binary_accuracy: 0.6618\n",
            "Epoch 232/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6321 - binary_accuracy: 0.6440 - val_loss: 0.6350 - val_binary_accuracy: 0.6580\n",
            "Epoch 233/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6354 - binary_accuracy: 0.6433 - val_loss: 0.6350 - val_binary_accuracy: 0.6572\n",
            "Epoch 234/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6324 - binary_accuracy: 0.6468 - val_loss: 0.6341 - val_binary_accuracy: 0.6585\n",
            "Epoch 235/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6338 - binary_accuracy: 0.6446 - val_loss: 0.6360 - val_binary_accuracy: 0.6484\n",
            "Epoch 236/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6328 - binary_accuracy: 0.6421 - val_loss: 0.6337 - val_binary_accuracy: 0.6522\n",
            "Epoch 237/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6480 - val_loss: 0.6340 - val_binary_accuracy: 0.6610\n",
            "Epoch 238/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6335 - binary_accuracy: 0.6428 - val_loss: 0.6345 - val_binary_accuracy: 0.6605\n",
            "Epoch 239/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6334 - binary_accuracy: 0.6454 - val_loss: 0.6345 - val_binary_accuracy: 0.6622\n",
            "Epoch 240/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6310 - binary_accuracy: 0.6419 - val_loss: 0.6336 - val_binary_accuracy: 0.6559\n",
            "Epoch 241/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6313 - binary_accuracy: 0.6460 - val_loss: 0.6327 - val_binary_accuracy: 0.6530\n",
            "Epoch 242/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6412 - val_loss: 0.6361 - val_binary_accuracy: 0.6568\n",
            "Epoch 243/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6447 - val_loss: 0.6315 - val_binary_accuracy: 0.6564\n",
            "Epoch 244/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6326 - binary_accuracy: 0.6469 - val_loss: 0.6331 - val_binary_accuracy: 0.6539\n",
            "Epoch 245/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6434 - val_loss: 0.6336 - val_binary_accuracy: 0.6568\n",
            "Epoch 246/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6327 - binary_accuracy: 0.6460 - val_loss: 0.6339 - val_binary_accuracy: 0.6593\n",
            "Epoch 247/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6308 - binary_accuracy: 0.6445 - val_loss: 0.6336 - val_binary_accuracy: 0.6555\n",
            "Epoch 248/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6309 - binary_accuracy: 0.6417 - val_loss: 0.6344 - val_binary_accuracy: 0.6618\n",
            "Epoch 249/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6419 - val_loss: 0.6356 - val_binary_accuracy: 0.6580\n",
            "Epoch 250/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6479 - val_loss: 0.6349 - val_binary_accuracy: 0.6593\n",
            "Epoch 251/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6458 - val_loss: 0.6330 - val_binary_accuracy: 0.6635\n",
            "Epoch 252/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6482 - val_loss: 0.6332 - val_binary_accuracy: 0.6656\n",
            "Epoch 253/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6314 - binary_accuracy: 0.6411 - val_loss: 0.6326 - val_binary_accuracy: 0.6505\n",
            "Epoch 254/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6434 - val_loss: 0.6343 - val_binary_accuracy: 0.6614\n",
            "Epoch 255/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6305 - binary_accuracy: 0.6468 - val_loss: 0.6338 - val_binary_accuracy: 0.6630\n",
            "Epoch 256/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6446 - val_loss: 0.6334 - val_binary_accuracy: 0.6593\n",
            "Epoch 257/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6468 - val_loss: 0.6313 - val_binary_accuracy: 0.6618\n",
            "Epoch 258/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6486 - val_loss: 0.6319 - val_binary_accuracy: 0.6522\n",
            "Epoch 259/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6296 - binary_accuracy: 0.6532 - val_loss: 0.6320 - val_binary_accuracy: 0.6559\n",
            "Epoch 260/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6468 - val_loss: 0.6335 - val_binary_accuracy: 0.6635\n",
            "Epoch 261/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6460 - val_loss: 0.6340 - val_binary_accuracy: 0.6534\n",
            "Epoch 262/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6445 - val_loss: 0.6332 - val_binary_accuracy: 0.6589\n",
            "Epoch 263/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6488 - val_loss: 0.6321 - val_binary_accuracy: 0.6509\n",
            "Epoch 264/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6318 - binary_accuracy: 0.6440 - val_loss: 0.6330 - val_binary_accuracy: 0.6610\n",
            "Epoch 265/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6281 - binary_accuracy: 0.6470 - val_loss: 0.6317 - val_binary_accuracy: 0.6605\n",
            "Epoch 266/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6471 - val_loss: 0.6306 - val_binary_accuracy: 0.6593\n",
            "Epoch 267/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6321 - binary_accuracy: 0.6438 - val_loss: 0.6316 - val_binary_accuracy: 0.6576\n",
            "Epoch 268/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6460 - val_loss: 0.6314 - val_binary_accuracy: 0.6576\n",
            "Epoch 269/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6491 - val_loss: 0.6306 - val_binary_accuracy: 0.6559\n",
            "Epoch 270/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6320 - binary_accuracy: 0.6448 - val_loss: 0.6317 - val_binary_accuracy: 0.6572\n",
            "Epoch 271/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6289 - binary_accuracy: 0.6456 - val_loss: 0.6324 - val_binary_accuracy: 0.6568\n",
            "Epoch 272/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6478 - val_loss: 0.6309 - val_binary_accuracy: 0.6585\n",
            "Epoch 273/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6324 - binary_accuracy: 0.6446 - val_loss: 0.6321 - val_binary_accuracy: 0.6601\n",
            "Epoch 274/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6494 - val_loss: 0.6333 - val_binary_accuracy: 0.6630\n",
            "Epoch 275/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6454 - val_loss: 0.6312 - val_binary_accuracy: 0.6643\n",
            "Epoch 276/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6438 - val_loss: 0.6305 - val_binary_accuracy: 0.6643\n",
            "Epoch 277/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6494 - val_loss: 0.6334 - val_binary_accuracy: 0.6547\n",
            "Epoch 278/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6297 - binary_accuracy: 0.6446 - val_loss: 0.6330 - val_binary_accuracy: 0.6593\n",
            "Epoch 279/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6496 - val_loss: 0.6324 - val_binary_accuracy: 0.6601\n",
            "Epoch 280/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6467 - val_loss: 0.6326 - val_binary_accuracy: 0.6630\n",
            "Epoch 281/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6488 - val_loss: 0.6328 - val_binary_accuracy: 0.6635\n",
            "Epoch 282/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6429 - val_loss: 0.6332 - val_binary_accuracy: 0.6559\n",
            "Epoch 283/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6501 - val_loss: 0.6316 - val_binary_accuracy: 0.6618\n",
            "Epoch 284/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6536 - val_loss: 0.6309 - val_binary_accuracy: 0.6505\n",
            "Epoch 285/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6522 - val_loss: 0.6312 - val_binary_accuracy: 0.6572\n",
            "Epoch 286/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6307 - binary_accuracy: 0.6505 - val_loss: 0.6317 - val_binary_accuracy: 0.6543\n",
            "Epoch 287/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6283 - binary_accuracy: 0.6471 - val_loss: 0.6308 - val_binary_accuracy: 0.6610\n",
            "Epoch 288/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6290 - binary_accuracy: 0.6506 - val_loss: 0.6305 - val_binary_accuracy: 0.6572\n",
            "Epoch 289/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6304 - binary_accuracy: 0.6471 - val_loss: 0.6292 - val_binary_accuracy: 0.6614\n",
            "Epoch 290/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6477 - val_loss: 0.6308 - val_binary_accuracy: 0.6630\n",
            "Epoch 291/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6277 - binary_accuracy: 0.6521 - val_loss: 0.6313 - val_binary_accuracy: 0.6601\n",
            "Epoch 292/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6487 - val_loss: 0.6308 - val_binary_accuracy: 0.6626\n",
            "Epoch 293/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6299 - binary_accuracy: 0.6447 - val_loss: 0.6309 - val_binary_accuracy: 0.6626\n",
            "Epoch 294/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6470 - val_loss: 0.6323 - val_binary_accuracy: 0.6601\n",
            "Epoch 295/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6303 - binary_accuracy: 0.6488 - val_loss: 0.6320 - val_binary_accuracy: 0.6630\n",
            "Epoch 296/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6553 - val_loss: 0.6287 - val_binary_accuracy: 0.6572\n",
            "Epoch 297/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6293 - binary_accuracy: 0.6471 - val_loss: 0.6300 - val_binary_accuracy: 0.6585\n",
            "Epoch 298/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6480 - val_loss: 0.6327 - val_binary_accuracy: 0.6614\n",
            "Epoch 299/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6481 - val_loss: 0.6304 - val_binary_accuracy: 0.6551\n",
            "Epoch 300/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6453 - val_loss: 0.6298 - val_binary_accuracy: 0.6547\n",
            "Epoch 301/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6486 - val_loss: 0.6289 - val_binary_accuracy: 0.6614\n",
            "Epoch 302/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6276 - binary_accuracy: 0.6486 - val_loss: 0.6310 - val_binary_accuracy: 0.6580\n",
            "Epoch 303/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6487 - val_loss: 0.6300 - val_binary_accuracy: 0.6614\n",
            "Epoch 304/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6478 - val_loss: 0.6303 - val_binary_accuracy: 0.6601\n",
            "Epoch 305/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6492 - val_loss: 0.6304 - val_binary_accuracy: 0.6618\n",
            "Epoch 306/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6275 - binary_accuracy: 0.6460 - val_loss: 0.6293 - val_binary_accuracy: 0.6597\n",
            "Epoch 307/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6287 - binary_accuracy: 0.6493 - val_loss: 0.6288 - val_binary_accuracy: 0.6576\n",
            "Epoch 308/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6495 - val_loss: 0.6288 - val_binary_accuracy: 0.6564\n",
            "Epoch 309/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6298 - binary_accuracy: 0.6454 - val_loss: 0.6290 - val_binary_accuracy: 0.6651\n",
            "Epoch 310/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6295 - binary_accuracy: 0.6444 - val_loss: 0.6306 - val_binary_accuracy: 0.6593\n",
            "Epoch 311/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6502 - val_loss: 0.6300 - val_binary_accuracy: 0.6630\n",
            "Epoch 312/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6523 - val_loss: 0.6282 - val_binary_accuracy: 0.6601\n",
            "Epoch 313/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6500 - val_loss: 0.6304 - val_binary_accuracy: 0.6597\n",
            "Epoch 314/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6515 - val_loss: 0.6288 - val_binary_accuracy: 0.6518\n",
            "Epoch 315/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6496 - val_loss: 0.6287 - val_binary_accuracy: 0.6630\n",
            "Epoch 316/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6291 - binary_accuracy: 0.6483 - val_loss: 0.6293 - val_binary_accuracy: 0.6622\n",
            "Epoch 317/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6514 - val_loss: 0.6289 - val_binary_accuracy: 0.6518\n",
            "Epoch 318/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6284 - binary_accuracy: 0.6491 - val_loss: 0.6292 - val_binary_accuracy: 0.6676\n",
            "Epoch 319/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6518 - val_loss: 0.6296 - val_binary_accuracy: 0.6630\n",
            "Epoch 320/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6513 - val_loss: 0.6300 - val_binary_accuracy: 0.6664\n",
            "Epoch 321/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6446 - val_loss: 0.6275 - val_binary_accuracy: 0.6656\n",
            "Epoch 322/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6485 - val_loss: 0.6293 - val_binary_accuracy: 0.6530\n",
            "Epoch 323/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6292 - binary_accuracy: 0.6493 - val_loss: 0.6300 - val_binary_accuracy: 0.6576\n",
            "Epoch 324/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6480 - val_loss: 0.6288 - val_binary_accuracy: 0.6672\n",
            "Epoch 325/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6520 - val_loss: 0.6290 - val_binary_accuracy: 0.6518\n",
            "Epoch 326/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6301 - binary_accuracy: 0.6476 - val_loss: 0.6300 - val_binary_accuracy: 0.6580\n",
            "Epoch 327/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6492 - val_loss: 0.6284 - val_binary_accuracy: 0.6572\n",
            "Epoch 328/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6282 - binary_accuracy: 0.6488 - val_loss: 0.6298 - val_binary_accuracy: 0.6526\n",
            "Epoch 329/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6488 - val_loss: 0.6282 - val_binary_accuracy: 0.6601\n",
            "Epoch 330/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6259 - binary_accuracy: 0.6477 - val_loss: 0.6281 - val_binary_accuracy: 0.6597\n",
            "Epoch 331/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6509 - val_loss: 0.6285 - val_binary_accuracy: 0.6551\n",
            "Epoch 332/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6279 - binary_accuracy: 0.6484 - val_loss: 0.6291 - val_binary_accuracy: 0.6551\n",
            "Epoch 333/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6488 - val_loss: 0.6294 - val_binary_accuracy: 0.6572\n",
            "Epoch 334/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6518 - val_loss: 0.6284 - val_binary_accuracy: 0.6643\n",
            "Epoch 335/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6503 - val_loss: 0.6277 - val_binary_accuracy: 0.6639\n",
            "Epoch 336/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6471 - val_loss: 0.6286 - val_binary_accuracy: 0.6622\n",
            "Epoch 337/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6508 - val_loss: 0.6273 - val_binary_accuracy: 0.6593\n",
            "Epoch 338/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6563 - val_loss: 0.6283 - val_binary_accuracy: 0.6647\n",
            "Epoch 339/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6257 - binary_accuracy: 0.6506 - val_loss: 0.6283 - val_binary_accuracy: 0.6660\n",
            "Epoch 340/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6505 - val_loss: 0.6272 - val_binary_accuracy: 0.6564\n",
            "Epoch 341/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6504 - val_loss: 0.6278 - val_binary_accuracy: 0.6610\n",
            "Epoch 342/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6511 - val_loss: 0.6258 - val_binary_accuracy: 0.6597\n",
            "Epoch 343/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6529 - val_loss: 0.6283 - val_binary_accuracy: 0.6610\n",
            "Epoch 344/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6555 - val_loss: 0.6288 - val_binary_accuracy: 0.6614\n",
            "Epoch 345/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6471 - val_loss: 0.6277 - val_binary_accuracy: 0.6630\n",
            "Epoch 346/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6573 - val_loss: 0.6281 - val_binary_accuracy: 0.6610\n",
            "Epoch 347/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6274 - binary_accuracy: 0.6475 - val_loss: 0.6297 - val_binary_accuracy: 0.6593\n",
            "Epoch 348/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6478 - val_loss: 0.6278 - val_binary_accuracy: 0.6618\n",
            "Epoch 349/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6574 - val_loss: 0.6257 - val_binary_accuracy: 0.6572\n",
            "Epoch 350/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6300 - binary_accuracy: 0.6514 - val_loss: 0.6298 - val_binary_accuracy: 0.6722\n",
            "Epoch 351/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6539 - val_loss: 0.6260 - val_binary_accuracy: 0.6630\n",
            "Epoch 352/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6545 - val_loss: 0.6292 - val_binary_accuracy: 0.6651\n",
            "Epoch 353/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6286 - binary_accuracy: 0.6512 - val_loss: 0.6293 - val_binary_accuracy: 0.6622\n",
            "Epoch 354/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6477 - val_loss: 0.6306 - val_binary_accuracy: 0.6643\n",
            "Epoch 355/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6508 - val_loss: 0.6283 - val_binary_accuracy: 0.6635\n",
            "Epoch 356/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6264 - binary_accuracy: 0.6527 - val_loss: 0.6276 - val_binary_accuracy: 0.6605\n",
            "Epoch 357/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6516 - val_loss: 0.6283 - val_binary_accuracy: 0.6526\n",
            "Epoch 358/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6535 - val_loss: 0.6286 - val_binary_accuracy: 0.6630\n",
            "Epoch 359/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6509 - val_loss: 0.6269 - val_binary_accuracy: 0.6647\n",
            "Epoch 360/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6258 - binary_accuracy: 0.6454 - val_loss: 0.6282 - val_binary_accuracy: 0.6564\n",
            "Epoch 361/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6253 - binary_accuracy: 0.6590 - val_loss: 0.6252 - val_binary_accuracy: 0.6630\n",
            "Epoch 362/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6534 - val_loss: 0.6278 - val_binary_accuracy: 0.6551\n",
            "Epoch 363/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6565 - val_loss: 0.6268 - val_binary_accuracy: 0.6635\n",
            "Epoch 364/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6543 - val_loss: 0.6284 - val_binary_accuracy: 0.6618\n",
            "Epoch 365/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6244 - binary_accuracy: 0.6545 - val_loss: 0.6297 - val_binary_accuracy: 0.6656\n",
            "Epoch 366/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6545 - val_loss: 0.6281 - val_binary_accuracy: 0.6589\n",
            "Epoch 367/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6521 - val_loss: 0.6280 - val_binary_accuracy: 0.6656\n",
            "Epoch 368/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6495 - val_loss: 0.6273 - val_binary_accuracy: 0.6568\n",
            "Epoch 369/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6515 - val_loss: 0.6258 - val_binary_accuracy: 0.6626\n",
            "Epoch 370/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6250 - binary_accuracy: 0.6507 - val_loss: 0.6296 - val_binary_accuracy: 0.6564\n",
            "Epoch 371/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6451 - val_loss: 0.6267 - val_binary_accuracy: 0.6672\n",
            "Epoch 372/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6542 - val_loss: 0.6266 - val_binary_accuracy: 0.6672\n",
            "Epoch 373/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6249 - binary_accuracy: 0.6512 - val_loss: 0.6259 - val_binary_accuracy: 0.6593\n",
            "Epoch 374/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6263 - binary_accuracy: 0.6503 - val_loss: 0.6269 - val_binary_accuracy: 0.6593\n",
            "Epoch 375/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6280 - binary_accuracy: 0.6531 - val_loss: 0.6271 - val_binary_accuracy: 0.6601\n",
            "Epoch 376/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6256 - binary_accuracy: 0.6509 - val_loss: 0.6288 - val_binary_accuracy: 0.6559\n",
            "Epoch 377/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6272 - binary_accuracy: 0.6481 - val_loss: 0.6280 - val_binary_accuracy: 0.6643\n",
            "Epoch 378/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6531 - val_loss: 0.6292 - val_binary_accuracy: 0.6647\n",
            "Epoch 379/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6480 - val_loss: 0.6284 - val_binary_accuracy: 0.6580\n",
            "Epoch 380/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6546 - val_loss: 0.6269 - val_binary_accuracy: 0.6651\n",
            "Epoch 381/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6546 - val_loss: 0.6286 - val_binary_accuracy: 0.6601\n",
            "Epoch 382/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6493 - val_loss: 0.6274 - val_binary_accuracy: 0.6610\n",
            "Epoch 383/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6499 - val_loss: 0.6258 - val_binary_accuracy: 0.6614\n",
            "Epoch 384/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6492 - val_loss: 0.6269 - val_binary_accuracy: 0.6630\n",
            "Epoch 385/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6269 - binary_accuracy: 0.6546 - val_loss: 0.6261 - val_binary_accuracy: 0.6610\n",
            "Epoch 386/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6231 - binary_accuracy: 0.6560 - val_loss: 0.6262 - val_binary_accuracy: 0.6530\n",
            "Epoch 387/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6254 - binary_accuracy: 0.6539 - val_loss: 0.6264 - val_binary_accuracy: 0.6610\n",
            "Epoch 388/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6514 - val_loss: 0.6265 - val_binary_accuracy: 0.6564\n",
            "Epoch 389/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6499 - val_loss: 0.6284 - val_binary_accuracy: 0.6526\n",
            "Epoch 390/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6261 - binary_accuracy: 0.6548 - val_loss: 0.6270 - val_binary_accuracy: 0.6614\n",
            "Epoch 391/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6514 - val_loss: 0.6256 - val_binary_accuracy: 0.6618\n",
            "Epoch 392/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6546 - val_loss: 0.6269 - val_binary_accuracy: 0.6651\n",
            "Epoch 393/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6533 - val_loss: 0.6250 - val_binary_accuracy: 0.6656\n",
            "Epoch 394/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6509 - val_loss: 0.6299 - val_binary_accuracy: 0.6618\n",
            "Epoch 395/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6536 - val_loss: 0.6265 - val_binary_accuracy: 0.6559\n",
            "Epoch 396/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6514 - val_loss: 0.6279 - val_binary_accuracy: 0.6643\n",
            "Epoch 397/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6574 - val_loss: 0.6264 - val_binary_accuracy: 0.6647\n",
            "Epoch 398/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6513 - val_loss: 0.6287 - val_binary_accuracy: 0.6664\n",
            "Epoch 399/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6535 - val_loss: 0.6256 - val_binary_accuracy: 0.6555\n",
            "Epoch 400/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6262 - binary_accuracy: 0.6506 - val_loss: 0.6271 - val_binary_accuracy: 0.6630\n",
            "Epoch 401/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6513 - val_loss: 0.6264 - val_binary_accuracy: 0.6555\n",
            "Epoch 402/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6534 - val_loss: 0.6261 - val_binary_accuracy: 0.6451\n",
            "Epoch 403/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6567 - val_loss: 0.6227 - val_binary_accuracy: 0.6639\n",
            "Epoch 404/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6556 - val_loss: 0.6249 - val_binary_accuracy: 0.6635\n",
            "Epoch 405/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6584 - val_loss: 0.6255 - val_binary_accuracy: 0.6643\n",
            "Epoch 406/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6544 - val_loss: 0.6260 - val_binary_accuracy: 0.6630\n",
            "Epoch 407/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6565 - val_loss: 0.6270 - val_binary_accuracy: 0.6651\n",
            "Epoch 408/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6273 - binary_accuracy: 0.6520 - val_loss: 0.6284 - val_binary_accuracy: 0.6593\n",
            "Epoch 409/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6547 - val_loss: 0.6260 - val_binary_accuracy: 0.6681\n",
            "Epoch 410/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6565 - val_loss: 0.6253 - val_binary_accuracy: 0.6643\n",
            "Epoch 411/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6265 - binary_accuracy: 0.6510 - val_loss: 0.6264 - val_binary_accuracy: 0.6576\n",
            "Epoch 412/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6591 - val_loss: 0.6252 - val_binary_accuracy: 0.6681\n",
            "Epoch 413/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6520 - val_loss: 0.6262 - val_binary_accuracy: 0.6568\n",
            "Epoch 414/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6523 - val_loss: 0.6292 - val_binary_accuracy: 0.6593\n",
            "Epoch 415/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6538 - val_loss: 0.6276 - val_binary_accuracy: 0.6597\n",
            "Epoch 416/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6544 - val_loss: 0.6255 - val_binary_accuracy: 0.6656\n",
            "Epoch 417/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6498 - val_loss: 0.6276 - val_binary_accuracy: 0.6681\n",
            "Epoch 418/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6576 - val_loss: 0.6247 - val_binary_accuracy: 0.6668\n",
            "Epoch 419/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6568 - val_loss: 0.6258 - val_binary_accuracy: 0.6559\n",
            "Epoch 420/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6566 - val_loss: 0.6252 - val_binary_accuracy: 0.6668\n",
            "Epoch 421/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6514 - val_loss: 0.6247 - val_binary_accuracy: 0.6668\n",
            "Epoch 422/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6506 - val_loss: 0.6273 - val_binary_accuracy: 0.6651\n",
            "Epoch 423/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6549 - val_loss: 0.6231 - val_binary_accuracy: 0.6664\n",
            "Epoch 424/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6247 - binary_accuracy: 0.6562 - val_loss: 0.6249 - val_binary_accuracy: 0.6656\n",
            "Epoch 425/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6548 - val_loss: 0.6248 - val_binary_accuracy: 0.6660\n",
            "Epoch 426/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6240 - binary_accuracy: 0.6538 - val_loss: 0.6257 - val_binary_accuracy: 0.6656\n",
            "Epoch 427/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6531 - val_loss: 0.6259 - val_binary_accuracy: 0.6605\n",
            "Epoch 428/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6537 - val_loss: 0.6236 - val_binary_accuracy: 0.6614\n",
            "Epoch 429/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6572 - val_loss: 0.6237 - val_binary_accuracy: 0.6635\n",
            "Epoch 430/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6541 - val_loss: 0.6268 - val_binary_accuracy: 0.6605\n",
            "Epoch 431/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6251 - binary_accuracy: 0.6527 - val_loss: 0.6260 - val_binary_accuracy: 0.6610\n",
            "Epoch 432/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6226 - binary_accuracy: 0.6550 - val_loss: 0.6243 - val_binary_accuracy: 0.6559\n",
            "Epoch 433/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6235 - binary_accuracy: 0.6516 - val_loss: 0.6238 - val_binary_accuracy: 0.6643\n",
            "Epoch 434/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6580 - val_loss: 0.6261 - val_binary_accuracy: 0.6647\n",
            "Epoch 435/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6252 - binary_accuracy: 0.6506 - val_loss: 0.6262 - val_binary_accuracy: 0.6668\n",
            "Epoch 436/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6248 - binary_accuracy: 0.6558 - val_loss: 0.6235 - val_binary_accuracy: 0.6672\n",
            "Epoch 437/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6267 - binary_accuracy: 0.6531 - val_loss: 0.6262 - val_binary_accuracy: 0.6547\n",
            "Epoch 438/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6550 - val_loss: 0.6244 - val_binary_accuracy: 0.6614\n",
            "Epoch 439/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6579 - val_loss: 0.6255 - val_binary_accuracy: 0.6480\n",
            "Epoch 440/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6574 - val_loss: 0.6255 - val_binary_accuracy: 0.6585\n",
            "Epoch 441/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6589 - val_loss: 0.6254 - val_binary_accuracy: 0.6626\n",
            "Epoch 442/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6514 - val_loss: 0.6242 - val_binary_accuracy: 0.6597\n",
            "Epoch 443/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6559 - val_loss: 0.6256 - val_binary_accuracy: 0.6626\n",
            "Epoch 444/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6553 - val_loss: 0.6265 - val_binary_accuracy: 0.6614\n",
            "Epoch 445/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6539 - val_loss: 0.6245 - val_binary_accuracy: 0.6639\n",
            "Epoch 446/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6553 - val_loss: 0.6260 - val_binary_accuracy: 0.6576\n",
            "Epoch 447/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6551 - val_loss: 0.6244 - val_binary_accuracy: 0.6635\n",
            "Epoch 448/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6569 - val_loss: 0.6227 - val_binary_accuracy: 0.6614\n",
            "Epoch 449/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6522 - val_loss: 0.6246 - val_binary_accuracy: 0.6647\n",
            "Epoch 450/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6570 - val_loss: 0.6251 - val_binary_accuracy: 0.6635\n",
            "Epoch 451/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6576 - val_loss: 0.6249 - val_binary_accuracy: 0.6660\n",
            "Epoch 452/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6584 - val_loss: 0.6254 - val_binary_accuracy: 0.6564\n",
            "Epoch 453/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6514 - val_loss: 0.6266 - val_binary_accuracy: 0.6660\n",
            "Epoch 454/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6571 - val_loss: 0.6257 - val_binary_accuracy: 0.6647\n",
            "Epoch 455/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6557 - val_loss: 0.6250 - val_binary_accuracy: 0.6559\n",
            "Epoch 456/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6573 - val_loss: 0.6234 - val_binary_accuracy: 0.6664\n",
            "Epoch 457/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6525 - val_loss: 0.6253 - val_binary_accuracy: 0.6639\n",
            "Epoch 458/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6573 - val_loss: 0.6239 - val_binary_accuracy: 0.6664\n",
            "Epoch 459/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6577 - val_loss: 0.6240 - val_binary_accuracy: 0.6647\n",
            "Epoch 460/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6223 - binary_accuracy: 0.6541 - val_loss: 0.6261 - val_binary_accuracy: 0.6593\n",
            "Epoch 461/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6544 - val_loss: 0.6254 - val_binary_accuracy: 0.6618\n",
            "Epoch 462/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6531 - val_loss: 0.6256 - val_binary_accuracy: 0.6639\n",
            "Epoch 463/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6606 - val_loss: 0.6243 - val_binary_accuracy: 0.6622\n",
            "Epoch 464/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6260 - binary_accuracy: 0.6528 - val_loss: 0.6241 - val_binary_accuracy: 0.6693\n",
            "Epoch 465/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6552 - val_loss: 0.6246 - val_binary_accuracy: 0.6597\n",
            "Epoch 466/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6554 - val_loss: 0.6228 - val_binary_accuracy: 0.6585\n",
            "Epoch 467/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6584 - val_loss: 0.6238 - val_binary_accuracy: 0.6656\n",
            "Epoch 468/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6242 - binary_accuracy: 0.6513 - val_loss: 0.6250 - val_binary_accuracy: 0.6585\n",
            "Epoch 469/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6555 - val_loss: 0.6257 - val_binary_accuracy: 0.6559\n",
            "Epoch 470/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6565 - val_loss: 0.6257 - val_binary_accuracy: 0.6605\n",
            "Epoch 471/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6521 - val_loss: 0.6232 - val_binary_accuracy: 0.6651\n",
            "Epoch 472/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6512 - val_loss: 0.6251 - val_binary_accuracy: 0.6651\n",
            "Epoch 473/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6607 - val_loss: 0.6255 - val_binary_accuracy: 0.6672\n",
            "Epoch 474/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6596 - val_loss: 0.6227 - val_binary_accuracy: 0.6593\n",
            "Epoch 475/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6579 - val_loss: 0.6241 - val_binary_accuracy: 0.6664\n",
            "Epoch 476/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6540 - val_loss: 0.6237 - val_binary_accuracy: 0.6672\n",
            "Epoch 477/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6553 - val_loss: 0.6237 - val_binary_accuracy: 0.6639\n",
            "Epoch 478/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6574 - val_loss: 0.6240 - val_binary_accuracy: 0.6614\n",
            "Epoch 479/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6544 - val_loss: 0.6225 - val_binary_accuracy: 0.6643\n",
            "Epoch 480/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6593 - val_loss: 0.6232 - val_binary_accuracy: 0.6643\n",
            "Epoch 481/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6573 - val_loss: 0.6252 - val_binary_accuracy: 0.6664\n",
            "Epoch 482/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6238 - binary_accuracy: 0.6557 - val_loss: 0.6244 - val_binary_accuracy: 0.6618\n",
            "Epoch 483/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6574 - val_loss: 0.6243 - val_binary_accuracy: 0.6630\n",
            "Epoch 484/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6570 - val_loss: 0.6239 - val_binary_accuracy: 0.6547\n",
            "Epoch 485/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6573 - val_loss: 0.6245 - val_binary_accuracy: 0.6660\n",
            "Epoch 486/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6486 - val_loss: 0.6241 - val_binary_accuracy: 0.6635\n",
            "Epoch 487/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6545 - val_loss: 0.6243 - val_binary_accuracy: 0.6614\n",
            "Epoch 488/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6531 - val_loss: 0.6238 - val_binary_accuracy: 0.6651\n",
            "Epoch 489/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6543 - val_loss: 0.6223 - val_binary_accuracy: 0.6626\n",
            "Epoch 490/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6582 - val_loss: 0.6223 - val_binary_accuracy: 0.6651\n",
            "Epoch 491/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6588 - val_loss: 0.6225 - val_binary_accuracy: 0.6672\n",
            "Epoch 492/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6239 - binary_accuracy: 0.6539 - val_loss: 0.6253 - val_binary_accuracy: 0.6656\n",
            "Epoch 493/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6589 - val_loss: 0.6223 - val_binary_accuracy: 0.6618\n",
            "Epoch 494/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6557 - val_loss: 0.6227 - val_binary_accuracy: 0.6622\n",
            "Epoch 495/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6225 - binary_accuracy: 0.6568 - val_loss: 0.6233 - val_binary_accuracy: 0.6568\n",
            "Epoch 496/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6572 - val_loss: 0.6253 - val_binary_accuracy: 0.6597\n",
            "Epoch 497/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6588 - val_loss: 0.6228 - val_binary_accuracy: 0.6622\n",
            "Epoch 498/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6529 - val_loss: 0.6241 - val_binary_accuracy: 0.6593\n",
            "Epoch 499/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6559 - val_loss: 0.6226 - val_binary_accuracy: 0.6589\n",
            "Epoch 500/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6594 - val_loss: 0.6232 - val_binary_accuracy: 0.6564\n",
            "Epoch 501/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6585 - val_loss: 0.6235 - val_binary_accuracy: 0.6647\n",
            "Epoch 502/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6241 - binary_accuracy: 0.6564 - val_loss: 0.6237 - val_binary_accuracy: 0.6626\n",
            "Epoch 503/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6582 - val_loss: 0.6230 - val_binary_accuracy: 0.6580\n",
            "Epoch 504/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6547 - val_loss: 0.6211 - val_binary_accuracy: 0.6614\n",
            "Epoch 505/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6536 - val_loss: 0.6254 - val_binary_accuracy: 0.6559\n",
            "Epoch 506/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6556 - val_loss: 0.6238 - val_binary_accuracy: 0.6576\n",
            "Epoch 507/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6218 - binary_accuracy: 0.6564 - val_loss: 0.6244 - val_binary_accuracy: 0.6605\n",
            "Epoch 508/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6597 - val_loss: 0.6212 - val_binary_accuracy: 0.6618\n",
            "Epoch 509/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6574 - val_loss: 0.6230 - val_binary_accuracy: 0.6647\n",
            "Epoch 510/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6553 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 511/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6574 - val_loss: 0.6216 - val_binary_accuracy: 0.6647\n",
            "Epoch 512/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6565 - val_loss: 0.6222 - val_binary_accuracy: 0.6647\n",
            "Epoch 513/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6589 - val_loss: 0.6220 - val_binary_accuracy: 0.6601\n",
            "Epoch 514/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6236 - binary_accuracy: 0.6558 - val_loss: 0.6248 - val_binary_accuracy: 0.6610\n",
            "Epoch 515/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6604 - val_loss: 0.6224 - val_binary_accuracy: 0.6656\n",
            "Epoch 516/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6594 - val_loss: 0.6229 - val_binary_accuracy: 0.6593\n",
            "Epoch 517/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6551 - val_loss: 0.6246 - val_binary_accuracy: 0.6522\n",
            "Epoch 518/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6547 - val_loss: 0.6233 - val_binary_accuracy: 0.6564\n",
            "Epoch 519/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6255 - binary_accuracy: 0.6578 - val_loss: 0.6240 - val_binary_accuracy: 0.6622\n",
            "Epoch 520/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6243 - binary_accuracy: 0.6602 - val_loss: 0.6246 - val_binary_accuracy: 0.6639\n",
            "Epoch 521/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6555 - val_loss: 0.6231 - val_binary_accuracy: 0.6601\n",
            "Epoch 522/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6610 - val_loss: 0.6204 - val_binary_accuracy: 0.6614\n",
            "Epoch 523/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6594 - val_loss: 0.6212 - val_binary_accuracy: 0.6660\n",
            "Epoch 524/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6568 - val_loss: 0.6233 - val_binary_accuracy: 0.6580\n",
            "Epoch 525/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6561 - val_loss: 0.6231 - val_binary_accuracy: 0.6614\n",
            "Epoch 526/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6541 - val_loss: 0.6234 - val_binary_accuracy: 0.6639\n",
            "Epoch 527/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6213 - binary_accuracy: 0.6642 - val_loss: 0.6227 - val_binary_accuracy: 0.6614\n",
            "Epoch 528/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6582 - val_loss: 0.6230 - val_binary_accuracy: 0.6597\n",
            "Epoch 529/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6602 - val_loss: 0.6206 - val_binary_accuracy: 0.6618\n",
            "Epoch 530/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6596 - val_loss: 0.6211 - val_binary_accuracy: 0.6589\n",
            "Epoch 531/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6574 - val_loss: 0.6224 - val_binary_accuracy: 0.6597\n",
            "Epoch 532/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6559 - val_loss: 0.6224 - val_binary_accuracy: 0.6585\n",
            "Epoch 533/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6245 - binary_accuracy: 0.6539 - val_loss: 0.6223 - val_binary_accuracy: 0.6622\n",
            "Epoch 534/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6557 - val_loss: 0.6226 - val_binary_accuracy: 0.6576\n",
            "Epoch 535/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6583 - val_loss: 0.6235 - val_binary_accuracy: 0.6589\n",
            "Epoch 536/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6553 - val_loss: 0.6223 - val_binary_accuracy: 0.6660\n",
            "Epoch 537/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6528 - val_loss: 0.6240 - val_binary_accuracy: 0.6559\n",
            "Epoch 538/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6591 - val_loss: 0.6221 - val_binary_accuracy: 0.6614\n",
            "Epoch 539/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6246 - binary_accuracy: 0.6538 - val_loss: 0.6244 - val_binary_accuracy: 0.6647\n",
            "Epoch 540/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6583 - val_loss: 0.6232 - val_binary_accuracy: 0.6580\n",
            "Epoch 541/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6542 - val_loss: 0.6227 - val_binary_accuracy: 0.6547\n",
            "Epoch 542/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6543 - val_loss: 0.6235 - val_binary_accuracy: 0.6610\n",
            "Epoch 543/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6604 - val_loss: 0.6226 - val_binary_accuracy: 0.6555\n",
            "Epoch 544/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6608 - val_loss: 0.6232 - val_binary_accuracy: 0.6651\n",
            "Epoch 545/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6605 - val_loss: 0.6214 - val_binary_accuracy: 0.6626\n",
            "Epoch 546/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6558 - val_loss: 0.6230 - val_binary_accuracy: 0.6572\n",
            "Epoch 547/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6615 - val_loss: 0.6225 - val_binary_accuracy: 0.6605\n",
            "Epoch 548/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6556 - val_loss: 0.6229 - val_binary_accuracy: 0.6610\n",
            "Epoch 549/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6234 - binary_accuracy: 0.6602 - val_loss: 0.6218 - val_binary_accuracy: 0.6576\n",
            "Epoch 550/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6561 - val_loss: 0.6231 - val_binary_accuracy: 0.6522\n",
            "Epoch 551/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6222 - binary_accuracy: 0.6595 - val_loss: 0.6245 - val_binary_accuracy: 0.6618\n",
            "Epoch 552/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6599 - val_loss: 0.6228 - val_binary_accuracy: 0.6601\n",
            "Epoch 553/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6619 - val_loss: 0.6214 - val_binary_accuracy: 0.6610\n",
            "Epoch 554/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6572 - val_loss: 0.6243 - val_binary_accuracy: 0.6518\n",
            "Epoch 555/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6574 - val_loss: 0.6222 - val_binary_accuracy: 0.6610\n",
            "Epoch 556/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6575 - val_loss: 0.6224 - val_binary_accuracy: 0.6601\n",
            "Epoch 557/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6586 - val_loss: 0.6238 - val_binary_accuracy: 0.6626\n",
            "Epoch 558/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6597 - val_loss: 0.6210 - val_binary_accuracy: 0.6676\n",
            "Epoch 559/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6232 - binary_accuracy: 0.6543 - val_loss: 0.6226 - val_binary_accuracy: 0.6626\n",
            "Epoch 560/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6590 - val_loss: 0.6240 - val_binary_accuracy: 0.6534\n",
            "Epoch 561/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6583 - val_loss: 0.6223 - val_binary_accuracy: 0.6643\n",
            "Epoch 562/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6584 - val_loss: 0.6210 - val_binary_accuracy: 0.6635\n",
            "Epoch 563/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6230 - binary_accuracy: 0.6535 - val_loss: 0.6232 - val_binary_accuracy: 0.6564\n",
            "Epoch 564/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6216 - binary_accuracy: 0.6580 - val_loss: 0.6213 - val_binary_accuracy: 0.6597\n",
            "Epoch 565/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6586 - val_loss: 0.6216 - val_binary_accuracy: 0.6593\n",
            "Epoch 566/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6602 - val_loss: 0.6206 - val_binary_accuracy: 0.6626\n",
            "Epoch 567/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6598 - val_loss: 0.6220 - val_binary_accuracy: 0.6626\n",
            "Epoch 568/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6200 - binary_accuracy: 0.6568 - val_loss: 0.6229 - val_binary_accuracy: 0.6572\n",
            "Epoch 569/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6525 - val_loss: 0.6229 - val_binary_accuracy: 0.6576\n",
            "Epoch 570/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6591 - val_loss: 0.6212 - val_binary_accuracy: 0.6639\n",
            "Epoch 571/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6592 - val_loss: 0.6206 - val_binary_accuracy: 0.6618\n",
            "Epoch 572/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6634 - val_loss: 0.6205 - val_binary_accuracy: 0.6630\n",
            "Epoch 573/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6565 - val_loss: 0.6222 - val_binary_accuracy: 0.6593\n",
            "Epoch 574/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6233 - binary_accuracy: 0.6571 - val_loss: 0.6245 - val_binary_accuracy: 0.6505\n",
            "Epoch 575/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6220 - binary_accuracy: 0.6560 - val_loss: 0.6244 - val_binary_accuracy: 0.6534\n",
            "Epoch 576/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6546 - val_loss: 0.6230 - val_binary_accuracy: 0.6555\n",
            "Epoch 577/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6578 - val_loss: 0.6231 - val_binary_accuracy: 0.6647\n",
            "Epoch 578/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6227 - binary_accuracy: 0.6564 - val_loss: 0.6239 - val_binary_accuracy: 0.6555\n",
            "Epoch 579/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6567 - val_loss: 0.6235 - val_binary_accuracy: 0.6597\n",
            "Epoch 580/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6596 - val_loss: 0.6236 - val_binary_accuracy: 0.6559\n",
            "Epoch 581/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6608 - val_loss: 0.6231 - val_binary_accuracy: 0.6630\n",
            "Epoch 582/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6625 - val_loss: 0.6209 - val_binary_accuracy: 0.6651\n",
            "Epoch 583/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6596 - val_loss: 0.6233 - val_binary_accuracy: 0.6618\n",
            "Epoch 584/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6545 - val_loss: 0.6213 - val_binary_accuracy: 0.6593\n",
            "Epoch 585/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6575 - val_loss: 0.6258 - val_binary_accuracy: 0.6572\n",
            "Epoch 586/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6228 - binary_accuracy: 0.6629 - val_loss: 0.6232 - val_binary_accuracy: 0.6589\n",
            "Epoch 587/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6606 - val_loss: 0.6219 - val_binary_accuracy: 0.6635\n",
            "Epoch 588/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6619 - val_loss: 0.6209 - val_binary_accuracy: 0.6618\n",
            "Epoch 589/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6548 - val_loss: 0.6232 - val_binary_accuracy: 0.6534\n",
            "Epoch 590/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6594 - val_loss: 0.6217 - val_binary_accuracy: 0.6589\n",
            "Epoch 591/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6604 - val_loss: 0.6205 - val_binary_accuracy: 0.6651\n",
            "Epoch 592/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6619 - val_loss: 0.6213 - val_binary_accuracy: 0.6593\n",
            "Epoch 593/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6573 - val_loss: 0.6226 - val_binary_accuracy: 0.6589\n",
            "Epoch 594/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6603 - val_loss: 0.6206 - val_binary_accuracy: 0.6643\n",
            "Epoch 595/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6584 - val_loss: 0.6224 - val_binary_accuracy: 0.6597\n",
            "Epoch 596/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6577 - val_loss: 0.6229 - val_binary_accuracy: 0.6614\n",
            "Epoch 597/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6582 - val_loss: 0.6235 - val_binary_accuracy: 0.6568\n",
            "Epoch 598/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6578 - val_loss: 0.6215 - val_binary_accuracy: 0.6585\n",
            "Epoch 599/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6625 - val_loss: 0.6225 - val_binary_accuracy: 0.6601\n",
            "Epoch 600/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6571 - val_loss: 0.6226 - val_binary_accuracy: 0.6593\n",
            "Epoch 601/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6610 - val_loss: 0.6226 - val_binary_accuracy: 0.6580\n",
            "Epoch 602/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6553 - val_loss: 0.6212 - val_binary_accuracy: 0.6576\n",
            "Epoch 603/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6600 - val_loss: 0.6214 - val_binary_accuracy: 0.6639\n",
            "Epoch 604/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6593 - val_loss: 0.6220 - val_binary_accuracy: 0.6589\n",
            "Epoch 605/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6584 - val_loss: 0.6226 - val_binary_accuracy: 0.6585\n",
            "Epoch 606/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6210 - binary_accuracy: 0.6623 - val_loss: 0.6230 - val_binary_accuracy: 0.6597\n",
            "Epoch 607/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6548 - val_loss: 0.6219 - val_binary_accuracy: 0.6564\n",
            "Epoch 608/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6565 - val_loss: 0.6221 - val_binary_accuracy: 0.6597\n",
            "Epoch 609/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6611 - val_loss: 0.6231 - val_binary_accuracy: 0.6518\n",
            "Epoch 610/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6219 - binary_accuracy: 0.6603 - val_loss: 0.6236 - val_binary_accuracy: 0.6605\n",
            "Epoch 611/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6595 - val_loss: 0.6224 - val_binary_accuracy: 0.6610\n",
            "Epoch 612/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6612 - val_loss: 0.6212 - val_binary_accuracy: 0.6630\n",
            "Epoch 613/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6565 - val_loss: 0.6224 - val_binary_accuracy: 0.6601\n",
            "Epoch 614/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6207 - binary_accuracy: 0.6552 - val_loss: 0.6212 - val_binary_accuracy: 0.6630\n",
            "Epoch 615/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6206 - binary_accuracy: 0.6540 - val_loss: 0.6227 - val_binary_accuracy: 0.6593\n",
            "Epoch 616/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6581 - val_loss: 0.6232 - val_binary_accuracy: 0.6622\n",
            "Epoch 617/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6566 - val_loss: 0.6243 - val_binary_accuracy: 0.6622\n",
            "Epoch 618/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6634 - val_loss: 0.6238 - val_binary_accuracy: 0.6568\n",
            "Epoch 619/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6563 - val_loss: 0.6212 - val_binary_accuracy: 0.6601\n",
            "Epoch 620/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6215 - binary_accuracy: 0.6593 - val_loss: 0.6243 - val_binary_accuracy: 0.6518\n",
            "Epoch 621/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6600 - val_loss: 0.6237 - val_binary_accuracy: 0.6639\n",
            "Epoch 622/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6634 - val_loss: 0.6218 - val_binary_accuracy: 0.6593\n",
            "Epoch 623/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6614 - val_loss: 0.6215 - val_binary_accuracy: 0.6593\n",
            "Epoch 624/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6624 - val_loss: 0.6220 - val_binary_accuracy: 0.6585\n",
            "Epoch 625/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6617 - val_loss: 0.6220 - val_binary_accuracy: 0.6601\n",
            "Epoch 626/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6641 - val_loss: 0.6221 - val_binary_accuracy: 0.6597\n",
            "Epoch 627/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6585 - val_loss: 0.6229 - val_binary_accuracy: 0.6555\n",
            "Epoch 628/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6596 - val_loss: 0.6231 - val_binary_accuracy: 0.6597\n",
            "Epoch 629/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6621 - val_loss: 0.6235 - val_binary_accuracy: 0.6597\n",
            "Epoch 630/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6602 - val_loss: 0.6231 - val_binary_accuracy: 0.6601\n",
            "Epoch 631/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6568 - val_loss: 0.6219 - val_binary_accuracy: 0.6626\n",
            "Epoch 632/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6615 - val_loss: 0.6246 - val_binary_accuracy: 0.6601\n",
            "Epoch 633/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6574 - val_loss: 0.6243 - val_binary_accuracy: 0.6493\n",
            "Epoch 634/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6571 - val_loss: 0.6221 - val_binary_accuracy: 0.6614\n",
            "Epoch 635/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6582 - val_loss: 0.6224 - val_binary_accuracy: 0.6572\n",
            "Epoch 636/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6619 - val_loss: 0.6217 - val_binary_accuracy: 0.6614\n",
            "Epoch 637/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6658 - val_loss: 0.6226 - val_binary_accuracy: 0.6589\n",
            "Epoch 638/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6217 - binary_accuracy: 0.6577 - val_loss: 0.6256 - val_binary_accuracy: 0.6614\n",
            "Epoch 639/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6614 - val_loss: 0.6240 - val_binary_accuracy: 0.6614\n",
            "Epoch 640/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6574 - val_loss: 0.6228 - val_binary_accuracy: 0.6585\n",
            "Epoch 641/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6600 - val_loss: 0.6216 - val_binary_accuracy: 0.6576\n",
            "Epoch 642/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6632 - val_loss: 0.6234 - val_binary_accuracy: 0.6568\n",
            "Epoch 643/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6636 - val_loss: 0.6259 - val_binary_accuracy: 0.6489\n",
            "Epoch 644/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6620 - val_loss: 0.6243 - val_binary_accuracy: 0.6605\n",
            "Epoch 645/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6610 - val_loss: 0.6228 - val_binary_accuracy: 0.6597\n",
            "Epoch 646/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6638 - val_loss: 0.6215 - val_binary_accuracy: 0.6622\n",
            "Epoch 647/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6221 - binary_accuracy: 0.6616 - val_loss: 0.6232 - val_binary_accuracy: 0.6601\n",
            "Epoch 648/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6212 - binary_accuracy: 0.6563 - val_loss: 0.6213 - val_binary_accuracy: 0.6601\n",
            "Epoch 649/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6538 - val_loss: 0.6233 - val_binary_accuracy: 0.6610\n",
            "Epoch 650/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6610 - val_loss: 0.6220 - val_binary_accuracy: 0.6593\n",
            "Epoch 651/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6626 - val_loss: 0.6236 - val_binary_accuracy: 0.6635\n",
            "Epoch 652/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6630 - val_loss: 0.6229 - val_binary_accuracy: 0.6626\n",
            "Epoch 653/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6551 - val_loss: 0.6223 - val_binary_accuracy: 0.6630\n",
            "Epoch 654/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6591 - val_loss: 0.6209 - val_binary_accuracy: 0.6576\n",
            "Epoch 655/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6632 - val_loss: 0.6211 - val_binary_accuracy: 0.6576\n",
            "Epoch 656/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6650 - val_loss: 0.6214 - val_binary_accuracy: 0.6605\n",
            "Epoch 657/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6619 - val_loss: 0.6215 - val_binary_accuracy: 0.6580\n",
            "Epoch 658/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6608 - val_loss: 0.6217 - val_binary_accuracy: 0.6601\n",
            "Epoch 659/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6623 - val_loss: 0.6224 - val_binary_accuracy: 0.6568\n",
            "Epoch 660/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6591 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 661/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6204 - binary_accuracy: 0.6623 - val_loss: 0.6220 - val_binary_accuracy: 0.6656\n",
            "Epoch 662/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6565 - val_loss: 0.6232 - val_binary_accuracy: 0.6564\n",
            "Epoch 663/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6579 - val_loss: 0.6211 - val_binary_accuracy: 0.6589\n",
            "Epoch 664/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6635 - val_loss: 0.6222 - val_binary_accuracy: 0.6610\n",
            "Epoch 665/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6638 - val_loss: 0.6228 - val_binary_accuracy: 0.6564\n",
            "Epoch 666/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6567 - val_loss: 0.6216 - val_binary_accuracy: 0.6576\n",
            "Epoch 667/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6557 - val_loss: 0.6243 - val_binary_accuracy: 0.6559\n",
            "Epoch 668/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6604 - val_loss: 0.6232 - val_binary_accuracy: 0.6630\n",
            "Epoch 669/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6607 - val_loss: 0.6209 - val_binary_accuracy: 0.6576\n",
            "Epoch 670/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6589 - val_loss: 0.6217 - val_binary_accuracy: 0.6597\n",
            "Epoch 671/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6229 - binary_accuracy: 0.6605 - val_loss: 0.6237 - val_binary_accuracy: 0.6605\n",
            "Epoch 672/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6190 - binary_accuracy: 0.6626 - val_loss: 0.6225 - val_binary_accuracy: 0.6614\n",
            "Epoch 673/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6616 - val_loss: 0.6218 - val_binary_accuracy: 0.6580\n",
            "Epoch 674/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6583 - val_loss: 0.6229 - val_binary_accuracy: 0.6568\n",
            "Epoch 675/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6595 - val_loss: 0.6227 - val_binary_accuracy: 0.6580\n",
            "Epoch 676/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6199 - binary_accuracy: 0.6552 - val_loss: 0.6236 - val_binary_accuracy: 0.6605\n",
            "Epoch 677/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6642 - val_loss: 0.6221 - val_binary_accuracy: 0.6626\n",
            "Epoch 678/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6600 - val_loss: 0.6226 - val_binary_accuracy: 0.6593\n",
            "Epoch 679/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6214 - binary_accuracy: 0.6627 - val_loss: 0.6245 - val_binary_accuracy: 0.6610\n",
            "Epoch 680/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6590 - val_loss: 0.6230 - val_binary_accuracy: 0.6605\n",
            "Epoch 681/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6608 - val_loss: 0.6225 - val_binary_accuracy: 0.6605\n",
            "Epoch 682/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6584 - val_loss: 0.6211 - val_binary_accuracy: 0.6568\n",
            "Epoch 683/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6224 - binary_accuracy: 0.6612 - val_loss: 0.6232 - val_binary_accuracy: 0.6534\n",
            "Epoch 684/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6628 - val_loss: 0.6219 - val_binary_accuracy: 0.6614\n",
            "Epoch 685/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6619 - val_loss: 0.6214 - val_binary_accuracy: 0.6618\n",
            "Epoch 686/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6613 - val_loss: 0.6215 - val_binary_accuracy: 0.6593\n",
            "Epoch 687/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6620 - val_loss: 0.6215 - val_binary_accuracy: 0.6593\n",
            "Epoch 688/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6595 - val_loss: 0.6222 - val_binary_accuracy: 0.6630\n",
            "Epoch 689/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6626 - val_loss: 0.6224 - val_binary_accuracy: 0.6593\n",
            "Epoch 690/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6625 - val_loss: 0.6229 - val_binary_accuracy: 0.6576\n",
            "Epoch 691/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6577 - val_loss: 0.6223 - val_binary_accuracy: 0.6555\n",
            "Epoch 692/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6601 - val_loss: 0.6237 - val_binary_accuracy: 0.6547\n",
            "Epoch 693/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6567 - val_loss: 0.6230 - val_binary_accuracy: 0.6593\n",
            "Epoch 694/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6625 - val_loss: 0.6213 - val_binary_accuracy: 0.6572\n",
            "Epoch 695/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6613 - val_loss: 0.6223 - val_binary_accuracy: 0.6564\n",
            "Epoch 696/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6590 - val_loss: 0.6236 - val_binary_accuracy: 0.6601\n",
            "Epoch 697/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6591 - val_loss: 0.6228 - val_binary_accuracy: 0.6543\n",
            "Epoch 698/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6607 - val_loss: 0.6220 - val_binary_accuracy: 0.6610\n",
            "Epoch 699/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6578 - val_loss: 0.6248 - val_binary_accuracy: 0.6601\n",
            "Epoch 700/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6588 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 701/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6590 - val_loss: 0.6230 - val_binary_accuracy: 0.6580\n",
            "Epoch 702/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6634 - val_loss: 0.6207 - val_binary_accuracy: 0.6601\n",
            "Epoch 703/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6592 - val_loss: 0.6225 - val_binary_accuracy: 0.6585\n",
            "Epoch 704/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6587 - val_loss: 0.6229 - val_binary_accuracy: 0.6622\n",
            "Epoch 705/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6606 - val_loss: 0.6244 - val_binary_accuracy: 0.6605\n",
            "Epoch 706/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6648 - val_loss: 0.6227 - val_binary_accuracy: 0.6622\n",
            "Epoch 707/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6625 - val_loss: 0.6216 - val_binary_accuracy: 0.6589\n",
            "Epoch 708/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6618 - val_loss: 0.6218 - val_binary_accuracy: 0.6580\n",
            "Epoch 709/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6614 - val_loss: 0.6245 - val_binary_accuracy: 0.6530\n",
            "Epoch 710/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6634 - val_loss: 0.6225 - val_binary_accuracy: 0.6576\n",
            "Epoch 711/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6563 - val_loss: 0.6228 - val_binary_accuracy: 0.6559\n",
            "Epoch 712/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6596 - val_loss: 0.6231 - val_binary_accuracy: 0.6589\n",
            "Epoch 713/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6607 - val_loss: 0.6231 - val_binary_accuracy: 0.6585\n",
            "Epoch 714/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6600 - val_loss: 0.6236 - val_binary_accuracy: 0.6597\n",
            "Epoch 715/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6202 - binary_accuracy: 0.6631 - val_loss: 0.6226 - val_binary_accuracy: 0.6593\n",
            "Epoch 716/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6621 - val_loss: 0.6232 - val_binary_accuracy: 0.6610\n",
            "Epoch 717/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6569 - val_loss: 0.6228 - val_binary_accuracy: 0.6576\n",
            "Epoch 718/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6583 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 719/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6629 - val_loss: 0.6213 - val_binary_accuracy: 0.6601\n",
            "Epoch 720/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6600 - val_loss: 0.6219 - val_binary_accuracy: 0.6622\n",
            "Epoch 721/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6591 - val_loss: 0.6204 - val_binary_accuracy: 0.6576\n",
            "Epoch 722/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6637 - val_loss: 0.6204 - val_binary_accuracy: 0.6610\n",
            "Epoch 723/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6605 - val_loss: 0.6204 - val_binary_accuracy: 0.6597\n",
            "Epoch 724/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6607 - val_loss: 0.6218 - val_binary_accuracy: 0.6580\n",
            "Epoch 725/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6624 - val_loss: 0.6231 - val_binary_accuracy: 0.6589\n",
            "Epoch 726/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6639 - val_loss: 0.6223 - val_binary_accuracy: 0.6589\n",
            "Epoch 727/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6614 - val_loss: 0.6234 - val_binary_accuracy: 0.6605\n",
            "Epoch 728/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6592 - val_loss: 0.6223 - val_binary_accuracy: 0.6589\n",
            "Epoch 729/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6594 - val_loss: 0.6209 - val_binary_accuracy: 0.6568\n",
            "Epoch 730/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6582 - val_loss: 0.6197 - val_binary_accuracy: 0.6614\n",
            "Epoch 731/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6607 - val_loss: 0.6197 - val_binary_accuracy: 0.6589\n",
            "Epoch 732/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6645 - val_loss: 0.6211 - val_binary_accuracy: 0.6551\n",
            "Epoch 733/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6607 - val_loss: 0.6228 - val_binary_accuracy: 0.6509\n",
            "Epoch 734/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6612 - val_loss: 0.6212 - val_binary_accuracy: 0.6601\n",
            "Epoch 735/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6651 - val_loss: 0.6208 - val_binary_accuracy: 0.6543\n",
            "Epoch 736/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6606 - val_loss: 0.6212 - val_binary_accuracy: 0.6585\n",
            "Epoch 737/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6608 - val_loss: 0.6243 - val_binary_accuracy: 0.6522\n",
            "Epoch 738/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6610 - val_loss: 0.6208 - val_binary_accuracy: 0.6597\n",
            "Epoch 739/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6551 - val_loss: 0.6194 - val_binary_accuracy: 0.6630\n",
            "Epoch 740/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6602 - val_loss: 0.6202 - val_binary_accuracy: 0.6597\n",
            "Epoch 741/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6194 - binary_accuracy: 0.6615 - val_loss: 0.6228 - val_binary_accuracy: 0.6601\n",
            "Epoch 742/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6617 - val_loss: 0.6196 - val_binary_accuracy: 0.6601\n",
            "Epoch 743/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6589 - val_loss: 0.6220 - val_binary_accuracy: 0.6568\n",
            "Epoch 744/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6600 - val_loss: 0.6213 - val_binary_accuracy: 0.6568\n",
            "Epoch 745/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6592 - val_loss: 0.6223 - val_binary_accuracy: 0.6610\n",
            "Epoch 746/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6622 - val_loss: 0.6210 - val_binary_accuracy: 0.6580\n",
            "Epoch 747/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6651 - val_loss: 0.6210 - val_binary_accuracy: 0.6605\n",
            "Epoch 748/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6600 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 749/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6635 - val_loss: 0.6213 - val_binary_accuracy: 0.6614\n",
            "Epoch 750/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6605 - val_loss: 0.6226 - val_binary_accuracy: 0.6572\n",
            "Epoch 751/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6624 - val_loss: 0.6226 - val_binary_accuracy: 0.6559\n",
            "Epoch 752/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6612 - val_loss: 0.6212 - val_binary_accuracy: 0.6622\n",
            "Epoch 753/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6592 - val_loss: 0.6220 - val_binary_accuracy: 0.6585\n",
            "Epoch 754/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6625 - val_loss: 0.6215 - val_binary_accuracy: 0.6576\n",
            "Epoch 755/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6601 - val_loss: 0.6220 - val_binary_accuracy: 0.6589\n",
            "Epoch 756/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6624 - val_loss: 0.6222 - val_binary_accuracy: 0.6555\n",
            "Epoch 757/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6627 - val_loss: 0.6222 - val_binary_accuracy: 0.6564\n",
            "Epoch 758/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6600 - val_loss: 0.6212 - val_binary_accuracy: 0.6605\n",
            "Epoch 759/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6625 - val_loss: 0.6212 - val_binary_accuracy: 0.6580\n",
            "Epoch 760/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6189 - binary_accuracy: 0.6635 - val_loss: 0.6232 - val_binary_accuracy: 0.6605\n",
            "Epoch 761/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6607 - val_loss: 0.6225 - val_binary_accuracy: 0.6509\n",
            "Epoch 762/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6563 - val_loss: 0.6238 - val_binary_accuracy: 0.6572\n",
            "Epoch 763/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6639 - val_loss: 0.6230 - val_binary_accuracy: 0.6568\n",
            "Epoch 764/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6616 - val_loss: 0.6215 - val_binary_accuracy: 0.6585\n",
            "Epoch 765/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6617 - val_loss: 0.6238 - val_binary_accuracy: 0.6568\n",
            "Epoch 766/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6633 - val_loss: 0.6233 - val_binary_accuracy: 0.6593\n",
            "Epoch 767/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6641 - val_loss: 0.6242 - val_binary_accuracy: 0.6564\n",
            "Epoch 768/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6620 - val_loss: 0.6251 - val_binary_accuracy: 0.6539\n",
            "Epoch 769/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6600 - val_loss: 0.6232 - val_binary_accuracy: 0.6589\n",
            "Epoch 770/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6634 - val_loss: 0.6233 - val_binary_accuracy: 0.6576\n",
            "Epoch 771/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6598 - val_loss: 0.6237 - val_binary_accuracy: 0.6572\n",
            "Epoch 772/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6619 - val_loss: 0.6233 - val_binary_accuracy: 0.6555\n",
            "Epoch 773/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6593 - val_loss: 0.6225 - val_binary_accuracy: 0.6605\n",
            "Epoch 774/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6654 - val_loss: 0.6227 - val_binary_accuracy: 0.6564\n",
            "Epoch 775/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6582 - val_loss: 0.6234 - val_binary_accuracy: 0.6551\n",
            "Epoch 776/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6615 - val_loss: 0.6220 - val_binary_accuracy: 0.6605\n",
            "Epoch 777/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6608 - val_loss: 0.6212 - val_binary_accuracy: 0.6589\n",
            "Epoch 778/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6658 - val_loss: 0.6217 - val_binary_accuracy: 0.6597\n",
            "Epoch 779/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6605 - val_loss: 0.6236 - val_binary_accuracy: 0.6605\n",
            "Epoch 780/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6193 - binary_accuracy: 0.6642 - val_loss: 0.6230 - val_binary_accuracy: 0.6580\n",
            "Epoch 781/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6636 - val_loss: 0.6233 - val_binary_accuracy: 0.6509\n",
            "Epoch 782/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6631 - val_loss: 0.6206 - val_binary_accuracy: 0.6610\n",
            "Epoch 783/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6574 - val_loss: 0.6220 - val_binary_accuracy: 0.6618\n",
            "Epoch 784/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6209 - binary_accuracy: 0.6588 - val_loss: 0.6233 - val_binary_accuracy: 0.6526\n",
            "Epoch 785/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6197 - binary_accuracy: 0.6633 - val_loss: 0.6229 - val_binary_accuracy: 0.6618\n",
            "Epoch 786/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6657 - val_loss: 0.6203 - val_binary_accuracy: 0.6626\n",
            "Epoch 787/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6637 - val_loss: 0.6208 - val_binary_accuracy: 0.6618\n",
            "Epoch 788/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6588 - val_loss: 0.6227 - val_binary_accuracy: 0.6605\n",
            "Epoch 789/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6205 - binary_accuracy: 0.6591 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 790/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6597 - val_loss: 0.6221 - val_binary_accuracy: 0.6597\n",
            "Epoch 791/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6632 - val_loss: 0.6202 - val_binary_accuracy: 0.6597\n",
            "Epoch 792/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6609 - val_loss: 0.6223 - val_binary_accuracy: 0.6576\n",
            "Epoch 793/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6615 - val_loss: 0.6241 - val_binary_accuracy: 0.6610\n",
            "Epoch 794/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6631 - val_loss: 0.6208 - val_binary_accuracy: 0.6601\n",
            "Epoch 795/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6611 - val_loss: 0.6218 - val_binary_accuracy: 0.6597\n",
            "Epoch 796/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6623 - val_loss: 0.6222 - val_binary_accuracy: 0.6585\n",
            "Epoch 797/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6211 - binary_accuracy: 0.6594 - val_loss: 0.6223 - val_binary_accuracy: 0.6593\n",
            "Epoch 798/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6565 - val_loss: 0.6227 - val_binary_accuracy: 0.6580\n",
            "Epoch 799/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6656 - val_loss: 0.6201 - val_binary_accuracy: 0.6660\n",
            "Epoch 800/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6619 - val_loss: 0.6209 - val_binary_accuracy: 0.6585\n",
            "Epoch 801/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6638 - val_loss: 0.6222 - val_binary_accuracy: 0.6585\n",
            "Epoch 802/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6685 - val_loss: 0.6195 - val_binary_accuracy: 0.6614\n",
            "Epoch 803/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6628 - val_loss: 0.6220 - val_binary_accuracy: 0.6614\n",
            "Epoch 804/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6619 - val_loss: 0.6198 - val_binary_accuracy: 0.6626\n",
            "Epoch 805/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6635 - val_loss: 0.6213 - val_binary_accuracy: 0.6589\n",
            "Epoch 806/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6623 - val_loss: 0.6209 - val_binary_accuracy: 0.6589\n",
            "Epoch 807/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6614 - val_loss: 0.6227 - val_binary_accuracy: 0.6559\n",
            "Epoch 808/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6640 - val_loss: 0.6216 - val_binary_accuracy: 0.6572\n",
            "Epoch 809/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6628 - val_loss: 0.6203 - val_binary_accuracy: 0.6555\n",
            "Epoch 810/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6610 - val_loss: 0.6199 - val_binary_accuracy: 0.6605\n",
            "Epoch 811/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6201 - binary_accuracy: 0.6658 - val_loss: 0.6201 - val_binary_accuracy: 0.6622\n",
            "Epoch 812/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6658 - val_loss: 0.6194 - val_binary_accuracy: 0.6618\n",
            "Epoch 813/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6626 - val_loss: 0.6194 - val_binary_accuracy: 0.6639\n",
            "Epoch 814/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6638 - val_loss: 0.6228 - val_binary_accuracy: 0.6572\n",
            "Epoch 815/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6660 - val_loss: 0.6214 - val_binary_accuracy: 0.6635\n",
            "Epoch 816/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6637 - val_loss: 0.6217 - val_binary_accuracy: 0.6572\n",
            "Epoch 817/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6684 - val_loss: 0.6203 - val_binary_accuracy: 0.6580\n",
            "Epoch 818/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6620 - val_loss: 0.6224 - val_binary_accuracy: 0.6597\n",
            "Epoch 819/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6601 - val_loss: 0.6214 - val_binary_accuracy: 0.6543\n",
            "Epoch 820/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6621 - val_loss: 0.6215 - val_binary_accuracy: 0.6580\n",
            "Epoch 821/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6652 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 822/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6648 - val_loss: 0.6222 - val_binary_accuracy: 0.6572\n",
            "Epoch 823/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6643 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 824/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6658 - val_loss: 0.6207 - val_binary_accuracy: 0.6576\n",
            "Epoch 825/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6203 - binary_accuracy: 0.6649 - val_loss: 0.6207 - val_binary_accuracy: 0.6585\n",
            "Epoch 826/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6676 - val_loss: 0.6231 - val_binary_accuracy: 0.6614\n",
            "Epoch 827/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6591 - val_loss: 0.6207 - val_binary_accuracy: 0.6610\n",
            "Epoch 828/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6630 - val_loss: 0.6231 - val_binary_accuracy: 0.6614\n",
            "Epoch 829/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6629 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 830/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6606 - val_loss: 0.6213 - val_binary_accuracy: 0.6630\n",
            "Epoch 831/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6624 - val_loss: 0.6215 - val_binary_accuracy: 0.6597\n",
            "Epoch 832/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6187 - binary_accuracy: 0.6641 - val_loss: 0.6215 - val_binary_accuracy: 0.6572\n",
            "Epoch 833/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6617 - val_loss: 0.6193 - val_binary_accuracy: 0.6618\n",
            "Epoch 834/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6606 - val_loss: 0.6202 - val_binary_accuracy: 0.6585\n",
            "Epoch 835/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6672 - val_loss: 0.6209 - val_binary_accuracy: 0.6635\n",
            "Epoch 836/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6645 - val_loss: 0.6200 - val_binary_accuracy: 0.6614\n",
            "Epoch 837/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6623 - val_loss: 0.6197 - val_binary_accuracy: 0.6626\n",
            "Epoch 838/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6191 - binary_accuracy: 0.6633 - val_loss: 0.6199 - val_binary_accuracy: 0.6614\n",
            "Epoch 839/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6615 - val_loss: 0.6222 - val_binary_accuracy: 0.6605\n",
            "Epoch 840/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6616 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 841/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6632 - val_loss: 0.6210 - val_binary_accuracy: 0.6605\n",
            "Epoch 842/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6618 - val_loss: 0.6224 - val_binary_accuracy: 0.6593\n",
            "Epoch 843/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6637 - val_loss: 0.6193 - val_binary_accuracy: 0.6618\n",
            "Epoch 844/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6669 - val_loss: 0.6189 - val_binary_accuracy: 0.6626\n",
            "Epoch 845/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6655 - val_loss: 0.6189 - val_binary_accuracy: 0.6639\n",
            "Epoch 846/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6185 - binary_accuracy: 0.6641 - val_loss: 0.6222 - val_binary_accuracy: 0.6451\n",
            "Epoch 847/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6645 - val_loss: 0.6214 - val_binary_accuracy: 0.6635\n",
            "Epoch 848/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6655 - val_loss: 0.6195 - val_binary_accuracy: 0.6597\n",
            "Epoch 849/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6640 - val_loss: 0.6209 - val_binary_accuracy: 0.6589\n",
            "Epoch 850/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6624 - val_loss: 0.6202 - val_binary_accuracy: 0.6614\n",
            "Epoch 851/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6634 - val_loss: 0.6197 - val_binary_accuracy: 0.6580\n",
            "Epoch 852/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6637 - val_loss: 0.6190 - val_binary_accuracy: 0.6593\n",
            "Epoch 853/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6626 - val_loss: 0.6221 - val_binary_accuracy: 0.6605\n",
            "Epoch 854/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6626 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 855/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6647 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 856/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6640 - val_loss: 0.6222 - val_binary_accuracy: 0.6564\n",
            "Epoch 857/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6639 - val_loss: 0.6204 - val_binary_accuracy: 0.6626\n",
            "Epoch 858/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6196 - binary_accuracy: 0.6619 - val_loss: 0.6226 - val_binary_accuracy: 0.6576\n",
            "Epoch 859/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6620 - val_loss: 0.6202 - val_binary_accuracy: 0.6585\n",
            "Epoch 860/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6605 - val_loss: 0.6217 - val_binary_accuracy: 0.6580\n",
            "Epoch 861/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6600 - val_loss: 0.6216 - val_binary_accuracy: 0.6580\n",
            "Epoch 862/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6617 - val_loss: 0.6204 - val_binary_accuracy: 0.6585\n",
            "Epoch 863/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6650 - val_loss: 0.6197 - val_binary_accuracy: 0.6601\n",
            "Epoch 864/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6667 - val_loss: 0.6229 - val_binary_accuracy: 0.6605\n",
            "Epoch 865/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6684 - val_loss: 0.6210 - val_binary_accuracy: 0.6593\n",
            "Epoch 866/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6635 - val_loss: 0.6196 - val_binary_accuracy: 0.6597\n",
            "Epoch 867/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6605 - val_loss: 0.6223 - val_binary_accuracy: 0.6555\n",
            "Epoch 868/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6645 - val_loss: 0.6210 - val_binary_accuracy: 0.6593\n",
            "Epoch 869/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6625 - val_loss: 0.6229 - val_binary_accuracy: 0.6585\n",
            "Epoch 870/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6601 - val_loss: 0.6206 - val_binary_accuracy: 0.6568\n",
            "Epoch 871/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6667 - val_loss: 0.6209 - val_binary_accuracy: 0.6568\n",
            "Epoch 872/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6644 - val_loss: 0.6202 - val_binary_accuracy: 0.6605\n",
            "Epoch 873/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6666 - val_loss: 0.6207 - val_binary_accuracy: 0.6576\n",
            "Epoch 874/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6629 - val_loss: 0.6190 - val_binary_accuracy: 0.6635\n",
            "Epoch 875/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6176 - binary_accuracy: 0.6617 - val_loss: 0.6187 - val_binary_accuracy: 0.6585\n",
            "Epoch 876/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6656 - val_loss: 0.6203 - val_binary_accuracy: 0.6601\n",
            "Epoch 877/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6652 - val_loss: 0.6213 - val_binary_accuracy: 0.6551\n",
            "Epoch 878/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6598 - val_loss: 0.6227 - val_binary_accuracy: 0.6585\n",
            "Epoch 879/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6675 - val_loss: 0.6206 - val_binary_accuracy: 0.6597\n",
            "Epoch 880/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6183 - binary_accuracy: 0.6608 - val_loss: 0.6209 - val_binary_accuracy: 0.6572\n",
            "Epoch 881/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6607 - val_loss: 0.6206 - val_binary_accuracy: 0.6610\n",
            "Epoch 882/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6642 - val_loss: 0.6198 - val_binary_accuracy: 0.6626\n",
            "Epoch 883/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6682 - val_loss: 0.6189 - val_binary_accuracy: 0.6576\n",
            "Epoch 884/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6181 - binary_accuracy: 0.6668 - val_loss: 0.6219 - val_binary_accuracy: 0.6589\n",
            "Epoch 885/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6679 - val_loss: 0.6202 - val_binary_accuracy: 0.6593\n",
            "Epoch 886/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6600 - val_loss: 0.6208 - val_binary_accuracy: 0.6647\n",
            "Epoch 887/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6627 - val_loss: 0.6228 - val_binary_accuracy: 0.6601\n",
            "Epoch 888/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6663 - val_loss: 0.6201 - val_binary_accuracy: 0.6597\n",
            "Epoch 889/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6647 - val_loss: 0.6218 - val_binary_accuracy: 0.6605\n",
            "Epoch 890/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6667 - val_loss: 0.6227 - val_binary_accuracy: 0.6635\n",
            "Epoch 891/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6597 - val_loss: 0.6214 - val_binary_accuracy: 0.6601\n",
            "Epoch 892/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6645 - val_loss: 0.6221 - val_binary_accuracy: 0.6580\n",
            "Epoch 893/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6642 - val_loss: 0.6209 - val_binary_accuracy: 0.6585\n",
            "Epoch 894/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6668 - val_loss: 0.6207 - val_binary_accuracy: 0.6559\n",
            "Epoch 895/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6637 - val_loss: 0.6210 - val_binary_accuracy: 0.6614\n",
            "Epoch 896/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6666 - val_loss: 0.6203 - val_binary_accuracy: 0.6597\n",
            "Epoch 897/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6673 - val_loss: 0.6201 - val_binary_accuracy: 0.6626\n",
            "Epoch 898/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6645 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 899/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6635 - val_loss: 0.6203 - val_binary_accuracy: 0.6614\n",
            "Epoch 900/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6626 - val_loss: 0.6205 - val_binary_accuracy: 0.6572\n",
            "Epoch 901/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6634 - val_loss: 0.6213 - val_binary_accuracy: 0.6585\n",
            "Epoch 902/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6683 - val_loss: 0.6208 - val_binary_accuracy: 0.6580\n",
            "Epoch 903/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6626 - val_loss: 0.6207 - val_binary_accuracy: 0.6601\n",
            "Epoch 904/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6626 - val_loss: 0.6200 - val_binary_accuracy: 0.6601\n",
            "Epoch 905/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6661 - val_loss: 0.6203 - val_binary_accuracy: 0.6639\n",
            "Epoch 906/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6602 - val_loss: 0.6213 - val_binary_accuracy: 0.6601\n",
            "Epoch 907/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6671 - val_loss: 0.6211 - val_binary_accuracy: 0.6601\n",
            "Epoch 908/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6651 - val_loss: 0.6201 - val_binary_accuracy: 0.6610\n",
            "Epoch 909/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6175 - binary_accuracy: 0.6644 - val_loss: 0.6209 - val_binary_accuracy: 0.6597\n",
            "Epoch 910/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6617 - val_loss: 0.6200 - val_binary_accuracy: 0.6610\n",
            "Epoch 911/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6645 - val_loss: 0.6213 - val_binary_accuracy: 0.6580\n",
            "Epoch 912/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6646 - val_loss: 0.6209 - val_binary_accuracy: 0.6618\n",
            "Epoch 913/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6646 - val_loss: 0.6208 - val_binary_accuracy: 0.6597\n",
            "Epoch 914/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6706 - val_loss: 0.6209 - val_binary_accuracy: 0.6618\n",
            "Epoch 915/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6665 - val_loss: 0.6212 - val_binary_accuracy: 0.6576\n",
            "Epoch 916/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6670 - val_loss: 0.6213 - val_binary_accuracy: 0.6547\n",
            "Epoch 917/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6647 - val_loss: 0.6198 - val_binary_accuracy: 0.6664\n",
            "Epoch 918/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6619 - val_loss: 0.6220 - val_binary_accuracy: 0.6622\n",
            "Epoch 919/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6649 - val_loss: 0.6211 - val_binary_accuracy: 0.6559\n",
            "Epoch 920/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6178 - binary_accuracy: 0.6651 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 921/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6635 - val_loss: 0.6197 - val_binary_accuracy: 0.6622\n",
            "Epoch 922/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6628 - val_loss: 0.6199 - val_binary_accuracy: 0.6576\n",
            "Epoch 923/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6586 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 924/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6611 - val_loss: 0.6204 - val_binary_accuracy: 0.6622\n",
            "Epoch 925/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6673 - val_loss: 0.6199 - val_binary_accuracy: 0.6555\n",
            "Epoch 926/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6646 - val_loss: 0.6198 - val_binary_accuracy: 0.6614\n",
            "Epoch 927/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6625 - val_loss: 0.6186 - val_binary_accuracy: 0.6597\n",
            "Epoch 928/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6676 - val_loss: 0.6216 - val_binary_accuracy: 0.6564\n",
            "Epoch 929/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6672 - val_loss: 0.6204 - val_binary_accuracy: 0.6568\n",
            "Epoch 930/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6192 - binary_accuracy: 0.6629 - val_loss: 0.6204 - val_binary_accuracy: 0.6585\n",
            "Epoch 931/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6626 - val_loss: 0.6195 - val_binary_accuracy: 0.6610\n",
            "Epoch 932/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6605 - val_loss: 0.6215 - val_binary_accuracy: 0.6555\n",
            "Epoch 933/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6627 - val_loss: 0.6207 - val_binary_accuracy: 0.6559\n",
            "Epoch 934/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6676 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 935/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6662 - val_loss: 0.6204 - val_binary_accuracy: 0.6589\n",
            "Epoch 936/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6678 - val_loss: 0.6207 - val_binary_accuracy: 0.6614\n",
            "Epoch 937/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6184 - binary_accuracy: 0.6643 - val_loss: 0.6212 - val_binary_accuracy: 0.6618\n",
            "Epoch 938/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6681 - val_loss: 0.6204 - val_binary_accuracy: 0.6559\n",
            "Epoch 939/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6198 - binary_accuracy: 0.6606 - val_loss: 0.6200 - val_binary_accuracy: 0.6610\n",
            "Epoch 940/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6660 - val_loss: 0.6208 - val_binary_accuracy: 0.6639\n",
            "Epoch 941/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6647 - val_loss: 0.6200 - val_binary_accuracy: 0.6605\n",
            "Epoch 942/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6648 - val_loss: 0.6206 - val_binary_accuracy: 0.6580\n",
            "Epoch 943/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6620 - val_loss: 0.6197 - val_binary_accuracy: 0.6605\n",
            "Epoch 944/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6624 - val_loss: 0.6202 - val_binary_accuracy: 0.6576\n",
            "Epoch 945/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6610 - val_loss: 0.6202 - val_binary_accuracy: 0.6576\n",
            "Epoch 946/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6648 - val_loss: 0.6187 - val_binary_accuracy: 0.6597\n",
            "Epoch 947/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6634 - val_loss: 0.6189 - val_binary_accuracy: 0.6589\n",
            "Epoch 948/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6636 - val_loss: 0.6204 - val_binary_accuracy: 0.6585\n",
            "Epoch 949/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6629 - val_loss: 0.6220 - val_binary_accuracy: 0.6597\n",
            "Epoch 950/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6613 - val_loss: 0.6195 - val_binary_accuracy: 0.6585\n",
            "Epoch 951/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6659 - val_loss: 0.6208 - val_binary_accuracy: 0.6601\n",
            "Epoch 952/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6651 - val_loss: 0.6199 - val_binary_accuracy: 0.6622\n",
            "Epoch 953/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6668 - val_loss: 0.6207 - val_binary_accuracy: 0.6572\n",
            "Epoch 954/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6182 - binary_accuracy: 0.6664 - val_loss: 0.6225 - val_binary_accuracy: 0.6572\n",
            "Epoch 955/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6642 - val_loss: 0.6222 - val_binary_accuracy: 0.6622\n",
            "Epoch 956/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6646 - val_loss: 0.6223 - val_binary_accuracy: 0.6580\n",
            "Epoch 957/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6651 - val_loss: 0.6195 - val_binary_accuracy: 0.6630\n",
            "Epoch 958/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6622 - val_loss: 0.6223 - val_binary_accuracy: 0.6630\n",
            "Epoch 959/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6691 - val_loss: 0.6191 - val_binary_accuracy: 0.6635\n",
            "Epoch 960/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6637 - val_loss: 0.6206 - val_binary_accuracy: 0.6593\n",
            "Epoch 961/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6614 - val_loss: 0.6204 - val_binary_accuracy: 0.6589\n",
            "Epoch 962/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6679 - val_loss: 0.6201 - val_binary_accuracy: 0.6605\n",
            "Epoch 963/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6171 - binary_accuracy: 0.6687 - val_loss: 0.6202 - val_binary_accuracy: 0.6580\n",
            "Epoch 964/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6708 - val_loss: 0.6237 - val_binary_accuracy: 0.6568\n",
            "Epoch 965/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6660 - val_loss: 0.6201 - val_binary_accuracy: 0.6568\n",
            "Epoch 966/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6620 - val_loss: 0.6212 - val_binary_accuracy: 0.6585\n",
            "Epoch 967/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6664 - val_loss: 0.6181 - val_binary_accuracy: 0.6635\n",
            "Epoch 968/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6610 - val_loss: 0.6211 - val_binary_accuracy: 0.6630\n",
            "Epoch 969/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6649 - val_loss: 0.6201 - val_binary_accuracy: 0.6564\n",
            "Epoch 970/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6667 - val_loss: 0.6202 - val_binary_accuracy: 0.6568\n",
            "Epoch 971/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6654 - val_loss: 0.6185 - val_binary_accuracy: 0.6580\n",
            "Epoch 972/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6654 - val_loss: 0.6199 - val_binary_accuracy: 0.6651\n",
            "Epoch 973/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6689 - val_loss: 0.6207 - val_binary_accuracy: 0.6618\n",
            "Epoch 974/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6624 - val_loss: 0.6218 - val_binary_accuracy: 0.6647\n",
            "Epoch 975/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6625 - val_loss: 0.6197 - val_binary_accuracy: 0.6622\n",
            "Epoch 976/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6631 - val_loss: 0.6209 - val_binary_accuracy: 0.6605\n",
            "Epoch 977/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6684 - val_loss: 0.6222 - val_binary_accuracy: 0.6614\n",
            "Epoch 978/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6681 - val_loss: 0.6203 - val_binary_accuracy: 0.6585\n",
            "Epoch 979/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6640 - val_loss: 0.6212 - val_binary_accuracy: 0.6622\n",
            "Epoch 980/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6669 - val_loss: 0.6203 - val_binary_accuracy: 0.6622\n",
            "Epoch 981/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6622 - val_loss: 0.6210 - val_binary_accuracy: 0.6639\n",
            "Epoch 982/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6627 - val_loss: 0.6208 - val_binary_accuracy: 0.6610\n",
            "Epoch 983/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6609 - val_loss: 0.6196 - val_binary_accuracy: 0.6622\n",
            "Epoch 984/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6684 - val_loss: 0.6206 - val_binary_accuracy: 0.6572\n",
            "Epoch 985/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6652 - val_loss: 0.6204 - val_binary_accuracy: 0.6601\n",
            "Epoch 986/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6155 - binary_accuracy: 0.6639 - val_loss: 0.6228 - val_binary_accuracy: 0.6622\n",
            "Epoch 987/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6653 - val_loss: 0.6207 - val_binary_accuracy: 0.6585\n",
            "Epoch 988/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6668 - val_loss: 0.6206 - val_binary_accuracy: 0.6601\n",
            "Epoch 989/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6672 - val_loss: 0.6194 - val_binary_accuracy: 0.6597\n",
            "Epoch 990/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6599 - val_loss: 0.6222 - val_binary_accuracy: 0.6580\n",
            "Epoch 991/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6660 - val_loss: 0.6216 - val_binary_accuracy: 0.6668\n",
            "Epoch 992/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6680 - val_loss: 0.6204 - val_binary_accuracy: 0.6622\n",
            "Epoch 993/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6668 - val_loss: 0.6210 - val_binary_accuracy: 0.6555\n",
            "Epoch 994/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6652 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 995/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6607 - val_loss: 0.6214 - val_binary_accuracy: 0.6643\n",
            "Epoch 996/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6679 - val_loss: 0.6218 - val_binary_accuracy: 0.6605\n",
            "Epoch 997/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6654 - val_loss: 0.6199 - val_binary_accuracy: 0.6630\n",
            "Epoch 998/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6168 - binary_accuracy: 0.6634 - val_loss: 0.6208 - val_binary_accuracy: 0.6593\n",
            "Epoch 999/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6165 - binary_accuracy: 0.6589 - val_loss: 0.6221 - val_binary_accuracy: 0.6559\n",
            "Epoch 1000/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6658 - val_loss: 0.6196 - val_binary_accuracy: 0.6593\n",
            "Epoch 1001/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6656 - val_loss: 0.6192 - val_binary_accuracy: 0.6610\n",
            "Epoch 1002/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6632 - val_loss: 0.6213 - val_binary_accuracy: 0.6618\n",
            "Epoch 1003/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6631 - val_loss: 0.6205 - val_binary_accuracy: 0.6618\n",
            "Epoch 1004/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6678 - val_loss: 0.6191 - val_binary_accuracy: 0.6618\n",
            "Epoch 1005/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6180 - binary_accuracy: 0.6620 - val_loss: 0.6222 - val_binary_accuracy: 0.6618\n",
            "Epoch 1006/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6665 - val_loss: 0.6202 - val_binary_accuracy: 0.6589\n",
            "Epoch 1007/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6661 - val_loss: 0.6213 - val_binary_accuracy: 0.6572\n",
            "Epoch 1008/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6170 - binary_accuracy: 0.6659 - val_loss: 0.6212 - val_binary_accuracy: 0.6660\n",
            "Epoch 1009/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6674 - val_loss: 0.6201 - val_binary_accuracy: 0.6597\n",
            "Epoch 1010/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6640 - val_loss: 0.6215 - val_binary_accuracy: 0.6572\n",
            "Epoch 1011/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6679 - val_loss: 0.6210 - val_binary_accuracy: 0.6626\n",
            "Epoch 1012/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6623 - val_loss: 0.6239 - val_binary_accuracy: 0.6626\n",
            "Epoch 1013/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6601 - val_loss: 0.6224 - val_binary_accuracy: 0.6551\n",
            "Epoch 1014/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6174 - binary_accuracy: 0.6638 - val_loss: 0.6214 - val_binary_accuracy: 0.6630\n",
            "Epoch 1015/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6665 - val_loss: 0.6201 - val_binary_accuracy: 0.6610\n",
            "Epoch 1016/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6693 - val_loss: 0.6218 - val_binary_accuracy: 0.6585\n",
            "Epoch 1017/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6667 - val_loss: 0.6232 - val_binary_accuracy: 0.6547\n",
            "Epoch 1018/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6583 - val_loss: 0.6195 - val_binary_accuracy: 0.6622\n",
            "Epoch 1019/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6188 - binary_accuracy: 0.6610 - val_loss: 0.6196 - val_binary_accuracy: 0.6610\n",
            "Epoch 1020/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6656 - val_loss: 0.6217 - val_binary_accuracy: 0.6593\n",
            "Epoch 1021/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6706 - val_loss: 0.6203 - val_binary_accuracy: 0.6614\n",
            "Epoch 1022/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6659 - val_loss: 0.6224 - val_binary_accuracy: 0.6589\n",
            "Epoch 1023/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6678 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 1024/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6633 - val_loss: 0.6192 - val_binary_accuracy: 0.6580\n",
            "Epoch 1025/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6640 - val_loss: 0.6194 - val_binary_accuracy: 0.6610\n",
            "Epoch 1026/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6677 - val_loss: 0.6201 - val_binary_accuracy: 0.6614\n",
            "Epoch 1027/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6677 - val_loss: 0.6204 - val_binary_accuracy: 0.6668\n",
            "Epoch 1028/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6654 - val_loss: 0.6211 - val_binary_accuracy: 0.6635\n",
            "Epoch 1029/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6673 - val_loss: 0.6197 - val_binary_accuracy: 0.6593\n",
            "Epoch 1030/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6651 - val_loss: 0.6217 - val_binary_accuracy: 0.6593\n",
            "Epoch 1031/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6694 - val_loss: 0.6212 - val_binary_accuracy: 0.6622\n",
            "Epoch 1032/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6697 - val_loss: 0.6188 - val_binary_accuracy: 0.6593\n",
            "Epoch 1033/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6622 - val_loss: 0.6216 - val_binary_accuracy: 0.6626\n",
            "Epoch 1034/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6649 - val_loss: 0.6224 - val_binary_accuracy: 0.6559\n",
            "Epoch 1035/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6641 - val_loss: 0.6195 - val_binary_accuracy: 0.6614\n",
            "Epoch 1036/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6674 - val_loss: 0.6196 - val_binary_accuracy: 0.6572\n",
            "Epoch 1037/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6683 - val_loss: 0.6181 - val_binary_accuracy: 0.6626\n",
            "Epoch 1038/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6659 - val_loss: 0.6187 - val_binary_accuracy: 0.6639\n",
            "Epoch 1039/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6587 - val_loss: 0.6199 - val_binary_accuracy: 0.6630\n",
            "Epoch 1040/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6675 - val_loss: 0.6188 - val_binary_accuracy: 0.6614\n",
            "Epoch 1041/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6660 - val_loss: 0.6193 - val_binary_accuracy: 0.6597\n",
            "Epoch 1042/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6684 - val_loss: 0.6193 - val_binary_accuracy: 0.6622\n",
            "Epoch 1043/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6652 - val_loss: 0.6197 - val_binary_accuracy: 0.6618\n",
            "Epoch 1044/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6648 - val_loss: 0.6232 - val_binary_accuracy: 0.6576\n",
            "Epoch 1045/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6651 - val_loss: 0.6222 - val_binary_accuracy: 0.6601\n",
            "Epoch 1046/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6651 - val_loss: 0.6205 - val_binary_accuracy: 0.6639\n",
            "Epoch 1047/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6686 - val_loss: 0.6210 - val_binary_accuracy: 0.6614\n",
            "Epoch 1048/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6689 - val_loss: 0.6180 - val_binary_accuracy: 0.6576\n",
            "Epoch 1049/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6642 - val_loss: 0.6212 - val_binary_accuracy: 0.6626\n",
            "Epoch 1050/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6668 - val_loss: 0.6194 - val_binary_accuracy: 0.6568\n",
            "Epoch 1051/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6664 - val_loss: 0.6179 - val_binary_accuracy: 0.6622\n",
            "Epoch 1052/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6670 - val_loss: 0.6224 - val_binary_accuracy: 0.6585\n",
            "Epoch 1053/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6661 - val_loss: 0.6216 - val_binary_accuracy: 0.6568\n",
            "Epoch 1054/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6167 - binary_accuracy: 0.6661 - val_loss: 0.6221 - val_binary_accuracy: 0.6580\n",
            "Epoch 1055/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6610 - val_loss: 0.6204 - val_binary_accuracy: 0.6643\n",
            "Epoch 1056/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6675 - val_loss: 0.6201 - val_binary_accuracy: 0.6555\n",
            "Epoch 1057/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6624 - val_loss: 0.6199 - val_binary_accuracy: 0.6597\n",
            "Epoch 1058/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6638 - val_loss: 0.6205 - val_binary_accuracy: 0.6622\n",
            "Epoch 1059/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6653 - val_loss: 0.6215 - val_binary_accuracy: 0.6635\n",
            "Epoch 1060/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6658 - val_loss: 0.6217 - val_binary_accuracy: 0.6564\n",
            "Epoch 1061/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6618 - val_loss: 0.6212 - val_binary_accuracy: 0.6576\n",
            "Epoch 1062/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6628 - val_loss: 0.6178 - val_binary_accuracy: 0.6597\n",
            "Epoch 1063/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6647 - val_loss: 0.6199 - val_binary_accuracy: 0.6568\n",
            "Epoch 1064/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6667 - val_loss: 0.6200 - val_binary_accuracy: 0.6610\n",
            "Epoch 1065/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6668 - val_loss: 0.6201 - val_binary_accuracy: 0.6618\n",
            "Epoch 1066/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6685 - val_loss: 0.6221 - val_binary_accuracy: 0.6597\n",
            "Epoch 1067/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6683 - val_loss: 0.6200 - val_binary_accuracy: 0.6618\n",
            "Epoch 1068/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6681 - val_loss: 0.6202 - val_binary_accuracy: 0.6614\n",
            "Epoch 1069/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6594 - val_loss: 0.6211 - val_binary_accuracy: 0.6605\n",
            "Epoch 1070/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6659 - val_loss: 0.6210 - val_binary_accuracy: 0.6630\n",
            "Epoch 1071/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6677 - val_loss: 0.6201 - val_binary_accuracy: 0.6605\n",
            "Epoch 1072/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6631 - val_loss: 0.6215 - val_binary_accuracy: 0.6618\n",
            "Epoch 1073/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6664 - val_loss: 0.6205 - val_binary_accuracy: 0.6651\n",
            "Epoch 1074/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6648 - val_loss: 0.6212 - val_binary_accuracy: 0.6610\n",
            "Epoch 1075/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6657 - val_loss: 0.6204 - val_binary_accuracy: 0.6568\n",
            "Epoch 1076/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6665 - val_loss: 0.6196 - val_binary_accuracy: 0.6614\n",
            "Epoch 1077/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6627 - val_loss: 0.6223 - val_binary_accuracy: 0.6568\n",
            "Epoch 1078/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6641 - val_loss: 0.6187 - val_binary_accuracy: 0.6605\n",
            "Epoch 1079/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6655 - val_loss: 0.6193 - val_binary_accuracy: 0.6605\n",
            "Epoch 1080/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6656 - val_loss: 0.6219 - val_binary_accuracy: 0.6572\n",
            "Epoch 1081/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6642 - val_loss: 0.6193 - val_binary_accuracy: 0.6593\n",
            "Epoch 1082/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6667 - val_loss: 0.6175 - val_binary_accuracy: 0.6597\n",
            "Epoch 1083/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6652 - val_loss: 0.6212 - val_binary_accuracy: 0.6639\n",
            "Epoch 1084/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6640 - val_loss: 0.6195 - val_binary_accuracy: 0.6614\n",
            "Epoch 1085/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6635 - val_loss: 0.6205 - val_binary_accuracy: 0.6660\n",
            "Epoch 1086/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6635 - val_loss: 0.6192 - val_binary_accuracy: 0.6610\n",
            "Epoch 1087/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6635 - val_loss: 0.6206 - val_binary_accuracy: 0.6630\n",
            "Epoch 1088/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6732 - val_loss: 0.6214 - val_binary_accuracy: 0.6597\n",
            "Epoch 1089/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6666 - val_loss: 0.6203 - val_binary_accuracy: 0.6559\n",
            "Epoch 1090/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6675 - val_loss: 0.6200 - val_binary_accuracy: 0.6618\n",
            "Epoch 1091/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6658 - val_loss: 0.6184 - val_binary_accuracy: 0.6610\n",
            "Epoch 1092/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6678 - val_loss: 0.6203 - val_binary_accuracy: 0.6547\n",
            "Epoch 1093/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6682 - val_loss: 0.6219 - val_binary_accuracy: 0.6505\n",
            "Epoch 1094/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6635 - val_loss: 0.6192 - val_binary_accuracy: 0.6605\n",
            "Epoch 1095/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6672 - val_loss: 0.6185 - val_binary_accuracy: 0.6580\n",
            "Epoch 1096/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6658 - val_loss: 0.6193 - val_binary_accuracy: 0.6656\n",
            "Epoch 1097/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6685 - val_loss: 0.6196 - val_binary_accuracy: 0.6618\n",
            "Epoch 1098/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6643 - val_loss: 0.6178 - val_binary_accuracy: 0.6585\n",
            "Epoch 1099/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6674 - val_loss: 0.6198 - val_binary_accuracy: 0.6618\n",
            "Epoch 1100/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6673 - val_loss: 0.6233 - val_binary_accuracy: 0.6555\n",
            "Epoch 1101/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6702 - val_loss: 0.6206 - val_binary_accuracy: 0.6601\n",
            "Epoch 1102/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6693 - val_loss: 0.6193 - val_binary_accuracy: 0.6614\n",
            "Epoch 1103/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6678 - val_loss: 0.6187 - val_binary_accuracy: 0.6601\n",
            "Epoch 1104/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6600 - val_loss: 0.6222 - val_binary_accuracy: 0.6618\n",
            "Epoch 1105/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6647 - val_loss: 0.6203 - val_binary_accuracy: 0.6589\n",
            "Epoch 1106/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6659 - val_loss: 0.6206 - val_binary_accuracy: 0.6626\n",
            "Epoch 1107/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6634 - val_loss: 0.6197 - val_binary_accuracy: 0.6580\n",
            "Epoch 1108/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6650 - val_loss: 0.6186 - val_binary_accuracy: 0.6601\n",
            "Epoch 1109/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6636 - val_loss: 0.6184 - val_binary_accuracy: 0.6576\n",
            "Epoch 1110/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6661 - val_loss: 0.6175 - val_binary_accuracy: 0.6580\n",
            "Epoch 1111/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6669 - val_loss: 0.6216 - val_binary_accuracy: 0.6639\n",
            "Epoch 1112/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6673 - val_loss: 0.6199 - val_binary_accuracy: 0.6605\n",
            "Epoch 1113/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6624 - val_loss: 0.6219 - val_binary_accuracy: 0.6568\n",
            "Epoch 1114/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6679 - val_loss: 0.6189 - val_binary_accuracy: 0.6597\n",
            "Epoch 1115/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6669 - val_loss: 0.6203 - val_binary_accuracy: 0.6618\n",
            "Epoch 1116/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6687 - val_loss: 0.6205 - val_binary_accuracy: 0.6605\n",
            "Epoch 1117/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6634 - val_loss: 0.6216 - val_binary_accuracy: 0.6626\n",
            "Epoch 1118/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6702 - val_loss: 0.6186 - val_binary_accuracy: 0.6626\n",
            "Epoch 1119/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6669 - val_loss: 0.6177 - val_binary_accuracy: 0.6589\n",
            "Epoch 1120/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6650 - val_loss: 0.6210 - val_binary_accuracy: 0.6593\n",
            "Epoch 1121/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6671 - val_loss: 0.6200 - val_binary_accuracy: 0.6605\n",
            "Epoch 1122/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6655 - val_loss: 0.6221 - val_binary_accuracy: 0.6601\n",
            "Epoch 1123/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6713 - val_loss: 0.6192 - val_binary_accuracy: 0.6618\n",
            "Epoch 1124/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6680 - val_loss: 0.6195 - val_binary_accuracy: 0.6593\n",
            "Epoch 1125/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6172 - binary_accuracy: 0.6654 - val_loss: 0.6201 - val_binary_accuracy: 0.6585\n",
            "Epoch 1126/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6688 - val_loss: 0.6202 - val_binary_accuracy: 0.6605\n",
            "Epoch 1127/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6652 - val_loss: 0.6192 - val_binary_accuracy: 0.6605\n",
            "Epoch 1128/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6675 - val_loss: 0.6200 - val_binary_accuracy: 0.6622\n",
            "Epoch 1129/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6635 - val_loss: 0.6225 - val_binary_accuracy: 0.6534\n",
            "Epoch 1130/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6680 - val_loss: 0.6222 - val_binary_accuracy: 0.6593\n",
            "Epoch 1131/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6617 - val_loss: 0.6199 - val_binary_accuracy: 0.6647\n",
            "Epoch 1132/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6671 - val_loss: 0.6211 - val_binary_accuracy: 0.6647\n",
            "Epoch 1133/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6136 - binary_accuracy: 0.6635 - val_loss: 0.6196 - val_binary_accuracy: 0.6622\n",
            "Epoch 1134/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6704 - val_loss: 0.6208 - val_binary_accuracy: 0.6651\n",
            "Epoch 1135/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6660 - val_loss: 0.6188 - val_binary_accuracy: 0.6593\n",
            "Epoch 1136/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6634 - val_loss: 0.6205 - val_binary_accuracy: 0.6597\n",
            "Epoch 1137/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6651 - val_loss: 0.6199 - val_binary_accuracy: 0.6647\n",
            "Epoch 1138/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6663 - val_loss: 0.6195 - val_binary_accuracy: 0.6585\n",
            "Epoch 1139/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6685 - val_loss: 0.6197 - val_binary_accuracy: 0.6635\n",
            "Epoch 1140/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6671 - val_loss: 0.6200 - val_binary_accuracy: 0.6605\n",
            "Epoch 1141/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6640 - val_loss: 0.6209 - val_binary_accuracy: 0.6534\n",
            "Epoch 1142/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6166 - binary_accuracy: 0.6664 - val_loss: 0.6197 - val_binary_accuracy: 0.6580\n",
            "Epoch 1143/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6677 - val_loss: 0.6193 - val_binary_accuracy: 0.6635\n",
            "Epoch 1144/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6698 - val_loss: 0.6207 - val_binary_accuracy: 0.6610\n",
            "Epoch 1145/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6675 - val_loss: 0.6211 - val_binary_accuracy: 0.6564\n",
            "Epoch 1146/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6684 - val_loss: 0.6184 - val_binary_accuracy: 0.6597\n",
            "Epoch 1147/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6648 - val_loss: 0.6188 - val_binary_accuracy: 0.6601\n",
            "Epoch 1148/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6712 - val_loss: 0.6200 - val_binary_accuracy: 0.6639\n",
            "Epoch 1149/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6694 - val_loss: 0.6205 - val_binary_accuracy: 0.6576\n",
            "Epoch 1150/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6651 - val_loss: 0.6191 - val_binary_accuracy: 0.6572\n",
            "Epoch 1151/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6639 - val_loss: 0.6212 - val_binary_accuracy: 0.6580\n",
            "Epoch 1152/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6684 - val_loss: 0.6182 - val_binary_accuracy: 0.6626\n",
            "Epoch 1153/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6646 - val_loss: 0.6188 - val_binary_accuracy: 0.6618\n",
            "Epoch 1154/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6634 - val_loss: 0.6187 - val_binary_accuracy: 0.6614\n",
            "Epoch 1155/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6704 - val_loss: 0.6204 - val_binary_accuracy: 0.6601\n",
            "Epoch 1156/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6683 - val_loss: 0.6186 - val_binary_accuracy: 0.6614\n",
            "Epoch 1157/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6676 - val_loss: 0.6200 - val_binary_accuracy: 0.6626\n",
            "Epoch 1158/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6691 - val_loss: 0.6205 - val_binary_accuracy: 0.6597\n",
            "Epoch 1159/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6677 - val_loss: 0.6185 - val_binary_accuracy: 0.6647\n",
            "Epoch 1160/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6163 - binary_accuracy: 0.6696 - val_loss: 0.6190 - val_binary_accuracy: 0.6585\n",
            "Epoch 1161/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6678 - val_loss: 0.6214 - val_binary_accuracy: 0.6630\n",
            "Epoch 1162/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6684 - val_loss: 0.6184 - val_binary_accuracy: 0.6630\n",
            "Epoch 1163/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6636 - val_loss: 0.6198 - val_binary_accuracy: 0.6580\n",
            "Epoch 1164/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6669 - val_loss: 0.6206 - val_binary_accuracy: 0.6618\n",
            "Epoch 1165/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6644 - val_loss: 0.6209 - val_binary_accuracy: 0.6593\n",
            "Epoch 1166/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6665 - val_loss: 0.6195 - val_binary_accuracy: 0.6622\n",
            "Epoch 1167/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6676 - val_loss: 0.6182 - val_binary_accuracy: 0.6593\n",
            "Epoch 1168/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6678 - val_loss: 0.6199 - val_binary_accuracy: 0.6614\n",
            "Epoch 1169/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6179 - binary_accuracy: 0.6668 - val_loss: 0.6188 - val_binary_accuracy: 0.6585\n",
            "Epoch 1170/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6745 - val_loss: 0.6212 - val_binary_accuracy: 0.6651\n",
            "Epoch 1171/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6660 - val_loss: 0.6220 - val_binary_accuracy: 0.6555\n",
            "Epoch 1172/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6644 - val_loss: 0.6189 - val_binary_accuracy: 0.6647\n",
            "Epoch 1173/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6666 - val_loss: 0.6186 - val_binary_accuracy: 0.6643\n",
            "Epoch 1174/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6668 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 1175/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6677 - val_loss: 0.6208 - val_binary_accuracy: 0.6597\n",
            "Epoch 1176/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6684 - val_loss: 0.6193 - val_binary_accuracy: 0.6622\n",
            "Epoch 1177/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6689 - val_loss: 0.6205 - val_binary_accuracy: 0.6647\n",
            "Epoch 1178/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6094 - binary_accuracy: 0.6672 - val_loss: 0.6189 - val_binary_accuracy: 0.6605\n",
            "Epoch 1179/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6658 - val_loss: 0.6189 - val_binary_accuracy: 0.6610\n",
            "Epoch 1180/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6678 - val_loss: 0.6200 - val_binary_accuracy: 0.6589\n",
            "Epoch 1181/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6149 - binary_accuracy: 0.6681 - val_loss: 0.6193 - val_binary_accuracy: 0.6593\n",
            "Epoch 1182/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6671 - val_loss: 0.6172 - val_binary_accuracy: 0.6568\n",
            "Epoch 1183/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6677 - val_loss: 0.6202 - val_binary_accuracy: 0.6572\n",
            "Epoch 1184/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6651 - val_loss: 0.6191 - val_binary_accuracy: 0.6601\n",
            "Epoch 1185/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6686 - val_loss: 0.6197 - val_binary_accuracy: 0.6610\n",
            "Epoch 1186/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6679 - val_loss: 0.6201 - val_binary_accuracy: 0.6555\n",
            "Epoch 1187/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6689 - val_loss: 0.6189 - val_binary_accuracy: 0.6643\n",
            "Epoch 1188/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6700 - val_loss: 0.6214 - val_binary_accuracy: 0.6585\n",
            "Epoch 1189/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6665 - val_loss: 0.6203 - val_binary_accuracy: 0.6605\n",
            "Epoch 1190/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6719 - val_loss: 0.6199 - val_binary_accuracy: 0.6585\n",
            "Epoch 1191/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6707 - val_loss: 0.6202 - val_binary_accuracy: 0.6614\n",
            "Epoch 1192/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6660 - val_loss: 0.6205 - val_binary_accuracy: 0.6614\n",
            "Epoch 1193/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6158 - binary_accuracy: 0.6642 - val_loss: 0.6208 - val_binary_accuracy: 0.6656\n",
            "Epoch 1194/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6647 - val_loss: 0.6192 - val_binary_accuracy: 0.6610\n",
            "Epoch 1195/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6137 - binary_accuracy: 0.6677 - val_loss: 0.6199 - val_binary_accuracy: 0.6614\n",
            "Epoch 1196/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6692 - val_loss: 0.6189 - val_binary_accuracy: 0.6568\n",
            "Epoch 1197/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6136 - binary_accuracy: 0.6676 - val_loss: 0.6194 - val_binary_accuracy: 0.6610\n",
            "Epoch 1198/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6696 - val_loss: 0.6188 - val_binary_accuracy: 0.6614\n",
            "Epoch 1199/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6682 - val_loss: 0.6197 - val_binary_accuracy: 0.6639\n",
            "Epoch 1200/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6665 - val_loss: 0.6198 - val_binary_accuracy: 0.6589\n",
            "Epoch 1201/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6684 - val_loss: 0.6192 - val_binary_accuracy: 0.6622\n",
            "Epoch 1202/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6698 - val_loss: 0.6186 - val_binary_accuracy: 0.6635\n",
            "Epoch 1203/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6177 - binary_accuracy: 0.6663 - val_loss: 0.6213 - val_binary_accuracy: 0.6597\n",
            "Epoch 1204/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6682 - val_loss: 0.6190 - val_binary_accuracy: 0.6597\n",
            "Epoch 1205/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6694 - val_loss: 0.6209 - val_binary_accuracy: 0.6572\n",
            "Epoch 1206/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6678 - val_loss: 0.6204 - val_binary_accuracy: 0.6643\n",
            "Epoch 1207/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.6671 - val_loss: 0.6207 - val_binary_accuracy: 0.6580\n",
            "Epoch 1208/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6638 - val_loss: 0.6193 - val_binary_accuracy: 0.6580\n",
            "Epoch 1209/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6700 - val_loss: 0.6191 - val_binary_accuracy: 0.6601\n",
            "Epoch 1210/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6671 - val_loss: 0.6189 - val_binary_accuracy: 0.6614\n",
            "Epoch 1211/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6651 - val_loss: 0.6192 - val_binary_accuracy: 0.6614\n",
            "Epoch 1212/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6696 - val_loss: 0.6196 - val_binary_accuracy: 0.6605\n",
            "Epoch 1213/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6686 - val_loss: 0.6180 - val_binary_accuracy: 0.6547\n",
            "Epoch 1214/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6091 - binary_accuracy: 0.6682 - val_loss: 0.6182 - val_binary_accuracy: 0.6605\n",
            "Epoch 1215/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6681 - val_loss: 0.6200 - val_binary_accuracy: 0.6635\n",
            "Epoch 1216/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6665 - val_loss: 0.6199 - val_binary_accuracy: 0.6622\n",
            "Epoch 1217/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6151 - binary_accuracy: 0.6662 - val_loss: 0.6206 - val_binary_accuracy: 0.6614\n",
            "Epoch 1218/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6640 - val_loss: 0.6204 - val_binary_accuracy: 0.6593\n",
            "Epoch 1219/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6673 - val_loss: 0.6196 - val_binary_accuracy: 0.6618\n",
            "Epoch 1220/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6669 - val_loss: 0.6202 - val_binary_accuracy: 0.6555\n",
            "Epoch 1221/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6656 - val_loss: 0.6192 - val_binary_accuracy: 0.6610\n",
            "Epoch 1222/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6699 - val_loss: 0.6186 - val_binary_accuracy: 0.6601\n",
            "Epoch 1223/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6685 - val_loss: 0.6211 - val_binary_accuracy: 0.6626\n",
            "Epoch 1224/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6087 - binary_accuracy: 0.6704 - val_loss: 0.6177 - val_binary_accuracy: 0.6601\n",
            "Epoch 1225/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6711 - val_loss: 0.6185 - val_binary_accuracy: 0.6568\n",
            "Epoch 1226/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6159 - binary_accuracy: 0.6644 - val_loss: 0.6198 - val_binary_accuracy: 0.6555\n",
            "Epoch 1227/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6691 - val_loss: 0.6196 - val_binary_accuracy: 0.6576\n",
            "Epoch 1228/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6123 - binary_accuracy: 0.6684 - val_loss: 0.6191 - val_binary_accuracy: 0.6630\n",
            "Epoch 1229/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6701 - val_loss: 0.6191 - val_binary_accuracy: 0.6618\n",
            "Epoch 1230/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6664 - val_loss: 0.6190 - val_binary_accuracy: 0.6622\n",
            "Epoch 1231/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6663 - val_loss: 0.6195 - val_binary_accuracy: 0.6614\n",
            "Epoch 1232/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6684 - val_loss: 0.6206 - val_binary_accuracy: 0.6630\n",
            "Epoch 1233/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6646 - val_loss: 0.6211 - val_binary_accuracy: 0.6630\n",
            "Epoch 1234/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6142 - binary_accuracy: 0.6639 - val_loss: 0.6197 - val_binary_accuracy: 0.6635\n",
            "Epoch 1235/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6722 - val_loss: 0.6178 - val_binary_accuracy: 0.6597\n",
            "Epoch 1236/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6660 - val_loss: 0.6182 - val_binary_accuracy: 0.6635\n",
            "Epoch 1237/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6743 - val_loss: 0.6196 - val_binary_accuracy: 0.6635\n",
            "Epoch 1238/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6648 - val_loss: 0.6189 - val_binary_accuracy: 0.6626\n",
            "Epoch 1239/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6722 - val_loss: 0.6195 - val_binary_accuracy: 0.6601\n",
            "Epoch 1240/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6678 - val_loss: 0.6198 - val_binary_accuracy: 0.6580\n",
            "Epoch 1241/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6689 - val_loss: 0.6201 - val_binary_accuracy: 0.6626\n",
            "Epoch 1242/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6668 - val_loss: 0.6201 - val_binary_accuracy: 0.6664\n",
            "Epoch 1243/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6630 - val_loss: 0.6200 - val_binary_accuracy: 0.6647\n",
            "Epoch 1244/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6140 - binary_accuracy: 0.6663 - val_loss: 0.6201 - val_binary_accuracy: 0.6630\n",
            "Epoch 1245/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6674 - val_loss: 0.6207 - val_binary_accuracy: 0.6585\n",
            "Epoch 1246/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6169 - binary_accuracy: 0.6683 - val_loss: 0.6191 - val_binary_accuracy: 0.6597\n",
            "Epoch 1247/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6726 - val_loss: 0.6188 - val_binary_accuracy: 0.6610\n",
            "Epoch 1248/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6693 - val_loss: 0.6203 - val_binary_accuracy: 0.6651\n",
            "Epoch 1249/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6706 - val_loss: 0.6209 - val_binary_accuracy: 0.6572\n",
            "Epoch 1250/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6649 - val_loss: 0.6177 - val_binary_accuracy: 0.6593\n",
            "Epoch 1251/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6618 - val_loss: 0.6182 - val_binary_accuracy: 0.6593\n",
            "Epoch 1252/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6690 - val_loss: 0.6172 - val_binary_accuracy: 0.6656\n",
            "Epoch 1253/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6654 - val_loss: 0.6184 - val_binary_accuracy: 0.6572\n",
            "Epoch 1254/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6683 - val_loss: 0.6184 - val_binary_accuracy: 0.6610\n",
            "Epoch 1255/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6684 - val_loss: 0.6191 - val_binary_accuracy: 0.6618\n",
            "Epoch 1256/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6705 - val_loss: 0.6196 - val_binary_accuracy: 0.6605\n",
            "Epoch 1257/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6651 - val_loss: 0.6189 - val_binary_accuracy: 0.6618\n",
            "Epoch 1258/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6152 - binary_accuracy: 0.6645 - val_loss: 0.6192 - val_binary_accuracy: 0.6576\n",
            "Epoch 1259/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6678 - val_loss: 0.6210 - val_binary_accuracy: 0.6585\n",
            "Epoch 1260/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6716 - val_loss: 0.6180 - val_binary_accuracy: 0.6601\n",
            "Epoch 1261/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6164 - binary_accuracy: 0.6719 - val_loss: 0.6190 - val_binary_accuracy: 0.6610\n",
            "Epoch 1262/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6682 - val_loss: 0.6195 - val_binary_accuracy: 0.6635\n",
            "Epoch 1263/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6710 - val_loss: 0.6186 - val_binary_accuracy: 0.6622\n",
            "Epoch 1264/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6699 - val_loss: 0.6180 - val_binary_accuracy: 0.6614\n",
            "Epoch 1265/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6685 - val_loss: 0.6203 - val_binary_accuracy: 0.6656\n",
            "Epoch 1266/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6677 - val_loss: 0.6196 - val_binary_accuracy: 0.6597\n",
            "Epoch 1267/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6701 - val_loss: 0.6190 - val_binary_accuracy: 0.6626\n",
            "Epoch 1268/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6653 - val_loss: 0.6185 - val_binary_accuracy: 0.6593\n",
            "Epoch 1269/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6709 - val_loss: 0.6192 - val_binary_accuracy: 0.6580\n",
            "Epoch 1270/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6099 - binary_accuracy: 0.6719 - val_loss: 0.6189 - val_binary_accuracy: 0.6614\n",
            "Epoch 1271/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6686 - val_loss: 0.6189 - val_binary_accuracy: 0.6656\n",
            "Epoch 1272/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6714 - val_loss: 0.6177 - val_binary_accuracy: 0.6664\n",
            "Epoch 1273/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6672 - val_loss: 0.6230 - val_binary_accuracy: 0.6564\n",
            "Epoch 1274/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6690 - val_loss: 0.6204 - val_binary_accuracy: 0.6614\n",
            "Epoch 1275/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6668 - val_loss: 0.6193 - val_binary_accuracy: 0.6576\n",
            "Epoch 1276/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6686 - val_loss: 0.6176 - val_binary_accuracy: 0.6610\n",
            "Epoch 1277/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6709 - val_loss: 0.6190 - val_binary_accuracy: 0.6601\n",
            "Epoch 1278/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6162 - binary_accuracy: 0.6668 - val_loss: 0.6207 - val_binary_accuracy: 0.6610\n",
            "Epoch 1279/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6675 - val_loss: 0.6197 - val_binary_accuracy: 0.6639\n",
            "Epoch 1280/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6701 - val_loss: 0.6171 - val_binary_accuracy: 0.6593\n",
            "Epoch 1281/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6674 - val_loss: 0.6197 - val_binary_accuracy: 0.6614\n",
            "Epoch 1282/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6677 - val_loss: 0.6186 - val_binary_accuracy: 0.6555\n",
            "Epoch 1283/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6727 - val_loss: 0.6200 - val_binary_accuracy: 0.6610\n",
            "Epoch 1284/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6717 - val_loss: 0.6188 - val_binary_accuracy: 0.6610\n",
            "Epoch 1285/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6675 - val_loss: 0.6185 - val_binary_accuracy: 0.6601\n",
            "Epoch 1286/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6693 - val_loss: 0.6196 - val_binary_accuracy: 0.6572\n",
            "Epoch 1287/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6143 - binary_accuracy: 0.6690 - val_loss: 0.6191 - val_binary_accuracy: 0.6630\n",
            "Epoch 1288/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6674 - val_loss: 0.6180 - val_binary_accuracy: 0.6614\n",
            "Epoch 1289/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6161 - binary_accuracy: 0.6674 - val_loss: 0.6199 - val_binary_accuracy: 0.6626\n",
            "Epoch 1290/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6677 - val_loss: 0.6204 - val_binary_accuracy: 0.6614\n",
            "Epoch 1291/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6160 - binary_accuracy: 0.6715 - val_loss: 0.6207 - val_binary_accuracy: 0.6622\n",
            "Epoch 1292/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6666 - val_loss: 0.6199 - val_binary_accuracy: 0.6626\n",
            "Epoch 1293/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6668 - val_loss: 0.6194 - val_binary_accuracy: 0.6626\n",
            "Epoch 1294/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6679 - val_loss: 0.6179 - val_binary_accuracy: 0.6576\n",
            "Epoch 1295/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6722 - val_loss: 0.6200 - val_binary_accuracy: 0.6622\n",
            "Epoch 1296/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6671 - val_loss: 0.6176 - val_binary_accuracy: 0.6614\n",
            "Epoch 1297/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6131 - binary_accuracy: 0.6693 - val_loss: 0.6212 - val_binary_accuracy: 0.6618\n",
            "Epoch 1298/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6721 - val_loss: 0.6208 - val_binary_accuracy: 0.6568\n",
            "Epoch 1299/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6150 - binary_accuracy: 0.6694 - val_loss: 0.6195 - val_binary_accuracy: 0.6618\n",
            "Epoch 1300/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6686 - val_loss: 0.6212 - val_binary_accuracy: 0.6605\n",
            "Epoch 1301/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6703 - val_loss: 0.6196 - val_binary_accuracy: 0.6647\n",
            "Epoch 1302/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6144 - binary_accuracy: 0.6708 - val_loss: 0.6231 - val_binary_accuracy: 0.6593\n",
            "Epoch 1303/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6106 - binary_accuracy: 0.6667 - val_loss: 0.6199 - val_binary_accuracy: 0.6601\n",
            "Epoch 1304/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6701 - val_loss: 0.6199 - val_binary_accuracy: 0.6639\n",
            "Epoch 1305/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6679 - val_loss: 0.6188 - val_binary_accuracy: 0.6630\n",
            "Epoch 1306/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6718 - val_loss: 0.6177 - val_binary_accuracy: 0.6626\n",
            "Epoch 1307/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6115 - binary_accuracy: 0.6652 - val_loss: 0.6172 - val_binary_accuracy: 0.6618\n",
            "Epoch 1308/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6638 - val_loss: 0.6185 - val_binary_accuracy: 0.6585\n",
            "Epoch 1309/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6678 - val_loss: 0.6177 - val_binary_accuracy: 0.6635\n",
            "Epoch 1310/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6683 - val_loss: 0.6183 - val_binary_accuracy: 0.6630\n",
            "Epoch 1311/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6141 - binary_accuracy: 0.6697 - val_loss: 0.6190 - val_binary_accuracy: 0.6626\n",
            "Epoch 1312/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6719 - val_loss: 0.6201 - val_binary_accuracy: 0.6597\n",
            "Epoch 1313/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6697 - val_loss: 0.6208 - val_binary_accuracy: 0.6589\n",
            "Epoch 1314/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6157 - binary_accuracy: 0.6694 - val_loss: 0.6208 - val_binary_accuracy: 0.6626\n",
            "Epoch 1315/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6685 - val_loss: 0.6180 - val_binary_accuracy: 0.6622\n",
            "Epoch 1316/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6156 - binary_accuracy: 0.6689 - val_loss: 0.6189 - val_binary_accuracy: 0.6635\n",
            "Epoch 1317/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6713 - val_loss: 0.6183 - val_binary_accuracy: 0.6597\n",
            "Epoch 1318/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6685 - val_loss: 0.6191 - val_binary_accuracy: 0.6576\n",
            "Epoch 1319/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6683 - val_loss: 0.6174 - val_binary_accuracy: 0.6610\n",
            "Epoch 1320/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6691 - val_loss: 0.6176 - val_binary_accuracy: 0.6601\n",
            "Epoch 1321/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6703 - val_loss: 0.6186 - val_binary_accuracy: 0.6622\n",
            "Epoch 1322/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6675 - val_loss: 0.6199 - val_binary_accuracy: 0.6568\n",
            "Epoch 1323/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6718 - val_loss: 0.6205 - val_binary_accuracy: 0.6610\n",
            "Epoch 1324/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6711 - val_loss: 0.6197 - val_binary_accuracy: 0.6576\n",
            "Epoch 1325/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6685 - val_loss: 0.6185 - val_binary_accuracy: 0.6614\n",
            "Epoch 1326/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6751 - val_loss: 0.6188 - val_binary_accuracy: 0.6618\n",
            "Epoch 1327/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6689 - val_loss: 0.6182 - val_binary_accuracy: 0.6610\n",
            "Epoch 1328/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6708 - val_loss: 0.6206 - val_binary_accuracy: 0.6597\n",
            "Epoch 1329/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6728 - val_loss: 0.6183 - val_binary_accuracy: 0.6630\n",
            "Epoch 1330/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6715 - val_loss: 0.6188 - val_binary_accuracy: 0.6639\n",
            "Epoch 1331/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6686 - val_loss: 0.6180 - val_binary_accuracy: 0.6614\n",
            "Epoch 1332/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6145 - binary_accuracy: 0.6681 - val_loss: 0.6211 - val_binary_accuracy: 0.6580\n",
            "Epoch 1333/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6685 - val_loss: 0.6199 - val_binary_accuracy: 0.6605\n",
            "Epoch 1334/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6730 - val_loss: 0.6174 - val_binary_accuracy: 0.6643\n",
            "Epoch 1335/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6717 - val_loss: 0.6182 - val_binary_accuracy: 0.6597\n",
            "Epoch 1336/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6125 - binary_accuracy: 0.6665 - val_loss: 0.6180 - val_binary_accuracy: 0.6580\n",
            "Epoch 1337/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6661 - val_loss: 0.6194 - val_binary_accuracy: 0.6643\n",
            "Epoch 1338/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6685 - val_loss: 0.6190 - val_binary_accuracy: 0.6585\n",
            "Epoch 1339/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6121 - binary_accuracy: 0.6695 - val_loss: 0.6187 - val_binary_accuracy: 0.6601\n",
            "Epoch 1340/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6129 - binary_accuracy: 0.6737 - val_loss: 0.6190 - val_binary_accuracy: 0.6597\n",
            "Epoch 1341/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6733 - val_loss: 0.6200 - val_binary_accuracy: 0.6601\n",
            "Epoch 1342/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6685 - val_loss: 0.6183 - val_binary_accuracy: 0.6580\n",
            "Epoch 1343/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6663 - val_loss: 0.6211 - val_binary_accuracy: 0.6580\n",
            "Epoch 1344/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6690 - val_loss: 0.6209 - val_binary_accuracy: 0.6576\n",
            "Epoch 1345/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6147 - binary_accuracy: 0.6689 - val_loss: 0.6197 - val_binary_accuracy: 0.6626\n",
            "Epoch 1346/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6674 - val_loss: 0.6201 - val_binary_accuracy: 0.6601\n",
            "Epoch 1347/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6720 - val_loss: 0.6174 - val_binary_accuracy: 0.6601\n",
            "Epoch 1348/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6662 - val_loss: 0.6182 - val_binary_accuracy: 0.6601\n",
            "Epoch 1349/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6678 - val_loss: 0.6199 - val_binary_accuracy: 0.6601\n",
            "Epoch 1350/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6683 - val_loss: 0.6188 - val_binary_accuracy: 0.6630\n",
            "Epoch 1351/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6699 - val_loss: 0.6191 - val_binary_accuracy: 0.6626\n",
            "Epoch 1352/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6683 - val_loss: 0.6181 - val_binary_accuracy: 0.6643\n",
            "Epoch 1353/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6081 - binary_accuracy: 0.6692 - val_loss: 0.6192 - val_binary_accuracy: 0.6630\n",
            "Epoch 1354/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6690 - val_loss: 0.6181 - val_binary_accuracy: 0.6580\n",
            "Epoch 1355/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6718 - val_loss: 0.6194 - val_binary_accuracy: 0.6622\n",
            "Epoch 1356/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6708 - val_loss: 0.6186 - val_binary_accuracy: 0.6626\n",
            "Epoch 1357/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6668 - val_loss: 0.6195 - val_binary_accuracy: 0.6593\n",
            "Epoch 1358/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6693 - val_loss: 0.6213 - val_binary_accuracy: 0.6610\n",
            "Epoch 1359/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6665 - val_loss: 0.6198 - val_binary_accuracy: 0.6610\n",
            "Epoch 1360/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6726 - val_loss: 0.6190 - val_binary_accuracy: 0.6610\n",
            "Epoch 1361/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6692 - val_loss: 0.6175 - val_binary_accuracy: 0.6610\n",
            "Epoch 1362/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6679 - val_loss: 0.6193 - val_binary_accuracy: 0.6630\n",
            "Epoch 1363/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6679 - val_loss: 0.6173 - val_binary_accuracy: 0.6585\n",
            "Epoch 1364/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6711 - val_loss: 0.6211 - val_binary_accuracy: 0.6568\n",
            "Epoch 1365/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6694 - val_loss: 0.6191 - val_binary_accuracy: 0.6622\n",
            "Epoch 1366/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6677 - val_loss: 0.6188 - val_binary_accuracy: 0.6610\n",
            "Epoch 1367/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6137 - binary_accuracy: 0.6727 - val_loss: 0.6195 - val_binary_accuracy: 0.6597\n",
            "Epoch 1368/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6701 - val_loss: 0.6189 - val_binary_accuracy: 0.6622\n",
            "Epoch 1369/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6718 - val_loss: 0.6199 - val_binary_accuracy: 0.6610\n",
            "Epoch 1370/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6103 - binary_accuracy: 0.6729 - val_loss: 0.6195 - val_binary_accuracy: 0.6672\n",
            "Epoch 1371/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6698 - val_loss: 0.6188 - val_binary_accuracy: 0.6676\n",
            "Epoch 1372/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6696 - val_loss: 0.6191 - val_binary_accuracy: 0.6643\n",
            "Epoch 1373/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6681 - val_loss: 0.6208 - val_binary_accuracy: 0.6564\n",
            "Epoch 1374/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6660 - val_loss: 0.6186 - val_binary_accuracy: 0.6626\n",
            "Epoch 1375/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6701 - val_loss: 0.6195 - val_binary_accuracy: 0.6589\n",
            "Epoch 1376/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6153 - binary_accuracy: 0.6662 - val_loss: 0.6175 - val_binary_accuracy: 0.6618\n",
            "Epoch 1377/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6138 - binary_accuracy: 0.6710 - val_loss: 0.6189 - val_binary_accuracy: 0.6622\n",
            "Epoch 1378/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6110 - binary_accuracy: 0.6694 - val_loss: 0.6206 - val_binary_accuracy: 0.6585\n",
            "Epoch 1379/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6711 - val_loss: 0.6192 - val_binary_accuracy: 0.6618\n",
            "Epoch 1380/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6716 - val_loss: 0.6202 - val_binary_accuracy: 0.6601\n",
            "Epoch 1381/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6708 - val_loss: 0.6177 - val_binary_accuracy: 0.6618\n",
            "Epoch 1382/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6112 - binary_accuracy: 0.6700 - val_loss: 0.6170 - val_binary_accuracy: 0.6626\n",
            "Epoch 1383/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6686 - val_loss: 0.6220 - val_binary_accuracy: 0.6572\n",
            "Epoch 1384/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6714 - val_loss: 0.6188 - val_binary_accuracy: 0.6601\n",
            "Epoch 1385/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6686 - val_loss: 0.6189 - val_binary_accuracy: 0.6630\n",
            "Epoch 1386/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6131 - binary_accuracy: 0.6705 - val_loss: 0.6195 - val_binary_accuracy: 0.6626\n",
            "Epoch 1387/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6682 - val_loss: 0.6211 - val_binary_accuracy: 0.6564\n",
            "Epoch 1388/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6153 - binary_accuracy: 0.6704 - val_loss: 0.6203 - val_binary_accuracy: 0.6626\n",
            "Epoch 1389/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6702 - val_loss: 0.6184 - val_binary_accuracy: 0.6610\n",
            "Epoch 1390/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6694 - val_loss: 0.6201 - val_binary_accuracy: 0.6572\n",
            "Epoch 1391/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6104 - binary_accuracy: 0.6674 - val_loss: 0.6181 - val_binary_accuracy: 0.6605\n",
            "Epoch 1392/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6670 - val_loss: 0.6207 - val_binary_accuracy: 0.6576\n",
            "Epoch 1393/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6103 - binary_accuracy: 0.6715 - val_loss: 0.6174 - val_binary_accuracy: 0.6605\n",
            "Epoch 1394/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6718 - val_loss: 0.6186 - val_binary_accuracy: 0.6626\n",
            "Epoch 1395/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6135 - binary_accuracy: 0.6695 - val_loss: 0.6201 - val_binary_accuracy: 0.6610\n",
            "Epoch 1396/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6096 - binary_accuracy: 0.6733 - val_loss: 0.6189 - val_binary_accuracy: 0.6597\n",
            "Epoch 1397/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6723 - val_loss: 0.6207 - val_binary_accuracy: 0.6622\n",
            "Epoch 1398/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6095 - binary_accuracy: 0.6736 - val_loss: 0.6183 - val_binary_accuracy: 0.6610\n",
            "Epoch 1399/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6087 - binary_accuracy: 0.6683 - val_loss: 0.6188 - val_binary_accuracy: 0.6618\n",
            "Epoch 1400/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6689 - val_loss: 0.6180 - val_binary_accuracy: 0.6622\n",
            "Epoch 1401/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6108 - binary_accuracy: 0.6722 - val_loss: 0.6184 - val_binary_accuracy: 0.6593\n",
            "Epoch 1402/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6133 - binary_accuracy: 0.6637 - val_loss: 0.6187 - val_binary_accuracy: 0.6605\n",
            "Epoch 1403/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6718 - val_loss: 0.6189 - val_binary_accuracy: 0.6601\n",
            "Epoch 1404/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6666 - val_loss: 0.6194 - val_binary_accuracy: 0.6576\n",
            "Epoch 1405/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6733 - val_loss: 0.6193 - val_binary_accuracy: 0.6630\n",
            "Epoch 1406/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6702 - val_loss: 0.6209 - val_binary_accuracy: 0.6605\n",
            "Epoch 1407/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6118 - binary_accuracy: 0.6719 - val_loss: 0.6186 - val_binary_accuracy: 0.6605\n",
            "Epoch 1408/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6731 - val_loss: 0.6184 - val_binary_accuracy: 0.6605\n",
            "Epoch 1409/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6071 - binary_accuracy: 0.6675 - val_loss: 0.6205 - val_binary_accuracy: 0.6614\n",
            "Epoch 1410/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6102 - binary_accuracy: 0.6679 - val_loss: 0.6203 - val_binary_accuracy: 0.6601\n",
            "Epoch 1411/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6130 - binary_accuracy: 0.6728 - val_loss: 0.6200 - val_binary_accuracy: 0.6605\n",
            "Epoch 1412/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6722 - val_loss: 0.6188 - val_binary_accuracy: 0.6630\n",
            "Epoch 1413/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6133 - binary_accuracy: 0.6690 - val_loss: 0.6205 - val_binary_accuracy: 0.6639\n",
            "Epoch 1414/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6132 - binary_accuracy: 0.6676 - val_loss: 0.6189 - val_binary_accuracy: 0.6597\n",
            "Epoch 1415/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6664 - val_loss: 0.6176 - val_binary_accuracy: 0.6585\n",
            "Epoch 1416/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6685 - val_loss: 0.6190 - val_binary_accuracy: 0.6597\n",
            "Epoch 1417/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6728 - val_loss: 0.6199 - val_binary_accuracy: 0.6585\n",
            "Epoch 1418/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6146 - binary_accuracy: 0.6668 - val_loss: 0.6209 - val_binary_accuracy: 0.6568\n",
            "Epoch 1419/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6736 - val_loss: 0.6194 - val_binary_accuracy: 0.6597\n",
            "Epoch 1420/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6099 - binary_accuracy: 0.6710 - val_loss: 0.6177 - val_binary_accuracy: 0.6626\n",
            "Epoch 1421/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6142 - binary_accuracy: 0.6694 - val_loss: 0.6189 - val_binary_accuracy: 0.6622\n",
            "Epoch 1422/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6145 - binary_accuracy: 0.6672 - val_loss: 0.6208 - val_binary_accuracy: 0.6601\n",
            "Epoch 1423/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6706 - val_loss: 0.6203 - val_binary_accuracy: 0.6593\n",
            "Epoch 1424/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6120 - binary_accuracy: 0.6694 - val_loss: 0.6173 - val_binary_accuracy: 0.6589\n",
            "Epoch 1425/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6093 - binary_accuracy: 0.6735 - val_loss: 0.6187 - val_binary_accuracy: 0.6639\n",
            "Epoch 1426/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6660 - val_loss: 0.6200 - val_binary_accuracy: 0.6618\n",
            "Epoch 1427/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6100 - binary_accuracy: 0.6702 - val_loss: 0.6191 - val_binary_accuracy: 0.6630\n",
            "Epoch 1428/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6126 - binary_accuracy: 0.6698 - val_loss: 0.6184 - val_binary_accuracy: 0.6618\n",
            "Epoch 1429/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6700 - val_loss: 0.6199 - val_binary_accuracy: 0.6618\n",
            "Epoch 1430/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6699 - val_loss: 0.6204 - val_binary_accuracy: 0.6618\n",
            "Epoch 1431/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6098 - binary_accuracy: 0.6685 - val_loss: 0.6216 - val_binary_accuracy: 0.6589\n",
            "Epoch 1432/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6727 - val_loss: 0.6180 - val_binary_accuracy: 0.6597\n",
            "Epoch 1433/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6701 - val_loss: 0.6198 - val_binary_accuracy: 0.6601\n",
            "Epoch 1434/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6728 - val_loss: 0.6178 - val_binary_accuracy: 0.6568\n",
            "Epoch 1435/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6102 - binary_accuracy: 0.6687 - val_loss: 0.6200 - val_binary_accuracy: 0.6601\n",
            "Epoch 1436/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6668 - val_loss: 0.6180 - val_binary_accuracy: 0.6610\n",
            "Epoch 1437/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6122 - binary_accuracy: 0.6714 - val_loss: 0.6179 - val_binary_accuracy: 0.6610\n",
            "Epoch 1438/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6134 - binary_accuracy: 0.6704 - val_loss: 0.6191 - val_binary_accuracy: 0.6605\n",
            "Epoch 1439/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6702 - val_loss: 0.6212 - val_binary_accuracy: 0.6568\n",
            "Epoch 1440/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6128 - binary_accuracy: 0.6682 - val_loss: 0.6205 - val_binary_accuracy: 0.6589\n",
            "Epoch 1441/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6120 - binary_accuracy: 0.6681 - val_loss: 0.6209 - val_binary_accuracy: 0.6585\n",
            "Epoch 1442/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6706 - val_loss: 0.6225 - val_binary_accuracy: 0.6618\n",
            "Epoch 1443/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6712 - val_loss: 0.6197 - val_binary_accuracy: 0.6589\n",
            "Epoch 1444/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6116 - binary_accuracy: 0.6728 - val_loss: 0.6185 - val_binary_accuracy: 0.6672\n",
            "Epoch 1445/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6127 - binary_accuracy: 0.6704 - val_loss: 0.6208 - val_binary_accuracy: 0.6614\n",
            "Epoch 1446/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6086 - binary_accuracy: 0.6720 - val_loss: 0.6185 - val_binary_accuracy: 0.6630\n",
            "Epoch 1447/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6105 - binary_accuracy: 0.6700 - val_loss: 0.6184 - val_binary_accuracy: 0.6630\n",
            "Epoch 1448/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6124 - binary_accuracy: 0.6727 - val_loss: 0.6222 - val_binary_accuracy: 0.6568\n",
            "Epoch 1449/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6117 - binary_accuracy: 0.6691 - val_loss: 0.6204 - val_binary_accuracy: 0.6597\n",
            "Epoch 1450/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6146 - binary_accuracy: 0.6648 - val_loss: 0.6208 - val_binary_accuracy: 0.6610\n",
            "Epoch 1451/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6708 - val_loss: 0.6212 - val_binary_accuracy: 0.6589\n",
            "Epoch 1452/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6105 - binary_accuracy: 0.6708 - val_loss: 0.6187 - val_binary_accuracy: 0.6635\n",
            "Epoch 1453/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6113 - binary_accuracy: 0.6716 - val_loss: 0.6195 - val_binary_accuracy: 0.6660\n",
            "Epoch 1454/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6692 - val_loss: 0.6191 - val_binary_accuracy: 0.6660\n",
            "Epoch 1455/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6686 - val_loss: 0.6211 - val_binary_accuracy: 0.6593\n",
            "Epoch 1456/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6691 - val_loss: 0.6209 - val_binary_accuracy: 0.6597\n",
            "Epoch 1457/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6109 - binary_accuracy: 0.6660 - val_loss: 0.6176 - val_binary_accuracy: 0.6605\n",
            "Epoch 1458/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6126 - binary_accuracy: 0.6694 - val_loss: 0.6185 - val_binary_accuracy: 0.6681\n",
            "Epoch 1459/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6651 - val_loss: 0.6197 - val_binary_accuracy: 0.6610\n",
            "Epoch 1460/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6677 - val_loss: 0.6218 - val_binary_accuracy: 0.6622\n",
            "Epoch 1461/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6111 - binary_accuracy: 0.6688 - val_loss: 0.6178 - val_binary_accuracy: 0.6610\n",
            "Epoch 1462/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6100 - binary_accuracy: 0.6699 - val_loss: 0.6215 - val_binary_accuracy: 0.6585\n",
            "Epoch 1463/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6706 - val_loss: 0.6191 - val_binary_accuracy: 0.6593\n",
            "Epoch 1464/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6074 - binary_accuracy: 0.6715 - val_loss: 0.6198 - val_binary_accuracy: 0.6635\n",
            "Epoch 1465/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6668 - val_loss: 0.6175 - val_binary_accuracy: 0.6635\n",
            "Epoch 1466/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6132 - binary_accuracy: 0.6660 - val_loss: 0.6191 - val_binary_accuracy: 0.6630\n",
            "Epoch 1467/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6107 - binary_accuracy: 0.6738 - val_loss: 0.6203 - val_binary_accuracy: 0.6572\n",
            "Epoch 1468/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6683 - val_loss: 0.6198 - val_binary_accuracy: 0.6630\n",
            "Epoch 1469/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6094 - binary_accuracy: 0.6702 - val_loss: 0.6184 - val_binary_accuracy: 0.6630\n",
            "Epoch 1470/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6731 - val_loss: 0.6190 - val_binary_accuracy: 0.6656\n",
            "Epoch 1471/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6108 - binary_accuracy: 0.6713 - val_loss: 0.6213 - val_binary_accuracy: 0.6597\n",
            "Epoch 1472/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6113 - binary_accuracy: 0.6678 - val_loss: 0.6203 - val_binary_accuracy: 0.6614\n",
            "Epoch 1473/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6683 - val_loss: 0.6187 - val_binary_accuracy: 0.6580\n",
            "Epoch 1474/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6117 - binary_accuracy: 0.6677 - val_loss: 0.6185 - val_binary_accuracy: 0.6597\n",
            "Epoch 1475/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6702 - val_loss: 0.6200 - val_binary_accuracy: 0.6585\n",
            "Epoch 1476/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6092 - binary_accuracy: 0.6696 - val_loss: 0.6217 - val_binary_accuracy: 0.6551\n",
            "Epoch 1477/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6682 - val_loss: 0.6202 - val_binary_accuracy: 0.6618\n",
            "Epoch 1478/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6731 - val_loss: 0.6175 - val_binary_accuracy: 0.6589\n",
            "Epoch 1479/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6722 - val_loss: 0.6190 - val_binary_accuracy: 0.6630\n",
            "Epoch 1480/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6104 - binary_accuracy: 0.6719 - val_loss: 0.6181 - val_binary_accuracy: 0.6568\n",
            "Epoch 1481/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6082 - binary_accuracy: 0.6707 - val_loss: 0.6177 - val_binary_accuracy: 0.6639\n",
            "Epoch 1482/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6154 - binary_accuracy: 0.6660 - val_loss: 0.6207 - val_binary_accuracy: 0.6597\n",
            "Epoch 1483/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6114 - binary_accuracy: 0.6719 - val_loss: 0.6192 - val_binary_accuracy: 0.6630\n",
            "Epoch 1484/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6680 - val_loss: 0.6192 - val_binary_accuracy: 0.6610\n",
            "Epoch 1485/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6095 - binary_accuracy: 0.6708 - val_loss: 0.6193 - val_binary_accuracy: 0.6622\n",
            "Epoch 1486/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6129 - binary_accuracy: 0.6704 - val_loss: 0.6196 - val_binary_accuracy: 0.6610\n",
            "Epoch 1487/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6121 - binary_accuracy: 0.6718 - val_loss: 0.6190 - val_binary_accuracy: 0.6605\n",
            "Epoch 1488/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6686 - val_loss: 0.6216 - val_binary_accuracy: 0.6568\n",
            "Epoch 1489/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6658 - val_loss: 0.6199 - val_binary_accuracy: 0.6626\n",
            "Epoch 1490/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6139 - binary_accuracy: 0.6659 - val_loss: 0.6206 - val_binary_accuracy: 0.6610\n",
            "Epoch 1491/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6124 - binary_accuracy: 0.6665 - val_loss: 0.6188 - val_binary_accuracy: 0.6605\n",
            "Epoch 1492/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6140 - binary_accuracy: 0.6686 - val_loss: 0.6192 - val_binary_accuracy: 0.6580\n",
            "Epoch 1493/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6101 - binary_accuracy: 0.6713 - val_loss: 0.6187 - val_binary_accuracy: 0.6618\n",
            "Epoch 1494/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6125 - binary_accuracy: 0.6681 - val_loss: 0.6204 - val_binary_accuracy: 0.6572\n",
            "Epoch 1495/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6106 - binary_accuracy: 0.6709 - val_loss: 0.6190 - val_binary_accuracy: 0.6630\n",
            "Epoch 1496/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6123 - binary_accuracy: 0.6695 - val_loss: 0.6222 - val_binary_accuracy: 0.6564\n",
            "Epoch 1497/1500\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6096 - binary_accuracy: 0.6686 - val_loss: 0.6188 - val_binary_accuracy: 0.6589\n",
            "Epoch 1498/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6118 - binary_accuracy: 0.6711 - val_loss: 0.6189 - val_binary_accuracy: 0.6622\n",
            "Epoch 1499/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6130 - binary_accuracy: 0.6681 - val_loss: 0.6210 - val_binary_accuracy: 0.6576\n",
            "Epoch 1500/1500\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.6097 - binary_accuracy: 0.6709 - val_loss: 0.6211 - val_binary_accuracy: 0.6551\n",
            "Accuracy on training data: 0.6763362884521484% \n",
            " Error on training data: 0.32366371154785156\n",
            "Accuracy on test data: 0.6662489771842957% \n",
            " Error on test data: 0.33375102281570435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "8eaed159-6420-4883-a0dc-30765286a9ef"
      },
      "source": [
        "Xnew=np.array([[1.7,2.05,57,43,0.69,0.5,0.5,0.5,1.2,0.62,0.71,1.31,77.8,0.78,0.33,1.26,2.6,1.2,0.67,0.74,1.17,85.5,0.79,0.62,1.18,4.6,1.09,0.67,0.71,1.04,78.3,0.73,0.51,1.08,4.4,0.99,0.69,0.71,0.9,71.7,0.61,0.55,0.89,6.0,0.86,0.7,0.66,0.82,61.8,0.54,0.38,0.77,4.6,1.1,0.68,0.71,1.13,86.8,0.68,0.58,1.00,4.4,1.2,0.65,0.71,1.35,79.1,0.81,0.31,1.26,1.0,1.02,0.69,0.68,0.99,72.9,0.66,0.56,0.95,3.7,1.05,0.63,0.69,1.0,71.2,0.67,0.59,1.07,3.9,1.0925,0.6625,0.6975,1.1175,77.5,0.7050000000000001,0.51,1.07,3.2500000000000004],\n",
        "               [1.3,3.2,20,134,0.44,0.71,0.473,0.5,1.1,0.67,0.69,1.13,82.3,0.7,0.44,1.05,8.1,1.1,0.6,0.71,1.06,71.0,0.69,0.3,1.14,4.3,1.06,0.68,0.71,0.97,76.6,0.71,0.54,1.04,3.1,0.97,0.69,0.71,0.95,65.6,0.6,0.53,0.88,3.7,0.87,0.7,0.68,0.77,62.4,0.53,0.61,0.75,3.6,1.22,0.66,0.73,1.36,85.0,0.77,0.53,1.18,5.0,1.22,0.64,0.75,1.25,83.5,0.79,0.48,1.23,6.4,1.16,0.57,0.76,1.01,75.0,0.73,0.27,1.28,3.3,1.1,0.59,0.72,1.0,74.5,0.66,0.62,1.12,4.9,0.85,0.71,0.64,0.88,60.9,0.56,0.43,0.78,4.0],\n",
        "               [2.03,1.73,74,33,0.67,0.47,0.472,0.589,1.27,0.62,0.76,1.36,87.7,0.8,0.59,1.30,3.5,1.12,0.65,0.76,1.01,75.3,0.76,0.52,1.17,4.3,1.11,0.61,0.71,1.12,70.9,0.71,0.34,1.16,7.5,1.09,0.64,0.71,1.16,75.5,0.67,0.48,1.05,5.8,0.96,0.68,0.68,0.93,71.5,0.59,0.46,0.86,4.2,1.24,0.54,0.76,1.29,73.4,0.75,0.26,1.39,2.5,1.18,0.65,0.7,1.26,83.1,0.75,0.52,1.16,5.8,0.99,0.66,0.7,0.88,70.9,0.6,0.56,0.91,5.4,0.95,0.68,0.69,0.84,69.7,0.6,0.55,0.88,8.6,0.94,0.68,0.66,0.87,69.0,0.6,0.6,0.89,3.3],\n",
        "               [2.3,1.5,25,22,0.59,0.66,0.5,0.521,1.2,0.57,0.73,1.14,78.4,0.76,0.24,1.33,3.7,1.13,0.67,0.69,1.16,82.6,0.73,0.5,1.09,5.0,1.0,0.64,0.68,0.9,71.2,0.64,0.59,0.99,4.4,0.91,0.67,0.67,0.83,67.0,0.57,0.47,0.85,5.7,1.06,0.6375,0.6925,1.0074999999999998,74.8,0.6749999999999999,0.45,1.065,4.7,1.19,0.59,0.72,1.22,75.5,0.76,0.27,1.28,2.2,1.12,0.6,0.73,1.01,76.8,0.68,0.44,1.14,5.1,1.11,0.68,0.71,1.13,81.7,0.73,0.53,1.07,4.0,1.01,0.68,0.7,0.98,73.4,0.63,0.54,0.93,6.9,1.1075,0.6375000000000001,0.7150000000000001,1.085,76.85,0.7,0.445,1.105,4.550000000000001],\n",
        "               [1.52,2.33,30,35,0.71,0.64,0.523,0.51,1.17,0.59,0.74,1.11,75.9,0.74,0.31,1.25,3.5,1.13,0.67,0.71,1.16,82.6,0.73,0.61,1.09,5.4,1.12,0.62,0.73,1.09,73.7,0.71,0.58,1.15,3.0,1.1,0.65,0.7,1.12,77.3,0.72,0.54,1.10,3.8,0.92,0.66,0.68,0.88,64.3,0.56,0.51,0.85,6.5,1.27,0.65,0.77,1.26,89.8,0.81,0.47,1.25,6.0,1.16,0.66,0.78,1.14,78.8,0.7,0.4,1.06,3.4,1.08,0.66,0.72,1.0,77.6,0.68,0.63,1.03,4.1,1.07,0.58,0.73,1.03,65.2,0.67,0.28,1.15,4.0,1.02,0.68,0.72,0.94,72.4,0.66,0.45,0.97,4.0],\n",
        "               [1.22,4.00,2,9,0.89,0.56,0.549,0.478,1.26,0.6,0.74,1.36,84.5,0.8,0.52,1.33,7.8,1.23,0.49,0.75,1.2,72.7,0.71,0.28,1.45,5.5,1.17,0.58,0.73,1.15,80.9,0.69,0.45,1.18,6.5,1.15,0.67,0.7,1.34,82.6,0.71,0.46,1.06,7.5,0.94,0.54,0.74,0.68,54.9,0.5,0.45,0.93,7.2,1.15,0.69,0.68,1.2,85.9,0.75,0.33,1.09,5.0,1.01,0.76,0.6,1.22,84.6,0.69,0.44,0.92,6.1,1.0,0.63,0.71,0.89,67.9,0.6,0.46,0.96,4.2,0.93,0.71,0.68,0.89,67.3,0.65,0.46,0.93,4.2,0.88,0.7,0.69,0.74,62.0,0.57,0.55,0.82,3.8],\n",
        "               [1.43,2.76,27,60,0.59,0.67,0.479,0.527,1.16,0.6,0.73,1.14,74.2,0.74,0.33,1.24,3.1,1.13,0.77,0.71,1.26,85.8,0.78,0.67,1.01,5.7,1.06,0.65,0.7,1.04,74.0,0.67,0.46,1.04,3.0,1.06,0.66,0.73,0.93,76.4,0.67,0.46,1.01,6.4,0.94,0.66,0.71,0.83,65.5,0.57,0.51,0.85,8.8,1.14,0.71,0.73,1.15,83.4,0.77,0.43,1.09,5.8,1.09,0.65,0.73,1.15,71.0,0.7,0.32,1.08,4.6,1.08,0.65,0.67,1.05,80.7,0.71,0.49,1.09,7.8,1.05,0.64,0.75,0.98,73.5,0.6,0.65,0.94,6.0,0.89,0.63,0.7,0.73,57.7,0.57,0.35,0.90,2.4],\n",
        "               [1.88,1.82,36,30,0.7,0.71,0.549,0.532,1.32,0.55,0.78,1.23,85.2,0.85,0.39,1.54,2.6,1.1,0.67,0.72,1.14,76.1,0.68,0.58,1.03,4.1,1.1,0.66,0.72,1.01,80.7,0.69,0.46,1.05,3.8,1.09,0.71,0.69,1.15,81.2,0.72,0.59,1.01,4.0,0.96,0.62,0.71,0.81,63.1,0.61,0.58,0.97,2.1,1.16,0.59,0.73,1.12,75.1,0.73,0.31,1.24,3.4,1.15,0.67,0.71,1.17,83.3,0.74,0.61,1.10,5.5,1.14,0.62,0.73,1.11,74.9,0.72,0.59,1.17,2.9,1.11,0.64,0.71,1.12,77.4,0.72,0.54,1.12,3.6,0.91,0.67,0.68,0.87,63.7,0.55,0.51,0.83,6.2]\n",
        "               ])\n",
        "Xnew=predictionScaler.transform(Xnew)\n",
        "model= keras.models.load_model(\"68model.h5\")\n",
        "\n",
        "ynew=(model.predict([Xnew]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49930856]\n",
            " [0.50274837]\n",
            " [0.54266787]\n",
            " [0.50696707]\n",
            " [0.5187108 ]\n",
            " [0.5136547 ]\n",
            " [0.5154686 ]\n",
            " [0.5333279 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDSZ8GXKuje"
      },
      "source": [
        "model.save('/content/save/68model.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KytdX4WSYkQ"
      },
      "source": [
        "n = 100 # Max number of neighbours you want to consider\n",
        "param_grid = {'n_neighbors': np.arange(n)}\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
        "grid.fit(X,y)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XU6SwMEp5r"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "pd.set_option(\"expand_frame_repr\", True)\n",
        "pd.set_option(\"large_repr\", \"info\")\n",
        "model.layers[0].get_weights()[0][98]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSBrO3pcCHlQ",
        "outputId": "61f3a2f7-e06a-4b0a-b5cb-95f6f4bb5ef3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6683375104427736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGzpVUzOYhY"
      },
      "source": [
        "import shap\n",
        "import xgboost\n",
        "\n",
        "CSV_COLUMN_NAMES2=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','team_one_name','team_two_name']\n",
        "shap.initjs()\n",
        "#explainer = shap.Explainer(model.predict, X_train)\n",
        "#shap_values = explainer.shap_values(np.array([[1.8,1.9,26,23,0.63,0.64,0.509,0.591,1.16,0.68,0.7,1.26,84.3,0.75,0.5,1.11,7.4,1.13,0.64,0.72,1.11,78.0,0.72,0.57,1.13,3.2,1.0,0.67,0.69,0.95,69.3,0.64,0.58,0.95,4.2,0.99,0.65,0.69,0.95,67.7,0.62,0.58,0.94,3.3,1.07,0.66,0.7,1.0675000000000001,74.825,0.6825,0.5575,1.0325000000000002,4.525,1.23,0.6,0.75,1.26,79.4,0.77,0.31,1.29,3.4,1.24,0.61,0.77,1.15,82.8,0.82,0.52,1.35,3.4,1.14,0.62,0.73,1.11,76.1,0.72,0.5,1.16,5.2,1.0,0.68,0.7,0.98,70.2,0.61,0.51,0.90,3.9,0.98,0.69,0.69,0.96,71.7,0.6,0.48,0.87,5.3]])\n",
        "\n",
        "keras_explainer = shap.DeepExplainer(model, shap.sample(X_train, 10))\n",
        "keras_shap_values = keras_explainer.shap_values(X_test)\n",
        "\n",
        "values = keras_shap_values[0]\n",
        "base_values = [keras_explainer.expected_value[0]]*len(keras_shap_values[0])\n",
        "\n",
        "tmp = shap.Explanation(values = np.array(values, dtype=np.float32),\n",
        "                       base_values = np.array(base_values, dtype=np.float32),\n",
        "                       data=np.array(X_train),\n",
        "                       feature_names=CSV_COLUMN_NAMES2)\n",
        "\n",
        "#shap.plots.waterfall(tmp[5])\n",
        "#shap.plots.bar(tmp,max_display=98)\n",
        "shap.summary_plot(tmp, X_test,max_display=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLaoTNJnIRM"
      },
      "source": [
        "#print(X_val)\n",
        "pokus=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)#vytvoří dataframe z našeho csv souboru\n",
        "pokus.pop('Match_link')\n",
        "pokus.pop('team_one_name')\n",
        "pokus.pop('team_two_name')\n",
        "pokus.pop('Result')\n",
        "\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaler.fit(pokus)\n",
        "data=scaler.transform(pokus)\n",
        "print(data)\n"
      ]
    }
  ]
}