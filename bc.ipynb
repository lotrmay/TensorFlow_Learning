{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrBdmwsPPT4yE3eqhlJhG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/bc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdqGaX3CRHW",
        "outputId": "10b64708-1ba1-40d1-a28f-fa44b8c42270"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import keras\n",
        "CSV_COLUMN_NAMES=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg','Match_link','Result','team_one_name','team_two_name']\n",
        "RESULTS=['0','1']\n",
        "CSV_COLUMN_NAMES_WITHOUT_STRINGS=['Odds_firstTeam','Odds_secondTeam','Rank_firstTeam','Rank_secondTeam','WinRate_firstTeam','WinRate_secondTeam','PistolWinRate_firstTeam','PistolWinRate_secondTeam',\n",
        "                  'playerAARating','playerAADpr','playerAAKast','playerAAImpact','playerAAAdr','playerAAKpr','playerAAHs','playerAAKD','playerAAGrenadeDmg',\n",
        "                  'playerABRating','playerABDpr','playerABKast','playerABImpact','playerABAdr','playerABKpr','playerABHs','playerABKD','playerABGrenadeDmg',\n",
        "                  'playerACRating','playerACDpr','playerACKast','playerACImpact','playerACAdr','playerACKpr','playerACHs','playerACKD','playerACGrenadeDmg',\n",
        "                  'playerADRating','playerADDpr','playerADKast','playerADImpact','playerADAdr','playerADKpr','playerADHs','playerADKD','playerADGrenadeDmg',\n",
        "                  'playerAERating','playerAEDpr','playerAEKast','playerAEImpact','playerAEAdr','playerAEKpr','playerAEHs','playerAEKD','playerAEGrenadeDmg',\n",
        "                  'playerBARating','playerBADpr','playerBAKast','playerBAImpact','playerBAAdr','playerBAKpr','playerBAHs','playerBAKD','playerBAGrenadeDmg',\n",
        "                  'playerBBRating','playerBBDpr','playerBBKast','playerBBImpact','playerBBAdr','playerBBKpr','playerBBHs','playerBBKD','playerBBGrenadeDmg',\n",
        "                  'playerBCRating','playerBCDpr','playerBCKast','playerBCImpact','playerBCAdr','playerBCKpr','playerBCHs','playerBCKD','playerBCGrenadeDmg',\n",
        "                  'playerBDRating','playerBDDpr','playerBDKast','playerBDImpact','playerBDAdr','playerBDKpr','playerBDHs','playerBDKD','playerBDGrenadeDmg',\n",
        "                  'playerBERating','playerBEDpr','playerBEKast','playerBEImpact','playerBEAdr','playerBEKpr','playerBEHs','playerBEKD','playerBEGrenadeDmg']\n",
        "\n",
        "\n",
        "\n",
        "train=pd.read_csv('/content/pokus.csv',sep=\";\",names=CSV_COLUMN_NAMES,error_bad_lines=False,header=None)\n",
        "#train_y=train.pop('Result')\n",
        "#test_y=test.pop('Result')\n",
        "train.pop('Match_link')\n",
        "train.pop('team_one_name')\n",
        "train.pop('team_two_name')\n",
        "target_column = ['Result'] \n",
        "predictors = list(set(list(train.columns))-set(target_column))\n",
        "scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "norm = StandardScaler()\n",
        "train[predictors]=norm.fit_transform(train[predictors])\n",
        "train[predictors] = scaler.fit_transform(train[predictors])\n",
        "\n",
        "\n",
        "#train[predictors] = train[predictors]/train[predictors].max()\n",
        "\n",
        "X = train[predictors].values\n",
        "y = train[target_column].values\n",
        "#print(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=35)\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "count_classes = y_test.shape[1]\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(98, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(learning_rate=0.01), #keras.optimizers.SGD(learning_rate=0.01)\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#adadelta \n",
        "#binary_crossentropy\n",
        "#categorical_crossentropy\n",
        "# categorical_hinge 0.677\n",
        "# hinge 0.667\n",
        "# MeanAbsoluteError 0.654, ale do 1500 epochs to bylo nad 0.67\n",
        "# MeanAbsolutePercentageError 0.6814 nevyskytuje se snížení po 1500 epochs jako minule\n",
        "history = model.fit(X_train, y_train, epochs=1000,batch_size=64,validation_data=(X_test, y_test))\n",
        "\n",
        "pred_train= model.predict(X_train)\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
        " \n",
        "pred_test= model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14081, 98)\n",
            "(4694, 98)\n",
            "Epoch 1/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.7082 - accuracy: 0.5417 - val_loss: 0.6958 - val_accuracy: 0.5215\n",
            "Epoch 2/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5400 - val_loss: 0.6937 - val_accuracy: 0.5239\n",
            "Epoch 3/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5359 - val_loss: 0.6921 - val_accuracy: 0.5254\n",
            "Epoch 4/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5418 - val_loss: 0.6908 - val_accuracy: 0.5279\n",
            "Epoch 5/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5423 - val_loss: 0.6892 - val_accuracy: 0.5320\n",
            "Epoch 6/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5526 - val_loss: 0.6880 - val_accuracy: 0.5362\n",
            "Epoch 7/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5459 - val_loss: 0.6874 - val_accuracy: 0.5343\n",
            "Epoch 8/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5516 - val_loss: 0.6859 - val_accuracy: 0.5411\n",
            "Epoch 9/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5590 - val_loss: 0.6851 - val_accuracy: 0.5398\n",
            "Epoch 10/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5538 - val_loss: 0.6842 - val_accuracy: 0.5418\n",
            "Epoch 11/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5541 - val_loss: 0.6829 - val_accuracy: 0.5450\n",
            "Epoch 12/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5604 - val_loss: 0.6822 - val_accuracy: 0.5450\n",
            "Epoch 13/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5592 - val_loss: 0.6809 - val_accuracy: 0.5509\n",
            "Epoch 14/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5632 - val_loss: 0.6800 - val_accuracy: 0.5520\n",
            "Epoch 15/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5646 - val_loss: 0.6792 - val_accuracy: 0.5513\n",
            "Epoch 16/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5696 - val_loss: 0.6782 - val_accuracy: 0.5569\n",
            "Epoch 17/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5719 - val_loss: 0.6775 - val_accuracy: 0.5575\n",
            "Epoch 18/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.5725 - val_loss: 0.6766 - val_accuracy: 0.5618\n",
            "Epoch 19/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5801 - val_loss: 0.6758 - val_accuracy: 0.5658\n",
            "Epoch 20/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5731 - val_loss: 0.6753 - val_accuracy: 0.5616\n",
            "Epoch 21/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5775 - val_loss: 0.6747 - val_accuracy: 0.5637\n",
            "Epoch 22/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.5764 - val_loss: 0.6736 - val_accuracy: 0.5703\n",
            "Epoch 23/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6709 - accuracy: 0.5820 - val_loss: 0.6729 - val_accuracy: 0.5714\n",
            "Epoch 24/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5834 - val_loss: 0.6723 - val_accuracy: 0.5712\n",
            "Epoch 25/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5874 - val_loss: 0.6716 - val_accuracy: 0.5718\n",
            "Epoch 26/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5855 - val_loss: 0.6709 - val_accuracy: 0.5720\n",
            "Epoch 27/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.5879 - val_loss: 0.6700 - val_accuracy: 0.5752\n",
            "Epoch 28/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.5951 - val_loss: 0.6692 - val_accuracy: 0.5788\n",
            "Epoch 29/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.5931 - val_loss: 0.6685 - val_accuracy: 0.5803\n",
            "Epoch 30/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5964 - val_loss: 0.6678 - val_accuracy: 0.5833\n",
            "Epoch 31/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6011 - val_loss: 0.6667 - val_accuracy: 0.5959\n",
            "Epoch 32/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6041 - val_loss: 0.6659 - val_accuracy: 0.6003\n",
            "Epoch 33/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6066 - val_loss: 0.6652 - val_accuracy: 0.6012\n",
            "Epoch 34/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.6052 - val_loss: 0.6650 - val_accuracy: 0.5916\n",
            "Epoch 35/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6051 - val_loss: 0.6644 - val_accuracy: 0.5925\n",
            "Epoch 36/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6075 - val_loss: 0.6635 - val_accuracy: 0.5967\n",
            "Epoch 37/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6030 - val_loss: 0.6628 - val_accuracy: 0.5978\n",
            "Epoch 38/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6108 - val_loss: 0.6618 - val_accuracy: 0.5999\n",
            "Epoch 39/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6163 - val_loss: 0.6612 - val_accuracy: 0.5995\n",
            "Epoch 40/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6590 - accuracy: 0.6118 - val_loss: 0.6606 - val_accuracy: 0.5995\n",
            "Epoch 41/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6152 - val_loss: 0.6596 - val_accuracy: 0.6127\n",
            "Epoch 42/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6186 - val_loss: 0.6594 - val_accuracy: 0.6012\n",
            "Epoch 43/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6153 - val_loss: 0.6588 - val_accuracy: 0.6040\n",
            "Epoch 44/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6170 - val_loss: 0.6579 - val_accuracy: 0.6133\n",
            "Epoch 45/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6222 - val_loss: 0.6573 - val_accuracy: 0.6129\n",
            "Epoch 46/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6245 - val_loss: 0.6567 - val_accuracy: 0.6121\n",
            "Epoch 47/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6246 - val_loss: 0.6558 - val_accuracy: 0.6221\n",
            "Epoch 48/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6257 - val_loss: 0.6564 - val_accuracy: 0.6025\n",
            "Epoch 49/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6245 - val_loss: 0.6547 - val_accuracy: 0.6221\n",
            "Epoch 50/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6242 - val_loss: 0.6544 - val_accuracy: 0.6142\n",
            "Epoch 51/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6224 - val_loss: 0.6538 - val_accuracy: 0.6180\n",
            "Epoch 52/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6304 - val_loss: 0.6525 - val_accuracy: 0.6329\n",
            "Epoch 53/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6379 - val_loss: 0.6521 - val_accuracy: 0.6297\n",
            "Epoch 54/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6349 - val_loss: 0.6520 - val_accuracy: 0.6236\n",
            "Epoch 55/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6294 - val_loss: 0.6512 - val_accuracy: 0.6285\n",
            "Epoch 56/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6318 - val_loss: 0.6504 - val_accuracy: 0.6319\n",
            "Epoch 57/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6296 - val_loss: 0.6507 - val_accuracy: 0.6221\n",
            "Epoch 58/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6264 - val_loss: 0.6505 - val_accuracy: 0.6176\n",
            "Epoch 59/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6299 - val_loss: 0.6493 - val_accuracy: 0.6293\n",
            "Epoch 60/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6320 - val_loss: 0.6493 - val_accuracy: 0.6219\n",
            "Epoch 61/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6256 - val_loss: 0.6487 - val_accuracy: 0.6242\n",
            "Epoch 62/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6473 - accuracy: 0.6280 - val_loss: 0.6474 - val_accuracy: 0.6302\n",
            "Epoch 63/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6365 - val_loss: 0.6467 - val_accuracy: 0.6336\n",
            "Epoch 64/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6363 - val_loss: 0.6465 - val_accuracy: 0.6312\n",
            "Epoch 65/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6385 - val_loss: 0.6459 - val_accuracy: 0.6329\n",
            "Epoch 66/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6387 - val_loss: 0.6461 - val_accuracy: 0.6280\n",
            "Epoch 67/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6326 - val_loss: 0.6452 - val_accuracy: 0.6319\n",
            "Epoch 68/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6384 - val_loss: 0.6450 - val_accuracy: 0.6312\n",
            "Epoch 69/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6350 - val_loss: 0.6444 - val_accuracy: 0.6319\n",
            "Epoch 70/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6443 - val_loss: 0.6444 - val_accuracy: 0.6314\n",
            "Epoch 71/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6362 - val_loss: 0.6430 - val_accuracy: 0.6342\n",
            "Epoch 72/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6542 - val_loss: 0.6430 - val_accuracy: 0.6331\n",
            "Epoch 73/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6386 - val_loss: 0.6425 - val_accuracy: 0.6334\n",
            "Epoch 74/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6405 - val_loss: 0.6420 - val_accuracy: 0.6336\n",
            "Epoch 75/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6415 - val_loss: 0.6415 - val_accuracy: 0.6361\n",
            "Epoch 76/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6478 - val_loss: 0.6422 - val_accuracy: 0.6304\n",
            "Epoch 77/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6367 - val_loss: 0.6416 - val_accuracy: 0.6327\n",
            "Epoch 78/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6401 - accuracy: 0.6374 - val_loss: 0.6402 - val_accuracy: 0.6349\n",
            "Epoch 79/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6487 - val_loss: 0.6396 - val_accuracy: 0.6402\n",
            "Epoch 80/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6571 - val_loss: 0.6395 - val_accuracy: 0.6344\n",
            "Epoch 81/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6379 - val_loss: 0.6390 - val_accuracy: 0.6374\n",
            "Epoch 82/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6513 - val_loss: 0.6393 - val_accuracy: 0.6323\n",
            "Epoch 83/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6365 - val_loss: 0.6387 - val_accuracy: 0.6349\n",
            "Epoch 84/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6537 - val_loss: 0.6387 - val_accuracy: 0.6327\n",
            "Epoch 85/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6465 - val_loss: 0.6379 - val_accuracy: 0.6368\n",
            "Epoch 86/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6557 - val_loss: 0.6379 - val_accuracy: 0.6331\n",
            "Epoch 87/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6355 - accuracy: 0.6445 - val_loss: 0.6367 - val_accuracy: 0.6423\n",
            "Epoch 88/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6461 - val_loss: 0.6366 - val_accuracy: 0.6370\n",
            "Epoch 89/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6556 - val_loss: 0.6371 - val_accuracy: 0.6344\n",
            "Epoch 90/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6526 - val_loss: 0.6357 - val_accuracy: 0.6423\n",
            "Epoch 91/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6358 - accuracy: 0.6443 - val_loss: 0.6353 - val_accuracy: 0.6419\n",
            "Epoch 92/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6489 - val_loss: 0.6355 - val_accuracy: 0.6359\n",
            "Epoch 93/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6458 - val_loss: 0.6349 - val_accuracy: 0.6398\n",
            "Epoch 94/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6418 - val_loss: 0.6350 - val_accuracy: 0.6355\n",
            "Epoch 95/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6320 - accuracy: 0.6528 - val_loss: 0.6352 - val_accuracy: 0.6334\n",
            "Epoch 96/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6547 - val_loss: 0.6336 - val_accuracy: 0.6440\n",
            "Epoch 97/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6563 - val_loss: 0.6336 - val_accuracy: 0.6423\n",
            "Epoch 98/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6524 - val_loss: 0.6332 - val_accuracy: 0.6429\n",
            "Epoch 99/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6472 - val_loss: 0.6330 - val_accuracy: 0.6417\n",
            "Epoch 100/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6478 - val_loss: 0.6323 - val_accuracy: 0.6457\n",
            "Epoch 101/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6441 - val_loss: 0.6328 - val_accuracy: 0.6380\n",
            "Epoch 102/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6306 - accuracy: 0.6439 - val_loss: 0.6317 - val_accuracy: 0.6457\n",
            "Epoch 103/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6522 - val_loss: 0.6320 - val_accuracy: 0.6400\n",
            "Epoch 104/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6529 - val_loss: 0.6315 - val_accuracy: 0.6423\n",
            "Epoch 105/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6559 - val_loss: 0.6314 - val_accuracy: 0.6398\n",
            "Epoch 106/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6573 - val_loss: 0.6304 - val_accuracy: 0.6438\n",
            "Epoch 107/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6291 - accuracy: 0.6540 - val_loss: 0.6313 - val_accuracy: 0.6389\n",
            "Epoch 108/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6554 - val_loss: 0.6303 - val_accuracy: 0.6447\n",
            "Epoch 109/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6493 - val_loss: 0.6298 - val_accuracy: 0.6451\n",
            "Epoch 110/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6488 - val_loss: 0.6297 - val_accuracy: 0.6453\n",
            "Epoch 111/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6554 - val_loss: 0.6291 - val_accuracy: 0.6438\n",
            "Epoch 112/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6529 - val_loss: 0.6288 - val_accuracy: 0.6449\n",
            "Epoch 113/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6491 - val_loss: 0.6292 - val_accuracy: 0.6432\n",
            "Epoch 114/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6555 - val_loss: 0.6287 - val_accuracy: 0.6455\n",
            "Epoch 115/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6496 - val_loss: 0.6286 - val_accuracy: 0.6447\n",
            "Epoch 116/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6576 - val_loss: 0.6281 - val_accuracy: 0.6459\n",
            "Epoch 117/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.6576 - val_loss: 0.6277 - val_accuracy: 0.6438\n",
            "Epoch 118/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6524 - val_loss: 0.6271 - val_accuracy: 0.6478\n",
            "Epoch 119/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6528 - val_loss: 0.6276 - val_accuracy: 0.6455\n",
            "Epoch 120/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6519 - val_loss: 0.6267 - val_accuracy: 0.6464\n",
            "Epoch 121/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6504 - val_loss: 0.6267 - val_accuracy: 0.6442\n",
            "Epoch 122/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6480 - val_loss: 0.6265 - val_accuracy: 0.6440\n",
            "Epoch 123/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6487 - val_loss: 0.6265 - val_accuracy: 0.6459\n",
            "Epoch 124/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6548 - val_loss: 0.6260 - val_accuracy: 0.6455\n",
            "Epoch 125/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6581 - val_loss: 0.6261 - val_accuracy: 0.6455\n",
            "Epoch 126/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6276 - accuracy: 0.6438 - val_loss: 0.6261 - val_accuracy: 0.6459\n",
            "Epoch 127/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.6556 - val_loss: 0.6260 - val_accuracy: 0.6457\n",
            "Epoch 128/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.6570 - val_loss: 0.6252 - val_accuracy: 0.6457\n",
            "Epoch 129/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6558 - val_loss: 0.6264 - val_accuracy: 0.6453\n",
            "Epoch 130/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6535 - val_loss: 0.6259 - val_accuracy: 0.6457\n",
            "Epoch 131/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6589 - val_loss: 0.6245 - val_accuracy: 0.6459\n",
            "Epoch 132/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6575 - val_loss: 0.6243 - val_accuracy: 0.6455\n",
            "Epoch 133/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6564 - val_loss: 0.6238 - val_accuracy: 0.6472\n",
            "Epoch 134/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6626 - val_loss: 0.6241 - val_accuracy: 0.6472\n",
            "Epoch 135/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6229 - accuracy: 0.6491 - val_loss: 0.6243 - val_accuracy: 0.6483\n",
            "Epoch 136/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6520 - val_loss: 0.6241 - val_accuracy: 0.6472\n",
            "Epoch 137/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6552 - val_loss: 0.6232 - val_accuracy: 0.6466\n",
            "Epoch 138/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.6519 - val_loss: 0.6230 - val_accuracy: 0.6464\n",
            "Epoch 139/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6549 - val_loss: 0.6232 - val_accuracy: 0.6487\n",
            "Epoch 140/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.6541 - val_loss: 0.6238 - val_accuracy: 0.6485\n",
            "Epoch 141/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6531 - val_loss: 0.6232 - val_accuracy: 0.6483\n",
            "Epoch 142/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6584 - val_loss: 0.6224 - val_accuracy: 0.6481\n",
            "Epoch 143/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.6550 - val_loss: 0.6220 - val_accuracy: 0.6466\n",
            "Epoch 144/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6552 - val_loss: 0.6217 - val_accuracy: 0.6461\n",
            "Epoch 145/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6589 - val_loss: 0.6213 - val_accuracy: 0.6470\n",
            "Epoch 146/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6505 - val_loss: 0.6218 - val_accuracy: 0.6483\n",
            "Epoch 147/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6607 - val_loss: 0.6214 - val_accuracy: 0.6476\n",
            "Epoch 148/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6589 - val_loss: 0.6207 - val_accuracy: 0.6500\n",
            "Epoch 149/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.6523 - val_loss: 0.6216 - val_accuracy: 0.6502\n",
            "Epoch 150/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.6620 - val_loss: 0.6208 - val_accuracy: 0.6476\n",
            "Epoch 151/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6511 - val_loss: 0.6212 - val_accuracy: 0.6493\n",
            "Epoch 152/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6558 - val_loss: 0.6204 - val_accuracy: 0.6476\n",
            "Epoch 153/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6563 - val_loss: 0.6199 - val_accuracy: 0.6498\n",
            "Epoch 154/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6191 - accuracy: 0.6570 - val_loss: 0.6202 - val_accuracy: 0.6476\n",
            "Epoch 155/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6559 - val_loss: 0.6199 - val_accuracy: 0.6485\n",
            "Epoch 156/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6578 - val_loss: 0.6197 - val_accuracy: 0.6489\n",
            "Epoch 157/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6542 - val_loss: 0.6202 - val_accuracy: 0.6500\n",
            "Epoch 158/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6580 - val_loss: 0.6194 - val_accuracy: 0.6491\n",
            "Epoch 159/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6597 - val_loss: 0.6187 - val_accuracy: 0.6517\n",
            "Epoch 160/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6603 - val_loss: 0.6185 - val_accuracy: 0.6530\n",
            "Epoch 161/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6147 - accuracy: 0.6592 - val_loss: 0.6191 - val_accuracy: 0.6498\n",
            "Epoch 162/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.6548 - val_loss: 0.6183 - val_accuracy: 0.6527\n",
            "Epoch 163/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6575 - val_loss: 0.6183 - val_accuracy: 0.6515\n",
            "Epoch 164/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6137 - accuracy: 0.6622 - val_loss: 0.6180 - val_accuracy: 0.6519\n",
            "Epoch 165/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6140 - accuracy: 0.6604 - val_loss: 0.6187 - val_accuracy: 0.6498\n",
            "Epoch 166/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6564 - val_loss: 0.6177 - val_accuracy: 0.6523\n",
            "Epoch 167/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.6624 - val_loss: 0.6184 - val_accuracy: 0.6496\n",
            "Epoch 168/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6595 - val_loss: 0.6193 - val_accuracy: 0.6506\n",
            "Epoch 169/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6170 - accuracy: 0.6546 - val_loss: 0.6179 - val_accuracy: 0.6510\n",
            "Epoch 170/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6668 - val_loss: 0.6169 - val_accuracy: 0.6551\n",
            "Epoch 171/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6144 - accuracy: 0.6575 - val_loss: 0.6167 - val_accuracy: 0.6551\n",
            "Epoch 172/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6641 - val_loss: 0.6174 - val_accuracy: 0.6513\n",
            "Epoch 173/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6583 - val_loss: 0.6180 - val_accuracy: 0.6496\n",
            "Epoch 174/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.6599 - val_loss: 0.6178 - val_accuracy: 0.6496\n",
            "Epoch 175/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6688 - val_loss: 0.6172 - val_accuracy: 0.6508\n",
            "Epoch 176/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6605 - val_loss: 0.6161 - val_accuracy: 0.6534\n",
            "Epoch 177/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6636 - val_loss: 0.6160 - val_accuracy: 0.6532\n",
            "Epoch 178/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6613 - val_loss: 0.6157 - val_accuracy: 0.6562\n",
            "Epoch 179/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6561 - val_loss: 0.6157 - val_accuracy: 0.6551\n",
            "Epoch 180/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6649 - val_loss: 0.6154 - val_accuracy: 0.6574\n",
            "Epoch 181/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6686 - val_loss: 0.6157 - val_accuracy: 0.6517\n",
            "Epoch 182/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.6635 - val_loss: 0.6157 - val_accuracy: 0.6534\n",
            "Epoch 183/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6592 - val_loss: 0.6153 - val_accuracy: 0.6534\n",
            "Epoch 184/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6630 - val_loss: 0.6154 - val_accuracy: 0.6523\n",
            "Epoch 185/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6725 - val_loss: 0.6150 - val_accuracy: 0.6542\n",
            "Epoch 186/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6621 - val_loss: 0.6153 - val_accuracy: 0.6532\n",
            "Epoch 187/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6655 - val_loss: 0.6162 - val_accuracy: 0.6504\n",
            "Epoch 188/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6614 - val_loss: 0.6150 - val_accuracy: 0.6532\n",
            "Epoch 189/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6575 - val_loss: 0.6144 - val_accuracy: 0.6557\n",
            "Epoch 190/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.6603 - val_loss: 0.6143 - val_accuracy: 0.6566\n",
            "Epoch 191/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6610 - val_loss: 0.6149 - val_accuracy: 0.6513\n",
            "Epoch 192/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6605 - val_loss: 0.6152 - val_accuracy: 0.6504\n",
            "Epoch 193/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6091 - accuracy: 0.6698 - val_loss: 0.6149 - val_accuracy: 0.6498\n",
            "Epoch 194/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6565 - val_loss: 0.6143 - val_accuracy: 0.6515\n",
            "Epoch 195/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6058 - accuracy: 0.6693 - val_loss: 0.6147 - val_accuracy: 0.6498\n",
            "Epoch 196/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6650 - val_loss: 0.6133 - val_accuracy: 0.6568\n",
            "Epoch 197/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6613 - val_loss: 0.6146 - val_accuracy: 0.6506\n",
            "Epoch 198/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6093 - accuracy: 0.6603 - val_loss: 0.6141 - val_accuracy: 0.6508\n",
            "Epoch 199/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6163 - accuracy: 0.6568 - val_loss: 0.6143 - val_accuracy: 0.6508\n",
            "Epoch 200/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6659 - val_loss: 0.6129 - val_accuracy: 0.6568\n",
            "Epoch 201/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6633 - val_loss: 0.6135 - val_accuracy: 0.6506\n",
            "Epoch 202/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6624 - val_loss: 0.6130 - val_accuracy: 0.6555\n",
            "Epoch 203/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6106 - accuracy: 0.6653 - val_loss: 0.6138 - val_accuracy: 0.6515\n",
            "Epoch 204/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6610 - val_loss: 0.6135 - val_accuracy: 0.6504\n",
            "Epoch 205/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6641 - val_loss: 0.6124 - val_accuracy: 0.6574\n",
            "Epoch 206/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6674 - val_loss: 0.6127 - val_accuracy: 0.6525\n",
            "Epoch 207/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6561 - val_loss: 0.6134 - val_accuracy: 0.6513\n",
            "Epoch 208/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6685 - val_loss: 0.6127 - val_accuracy: 0.6515\n",
            "Epoch 209/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6098 - accuracy: 0.6646 - val_loss: 0.6126 - val_accuracy: 0.6517\n",
            "Epoch 210/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6626 - val_loss: 0.6123 - val_accuracy: 0.6542\n",
            "Epoch 211/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6648 - val_loss: 0.6124 - val_accuracy: 0.6519\n",
            "Epoch 212/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6117 - accuracy: 0.6617 - val_loss: 0.6124 - val_accuracy: 0.6508\n",
            "Epoch 213/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.6657 - val_loss: 0.6120 - val_accuracy: 0.6542\n",
            "Epoch 214/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6098 - accuracy: 0.6619 - val_loss: 0.6123 - val_accuracy: 0.6510\n",
            "Epoch 215/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6765 - val_loss: 0.6115 - val_accuracy: 0.6555\n",
            "Epoch 216/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6616 - val_loss: 0.6112 - val_accuracy: 0.6562\n",
            "Epoch 217/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6107 - accuracy: 0.6608 - val_loss: 0.6117 - val_accuracy: 0.6538\n",
            "Epoch 218/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.6633 - val_loss: 0.6117 - val_accuracy: 0.6517\n",
            "Epoch 219/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6652 - val_loss: 0.6113 - val_accuracy: 0.6538\n",
            "Epoch 220/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6695 - val_loss: 0.6121 - val_accuracy: 0.6532\n",
            "Epoch 221/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6693 - val_loss: 0.6105 - val_accuracy: 0.6591\n",
            "Epoch 222/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6650 - val_loss: 0.6115 - val_accuracy: 0.6525\n",
            "Epoch 223/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6665 - val_loss: 0.6112 - val_accuracy: 0.6525\n",
            "Epoch 224/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.6647 - val_loss: 0.6111 - val_accuracy: 0.6527\n",
            "Epoch 225/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.6665 - val_loss: 0.6103 - val_accuracy: 0.6570\n",
            "Epoch 226/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.6684 - val_loss: 0.6109 - val_accuracy: 0.6534\n",
            "Epoch 227/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6662 - val_loss: 0.6099 - val_accuracy: 0.6581\n",
            "Epoch 228/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6055 - accuracy: 0.6688 - val_loss: 0.6106 - val_accuracy: 0.6538\n",
            "Epoch 229/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6676 - val_loss: 0.6101 - val_accuracy: 0.6545\n",
            "Epoch 230/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6604 - val_loss: 0.6100 - val_accuracy: 0.6545\n",
            "Epoch 231/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6086 - accuracy: 0.6654 - val_loss: 0.6096 - val_accuracy: 0.6570\n",
            "Epoch 232/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6101 - accuracy: 0.6642 - val_loss: 0.6095 - val_accuracy: 0.6572\n",
            "Epoch 233/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.6637 - val_loss: 0.6095 - val_accuracy: 0.6570\n",
            "Epoch 234/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6077 - accuracy: 0.6632 - val_loss: 0.6093 - val_accuracy: 0.6570\n",
            "Epoch 235/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6620 - val_loss: 0.6104 - val_accuracy: 0.6551\n",
            "Epoch 236/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6632 - val_loss: 0.6102 - val_accuracy: 0.6549\n",
            "Epoch 237/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6655 - val_loss: 0.6089 - val_accuracy: 0.6583\n",
            "Epoch 238/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6666 - val_loss: 0.6093 - val_accuracy: 0.6551\n",
            "Epoch 239/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6025 - accuracy: 0.6736 - val_loss: 0.6087 - val_accuracy: 0.6596\n",
            "Epoch 240/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6660 - val_loss: 0.6098 - val_accuracy: 0.6549\n",
            "Epoch 241/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6072 - accuracy: 0.6616 - val_loss: 0.6087 - val_accuracy: 0.6572\n",
            "Epoch 242/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.6697 - val_loss: 0.6087 - val_accuracy: 0.6574\n",
            "Epoch 243/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6614 - val_loss: 0.6098 - val_accuracy: 0.6547\n",
            "Epoch 244/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6668 - val_loss: 0.6092 - val_accuracy: 0.6549\n",
            "Epoch 245/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6079 - accuracy: 0.6684 - val_loss: 0.6098 - val_accuracy: 0.6555\n",
            "Epoch 246/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6053 - accuracy: 0.6674 - val_loss: 0.6082 - val_accuracy: 0.6576\n",
            "Epoch 247/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6630 - val_loss: 0.6084 - val_accuracy: 0.6570\n",
            "Epoch 248/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6707 - val_loss: 0.6085 - val_accuracy: 0.6551\n",
            "Epoch 249/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6055 - accuracy: 0.6667 - val_loss: 0.6087 - val_accuracy: 0.6549\n",
            "Epoch 250/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6643 - val_loss: 0.6078 - val_accuracy: 0.6594\n",
            "Epoch 251/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6652 - val_loss: 0.6077 - val_accuracy: 0.6589\n",
            "Epoch 252/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6671 - val_loss: 0.6076 - val_accuracy: 0.6594\n",
            "Epoch 253/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6684 - val_loss: 0.6079 - val_accuracy: 0.6559\n",
            "Epoch 254/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6663 - val_loss: 0.6076 - val_accuracy: 0.6566\n",
            "Epoch 255/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6746 - val_loss: 0.6074 - val_accuracy: 0.6587\n",
            "Epoch 256/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6034 - accuracy: 0.6644 - val_loss: 0.6078 - val_accuracy: 0.6570\n",
            "Epoch 257/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.6645 - val_loss: 0.6076 - val_accuracy: 0.6564\n",
            "Epoch 258/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6076 - accuracy: 0.6684 - val_loss: 0.6075 - val_accuracy: 0.6562\n",
            "Epoch 259/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6064 - accuracy: 0.6649 - val_loss: 0.6072 - val_accuracy: 0.6566\n",
            "Epoch 260/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.6695 - val_loss: 0.6086 - val_accuracy: 0.6555\n",
            "Epoch 261/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6095 - accuracy: 0.6584 - val_loss: 0.6069 - val_accuracy: 0.6591\n",
            "Epoch 262/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6030 - accuracy: 0.6737 - val_loss: 0.6072 - val_accuracy: 0.6566\n",
            "Epoch 263/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6704 - val_loss: 0.6071 - val_accuracy: 0.6570\n",
            "Epoch 264/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6719 - val_loss: 0.6074 - val_accuracy: 0.6566\n",
            "Epoch 265/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.6681 - val_loss: 0.6070 - val_accuracy: 0.6568\n",
            "Epoch 266/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6644 - val_loss: 0.6071 - val_accuracy: 0.6570\n",
            "Epoch 267/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6051 - accuracy: 0.6704 - val_loss: 0.6078 - val_accuracy: 0.6555\n",
            "Epoch 268/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6034 - accuracy: 0.6717 - val_loss: 0.6067 - val_accuracy: 0.6562\n",
            "Epoch 269/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.6667 - val_loss: 0.6070 - val_accuracy: 0.6576\n",
            "Epoch 270/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6694 - val_loss: 0.6060 - val_accuracy: 0.6623\n",
            "Epoch 271/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.6645 - val_loss: 0.6069 - val_accuracy: 0.6581\n",
            "Epoch 272/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6619 - val_loss: 0.6071 - val_accuracy: 0.6576\n",
            "Epoch 273/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6692 - val_loss: 0.6060 - val_accuracy: 0.6589\n",
            "Epoch 274/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6693 - val_loss: 0.6062 - val_accuracy: 0.6559\n",
            "Epoch 275/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6036 - accuracy: 0.6676 - val_loss: 0.6064 - val_accuracy: 0.6576\n",
            "Epoch 276/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6674 - val_loss: 0.6060 - val_accuracy: 0.6564\n",
            "Epoch 277/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6750 - val_loss: 0.6068 - val_accuracy: 0.6572\n",
            "Epoch 278/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6065 - accuracy: 0.6656 - val_loss: 0.6058 - val_accuracy: 0.6564\n",
            "Epoch 279/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6750 - val_loss: 0.6055 - val_accuracy: 0.6600\n",
            "Epoch 280/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6716 - val_loss: 0.6068 - val_accuracy: 0.6572\n",
            "Epoch 281/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6033 - accuracy: 0.6664 - val_loss: 0.6061 - val_accuracy: 0.6591\n",
            "Epoch 282/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.6683 - val_loss: 0.6066 - val_accuracy: 0.6576\n",
            "Epoch 283/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6687 - val_loss: 0.6057 - val_accuracy: 0.6574\n",
            "Epoch 284/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6737 - val_loss: 0.6054 - val_accuracy: 0.6566\n",
            "Epoch 285/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6609 - val_loss: 0.6055 - val_accuracy: 0.6576\n",
            "Epoch 286/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.6660 - val_loss: 0.6062 - val_accuracy: 0.6572\n",
            "Epoch 287/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6019 - accuracy: 0.6706 - val_loss: 0.6060 - val_accuracy: 0.6587\n",
            "Epoch 288/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6719 - val_loss: 0.6060 - val_accuracy: 0.6581\n",
            "Epoch 289/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6650 - val_loss: 0.6065 - val_accuracy: 0.6568\n",
            "Epoch 290/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.6689 - val_loss: 0.6056 - val_accuracy: 0.6587\n",
            "Epoch 291/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5999 - accuracy: 0.6739 - val_loss: 0.6057 - val_accuracy: 0.6583\n",
            "Epoch 292/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6656 - val_loss: 0.6047 - val_accuracy: 0.6587\n",
            "Epoch 293/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6696 - val_loss: 0.6047 - val_accuracy: 0.6583\n",
            "Epoch 294/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6706 - val_loss: 0.6048 - val_accuracy: 0.6576\n",
            "Epoch 295/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6704 - val_loss: 0.6045 - val_accuracy: 0.6587\n",
            "Epoch 296/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6704 - val_loss: 0.6052 - val_accuracy: 0.6579\n",
            "Epoch 297/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6738 - val_loss: 0.6048 - val_accuracy: 0.6576\n",
            "Epoch 298/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6053 - accuracy: 0.6691 - val_loss: 0.6044 - val_accuracy: 0.6581\n",
            "Epoch 299/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6703 - val_loss: 0.6044 - val_accuracy: 0.6581\n",
            "Epoch 300/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6688 - val_loss: 0.6058 - val_accuracy: 0.6572\n",
            "Epoch 301/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6731 - val_loss: 0.6053 - val_accuracy: 0.6589\n",
            "Epoch 302/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.6679 - val_loss: 0.6061 - val_accuracy: 0.6570\n",
            "Epoch 303/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6059 - accuracy: 0.6683 - val_loss: 0.6041 - val_accuracy: 0.6583\n",
            "Epoch 304/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6783 - val_loss: 0.6070 - val_accuracy: 0.6587\n",
            "Epoch 305/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.6663 - val_loss: 0.6052 - val_accuracy: 0.6583\n",
            "Epoch 306/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6018 - accuracy: 0.6697 - val_loss: 0.6039 - val_accuracy: 0.6594\n",
            "Epoch 307/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6710 - val_loss: 0.6048 - val_accuracy: 0.6589\n",
            "Epoch 308/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6690 - val_loss: 0.6037 - val_accuracy: 0.6636\n",
            "Epoch 309/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.6716 - val_loss: 0.6044 - val_accuracy: 0.6585\n",
            "Epoch 310/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.6701 - val_loss: 0.6036 - val_accuracy: 0.6640\n",
            "Epoch 311/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6680 - val_loss: 0.6042 - val_accuracy: 0.6591\n",
            "Epoch 312/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.6648 - val_loss: 0.6038 - val_accuracy: 0.6583\n",
            "Epoch 313/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6700 - val_loss: 0.6047 - val_accuracy: 0.6587\n",
            "Epoch 314/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6665 - val_loss: 0.6047 - val_accuracy: 0.6587\n",
            "Epoch 315/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6733 - val_loss: 0.6044 - val_accuracy: 0.6585\n",
            "Epoch 316/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.6750 - val_loss: 0.6037 - val_accuracy: 0.6598\n",
            "Epoch 317/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.6703 - val_loss: 0.6039 - val_accuracy: 0.6596\n",
            "Epoch 318/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6684 - val_loss: 0.6038 - val_accuracy: 0.6598\n",
            "Epoch 319/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6688 - val_loss: 0.6039 - val_accuracy: 0.6587\n",
            "Epoch 320/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.6652 - val_loss: 0.6033 - val_accuracy: 0.6608\n",
            "Epoch 321/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6723 - val_loss: 0.6048 - val_accuracy: 0.6572\n",
            "Epoch 322/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6710 - val_loss: 0.6041 - val_accuracy: 0.6585\n",
            "Epoch 323/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.6732 - val_loss: 0.6042 - val_accuracy: 0.6594\n",
            "Epoch 324/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6716 - val_loss: 0.6034 - val_accuracy: 0.6608\n",
            "Epoch 325/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6723 - val_loss: 0.6037 - val_accuracy: 0.6583\n",
            "Epoch 326/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6726 - val_loss: 0.6044 - val_accuracy: 0.6596\n",
            "Epoch 327/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.6664 - val_loss: 0.6034 - val_accuracy: 0.6589\n",
            "Epoch 328/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6689 - val_loss: 0.6030 - val_accuracy: 0.6615\n",
            "Epoch 329/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6050 - accuracy: 0.6633 - val_loss: 0.6031 - val_accuracy: 0.6604\n",
            "Epoch 330/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6710 - val_loss: 0.6042 - val_accuracy: 0.6594\n",
            "Epoch 331/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.6703 - val_loss: 0.6032 - val_accuracy: 0.6608\n",
            "Epoch 332/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6647 - val_loss: 0.6030 - val_accuracy: 0.6604\n",
            "Epoch 333/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6670 - val_loss: 0.6027 - val_accuracy: 0.6636\n",
            "Epoch 334/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6725 - val_loss: 0.6038 - val_accuracy: 0.6591\n",
            "Epoch 335/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6739 - val_loss: 0.6040 - val_accuracy: 0.6594\n",
            "Epoch 336/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6773 - val_loss: 0.6028 - val_accuracy: 0.6621\n",
            "Epoch 337/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6683 - val_loss: 0.6030 - val_accuracy: 0.6606\n",
            "Epoch 338/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6721 - val_loss: 0.6025 - val_accuracy: 0.6640\n",
            "Epoch 339/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6756 - val_loss: 0.6024 - val_accuracy: 0.6645\n",
            "Epoch 340/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6751 - val_loss: 0.6027 - val_accuracy: 0.6615\n",
            "Epoch 341/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6750 - val_loss: 0.6025 - val_accuracy: 0.6630\n",
            "Epoch 342/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6712 - val_loss: 0.6026 - val_accuracy: 0.6611\n",
            "Epoch 343/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.6715 - val_loss: 0.6028 - val_accuracy: 0.6600\n",
            "Epoch 344/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6628 - val_loss: 0.6036 - val_accuracy: 0.6591\n",
            "Epoch 345/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.6696 - val_loss: 0.6032 - val_accuracy: 0.6598\n",
            "Epoch 346/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6706 - val_loss: 0.6036 - val_accuracy: 0.6589\n",
            "Epoch 347/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6749 - val_loss: 0.6028 - val_accuracy: 0.6591\n",
            "Epoch 348/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6046 - accuracy: 0.6695 - val_loss: 0.6019 - val_accuracy: 0.6685\n",
            "Epoch 349/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6676 - val_loss: 0.6032 - val_accuracy: 0.6596\n",
            "Epoch 350/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.6705 - val_loss: 0.6028 - val_accuracy: 0.6587\n",
            "Epoch 351/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6742 - val_loss: 0.6020 - val_accuracy: 0.6655\n",
            "Epoch 352/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.6679 - val_loss: 0.6038 - val_accuracy: 0.6589\n",
            "Epoch 353/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6738 - val_loss: 0.6028 - val_accuracy: 0.6589\n",
            "Epoch 354/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6044 - accuracy: 0.6679 - val_loss: 0.6023 - val_accuracy: 0.6600\n",
            "Epoch 355/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6706 - val_loss: 0.6021 - val_accuracy: 0.6628\n",
            "Epoch 356/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6675 - val_loss: 0.6023 - val_accuracy: 0.6606\n",
            "Epoch 357/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6701 - val_loss: 0.6023 - val_accuracy: 0.6604\n",
            "Epoch 358/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6690 - val_loss: 0.6037 - val_accuracy: 0.6591\n",
            "Epoch 359/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6738 - val_loss: 0.6026 - val_accuracy: 0.6596\n",
            "Epoch 360/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6743 - val_loss: 0.6017 - val_accuracy: 0.6679\n",
            "Epoch 361/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6019 - accuracy: 0.6661 - val_loss: 0.6016 - val_accuracy: 0.6683\n",
            "Epoch 362/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6727 - val_loss: 0.6027 - val_accuracy: 0.6587\n",
            "Epoch 363/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6739 - val_loss: 0.6017 - val_accuracy: 0.6660\n",
            "Epoch 364/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6709 - val_loss: 0.6020 - val_accuracy: 0.6613\n",
            "Epoch 365/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6751 - val_loss: 0.6018 - val_accuracy: 0.6632\n",
            "Epoch 366/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6713 - val_loss: 0.6026 - val_accuracy: 0.6587\n",
            "Epoch 367/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6767 - val_loss: 0.6014 - val_accuracy: 0.6685\n",
            "Epoch 368/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6692 - val_loss: 0.6016 - val_accuracy: 0.6647\n",
            "Epoch 369/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5951 - accuracy: 0.6744 - val_loss: 0.6013 - val_accuracy: 0.6664\n",
            "Epoch 370/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6776 - val_loss: 0.6016 - val_accuracy: 0.6638\n",
            "Epoch 371/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6688 - val_loss: 0.6035 - val_accuracy: 0.6579\n",
            "Epoch 372/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6786 - val_loss: 0.6011 - val_accuracy: 0.6674\n",
            "Epoch 373/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6711 - val_loss: 0.6019 - val_accuracy: 0.6600\n",
            "Epoch 374/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6691 - val_loss: 0.6020 - val_accuracy: 0.6604\n",
            "Epoch 375/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6581 - val_loss: 0.6026 - val_accuracy: 0.6579\n",
            "Epoch 376/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.6678 - val_loss: 0.6018 - val_accuracy: 0.6606\n",
            "Epoch 377/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6737 - val_loss: 0.6010 - val_accuracy: 0.6668\n",
            "Epoch 378/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.6722 - val_loss: 0.6010 - val_accuracy: 0.6679\n",
            "Epoch 379/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6717 - val_loss: 0.6026 - val_accuracy: 0.6572\n",
            "Epoch 380/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6773 - val_loss: 0.6021 - val_accuracy: 0.6598\n",
            "Epoch 381/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6032 - accuracy: 0.6636 - val_loss: 0.6016 - val_accuracy: 0.6615\n",
            "Epoch 382/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6684 - val_loss: 0.6012 - val_accuracy: 0.6657\n",
            "Epoch 383/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6674 - val_loss: 0.6018 - val_accuracy: 0.6613\n",
            "Epoch 384/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6711 - val_loss: 0.6009 - val_accuracy: 0.6706\n",
            "Epoch 385/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6709 - val_loss: 0.6008 - val_accuracy: 0.6668\n",
            "Epoch 386/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6719 - val_loss: 0.6021 - val_accuracy: 0.6594\n",
            "Epoch 387/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6749 - val_loss: 0.6019 - val_accuracy: 0.6602\n",
            "Epoch 388/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.6750 - val_loss: 0.6011 - val_accuracy: 0.6651\n",
            "Epoch 389/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6738 - val_loss: 0.6009 - val_accuracy: 0.6689\n",
            "Epoch 390/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6741 - val_loss: 0.6015 - val_accuracy: 0.6602\n",
            "Epoch 391/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6019 - accuracy: 0.6672 - val_loss: 0.6021 - val_accuracy: 0.6583\n",
            "Epoch 392/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6765 - val_loss: 0.6021 - val_accuracy: 0.6583\n",
            "Epoch 393/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5989 - accuracy: 0.6743 - val_loss: 0.6007 - val_accuracy: 0.6702\n",
            "Epoch 394/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6731 - val_loss: 0.6008 - val_accuracy: 0.6668\n",
            "Epoch 395/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6717 - val_loss: 0.6016 - val_accuracy: 0.6615\n",
            "Epoch 396/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6747 - val_loss: 0.6014 - val_accuracy: 0.6606\n",
            "Epoch 397/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6727 - val_loss: 0.6007 - val_accuracy: 0.6685\n",
            "Epoch 398/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6768 - val_loss: 0.6009 - val_accuracy: 0.6651\n",
            "Epoch 399/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6731 - val_loss: 0.6011 - val_accuracy: 0.6634\n",
            "Epoch 400/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6737 - val_loss: 0.6011 - val_accuracy: 0.6636\n",
            "Epoch 401/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.6687 - val_loss: 0.6015 - val_accuracy: 0.6617\n",
            "Epoch 402/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6725 - val_loss: 0.6027 - val_accuracy: 0.6591\n",
            "Epoch 403/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6738 - val_loss: 0.6004 - val_accuracy: 0.6696\n",
            "Epoch 404/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6715 - val_loss: 0.6003 - val_accuracy: 0.6685\n",
            "Epoch 405/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6678 - val_loss: 0.6007 - val_accuracy: 0.6660\n",
            "Epoch 406/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6792 - val_loss: 0.6005 - val_accuracy: 0.6689\n",
            "Epoch 407/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6787 - val_loss: 0.6007 - val_accuracy: 0.6655\n",
            "Epoch 408/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6803 - val_loss: 0.6019 - val_accuracy: 0.6574\n",
            "Epoch 409/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5946 - accuracy: 0.6811 - val_loss: 0.6012 - val_accuracy: 0.6621\n",
            "Epoch 410/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6806 - val_loss: 0.6001 - val_accuracy: 0.6677\n",
            "Epoch 411/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6771 - val_loss: 0.6001 - val_accuracy: 0.6681\n",
            "Epoch 412/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6719 - val_loss: 0.6001 - val_accuracy: 0.6698\n",
            "Epoch 413/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6771 - val_loss: 0.6017 - val_accuracy: 0.6589\n",
            "Epoch 414/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6728 - val_loss: 0.6018 - val_accuracy: 0.6579\n",
            "Epoch 415/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6775 - val_loss: 0.6009 - val_accuracy: 0.6625\n",
            "Epoch 416/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6761 - val_loss: 0.6000 - val_accuracy: 0.6670\n",
            "Epoch 417/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6761 - val_loss: 0.6004 - val_accuracy: 0.6664\n",
            "Epoch 418/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6689 - val_loss: 0.6005 - val_accuracy: 0.6653\n",
            "Epoch 419/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5963 - accuracy: 0.6736 - val_loss: 0.6013 - val_accuracy: 0.6611\n",
            "Epoch 420/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6738 - val_loss: 0.6009 - val_accuracy: 0.6628\n",
            "Epoch 421/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6768 - val_loss: 0.6004 - val_accuracy: 0.6666\n",
            "Epoch 422/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6759 - val_loss: 0.6016 - val_accuracy: 0.6579\n",
            "Epoch 423/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6808 - val_loss: 0.6003 - val_accuracy: 0.6666\n",
            "Epoch 424/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6738 - val_loss: 0.6013 - val_accuracy: 0.6598\n",
            "Epoch 425/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6761 - val_loss: 0.6007 - val_accuracy: 0.6645\n",
            "Epoch 426/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5985 - accuracy: 0.6745 - val_loss: 0.6003 - val_accuracy: 0.6664\n",
            "Epoch 427/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6754 - val_loss: 0.5998 - val_accuracy: 0.6689\n",
            "Epoch 428/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6709 - val_loss: 0.5999 - val_accuracy: 0.6687\n",
            "Epoch 429/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6765 - val_loss: 0.5997 - val_accuracy: 0.6685\n",
            "Epoch 430/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6822 - val_loss: 0.6002 - val_accuracy: 0.6662\n",
            "Epoch 431/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6726 - val_loss: 0.6000 - val_accuracy: 0.6679\n",
            "Epoch 432/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6686 - val_loss: 0.6002 - val_accuracy: 0.6668\n",
            "Epoch 433/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5969 - accuracy: 0.6730 - val_loss: 0.6001 - val_accuracy: 0.6668\n",
            "Epoch 434/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5955 - accuracy: 0.6745 - val_loss: 0.5997 - val_accuracy: 0.6685\n",
            "Epoch 435/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6689 - val_loss: 0.6000 - val_accuracy: 0.6672\n",
            "Epoch 436/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6771 - val_loss: 0.6020 - val_accuracy: 0.6606\n",
            "Epoch 437/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5991 - accuracy: 0.6711 - val_loss: 0.5996 - val_accuracy: 0.6685\n",
            "Epoch 438/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6744 - val_loss: 0.5997 - val_accuracy: 0.6702\n",
            "Epoch 439/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5974 - accuracy: 0.6713 - val_loss: 0.6000 - val_accuracy: 0.6672\n",
            "Epoch 440/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6748 - val_loss: 0.6000 - val_accuracy: 0.6668\n",
            "Epoch 441/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6753 - val_loss: 0.6003 - val_accuracy: 0.6643\n",
            "Epoch 442/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6742 - val_loss: 0.5997 - val_accuracy: 0.6694\n",
            "Epoch 443/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5938 - accuracy: 0.6741 - val_loss: 0.6011 - val_accuracy: 0.6602\n",
            "Epoch 444/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6799 - val_loss: 0.6003 - val_accuracy: 0.6640\n",
            "Epoch 445/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6761 - val_loss: 0.6004 - val_accuracy: 0.6638\n",
            "Epoch 446/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6755 - val_loss: 0.6009 - val_accuracy: 0.6602\n",
            "Epoch 447/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6730 - val_loss: 0.5996 - val_accuracy: 0.6685\n",
            "Epoch 448/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6727 - val_loss: 0.6003 - val_accuracy: 0.6643\n",
            "Epoch 449/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5959 - accuracy: 0.6761 - val_loss: 0.5997 - val_accuracy: 0.6674\n",
            "Epoch 450/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6727 - val_loss: 0.6000 - val_accuracy: 0.6655\n",
            "Epoch 451/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6660 - val_loss: 0.6002 - val_accuracy: 0.6638\n",
            "Epoch 452/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6777 - val_loss: 0.6024 - val_accuracy: 0.6608\n",
            "Epoch 453/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5960 - accuracy: 0.6785 - val_loss: 0.6021 - val_accuracy: 0.6611\n",
            "Epoch 454/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6810 - val_loss: 0.5996 - val_accuracy: 0.6679\n",
            "Epoch 455/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5928 - accuracy: 0.6798 - val_loss: 0.6007 - val_accuracy: 0.6623\n",
            "Epoch 456/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6789 - val_loss: 0.5996 - val_accuracy: 0.6679\n",
            "Epoch 457/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6729 - val_loss: 0.6006 - val_accuracy: 0.6628\n",
            "Epoch 458/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.6715 - val_loss: 0.5999 - val_accuracy: 0.6657\n",
            "Epoch 459/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6789 - val_loss: 0.5996 - val_accuracy: 0.6674\n",
            "Epoch 460/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6757 - val_loss: 0.6010 - val_accuracy: 0.6613\n",
            "Epoch 461/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6777 - val_loss: 0.5994 - val_accuracy: 0.6683\n",
            "Epoch 462/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6793 - val_loss: 0.5993 - val_accuracy: 0.6685\n",
            "Epoch 463/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6733 - val_loss: 0.6005 - val_accuracy: 0.6628\n",
            "Epoch 464/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6712 - val_loss: 0.6007 - val_accuracy: 0.6623\n",
            "Epoch 465/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5988 - accuracy: 0.6763 - val_loss: 0.5991 - val_accuracy: 0.6660\n",
            "Epoch 466/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6771 - val_loss: 0.6002 - val_accuracy: 0.6628\n",
            "Epoch 467/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5972 - accuracy: 0.6730 - val_loss: 0.6008 - val_accuracy: 0.6621\n",
            "Epoch 468/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6776 - val_loss: 0.5995 - val_accuracy: 0.6679\n",
            "Epoch 469/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5988 - accuracy: 0.6718 - val_loss: 0.5996 - val_accuracy: 0.6662\n",
            "Epoch 470/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6765 - val_loss: 0.6001 - val_accuracy: 0.6630\n",
            "Epoch 471/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5938 - accuracy: 0.6768 - val_loss: 0.5992 - val_accuracy: 0.6683\n",
            "Epoch 472/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6728 - val_loss: 0.5995 - val_accuracy: 0.6681\n",
            "Epoch 473/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6762 - val_loss: 0.6004 - val_accuracy: 0.6621\n",
            "Epoch 474/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6704 - val_loss: 0.5994 - val_accuracy: 0.6681\n",
            "Epoch 475/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6781 - val_loss: 0.6005 - val_accuracy: 0.6623\n",
            "Epoch 476/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6781 - val_loss: 0.5996 - val_accuracy: 0.6657\n",
            "Epoch 477/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6738 - val_loss: 0.5989 - val_accuracy: 0.6660\n",
            "Epoch 478/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6770 - val_loss: 0.6003 - val_accuracy: 0.6623\n",
            "Epoch 479/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6761 - val_loss: 0.5997 - val_accuracy: 0.6653\n",
            "Epoch 480/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6793 - val_loss: 0.5988 - val_accuracy: 0.6683\n",
            "Epoch 481/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6821 - val_loss: 0.5997 - val_accuracy: 0.6651\n",
            "Epoch 482/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5971 - accuracy: 0.6728 - val_loss: 0.5990 - val_accuracy: 0.6681\n",
            "Epoch 483/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6759 - val_loss: 0.5988 - val_accuracy: 0.6666\n",
            "Epoch 484/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6006 - accuracy: 0.6714 - val_loss: 0.6000 - val_accuracy: 0.6625\n",
            "Epoch 485/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.6825 - val_loss: 0.5988 - val_accuracy: 0.6655\n",
            "Epoch 486/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6750 - val_loss: 0.6004 - val_accuracy: 0.6632\n",
            "Epoch 487/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6759 - val_loss: 0.5988 - val_accuracy: 0.6683\n",
            "Epoch 488/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6789 - val_loss: 0.5998 - val_accuracy: 0.6634\n",
            "Epoch 489/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6701 - val_loss: 0.5992 - val_accuracy: 0.6677\n",
            "Epoch 490/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6753 - val_loss: 0.5999 - val_accuracy: 0.6625\n",
            "Epoch 491/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6782 - val_loss: 0.5987 - val_accuracy: 0.6655\n",
            "Epoch 492/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.6769 - val_loss: 0.6004 - val_accuracy: 0.6628\n",
            "Epoch 493/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6729 - val_loss: 0.5991 - val_accuracy: 0.6677\n",
            "Epoch 494/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6789 - val_loss: 0.5998 - val_accuracy: 0.6630\n",
            "Epoch 495/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6805 - val_loss: 0.5988 - val_accuracy: 0.6672\n",
            "Epoch 496/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6698 - val_loss: 0.5992 - val_accuracy: 0.6670\n",
            "Epoch 497/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6723 - val_loss: 0.6001 - val_accuracy: 0.6628\n",
            "Epoch 498/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5943 - accuracy: 0.6759 - val_loss: 0.5988 - val_accuracy: 0.6664\n",
            "Epoch 499/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6776 - val_loss: 0.5991 - val_accuracy: 0.6672\n",
            "Epoch 500/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5981 - accuracy: 0.6680 - val_loss: 0.5990 - val_accuracy: 0.6672\n",
            "Epoch 501/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6703 - val_loss: 0.5997 - val_accuracy: 0.6634\n",
            "Epoch 502/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6743 - val_loss: 0.5999 - val_accuracy: 0.6625\n",
            "Epoch 503/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6814 - val_loss: 0.5995 - val_accuracy: 0.6649\n",
            "Epoch 504/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6760 - val_loss: 0.5987 - val_accuracy: 0.6668\n",
            "Epoch 505/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6753 - val_loss: 0.5990 - val_accuracy: 0.6674\n",
            "Epoch 506/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.6770 - val_loss: 0.6000 - val_accuracy: 0.6623\n",
            "Epoch 507/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5974 - accuracy: 0.6761 - val_loss: 0.5998 - val_accuracy: 0.6630\n",
            "Epoch 508/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5922 - accuracy: 0.6795 - val_loss: 0.5989 - val_accuracy: 0.6672\n",
            "Epoch 509/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5962 - accuracy: 0.6751 - val_loss: 0.5985 - val_accuracy: 0.6662\n",
            "Epoch 510/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6755 - val_loss: 0.5989 - val_accuracy: 0.6679\n",
            "Epoch 511/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6739 - val_loss: 0.5989 - val_accuracy: 0.6677\n",
            "Epoch 512/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5898 - accuracy: 0.6828 - val_loss: 0.5987 - val_accuracy: 0.6683\n",
            "Epoch 513/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5993 - accuracy: 0.6712 - val_loss: 0.5999 - val_accuracy: 0.6625\n",
            "Epoch 514/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6756 - val_loss: 0.5993 - val_accuracy: 0.6657\n",
            "Epoch 515/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6811 - val_loss: 0.5987 - val_accuracy: 0.6685\n",
            "Epoch 516/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6698 - val_loss: 0.5992 - val_accuracy: 0.6668\n",
            "Epoch 517/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6783 - val_loss: 0.5984 - val_accuracy: 0.6687\n",
            "Epoch 518/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6695 - val_loss: 0.5986 - val_accuracy: 0.6674\n",
            "Epoch 519/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6794 - val_loss: 0.6010 - val_accuracy: 0.6619\n",
            "Epoch 520/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6721 - val_loss: 0.5996 - val_accuracy: 0.6628\n",
            "Epoch 521/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6769 - val_loss: 0.5985 - val_accuracy: 0.6662\n",
            "Epoch 522/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6732 - val_loss: 0.5994 - val_accuracy: 0.6653\n",
            "Epoch 523/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6796 - val_loss: 0.5998 - val_accuracy: 0.6625\n",
            "Epoch 524/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5972 - accuracy: 0.6800 - val_loss: 0.5985 - val_accuracy: 0.6666\n",
            "Epoch 525/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6751 - val_loss: 0.6003 - val_accuracy: 0.6636\n",
            "Epoch 526/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6757 - val_loss: 0.5990 - val_accuracy: 0.6666\n",
            "Epoch 527/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6758 - val_loss: 0.5984 - val_accuracy: 0.6662\n",
            "Epoch 528/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6790 - val_loss: 0.6006 - val_accuracy: 0.6643\n",
            "Epoch 529/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.6742 - val_loss: 0.5983 - val_accuracy: 0.6668\n",
            "Epoch 530/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6742 - val_loss: 0.5992 - val_accuracy: 0.6672\n",
            "Epoch 531/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6801 - val_loss: 0.5991 - val_accuracy: 0.6668\n",
            "Epoch 532/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6740 - val_loss: 0.5992 - val_accuracy: 0.6668\n",
            "Epoch 533/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6770 - val_loss: 0.5991 - val_accuracy: 0.6668\n",
            "Epoch 534/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6746 - val_loss: 0.5999 - val_accuracy: 0.6623\n",
            "Epoch 535/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5992 - accuracy: 0.6711 - val_loss: 0.5989 - val_accuracy: 0.6666\n",
            "Epoch 536/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5885 - accuracy: 0.6856 - val_loss: 0.5982 - val_accuracy: 0.6664\n",
            "Epoch 537/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6728 - val_loss: 0.5983 - val_accuracy: 0.6662\n",
            "Epoch 538/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6775 - val_loss: 0.6007 - val_accuracy: 0.6640\n",
            "Epoch 539/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6745 - val_loss: 0.5995 - val_accuracy: 0.6628\n",
            "Epoch 540/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6740 - val_loss: 0.5990 - val_accuracy: 0.6668\n",
            "Epoch 541/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6817 - val_loss: 0.5992 - val_accuracy: 0.6651\n",
            "Epoch 542/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6703 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 543/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6008 - accuracy: 0.6709 - val_loss: 0.6004 - val_accuracy: 0.6647\n",
            "Epoch 544/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6025 - accuracy: 0.6678 - val_loss: 0.5992 - val_accuracy: 0.6655\n",
            "Epoch 545/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6751 - val_loss: 0.5984 - val_accuracy: 0.6662\n",
            "Epoch 546/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6712 - val_loss: 0.5982 - val_accuracy: 0.6655\n",
            "Epoch 547/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6711 - val_loss: 0.5997 - val_accuracy: 0.6625\n",
            "Epoch 548/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6732 - val_loss: 0.5982 - val_accuracy: 0.6660\n",
            "Epoch 549/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6777 - val_loss: 0.5983 - val_accuracy: 0.6647\n",
            "Epoch 550/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6722 - val_loss: 0.5993 - val_accuracy: 0.6632\n",
            "Epoch 551/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6835 - val_loss: 0.5991 - val_accuracy: 0.6655\n",
            "Epoch 552/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.6727 - val_loss: 0.6001 - val_accuracy: 0.6638\n",
            "Epoch 553/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.6758 - val_loss: 0.5981 - val_accuracy: 0.6662\n",
            "Epoch 554/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6703 - val_loss: 0.5984 - val_accuracy: 0.6670\n",
            "Epoch 555/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6746 - val_loss: 0.5986 - val_accuracy: 0.6660\n",
            "Epoch 556/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6754 - val_loss: 0.5985 - val_accuracy: 0.6668\n",
            "Epoch 557/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6812 - val_loss: 0.5995 - val_accuracy: 0.6632\n",
            "Epoch 558/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.6763 - val_loss: 0.5990 - val_accuracy: 0.6662\n",
            "Epoch 559/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6756 - val_loss: 0.5980 - val_accuracy: 0.6666\n",
            "Epoch 560/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.6834 - val_loss: 0.6017 - val_accuracy: 0.6634\n",
            "Epoch 561/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6845 - val_loss: 0.5986 - val_accuracy: 0.6664\n",
            "Epoch 562/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5981 - accuracy: 0.6760 - val_loss: 0.5983 - val_accuracy: 0.6666\n",
            "Epoch 563/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6741 - val_loss: 0.5988 - val_accuracy: 0.6670\n",
            "Epoch 564/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.6765 - val_loss: 0.5990 - val_accuracy: 0.6664\n",
            "Epoch 565/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6804 - val_loss: 0.5983 - val_accuracy: 0.6664\n",
            "Epoch 566/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6717 - val_loss: 0.6003 - val_accuracy: 0.6634\n",
            "Epoch 567/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6794 - val_loss: 0.5980 - val_accuracy: 0.6657\n",
            "Epoch 568/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6728 - val_loss: 0.5984 - val_accuracy: 0.6672\n",
            "Epoch 569/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6760 - val_loss: 0.5984 - val_accuracy: 0.6670\n",
            "Epoch 570/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6747 - val_loss: 0.5986 - val_accuracy: 0.6664\n",
            "Epoch 571/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5953 - accuracy: 0.6760 - val_loss: 0.5991 - val_accuracy: 0.6653\n",
            "Epoch 572/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.6791 - val_loss: 0.5989 - val_accuracy: 0.6657\n",
            "Epoch 573/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6769 - val_loss: 0.5998 - val_accuracy: 0.6638\n",
            "Epoch 574/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6737 - val_loss: 0.5987 - val_accuracy: 0.6662\n",
            "Epoch 575/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5949 - accuracy: 0.6745 - val_loss: 0.5985 - val_accuracy: 0.6664\n",
            "Epoch 576/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5946 - accuracy: 0.6769 - val_loss: 0.5981 - val_accuracy: 0.6660\n",
            "Epoch 577/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6761 - val_loss: 0.5987 - val_accuracy: 0.6664\n",
            "Epoch 578/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6786 - val_loss: 0.5992 - val_accuracy: 0.6638\n",
            "Epoch 579/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6787 - val_loss: 0.5989 - val_accuracy: 0.6649\n",
            "Epoch 580/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5983 - accuracy: 0.6698 - val_loss: 0.5992 - val_accuracy: 0.6651\n",
            "Epoch 581/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6750 - val_loss: 0.5980 - val_accuracy: 0.6657\n",
            "Epoch 582/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6762 - val_loss: 0.5984 - val_accuracy: 0.6670\n",
            "Epoch 583/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6768 - val_loss: 0.5985 - val_accuracy: 0.6664\n",
            "Epoch 584/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.6802 - val_loss: 0.5979 - val_accuracy: 0.6657\n",
            "Epoch 585/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6738 - val_loss: 0.5994 - val_accuracy: 0.6638\n",
            "Epoch 586/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6828 - val_loss: 0.5986 - val_accuracy: 0.6660\n",
            "Epoch 587/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6807 - val_loss: 0.5983 - val_accuracy: 0.6670\n",
            "Epoch 588/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6819 - val_loss: 0.5988 - val_accuracy: 0.6651\n",
            "Epoch 589/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6842 - val_loss: 0.5982 - val_accuracy: 0.6672\n",
            "Epoch 590/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5999 - accuracy: 0.6720 - val_loss: 0.5978 - val_accuracy: 0.6662\n",
            "Epoch 591/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6664 - val_loss: 0.5980 - val_accuracy: 0.6666\n",
            "Epoch 592/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6798 - val_loss: 0.5992 - val_accuracy: 0.6647\n",
            "Epoch 593/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.6716 - val_loss: 0.5987 - val_accuracy: 0.6651\n",
            "Epoch 594/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.6772 - val_loss: 0.5988 - val_accuracy: 0.6649\n",
            "Epoch 595/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6821 - val_loss: 0.5977 - val_accuracy: 0.6662\n",
            "Epoch 596/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.6769 - val_loss: 0.5977 - val_accuracy: 0.6670\n",
            "Epoch 597/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6788 - val_loss: 0.5991 - val_accuracy: 0.6651\n",
            "Epoch 598/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.6815 - val_loss: 0.5985 - val_accuracy: 0.6655\n",
            "Epoch 599/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6817 - val_loss: 0.5978 - val_accuracy: 0.6651\n",
            "Epoch 600/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5973 - accuracy: 0.6740 - val_loss: 0.5977 - val_accuracy: 0.6670\n",
            "Epoch 601/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.6768 - val_loss: 0.5979 - val_accuracy: 0.6655\n",
            "Epoch 602/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6771 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 603/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6784 - val_loss: 0.5982 - val_accuracy: 0.6668\n",
            "Epoch 604/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6856 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 605/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6788 - val_loss: 0.5980 - val_accuracy: 0.6664\n",
            "Epoch 606/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6701 - val_loss: 0.5978 - val_accuracy: 0.6655\n",
            "Epoch 607/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5922 - accuracy: 0.6755 - val_loss: 0.5976 - val_accuracy: 0.6668\n",
            "Epoch 608/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6744 - val_loss: 0.5976 - val_accuracy: 0.6672\n",
            "Epoch 609/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6788 - val_loss: 0.5982 - val_accuracy: 0.6668\n",
            "Epoch 610/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6766 - val_loss: 0.5987 - val_accuracy: 0.6653\n",
            "Epoch 611/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6005 - accuracy: 0.6732 - val_loss: 0.5980 - val_accuracy: 0.6662\n",
            "Epoch 612/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6795 - val_loss: 0.5989 - val_accuracy: 0.6660\n",
            "Epoch 613/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6737 - val_loss: 0.5992 - val_accuracy: 0.6643\n",
            "Epoch 614/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.6831 - val_loss: 0.5989 - val_accuracy: 0.6649\n",
            "Epoch 615/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.6807 - val_loss: 0.5984 - val_accuracy: 0.6660\n",
            "Epoch 616/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6762 - val_loss: 0.5984 - val_accuracy: 0.6647\n",
            "Epoch 617/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6773 - val_loss: 0.5985 - val_accuracy: 0.6653\n",
            "Epoch 618/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5983 - accuracy: 0.6757 - val_loss: 0.5976 - val_accuracy: 0.6670\n",
            "Epoch 619/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5977 - accuracy: 0.6733 - val_loss: 0.5986 - val_accuracy: 0.6651\n",
            "Epoch 620/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6756 - val_loss: 0.5980 - val_accuracy: 0.6670\n",
            "Epoch 621/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6815 - val_loss: 0.5979 - val_accuracy: 0.6664\n",
            "Epoch 622/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6790 - val_loss: 0.5990 - val_accuracy: 0.6655\n",
            "Epoch 623/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.6818 - val_loss: 0.5977 - val_accuracy: 0.6660\n",
            "Epoch 624/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6725 - val_loss: 0.5977 - val_accuracy: 0.6666\n",
            "Epoch 625/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6796 - val_loss: 0.5980 - val_accuracy: 0.6666\n",
            "Epoch 626/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6751 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 627/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6805 - val_loss: 0.6001 - val_accuracy: 0.6640\n",
            "Epoch 628/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6715 - val_loss: 0.5995 - val_accuracy: 0.6649\n",
            "Epoch 629/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5965 - accuracy: 0.6789 - val_loss: 0.5982 - val_accuracy: 0.6660\n",
            "Epoch 630/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5976 - accuracy: 0.6769 - val_loss: 0.5974 - val_accuracy: 0.6666\n",
            "Epoch 631/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6735 - val_loss: 0.5978 - val_accuracy: 0.6662\n",
            "Epoch 632/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6867 - val_loss: 0.5976 - val_accuracy: 0.6668\n",
            "Epoch 633/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6760 - val_loss: 0.5976 - val_accuracy: 0.6664\n",
            "Epoch 634/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5953 - accuracy: 0.6737 - val_loss: 0.5974 - val_accuracy: 0.6668\n",
            "Epoch 635/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6042 - accuracy: 0.6645 - val_loss: 0.5990 - val_accuracy: 0.6657\n",
            "Epoch 636/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6813 - val_loss: 0.5977 - val_accuracy: 0.6657\n",
            "Epoch 637/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6743 - val_loss: 0.5974 - val_accuracy: 0.6670\n",
            "Epoch 638/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6761 - val_loss: 0.5983 - val_accuracy: 0.6649\n",
            "Epoch 639/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6824 - val_loss: 0.5974 - val_accuracy: 0.6657\n",
            "Epoch 640/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6756 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 641/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.6763 - val_loss: 0.5999 - val_accuracy: 0.6643\n",
            "Epoch 642/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6716 - val_loss: 0.5978 - val_accuracy: 0.6660\n",
            "Epoch 643/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6795 - val_loss: 0.5974 - val_accuracy: 0.6674\n",
            "Epoch 644/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6797 - val_loss: 0.5978 - val_accuracy: 0.6662\n",
            "Epoch 645/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6749 - val_loss: 0.5989 - val_accuracy: 0.6657\n",
            "Epoch 646/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.6768 - val_loss: 0.5975 - val_accuracy: 0.6657\n",
            "Epoch 647/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6791 - val_loss: 0.5974 - val_accuracy: 0.6662\n",
            "Epoch 648/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6795 - val_loss: 0.5987 - val_accuracy: 0.6657\n",
            "Epoch 649/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6872 - val_loss: 0.5979 - val_accuracy: 0.6664\n",
            "Epoch 650/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6736 - val_loss: 0.5992 - val_accuracy: 0.6657\n",
            "Epoch 651/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6818 - val_loss: 0.5977 - val_accuracy: 0.6649\n",
            "Epoch 652/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6779 - val_loss: 0.5982 - val_accuracy: 0.6653\n",
            "Epoch 653/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6764 - val_loss: 0.5981 - val_accuracy: 0.6660\n",
            "Epoch 654/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6765 - val_loss: 0.5979 - val_accuracy: 0.6666\n",
            "Epoch 655/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5982 - accuracy: 0.6716 - val_loss: 0.5985 - val_accuracy: 0.6647\n",
            "Epoch 656/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6782 - val_loss: 0.5978 - val_accuracy: 0.6666\n",
            "Epoch 657/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6757 - val_loss: 0.5988 - val_accuracy: 0.6647\n",
            "Epoch 658/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5931 - accuracy: 0.6764 - val_loss: 0.5977 - val_accuracy: 0.6660\n",
            "Epoch 659/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6728 - val_loss: 0.5979 - val_accuracy: 0.6668\n",
            "Epoch 660/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6851 - val_loss: 0.5980 - val_accuracy: 0.6666\n",
            "Epoch 661/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5878 - accuracy: 0.6804 - val_loss: 0.5973 - val_accuracy: 0.6672\n",
            "Epoch 662/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6747 - val_loss: 0.5974 - val_accuracy: 0.6653\n",
            "Epoch 663/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.6761 - val_loss: 0.5974 - val_accuracy: 0.6666\n",
            "Epoch 664/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6772 - val_loss: 0.5972 - val_accuracy: 0.6655\n",
            "Epoch 665/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6787 - val_loss: 0.5982 - val_accuracy: 0.6649\n",
            "Epoch 666/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6810 - val_loss: 0.5983 - val_accuracy: 0.6647\n",
            "Epoch 667/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.6772 - val_loss: 0.5975 - val_accuracy: 0.6664\n",
            "Epoch 668/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6842 - val_loss: 0.5975 - val_accuracy: 0.6664\n",
            "Epoch 669/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6775 - val_loss: 0.5974 - val_accuracy: 0.6660\n",
            "Epoch 670/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6811 - val_loss: 0.5982 - val_accuracy: 0.6649\n",
            "Epoch 671/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6722 - val_loss: 0.5985 - val_accuracy: 0.6653\n",
            "Epoch 672/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5962 - accuracy: 0.6743 - val_loss: 0.5984 - val_accuracy: 0.6638\n",
            "Epoch 673/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.6803 - val_loss: 0.5979 - val_accuracy: 0.6660\n",
            "Epoch 674/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.6848 - val_loss: 0.5983 - val_accuracy: 0.6638\n",
            "Epoch 675/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5963 - accuracy: 0.6761 - val_loss: 0.5990 - val_accuracy: 0.6660\n",
            "Epoch 676/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.6800 - val_loss: 0.5993 - val_accuracy: 0.6651\n",
            "Epoch 677/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6761 - val_loss: 0.5975 - val_accuracy: 0.6653\n",
            "Epoch 678/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5972 - accuracy: 0.6791 - val_loss: 0.5986 - val_accuracy: 0.6649\n",
            "Epoch 679/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.6819 - val_loss: 0.5979 - val_accuracy: 0.6666\n",
            "Epoch 680/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6817 - val_loss: 0.5989 - val_accuracy: 0.6662\n",
            "Epoch 681/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5945 - accuracy: 0.6763 - val_loss: 0.5977 - val_accuracy: 0.6670\n",
            "Epoch 682/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6805 - val_loss: 0.5976 - val_accuracy: 0.6653\n",
            "Epoch 683/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6741 - val_loss: 0.5992 - val_accuracy: 0.6649\n",
            "Epoch 684/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6803 - val_loss: 0.5973 - val_accuracy: 0.6660\n",
            "Epoch 685/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6771 - val_loss: 0.5972 - val_accuracy: 0.6668\n",
            "Epoch 686/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5980 - accuracy: 0.6684 - val_loss: 0.5986 - val_accuracy: 0.6653\n",
            "Epoch 687/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6713 - val_loss: 0.5973 - val_accuracy: 0.6666\n",
            "Epoch 688/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6748 - val_loss: 0.5986 - val_accuracy: 0.6657\n",
            "Epoch 689/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.6719 - val_loss: 0.5972 - val_accuracy: 0.6674\n",
            "Epoch 690/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.6813 - val_loss: 0.5972 - val_accuracy: 0.6670\n",
            "Epoch 691/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6768 - val_loss: 0.5978 - val_accuracy: 0.6660\n",
            "Epoch 692/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6804 - val_loss: 0.5977 - val_accuracy: 0.6664\n",
            "Epoch 693/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6787 - val_loss: 0.5971 - val_accuracy: 0.6674\n",
            "Epoch 694/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.6004 - accuracy: 0.6758 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 695/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6785 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 696/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5934 - accuracy: 0.6781 - val_loss: 0.5972 - val_accuracy: 0.6668\n",
            "Epoch 697/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6794 - val_loss: 0.5971 - val_accuracy: 0.6670\n",
            "Epoch 698/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.6711 - val_loss: 0.5981 - val_accuracy: 0.6653\n",
            "Epoch 699/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6767 - val_loss: 0.5972 - val_accuracy: 0.6666\n",
            "Epoch 700/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6814 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 701/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5925 - accuracy: 0.6754 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 702/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6769 - val_loss: 0.5974 - val_accuracy: 0.6655\n",
            "Epoch 703/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5977 - accuracy: 0.6768 - val_loss: 0.5982 - val_accuracy: 0.6645\n",
            "Epoch 704/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.6793 - val_loss: 0.5973 - val_accuracy: 0.6664\n",
            "Epoch 705/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6798 - val_loss: 0.5971 - val_accuracy: 0.6664\n",
            "Epoch 706/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.6765 - val_loss: 0.5981 - val_accuracy: 0.6649\n",
            "Epoch 707/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.6808 - val_loss: 0.5986 - val_accuracy: 0.6657\n",
            "Epoch 708/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.6787 - val_loss: 0.5970 - val_accuracy: 0.6672\n",
            "Epoch 709/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6818 - val_loss: 0.5981 - val_accuracy: 0.6649\n",
            "Epoch 710/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6781 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 711/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6820 - val_loss: 0.5973 - val_accuracy: 0.6657\n",
            "Epoch 712/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6747 - val_loss: 0.5982 - val_accuracy: 0.6653\n",
            "Epoch 713/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6872 - val_loss: 0.5974 - val_accuracy: 0.6651\n",
            "Epoch 714/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6797 - val_loss: 0.5979 - val_accuracy: 0.6640\n",
            "Epoch 715/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6764 - val_loss: 0.5972 - val_accuracy: 0.6666\n",
            "Epoch 716/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6835 - val_loss: 0.5979 - val_accuracy: 0.6645\n",
            "Epoch 717/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.6814 - val_loss: 0.5970 - val_accuracy: 0.6655\n",
            "Epoch 718/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6777 - val_loss: 0.5984 - val_accuracy: 0.6655\n",
            "Epoch 719/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6827 - val_loss: 0.5970 - val_accuracy: 0.6645\n",
            "Epoch 720/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5944 - accuracy: 0.6736 - val_loss: 0.5995 - val_accuracy: 0.6645\n",
            "Epoch 721/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6765 - val_loss: 0.5970 - val_accuracy: 0.6670\n",
            "Epoch 722/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5971 - accuracy: 0.6737 - val_loss: 0.5970 - val_accuracy: 0.6668\n",
            "Epoch 723/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6806 - val_loss: 0.5986 - val_accuracy: 0.6657\n",
            "Epoch 724/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.6744 - val_loss: 0.5984 - val_accuracy: 0.6657\n",
            "Epoch 725/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6733 - val_loss: 0.5982 - val_accuracy: 0.6643\n",
            "Epoch 726/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6825 - val_loss: 0.5970 - val_accuracy: 0.6668\n",
            "Epoch 727/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.6830 - val_loss: 0.5977 - val_accuracy: 0.6657\n",
            "Epoch 728/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6793 - val_loss: 0.5981 - val_accuracy: 0.6651\n",
            "Epoch 729/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6823 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 730/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5943 - accuracy: 0.6775 - val_loss: 0.5981 - val_accuracy: 0.6649\n",
            "Epoch 731/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6783 - val_loss: 0.5977 - val_accuracy: 0.6643\n",
            "Epoch 732/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6747 - val_loss: 0.5971 - val_accuracy: 0.6657\n",
            "Epoch 733/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.6791 - val_loss: 0.5976 - val_accuracy: 0.6662\n",
            "Epoch 734/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6847 - val_loss: 0.5971 - val_accuracy: 0.6662\n",
            "Epoch 735/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5997 - accuracy: 0.6730 - val_loss: 0.5971 - val_accuracy: 0.6657\n",
            "Epoch 736/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5938 - accuracy: 0.6763 - val_loss: 0.5983 - val_accuracy: 0.6662\n",
            "Epoch 737/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6829 - val_loss: 0.5985 - val_accuracy: 0.6649\n",
            "Epoch 738/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.6769 - val_loss: 0.5969 - val_accuracy: 0.6672\n",
            "Epoch 739/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.6740 - val_loss: 0.5977 - val_accuracy: 0.6655\n",
            "Epoch 740/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6805 - val_loss: 0.5975 - val_accuracy: 0.6660\n",
            "Epoch 741/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.6725 - val_loss: 0.5979 - val_accuracy: 0.6653\n",
            "Epoch 742/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6774 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 743/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5878 - accuracy: 0.6822 - val_loss: 0.5987 - val_accuracy: 0.6655\n",
            "Epoch 744/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6803 - val_loss: 0.5995 - val_accuracy: 0.6651\n",
            "Epoch 745/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6818 - val_loss: 0.5984 - val_accuracy: 0.6649\n",
            "Epoch 746/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.6850 - val_loss: 0.5969 - val_accuracy: 0.6664\n",
            "Epoch 747/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6780 - val_loss: 0.5975 - val_accuracy: 0.6655\n",
            "Epoch 748/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6768 - val_loss: 0.5970 - val_accuracy: 0.6662\n",
            "Epoch 749/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6809 - val_loss: 0.5988 - val_accuracy: 0.6655\n",
            "Epoch 750/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6800 - val_loss: 0.5980 - val_accuracy: 0.6651\n",
            "Epoch 751/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6824 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 752/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6800 - val_loss: 0.5976 - val_accuracy: 0.6651\n",
            "Epoch 753/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5869 - accuracy: 0.6865 - val_loss: 0.5976 - val_accuracy: 0.6651\n",
            "Epoch 754/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6702 - val_loss: 0.5978 - val_accuracy: 0.6649\n",
            "Epoch 755/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6784 - val_loss: 0.5968 - val_accuracy: 0.6666\n",
            "Epoch 756/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.6779 - val_loss: 0.5970 - val_accuracy: 0.6655\n",
            "Epoch 757/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6853 - val_loss: 0.5981 - val_accuracy: 0.6649\n",
            "Epoch 758/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6761 - val_loss: 0.5971 - val_accuracy: 0.6664\n",
            "Epoch 759/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5920 - accuracy: 0.6806 - val_loss: 0.5974 - val_accuracy: 0.6655\n",
            "Epoch 760/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6720 - val_loss: 0.5979 - val_accuracy: 0.6655\n",
            "Epoch 761/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5848 - accuracy: 0.6837 - val_loss: 0.5974 - val_accuracy: 0.6655\n",
            "Epoch 762/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5896 - accuracy: 0.6763 - val_loss: 0.5968 - val_accuracy: 0.6655\n",
            "Epoch 763/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6770 - val_loss: 0.5972 - val_accuracy: 0.6655\n",
            "Epoch 764/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6803 - val_loss: 0.5981 - val_accuracy: 0.6664\n",
            "Epoch 765/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.6790 - val_loss: 0.5970 - val_accuracy: 0.6662\n",
            "Epoch 766/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.6832 - val_loss: 0.5981 - val_accuracy: 0.6660\n",
            "Epoch 767/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6843 - val_loss: 0.5968 - val_accuracy: 0.6672\n",
            "Epoch 768/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6816 - val_loss: 0.5972 - val_accuracy: 0.6649\n",
            "Epoch 769/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5983 - accuracy: 0.6734 - val_loss: 0.5968 - val_accuracy: 0.6649\n",
            "Epoch 770/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6790 - val_loss: 0.5981 - val_accuracy: 0.6655\n",
            "Epoch 771/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6786 - val_loss: 0.5988 - val_accuracy: 0.6649\n",
            "Epoch 772/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6749 - val_loss: 0.5975 - val_accuracy: 0.6655\n",
            "Epoch 773/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6744 - val_loss: 0.5981 - val_accuracy: 0.6657\n",
            "Epoch 774/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6861 - val_loss: 0.5989 - val_accuracy: 0.6660\n",
            "Epoch 775/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6765 - val_loss: 0.5971 - val_accuracy: 0.6662\n",
            "Epoch 776/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5933 - accuracy: 0.6774 - val_loss: 0.5979 - val_accuracy: 0.6657\n",
            "Epoch 777/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6766 - val_loss: 0.5972 - val_accuracy: 0.6651\n",
            "Epoch 778/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.6784 - val_loss: 0.5973 - val_accuracy: 0.6651\n",
            "Epoch 779/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6788 - val_loss: 0.5970 - val_accuracy: 0.6655\n",
            "Epoch 780/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6806 - val_loss: 0.5971 - val_accuracy: 0.6662\n",
            "Epoch 781/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6791 - val_loss: 0.5972 - val_accuracy: 0.6643\n",
            "Epoch 782/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.6853 - val_loss: 0.5977 - val_accuracy: 0.6645\n",
            "Epoch 783/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6846 - val_loss: 0.5968 - val_accuracy: 0.6670\n",
            "Epoch 784/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6809 - val_loss: 0.5996 - val_accuracy: 0.6655\n",
            "Epoch 785/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5900 - accuracy: 0.6814 - val_loss: 0.5975 - val_accuracy: 0.6657\n",
            "Epoch 786/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6787 - val_loss: 0.5971 - val_accuracy: 0.6636\n",
            "Epoch 787/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5925 - accuracy: 0.6788 - val_loss: 0.5969 - val_accuracy: 0.6657\n",
            "Epoch 788/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5849 - accuracy: 0.6813 - val_loss: 0.5971 - val_accuracy: 0.6645\n",
            "Epoch 789/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6789 - val_loss: 0.5975 - val_accuracy: 0.6655\n",
            "Epoch 790/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.6746 - val_loss: 0.5980 - val_accuracy: 0.6660\n",
            "Epoch 791/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.6776 - val_loss: 0.5969 - val_accuracy: 0.6655\n",
            "Epoch 792/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6746 - val_loss: 0.5973 - val_accuracy: 0.6655\n",
            "Epoch 793/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6813 - val_loss: 0.5967 - val_accuracy: 0.6668\n",
            "Epoch 794/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6740 - val_loss: 0.5967 - val_accuracy: 0.6668\n",
            "Epoch 795/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.6753 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 796/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6764 - val_loss: 0.5975 - val_accuracy: 0.6660\n",
            "Epoch 797/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6829 - val_loss: 0.5985 - val_accuracy: 0.6662\n",
            "Epoch 798/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6748 - val_loss: 0.5971 - val_accuracy: 0.6647\n",
            "Epoch 799/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6802 - val_loss: 0.5977 - val_accuracy: 0.6645\n",
            "Epoch 800/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6805 - val_loss: 0.5972 - val_accuracy: 0.6643\n",
            "Epoch 801/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6737 - val_loss: 0.5972 - val_accuracy: 0.6647\n",
            "Epoch 802/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5916 - accuracy: 0.6784 - val_loss: 0.5981 - val_accuracy: 0.6662\n",
            "Epoch 803/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6697 - val_loss: 0.5971 - val_accuracy: 0.6645\n",
            "Epoch 804/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.6805 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 805/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5889 - accuracy: 0.6800 - val_loss: 0.5973 - val_accuracy: 0.6662\n",
            "Epoch 806/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.6839 - val_loss: 0.5969 - val_accuracy: 0.6653\n",
            "Epoch 807/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6781 - val_loss: 0.5966 - val_accuracy: 0.6638\n",
            "Epoch 808/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.6851 - val_loss: 0.5971 - val_accuracy: 0.6651\n",
            "Epoch 809/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5953 - accuracy: 0.6799 - val_loss: 0.5974 - val_accuracy: 0.6657\n",
            "Epoch 810/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5928 - accuracy: 0.6762 - val_loss: 0.5973 - val_accuracy: 0.6664\n",
            "Epoch 811/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6776 - val_loss: 0.5968 - val_accuracy: 0.6649\n",
            "Epoch 812/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5869 - accuracy: 0.6861 - val_loss: 0.5969 - val_accuracy: 0.6657\n",
            "Epoch 813/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6768 - val_loss: 0.5966 - val_accuracy: 0.6664\n",
            "Epoch 814/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6767 - val_loss: 0.5978 - val_accuracy: 0.6653\n",
            "Epoch 815/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6792 - val_loss: 0.5973 - val_accuracy: 0.6662\n",
            "Epoch 816/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.6716 - val_loss: 0.5979 - val_accuracy: 0.6655\n",
            "Epoch 817/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6828 - val_loss: 0.5986 - val_accuracy: 0.6660\n",
            "Epoch 818/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6799 - val_loss: 0.5977 - val_accuracy: 0.6647\n",
            "Epoch 819/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5895 - accuracy: 0.6792 - val_loss: 0.5968 - val_accuracy: 0.6647\n",
            "Epoch 820/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6789 - val_loss: 0.5972 - val_accuracy: 0.6649\n",
            "Epoch 821/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.6803 - val_loss: 0.5970 - val_accuracy: 0.6651\n",
            "Epoch 822/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6819 - val_loss: 0.5973 - val_accuracy: 0.6655\n",
            "Epoch 823/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6743 - val_loss: 0.5985 - val_accuracy: 0.6660\n",
            "Epoch 824/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6836 - val_loss: 0.5974 - val_accuracy: 0.6660\n",
            "Epoch 825/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.6847 - val_loss: 0.5968 - val_accuracy: 0.6651\n",
            "Epoch 826/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6756 - val_loss: 0.5973 - val_accuracy: 0.6655\n",
            "Epoch 827/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6806 - val_loss: 0.5976 - val_accuracy: 0.6647\n",
            "Epoch 828/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6807 - val_loss: 0.5975 - val_accuracy: 0.6657\n",
            "Epoch 829/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6761 - val_loss: 0.5966 - val_accuracy: 0.6638\n",
            "Epoch 830/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6730 - val_loss: 0.5977 - val_accuracy: 0.6649\n",
            "Epoch 831/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5890 - accuracy: 0.6814 - val_loss: 0.5970 - val_accuracy: 0.6651\n",
            "Epoch 832/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6827 - val_loss: 0.5980 - val_accuracy: 0.6660\n",
            "Epoch 833/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.6878 - val_loss: 0.5977 - val_accuracy: 0.6647\n",
            "Epoch 834/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5976 - accuracy: 0.6741 - val_loss: 0.5966 - val_accuracy: 0.6666\n",
            "Epoch 835/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5885 - accuracy: 0.6845 - val_loss: 0.5968 - val_accuracy: 0.6651\n",
            "Epoch 836/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5854 - accuracy: 0.6883 - val_loss: 0.5969 - val_accuracy: 0.6649\n",
            "Epoch 837/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.6840 - val_loss: 0.5966 - val_accuracy: 0.6660\n",
            "Epoch 838/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5973 - accuracy: 0.6728 - val_loss: 0.5966 - val_accuracy: 0.6662\n",
            "Epoch 839/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5866 - accuracy: 0.6820 - val_loss: 0.5967 - val_accuracy: 0.6660\n",
            "Epoch 840/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6743 - val_loss: 0.5975 - val_accuracy: 0.6653\n",
            "Epoch 841/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6771 - val_loss: 0.5966 - val_accuracy: 0.6664\n",
            "Epoch 842/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6790 - val_loss: 0.5968 - val_accuracy: 0.6651\n",
            "Epoch 843/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6827 - val_loss: 0.5968 - val_accuracy: 0.6651\n",
            "Epoch 844/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6775 - val_loss: 0.5982 - val_accuracy: 0.6664\n",
            "Epoch 845/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6850 - val_loss: 0.5969 - val_accuracy: 0.6657\n",
            "Epoch 846/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6802 - val_loss: 0.5967 - val_accuracy: 0.6657\n",
            "Epoch 847/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6807 - val_loss: 0.5978 - val_accuracy: 0.6662\n",
            "Epoch 848/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6752 - val_loss: 0.5986 - val_accuracy: 0.6657\n",
            "Epoch 849/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6762 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 850/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5931 - accuracy: 0.6770 - val_loss: 0.5977 - val_accuracy: 0.6649\n",
            "Epoch 851/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6796 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 852/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.6790 - val_loss: 0.5972 - val_accuracy: 0.6662\n",
            "Epoch 853/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6716 - val_loss: 0.5967 - val_accuracy: 0.6655\n",
            "Epoch 854/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6778 - val_loss: 0.5967 - val_accuracy: 0.6655\n",
            "Epoch 855/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6791 - val_loss: 0.5987 - val_accuracy: 0.6666\n",
            "Epoch 856/1000\n",
            "221/221 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6768 - val_loss: 0.5965 - val_accuracy: 0.6657\n",
            "Epoch 857/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6773 - val_loss: 0.5971 - val_accuracy: 0.6655\n",
            "Epoch 858/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6750 - val_loss: 0.5969 - val_accuracy: 0.6660\n",
            "Epoch 859/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.6777 - val_loss: 0.5979 - val_accuracy: 0.6655\n",
            "Epoch 860/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.6756 - val_loss: 0.5965 - val_accuracy: 0.6655\n",
            "Epoch 861/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5925 - accuracy: 0.6757 - val_loss: 0.5968 - val_accuracy: 0.6657\n",
            "Epoch 862/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6768 - val_loss: 0.5977 - val_accuracy: 0.6662\n",
            "Epoch 863/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6730 - val_loss: 0.5983 - val_accuracy: 0.6662\n",
            "Epoch 864/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.6696 - val_loss: 0.5977 - val_accuracy: 0.6662\n",
            "Epoch 865/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5887 - accuracy: 0.6782 - val_loss: 0.5966 - val_accuracy: 0.6662\n",
            "Epoch 866/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6817 - val_loss: 0.5965 - val_accuracy: 0.6645\n",
            "Epoch 867/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6771 - val_loss: 0.5967 - val_accuracy: 0.6651\n",
            "Epoch 868/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.6754 - val_loss: 0.5967 - val_accuracy: 0.6653\n",
            "Epoch 869/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6833 - val_loss: 0.5971 - val_accuracy: 0.6655\n",
            "Epoch 870/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5922 - accuracy: 0.6841 - val_loss: 0.5973 - val_accuracy: 0.6657\n",
            "Epoch 871/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.6791 - val_loss: 0.5968 - val_accuracy: 0.6655\n",
            "Epoch 872/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5929 - accuracy: 0.6756 - val_loss: 0.5979 - val_accuracy: 0.6666\n",
            "Epoch 873/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6774 - val_loss: 0.5974 - val_accuracy: 0.6660\n",
            "Epoch 874/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.6859 - val_loss: 0.5967 - val_accuracy: 0.6647\n",
            "Epoch 875/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6761 - val_loss: 0.5969 - val_accuracy: 0.6664\n",
            "Epoch 876/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6776 - val_loss: 0.5964 - val_accuracy: 0.6647\n",
            "Epoch 877/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5973 - accuracy: 0.6703 - val_loss: 0.5970 - val_accuracy: 0.6657\n",
            "Epoch 878/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6797 - val_loss: 0.5983 - val_accuracy: 0.6662\n",
            "Epoch 879/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5946 - accuracy: 0.6768 - val_loss: 0.5980 - val_accuracy: 0.6670\n",
            "Epoch 880/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6804 - val_loss: 0.5965 - val_accuracy: 0.6653\n",
            "Epoch 881/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5971 - accuracy: 0.6724 - val_loss: 0.5976 - val_accuracy: 0.6649\n",
            "Epoch 882/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.6823 - val_loss: 0.5967 - val_accuracy: 0.6649\n",
            "Epoch 883/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6787 - val_loss: 0.5978 - val_accuracy: 0.6657\n",
            "Epoch 884/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6728 - val_loss: 0.5975 - val_accuracy: 0.6647\n",
            "Epoch 885/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6815 - val_loss: 0.5972 - val_accuracy: 0.6662\n",
            "Epoch 886/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6825 - val_loss: 0.5980 - val_accuracy: 0.6668\n",
            "Epoch 887/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5943 - accuracy: 0.6765 - val_loss: 0.5972 - val_accuracy: 0.6655\n",
            "Epoch 888/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6825 - val_loss: 0.5978 - val_accuracy: 0.6660\n",
            "Epoch 889/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6821 - val_loss: 0.5965 - val_accuracy: 0.6657\n",
            "Epoch 890/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6793 - val_loss: 0.5966 - val_accuracy: 0.6657\n",
            "Epoch 891/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5934 - accuracy: 0.6803 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 892/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6816 - val_loss: 0.5983 - val_accuracy: 0.6668\n",
            "Epoch 893/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6815 - val_loss: 0.5978 - val_accuracy: 0.6664\n",
            "Epoch 894/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6781 - val_loss: 0.5988 - val_accuracy: 0.6651\n",
            "Epoch 895/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.6804 - val_loss: 0.5965 - val_accuracy: 0.6651\n",
            "Epoch 896/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6805 - val_loss: 0.5973 - val_accuracy: 0.6657\n",
            "Epoch 897/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6833 - val_loss: 0.5965 - val_accuracy: 0.6662\n",
            "Epoch 898/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6788 - val_loss: 0.5987 - val_accuracy: 0.6653\n",
            "Epoch 899/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5871 - accuracy: 0.6815 - val_loss: 0.5996 - val_accuracy: 0.6655\n",
            "Epoch 900/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6760 - val_loss: 0.5982 - val_accuracy: 0.6672\n",
            "Epoch 901/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.6817 - val_loss: 0.5964 - val_accuracy: 0.6655\n",
            "Epoch 902/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.6849 - val_loss: 0.5964 - val_accuracy: 0.6645\n",
            "Epoch 903/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5972 - accuracy: 0.6726 - val_loss: 0.5982 - val_accuracy: 0.6670\n",
            "Epoch 904/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.6833 - val_loss: 0.5970 - val_accuracy: 0.6653\n",
            "Epoch 905/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6780 - val_loss: 0.5976 - val_accuracy: 0.6655\n",
            "Epoch 906/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.6813 - val_loss: 0.5971 - val_accuracy: 0.6660\n",
            "Epoch 907/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6792 - val_loss: 0.5966 - val_accuracy: 0.6647\n",
            "Epoch 908/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5868 - accuracy: 0.6832 - val_loss: 0.5977 - val_accuracy: 0.6668\n",
            "Epoch 909/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5847 - accuracy: 0.6876 - val_loss: 0.5968 - val_accuracy: 0.6662\n",
            "Epoch 910/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.6852 - val_loss: 0.5967 - val_accuracy: 0.6653\n",
            "Epoch 911/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6787 - val_loss: 0.5972 - val_accuracy: 0.6657\n",
            "Epoch 912/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6712 - val_loss: 0.5975 - val_accuracy: 0.6653\n",
            "Epoch 913/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6696 - val_loss: 0.5966 - val_accuracy: 0.6647\n",
            "Epoch 914/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5899 - accuracy: 0.6793 - val_loss: 0.5970 - val_accuracy: 0.6651\n",
            "Epoch 915/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.6828 - val_loss: 0.5971 - val_accuracy: 0.6662\n",
            "Epoch 916/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5868 - accuracy: 0.6799 - val_loss: 0.5977 - val_accuracy: 0.6662\n",
            "Epoch 917/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6826 - val_loss: 0.5970 - val_accuracy: 0.6655\n",
            "Epoch 918/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.6856 - val_loss: 0.5964 - val_accuracy: 0.6651\n",
            "Epoch 919/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6769 - val_loss: 0.5964 - val_accuracy: 0.6649\n",
            "Epoch 920/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6793 - val_loss: 0.5964 - val_accuracy: 0.6653\n",
            "Epoch 921/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6805 - val_loss: 0.5964 - val_accuracy: 0.6651\n",
            "Epoch 922/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.6752 - val_loss: 0.5986 - val_accuracy: 0.6660\n",
            "Epoch 923/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6768 - val_loss: 0.5978 - val_accuracy: 0.6668\n",
            "Epoch 924/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6825 - val_loss: 0.5964 - val_accuracy: 0.6655\n",
            "Epoch 925/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.6738 - val_loss: 0.5977 - val_accuracy: 0.6670\n",
            "Epoch 926/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.6809 - val_loss: 0.5965 - val_accuracy: 0.6655\n",
            "Epoch 927/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6809 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 928/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6798 - val_loss: 0.5976 - val_accuracy: 0.6660\n",
            "Epoch 929/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.6794 - val_loss: 0.5964 - val_accuracy: 0.6651\n",
            "Epoch 930/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.6841 - val_loss: 0.5965 - val_accuracy: 0.6653\n",
            "Epoch 931/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6796 - val_loss: 0.5979 - val_accuracy: 0.6668\n",
            "Epoch 932/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5887 - accuracy: 0.6837 - val_loss: 0.5966 - val_accuracy: 0.6651\n",
            "Epoch 933/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.6860 - val_loss: 0.5963 - val_accuracy: 0.6643\n",
            "Epoch 934/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.6733 - val_loss: 0.5964 - val_accuracy: 0.6660\n",
            "Epoch 935/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6792 - val_loss: 0.5974 - val_accuracy: 0.6651\n",
            "Epoch 936/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.6786 - val_loss: 0.5963 - val_accuracy: 0.6655\n",
            "Epoch 937/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.6795 - val_loss: 0.5963 - val_accuracy: 0.6651\n",
            "Epoch 938/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.6761 - val_loss: 0.5965 - val_accuracy: 0.6647\n",
            "Epoch 939/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6805 - val_loss: 0.5987 - val_accuracy: 0.6653\n",
            "Epoch 940/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6789 - val_loss: 0.5981 - val_accuracy: 0.6666\n",
            "Epoch 941/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.6792 - val_loss: 0.5963 - val_accuracy: 0.6651\n",
            "Epoch 942/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5981 - accuracy: 0.6728 - val_loss: 0.5983 - val_accuracy: 0.6653\n",
            "Epoch 943/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6763 - val_loss: 0.5980 - val_accuracy: 0.6668\n",
            "Epoch 944/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6808 - val_loss: 0.5965 - val_accuracy: 0.6657\n",
            "Epoch 945/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.6777 - val_loss: 0.5967 - val_accuracy: 0.6657\n",
            "Epoch 946/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6764 - val_loss: 0.5972 - val_accuracy: 0.6662\n",
            "Epoch 947/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.6743 - val_loss: 0.5976 - val_accuracy: 0.6657\n",
            "Epoch 948/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6792 - val_loss: 0.5970 - val_accuracy: 0.6660\n",
            "Epoch 949/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5931 - accuracy: 0.6754 - val_loss: 0.5986 - val_accuracy: 0.6653\n",
            "Epoch 950/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.6769 - val_loss: 0.5963 - val_accuracy: 0.6655\n",
            "Epoch 951/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.6781 - val_loss: 0.5981 - val_accuracy: 0.6664\n",
            "Epoch 952/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6763 - val_loss: 0.5979 - val_accuracy: 0.6668\n",
            "Epoch 953/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6776 - val_loss: 0.5978 - val_accuracy: 0.6674\n",
            "Epoch 954/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.6758 - val_loss: 0.5963 - val_accuracy: 0.6655\n",
            "Epoch 955/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.6808 - val_loss: 0.5964 - val_accuracy: 0.6657\n",
            "Epoch 956/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5973 - accuracy: 0.6742 - val_loss: 0.5975 - val_accuracy: 0.6651\n",
            "Epoch 957/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.6774 - val_loss: 0.5970 - val_accuracy: 0.6664\n",
            "Epoch 958/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6755 - val_loss: 0.5966 - val_accuracy: 0.6660\n",
            "Epoch 959/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6790 - val_loss: 0.5962 - val_accuracy: 0.6645\n",
            "Epoch 960/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.6849 - val_loss: 0.5968 - val_accuracy: 0.6660\n",
            "Epoch 961/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5925 - accuracy: 0.6756 - val_loss: 0.5965 - val_accuracy: 0.6651\n",
            "Epoch 962/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.6840 - val_loss: 0.5968 - val_accuracy: 0.6662\n",
            "Epoch 963/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.6820 - val_loss: 0.5962 - val_accuracy: 0.6643\n",
            "Epoch 964/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.6773 - val_loss: 0.5965 - val_accuracy: 0.6655\n",
            "Epoch 965/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.6772 - val_loss: 0.5969 - val_accuracy: 0.6655\n",
            "Epoch 966/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.6743 - val_loss: 0.5964 - val_accuracy: 0.6647\n",
            "Epoch 967/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.6797 - val_loss: 0.5994 - val_accuracy: 0.6657\n",
            "Epoch 968/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.6785 - val_loss: 0.5963 - val_accuracy: 0.6655\n",
            "Epoch 969/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6757 - val_loss: 0.5963 - val_accuracy: 0.6653\n",
            "Epoch 970/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5915 - accuracy: 0.6781 - val_loss: 0.5965 - val_accuracy: 0.6655\n",
            "Epoch 971/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6786 - val_loss: 0.5963 - val_accuracy: 0.6655\n",
            "Epoch 972/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6876 - val_loss: 0.5964 - val_accuracy: 0.6649\n",
            "Epoch 973/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6758 - val_loss: 0.5962 - val_accuracy: 0.6649\n",
            "Epoch 974/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6830 - val_loss: 0.5969 - val_accuracy: 0.6664\n",
            "Epoch 975/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5973 - accuracy: 0.6783 - val_loss: 0.5975 - val_accuracy: 0.6653\n",
            "Epoch 976/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6789 - val_loss: 0.5973 - val_accuracy: 0.6645\n",
            "Epoch 977/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.6771 - val_loss: 0.5964 - val_accuracy: 0.6647\n",
            "Epoch 978/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6838 - val_loss: 0.5962 - val_accuracy: 0.6653\n",
            "Epoch 979/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6817 - val_loss: 0.5962 - val_accuracy: 0.6645\n",
            "Epoch 980/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.6738 - val_loss: 0.5975 - val_accuracy: 0.6647\n",
            "Epoch 981/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.6800 - val_loss: 0.5965 - val_accuracy: 0.6651\n",
            "Epoch 982/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6802 - val_loss: 0.5964 - val_accuracy: 0.6645\n",
            "Epoch 983/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5958 - accuracy: 0.6757 - val_loss: 0.5980 - val_accuracy: 0.6664\n",
            "Epoch 984/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5902 - accuracy: 0.6772 - val_loss: 0.5980 - val_accuracy: 0.6668\n",
            "Epoch 985/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.6788 - val_loss: 0.5974 - val_accuracy: 0.6647\n",
            "Epoch 986/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5928 - accuracy: 0.6784 - val_loss: 0.5965 - val_accuracy: 0.6653\n",
            "Epoch 987/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5895 - accuracy: 0.6850 - val_loss: 0.5965 - val_accuracy: 0.6655\n",
            "Epoch 988/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5866 - accuracy: 0.6823 - val_loss: 0.5975 - val_accuracy: 0.6649\n",
            "Epoch 989/1000\n",
            "221/221 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6826 - val_loss: 0.5968 - val_accuracy: 0.6668\n",
            "Epoch 990/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5959 - accuracy: 0.6794 - val_loss: 0.5968 - val_accuracy: 0.6668\n",
            "Epoch 991/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.6763 - val_loss: 0.5963 - val_accuracy: 0.6649\n",
            "Epoch 992/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5850 - accuracy: 0.6788 - val_loss: 0.5965 - val_accuracy: 0.6660\n",
            "Epoch 993/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5964 - accuracy: 0.6750 - val_loss: 0.5962 - val_accuracy: 0.6653\n",
            "Epoch 994/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6810 - val_loss: 0.5970 - val_accuracy: 0.6664\n",
            "Epoch 995/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5945 - accuracy: 0.6785 - val_loss: 0.5970 - val_accuracy: 0.6664\n",
            "Epoch 996/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5865 - accuracy: 0.6856 - val_loss: 0.5962 - val_accuracy: 0.6657\n",
            "Epoch 997/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.6758 - val_loss: 0.5975 - val_accuracy: 0.6655\n",
            "Epoch 998/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.6787 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 999/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.6758 - val_loss: 0.5972 - val_accuracy: 0.6649\n",
            "Epoch 1000/1000\n",
            "221/221 [==============================] - 1s 3ms/step - loss: 0.5928 - accuracy: 0.6757 - val_loss: 0.5979 - val_accuracy: 0.6670\n",
            "Accuracy on training data: 0.6785029768943787% \n",
            " Error on training data: 0.32149702310562134\n",
            "Accuracy on test data: 0.6670217514038086% \n",
            " Error on test data: 0.3329782485961914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3yV1f3A8c83ezEy2ENAgoKIIBEnCiqIC3EUFRfWilVRW4uttmqtXVrburXOqvXnqNSBiii4FVBA9p5CmCEheyff3x/nSXJzcwMBcnND8n2/XveV+5xnfe9Fn+99zjnPOaKqGGOMMf7CQh2AMcaY5skShDHGmIAsQRhjjAnIEoQxxpiALEEYY4wJyBKEMcaYgCxBGAOIyEsi8qcGbrtJRM4MdkzGhJolCGOMMQFZgjCmBRGRiFDHYFoOSxDmkOFV7dwhIktEpEBEXhCRTiLykYjkicgsEUn02X6siCwXkWwR+UJE+vusGyIiP3j7vQnE+J3rPBFZ5O07W0QGNTDGc0VkoYjkisgWEbnPb/0p3vGyvfUTvfJYEfmHiPwoIjki8o1XNkJE0gN8D2d67+8Tkaki8qqI5AITRWSYiMzxzrFdRJ4QkSif/Y8SkZkikiUiO0XktyLSWUQKRSTZZ7tjRSRDRCIb8tlNy2MJwhxqLgZGAf2A84GPgN8CHXD/Pd8KICL9gNeBX3jrpgPvi0iUd7F8F/gPkAS85R0Xb98hwIvADUAy8AwwTUSiGxBfAXA10B44F7hRRMZ5xz3Mi/dxL6bBwCJvv78DQ4GTvJh+DVQ28Du5AJjqnfP/gArgl0AKcCJwBnCTF0MbYBYwA+gK9AU+VdUdwBfAeJ/jXgW8oaplDYzDtDCWIMyh5nFV3amqW4Gvge9UdaGqFgPvAEO87S4FPlTVmd4F7u9ALO4CfAIQCTyiqmWqOhWY53OOScAzqvqdqlao6stAibffXqnqF6q6VFUrVXUJLkmd5q2eAMxS1de982aq6iIRCQN+Ctymqlu9c85W1ZIGfidzVPVd75xFqrpAVeeqarmqbsIluKoYzgN2qOo/VLVYVfNU9Ttv3cvAlQAiEg5cjkuippWyBGEONTt93hcFWE7w3ncFfqxaoaqVwBagm7duq9YeqfJHn/eHAb/yqmiyRSQb6OHtt1cicryIfO5VzeQAP8f9ksc7xvoAu6XgqrgCrWuILX4x9BORD0Rkh1ft9JcGxADwHjBARHrj7tJyVPX7A4zJtACWIExLtQ13oQdARAR3cdwKbAe6eWVVevq83wL8WVXb+7ziVPX1Bpz3NWAa0ENV2wH/AqrOswU4PMA+u4HietYVAHE+nyMcVz3ly39I5qeBVUCqqrbFVcH5xtAnUODeXdh/cXcRV2F3D62eJQjTUv0XOFdEzvAaWX+FqyaaDcwByoFbRSRSRC4Chvns+xzwc+9uQEQk3mt8btOA87YBslS1WESG4aqVqvwfcKaIjBeRCBFJFpHB3t3Ni8A/RaSriISLyIlem8caIMY7fyRwN7CvtpA2QC6QLyJHAjf6rPsA6CIivxCRaBFpIyLH+6x/BZgIjMUSRKtnCcK0SKq6GvdL+HHcL/TzgfNVtVRVS4GLcBfCLFx7xds++84HrgeeAPYA67xtG+Im4H4RyQPuxSWqquNuBs7BJassXAP1Md7qKcBSXFtIFvAgEKaqOd4xn8fd/RQAtXo1BTAFl5jycMnuTZ8Y8nDVR+cDO4C1wEif9d/iGsd/UFXfajfTColNGGSM8SUinwGvqerzoY7FhJYlCGNMNRE5DpiJa0PJC3U8JrSsiskYA4CIvIx7RuIXlhwM2B2EMcaYetgdhDHGmIBazMBeKSkp2qtXr1CHYYwxh5QFCxbsVlX/Z2uAFpQgevXqxfz580MdhjHGHFJEpN7uzFbFZIwxJiBLEMYYYwKyBGGMMSagFtMGEUhZWRnp6ekUFxeHOpSgi4mJoXv37kRG2twuxpjG0aITRHp6Om3atKFXr17UHrizZVFVMjMzSU9Pp3fv3qEOxxjTQrToKqbi4mKSk5NbdHIAEBGSk5NbxZ2SMabptOgEAbT45FCltXxOY0zTCWqCEJExIrJaRNaJyJ31bDNeRFZ4k8u/5lP+N69spYg8JnYFNMa0Igs372Fpek5IYwhagvBmvnoSOBsYAFwuIgP8tkkF7gJOVtWjcBPMIyInAScDg4CBwHHUzKl7SMnOzuapp57a7/3OOeccsrOzgxCRMaYpFJdVkFNYdsD7X/jUbM5/4ptaZec8+jWPzlpLRl4Ju/NLeH/xNn77zlLKKioPNtyAgtlIPQxYp6obAETkDeACYIXPNtcDT6rqHgBV3eWVK26O3ijcVImR1J57+JBRlSBuuummWuXl5eVERNT/9U+fPj3YoRnTaPJLyrnx1QX8YexR9OmQsM/tVZXl23IZ2K3dQZ97R04xyQlRRIQJy7bmcnT3dny8fAfJ8VGk9UoCYNnWHAZ0aUtYWN2KiPQ9hazblc+Arm3JLy6nd0p8rSrbsopK7n1vORcO6Uav5DhEhKLSCpISokiIrvl/+P+++5EeiXFMeWsxu/JKOOPIjny6ahcDurSlf5e2/GP8McxYtp1ZK3fxp3ED+fe3m4gMF/7vu81s3F3A51NGECbQsU0Mi7bU/Dj8z5xNLNuay5vz3dTjK7bn8vCsNUSFh1HqJYbhfVM4++guB/1d+gtmguhG7cnU04Hj/bbpByAi3wLhwH2qOkNV54jI57i5gwV4QlVX+p9ARCYBkwB69uzpv7pZuPPOO1m/fj2DBw8mMjKSmJgYEhMTWbVqFWvWrGHcuHFs2bKF4uJibrvtNiZNmgTUDB2Sn5/P2WefzSmnnMLs2bPp1q0b7733HrGxsSH+ZKap7MotJj46gvjoxvnfNbuwlHaxkfW2WxWWlpNdWEbX9nv/b6y4rIKMvBI6tY1h4O8/BuBPH67khlP7UFGpnNQ3pc4+b87bTGFpBe3jIvnlm4sB+NeVxzJmYOCLW15xGQq89O0mRhzRgYKSCjZnFXDWUZ2ZuyGLzVkF/GX6qlr7nDeoCx8s2Q7Af64bxrRF23hrQTo3jTiciPAwLh/Wg8Vbcvgxs4DySuWhj1fXOe+w3kkclhTHzSP7Mu6pb8kuLOP17zcHjPH8Y7ry0dLtlFfWHhn701Xu9+6K7bms2J7L/36omQhw6oK6kwKO/PsXAY9/z3vLA5aX+tw1/O+HrUFJEEEb7ltELgHGqOrPvOWrgONVdbLPNh8AZcB4oDvwFXA0kAI8ipsKEtwEJr9W1a/rO19aWpr6j8W0cuVK+vfvD8Af3l/Oim25jfPhPAO6tuX35x+11202bdrEeeedx7Jly/jiiy8499xzWbZsWXV31KysLJKSkigqKuK4447jyy+/JDk5uVaC6Nu3L/Pnz2fw4MGMHz+esWPHcuWVV9Y5l+/nNS1Hrzs/5MjObZjxi1PrrJuxbDvzNu3hnvNc7e0HS7bRJyWBxz5dy0XHduP43sm0i3PPxrz23Wb+OXMNu/NLuPe8Afz0lN5syMh350iO54nP13FYchxvztvC7PWZLP/DWSxOz+bEPslszipk+bZcHpm1hqyCMnbnl1TH8P7kU+pUhQCMGtCJYb2SWLE9l3cWbq21Lik+iqyC0url20f1IzE+ispK5bNVuzjn6M5MW7yNb9dlHvwX2MR6JsWxOauwUY9588jDefLz9QHX3XZGKpHhwuTTUw/o2CKyQFXTAq0L5h3EVqCHz3J3r8xXOvCdqpYBG0VkDZAKjADmqmo+gIh8BJwI1JsgDhXDhg2r9azCY489xjvvvAPAli1bWLt2LcnJybX26d27N4MHDwZg6NChbNq0qcniNcGVvqeQzm1jiAgPq7NcXFbBul3uAr5qRx6rd+TxwZJt3D6qX/Wv/5+/+gMAZ/TvyHG9kpj82sLqY89YvgOAe88bQF5xOQ/PWlO97v4PVtCnQzwT/z0PgKO6tmW53w+oo7y7guN6JTJv0556P0Og5AAwc8VOZq4IXDPsmxwA/jlzTa3lL9dk1Hu+5qB9XCTZfu0LKQlRHNG5DU9fOZTpS7aTWVDKxJN68d6ibazYnsP6XQXM2ZDJM1cNZdX2PBZt2UNifBSd28Zw2XE9eeiT1UwY1pPLn5tLm+gIju+TzKyVO5kyuh+TT08lKT6a5PgoTuvXgfyScqYv3U5RWQW/OLNf0D5nMBPEPCBVRHrjEsNluInUfb0LXA78W0RScFVOG4A+wPUi8ldcFdNpwCMHE8y+fuk3lfj4+Or3X3zxBbNmzWLOnDnExcUxYsSIgM8yREdHV78PDw+nqKioSWI1++eL1btISYgOWK++M7eYjLwSBnZrR3FZBTtyiklpE80pD35Oj6RYzjm6Cz8Z2oMz//klt56Rym1npHLPu8t4y6cq4qxHvgKgTUwEf5m+ijvOOqJ63YTnvuP43kkB47r/gxUBy6uSA1AnOfiqLzl0bBPNrrySgOuqDOnZnoWb6+9scWb/jqzcnsfW7CLCw4QKn2qaNyedwOCe7dmRU8yrc3/kua83cvmwHogIr31XU91z0uHJzF6fybBeSXy/Kcvn2J1YujWbl64dRk5RGZc9O5e/XTKItjERJCdE079LW0558DN+eWY/Tjo8mdU781i6NYcbTzucmMhwXvhmI7NW7uSnJ/fmrKM6c+97y+jWPpZbzkhFVSmvVApLKrjihbmMT+vB1Sf2qj73ZcNqqrwnHO/eV1QqlapEhodx1lGd63wXj18+BIBF944iJjKcmMjwWuuvO6Xmh2VifBQ3nHb4Xr/7xhC0BKGq5SIyGfgY177woqouF5H7gfmqOs1bN1pEVgAVwB2qmikiU4HTgaW4BusZqvp+sGINpjZt2pCXF3j2xpycHBITE4mLi2PVqlXMnTu3iaMz++ObtbvZll3EGf07kpwQXWd91QV30wPnVpfNWZ9JhzbRnPvY15SUV/LGpBN4efYmPlrmGlEBtmQV8cyXG3jmyw0APPbpWpZvzamuw/ZXVefuX3f+3casWsu9U+LZuLugzv5v/fxEfvKvOXXKf3dOfwb3bE/X9rE899UGNmUWcPe5/blj6hIE+GFzNucN6oICfx43kPZxUWTml3D3u8vILynnJ2k9iI0Mp6yikuKyCs4c0InYyHCWbs2hT0o8uUXlnPrQ5wD065TAx784tU47SK87PwSgU9toju/j7qQPS47nt+f056YRfUn0vrM7Rh9BTlEZ3RNjqxNLRHgYz361nlU78vj5aYfTr1ObWsfe8Jdz6jRSL7p3dPX71E5tOG9Q1+rlm0f25eaRfauXH7h4UPV7ESEyXGgXF8YHtwyv810GEh4mhLPv3vrt46IadLymENShNlR1OjDdr+xen/cK3O69fLepAG4IZmxNJTk5mZNPPpmBAwcSGxtLp06dqteNGTOGf/3rX/Tv358jjjiCE044IYSRHtqWpufQt2MCsVHh+944AFWltKKSiLAw8kvKaRcbSWWl8tLsTRzVtS3JCdFc+cJ31dvHRoZzydDuTD69L21iImpdnB//dC3LtuVwar8O/O6dZbXOc9mzNT8CMv2qWXwFSg4PXnw0v/nf0nr3SY6P4tmr07j73WXccnpfRg3oxEMfr2bh5j1cPqwnQ3omUlxWQf8ubbnl9L48/tk6Hrl0MOOGdKtzrPvG1txxv3PTyfWfMyGap68cWu96gGN7JgJU/9vcekYqt5zeN2Aj+azbTyM6IoweSXG1ykWkOjmA+wXtuxwR7o416dT6f1UH6sFk9q7FzEm9r0bq1qC1fd4q2YWlDL5/JucO6sKTE44NuM3K7bl8vTaj+gKyp6CUW99YyLE9EzklNSXgL+pT+3Xgq0asC594Ui9emr2p3vVphyWyekceeSXlADx0ySCiI8O59fWFPH3FsYwZ2JmPlu0grVciiXFRpP7uIwAW3H0ma3flc0Kf5HqP3VxUVqpdqJuZUDVSG9MoNu4uILuwlH99uZ5Jpx7O0MMSq9cVlJSzM9fVg3+4ZDtXnZDJCX2SWbMzj6tf+J4xAzvXuihvyy5GBP79rSv7eu1uHv10bcDzHmxyuHBIN5Ljozi8YwLtYiM55+gu/P78ASxOz+GBj1Yyd0MWU0b3Y3F6Dk9OOJbIcKn+VZ1TVEa7WNf76Nie7enWPhYR4Ryfroz/u/FEpi/dQXJCdMAqr+bIksOhxe4gWpCW+nmr6qWrPHb5EIb0aM8rczbx3NcbaRsTQW5xeaOes3tiLN3axzLyyI68/UM6a3bm8+p1xzOsdxK780s46YHPAFh632h25ZVw6TNzAeXLO0by8fIdnDuoC9ER9Vd3VVa6Rs6oiBY/HJpp5uwOwjQrb87bTL9ObRjSM7FWeUFJOfHRESzekk3X9rFMXZDOiYfXrTa59fWFtZb3lRwSoiPIL6m9zfG9k3j0siHERIZx4l8/o7yykr9dMojpS3cwc8VORg/ozL3nu2cLfu7XW6Rr+9haDdFtYiKZf/eZ1csXHdt9r/GA+yUdZb+mTTNnCcI0qZ25xdUNrev/cg6zVu5kSXo2MRHh/GPmGi4a0o23F/o/LtNwN5zWp7o3UJVHLxvMdS/PJyoijD+PG+iekk2u6W684v6zqqt2xg3uxrTF2wJ2QzSmtbEEYRpdaXkllapEhYfx9JfriYsK58EZqyivULol1gzfcPhv6443VV9yuOHUPvTtmEBxeSX3vOt6Br318xPp2CaaSa8sYPXOPL7+9Uh6JMVxZsRSBs+9lU/GfMmXi9cyvO0OvpgygtiocDq1jalzbN/eNCLCBYO7wZbvof1h0KZTne2NaS0sQZhGMXv9btrFRtIrOZ4rX/iOhZuzaRMdUd0jp8qPmXsfgiA5PopB3dvx8KWDmbliJz9s3sPr32/h3EFdGNS9PQBXnXBYrX0+uPUUKiq1+sGi4zY/DxVFnNsxk3PTr4DnoNd9OZC+ANavhCFXwptXQa9T4PgAvakrK+GFURARCzfNgSSbpc+0TpYggiw7O5vXXnutzmiuDfHII48wadIk4uLi9r1xE1q4eQ8XPjWbtMMS6ZUSH3DgMaBOcgAYnprC12t31yl/4Zo0zuhf+9f6T9J68JO0Hvz1okFQWQE7lkHngTUbVFZCaR6RhZlEJvWpKY/07lLevbGmbNdKeP4MQN37ldPcqypBZG2EabfAmfdBnhuigvIieGww3PAVdB4EVXca+RlQnA0pqS6GsP1saC4tgLlPQd8zoeuQ/dvXmCZkvZiCzHewvv1VNWBfSkrdUTEDCebnVdXqqpjb31zU4HaCqjaF1I4J3DjicMYN7sbW7CLOf+Ib8orLWf+XcxoWwGd/gq8eghvnQKcB8M0jrqxdN9izCe7LgYpy+OFlWD0d1s1q2HHv8yZkWfQ6vPvz+rc7+yGoKIXwKPjoDohuB5e/Dq9eBOXFcOGz8M4kaNsdctPh2Kvh5F9AUp+axALwyjjY8Hnd8xsTItaLKYR8h/seNWoUHTt25L///S8lJSVceOGF/OEPf6CgoIDx48eTnp5ORUUF99xzDzt37mTbtm2MHDmSlJQUPv/8832frJGs25VHfHQEWQWlrNyex8rtubzwzcZ6f/3/4yfHMGZgZz5csp1f/28JAEMPS+TpK4+lfWwU44Z0Y3hqSnWC6ZEUV2uIgwZJ98YNytvuEsSs37vlPZvc3/vaQWJv2LNx/4676VvodTLk7iPhfXRH7eWSHHjJJ7m944ZpJ9e7m/rhFfcC6DsKwiNd4gpEFT7/MyR0gqHXQmkeRMTU3AllbYBtC6H/WPjxW0Bg6Vsw4k5o5/WYWv4OJKfCB7+E038HUQlQ4P1bdewP3z4CJ9wMKX3h++cgNhGOvsStL8yC3G2wa4W7u/nkHvjNJgj3Lg9lRfDhFEi7Frr7XUc2fAnxKe7f5/3bXNnpd8NxP3PnWP6Oi2PY9W7dtoVQkg/JfaGt90zHj7Nh/ecu7vosect9L2k/rSnbMg9i2kGHfu4zlOZD+yAP+79nk3v1OhXyd7rzlxVBZAx8+CvoOACGXgMIxLSt2W/zd1BW6L4/1Zp1eTsgviOUFcDDA2HsYzDggvrPX14CJXnus8YmuvMvnQoVZTD48kb/uK3nDuKjO2FH/cMUHJDOR8PZD+x1E987iE8++YSpU6fyzDPPoKqMHTuWX//612RkZDBjxgyee+45wI3R1K5duya9g9ieU0RkeBhhIhz7x5kN3m/C8T35y4VHVy/nFZfxwjcbuXlkXyLDG7GP/ysXwIYv4Mq3oe8ZLiHUJzLO/c94KEjsVZPk/F36KvQ+DR7oEXh91yHuYtGxP6xswFBlEgZXvQuvjK0pSz0L1n5cd9vDToEew+Cbf9Yu7z/WXQC7DHYX/+lT6j/fqb+Gr/7m3p9+Nyx7x/27VCXxI851x3ptvFv+zSaYcZe7yMe0g49/C8deA0ddCP8Z57b53Q5Y/5n73p4+yZXdkwnPjXD/f1/+hkuseTsgui3MeQLikmDMA9CmC+Tvcolpyzx393fqFPhxDqBw9E9ce9M7N7rkOeAClwD7ngEL/wOzH4dKr9p06LWw4N/u32fjl5A6GtZ+4vtlw22LYPNcF+uLZ9X+bn63Ax4ZBAW73L9j31E139XYx93n7z/W3X2u+9T9SBh2PTyeBpk+D3YOGAcr3oWeJ8JPZ9T/b7EXe7uDsARxMPYzQUyZMoWpU6fSvr1rbM3Pz+euu+5i+PDhjB49mksvvZTzzjuP4cPd4F/BTBCqSlZBKec//g0iwtbsfY8QmxwfVT1+0OLfj2brniJSOyU0biKoT1WCOPx0uOqdvScIYwLpNRw2HWIzBrTp4u6awf04evWiwNu16wm/PLDrm1UxwT4v5E1BVbnrrru44Ya6PWd++OEHpk+fzt13380ZZ5zBvffeG+AIB+eN7zcza+VOnrkqjdEPf8n6jLojfVZJjItk8umpXHdKb/rfM4Pzj+nCgxcP4tW5PzJ2cDfaxUZWDwURVNsXQ4cjoWoUzPWfQV6QZp897BS49sOWl3zqu0uQcNAK16srqQ98ev/BneeUX0JYhGsrakx7u8vy1fVY2PZD/ev3NznEJkFR1t63OZBqzf1RlRyg/uQAEBWcjiytJ0GEiO9w32eddRb33HMPV1xxBQkJCWzdupXIyEjKy8tJSkriyiuvpH379jz//PO19m3oHUQg+SXl1fPm3vm2+4Xx66lL6iSHCcf3ZOJJvRj98FdcPqwnf72optrI90Gyq3zGvD8opYWu19Dgy11vHn+52yB9Pvz3KhjzYO2G3srGHVajWmz74By3KcS0dz2rwqOgrTc667DrXfVM266ut9XfU6Fwt6vS+MlL8O2jMP9F6HkSDLnCVWMsfBUGXgwXPe/aRX54GQoy4MbZLjmvfB+21IxqywVPws4VMPxXEO899X7anbB5Nrx8vqvmGTQe5j1ff+zjnnbtL1HxsPFr6DMCVr0Pu9fBMZe6qp6sjfDWROhwBIy4C6Ze69ozqlz/mauTf8yvV1j/sXD6PfDG5a5bc2wifPNwzfqLnnPfD+Kqnhb+H4z8LYR5w6R8OAXmPQe/Wg3/8ObfOPUOlwSvehcOH+m+l+h28NkfXQeEzke76qrFb8IJN8Lqj2DUH1wy+ex+970DdDkGLnzGVRGWFbmqsS8fgs//5PPd/AvWzHDVSL46HQ2pZ8LIu2H2o3DkefV/vweh9VQxhdCECRNYsmQJZ599Nt27d69OAAkJCbz66qusW7eOO+64g7CwMCIjI3n66adJS0vj8ccf54knnqBr164NaqT2/7zfb8xi/DNzOLVfB8IFPl9d/+BzS+4bTduYJrgjqPLvc7wGVwL35PH9FZ/c19VLr3fjH3HtR/Dvsxs/pqMudBfOYN5BhEUETnDj/+OSYZWTb6u5kAQS1ca1EZQXw7ZFcOX/XDXc1e/CYScF3idro6uD7+lNDZ+9xZ1j9J9cIyu4i1mv4RCdUP+5p98B3z/rLq6Dxte/XUFmTdL47hmXLHoMg+g2rkG8bTcoyYVuex8uPKCSfHdH8PplkHIETP7ele9aBfk7XFfm75+DWxbU/nEB7hmYhI5w7j/2fZ6KspoG4X0pL3Vdo2P28t+PKqz60FWV1vervyATdi6FjkdBQgdXVpQNWule8Qf+gzEQa4NoJao+b1WX1Idnrql3pNKB3dqybKubRcx3XKEDVlnhehadcHNN75S98b0I+yeIijL4o9//BD1OgC1BnlDp6J/Axc/XxHbYyTVJrLEkdHK9X3y17Q63L6/9nZz3CHzwC/f+4hfc37WfwIk3u4t8Sj9IrP3AYKuUn+GSWWTsvrc1AYWsDUJExgCP4maUe15V6zQEiMh44D7czHGLVXWCV94TeB43r7UC56jqpmDGeyirVCWvuIyTH/iMbTlFBMr7PZPiePbqoWzPKWbkER3ZkJG/zykjG2zzXNfLY9cquHLqgR8na4P75ecvZ8uBH7Ohwvz+d6is2Pc+J9wMc59078/+m/tV3OEId7fTPQ3iUlw9/8r3XXfOs//mGtvDwuG9m6HH8TDe6w57/qOuS+iR57kE0HGAu9vo5U3YU9Ut1dSo+oVtgiJoCUJEwoEngVFAOjBPRKap6gqfbVKBu4CTVXWPiHT0OcQrwJ9VdaaIJACVwYr1UFZRqWzPKaJSIaeovE5vpME92vP2jSexp7C0es6AIzu7Pth9OiTQp8NeqhL2h3r/PGUHOF/2+7e55FLfXcK+nlNoDGF+w3OX+8wPHtXG9cO/5EWY+lO45n3XqB0WBmP+UvdYKam1l0++zb3Ade1UdUmg+3E1VSBDJ9bep6oqyJgQCWb/xGHAOlXdoKqlwBuA/xMg1wNPquoeAFXdBSAiA4AIVZ3pleer6gF1bG8pVWj+VBVVJSOvhKyCUvYUlKDU/ay3j+pHWJgc3IQypQWu0XivAXm/trUSdq+F//3M1ck2xFcPwYKXAieH+I51yw7EkKsCl584ueZ91R3EOX93Dbm+YzBd8gKc9VfXgHv3Luh96v4PseFLxNXHB5h205jmIphVTN0A33qBdMD/J1E/ABH5FlcNdZ+qzvDKs0XkbaA3MAu405urupqITAImAfTsWfcJypiYGDIzM0lOTg44/+2hqqJSWb6tpg9XavAAACAASURBVN5eVSkvzGVLjmv8HDWgE89dHbBKce9U3YNKQ69xPSuqvHSe6z54X45r2HzEGw/pNz+6B4iSU2sSxObZ8M7PYet89zTwGfe6h6PCIlwPm8LMus+jfPYn6nXFW/Dsafv/WXwNvsI9fLTwP3XXda6ZiJ5jr3F/h13vXiV50O9s18ult8/E9BGHxuxtxhysUHdzjQBSgRFAd+ArETnaKx8ODAE2A28CE4EXfHdW1WeBZ8E1UvsfvHv37qSnp5OR0XjzCjcHu/NLKC6rqXFTlOLKMM45/ig2lmzktjP6HdiBc9Lhu6ddL4uzH4R+Y6CyrKZvuSpkrK7Z/kGfRtILn6l5v9XrLLDwP4Evyg0x8m7XvbLzILjsdddNscoR57r+6ZvrziNd7bpZrqvkt4+6YRhEYMRv3VO1vk//+lYrdfObzzq6jetmaUwrFcwEsRXXwFylu1fmKx34TlXLgI0isgaXMNKBRaq6AUBE3gVOwC9B7EtkZCS9e7eMoZrfX7yNtbvyiY0M58EZNRPifD5lBL2S46rvkP40rub5BXYsdfMaHHdd4IMueNn1xe462C1XtSPkbHYX5GE31L6A/vdqNwJqIEXZ+/+h0q5zfdkHXgyfeOPwdD8Orp5Wuwvgkee4u5f8DEBdF0Vw/eQjolzj+PfP1j52j+PcQH5b5tV8/hG/qZ3gwCUBY0xAwUwQ84BUEemNSwyXARP8tnkXuBz4t4ik4KqWNgDZQHsR6aCqGcDpwHxaqXmbsrjFb5rNuKhwXrp2GL1T4uvZC/jXKe7vcddB5nrXb7y00P2qj+/gxpABd/FVrdvA/P0ztZfrSw4AM36z9w9x7DWue+cab7yYSV/WJCaAnctg8etw3cz66+X9e6yk9HV/xzwAx3h3GM+NrHloqG1X+OlHtfdJ7O16Dp15H4RFup5Gv1jqqsOMMbUELUGoarmITAY+xrUvvKiqy0XkfmC+qk7z1o0WkRVABXCHqmYCiMgU4FNxP40XAAH6PrZslZXK3I2ZTHiu5snVDm2iGXNUZy49rgcDu+3lgZxcn0f0K8rh8WPr3xbcU80HWh1Un2Mud8MVRES7p1PDI6E4xz3Y5ZscAC54Cs5/7MAabcPCa6qH7sl0g9LVJyIKrvukdlmwRwA15hAV1DYIVZ0OTPcru9fnvQK3ey//fWcCg/zLW7qyikp+zCzgfz9s5ekv1tdad90pvbnnvAF7P8CaT1yPoCFX+By0/jGXqu1vcjj2aveA1xd/gXP/CR/eDsdMcBP6xKVA//Pc0An+YtpBnwCNzmFhEBa1fzEEEh7qZjVjWg77v6mZeHDGKl6d8yOjj+rM/36omaFtYLe2vHTtMKIiwoiLDN/LETwz74GMVW6Asyof/3bv+7x6cf3rehxfe+wdgA79Xa8ggMET3JwE/c5yI0/6P0tgjDlkteihNg4VlZVKn9/WnUymT0o8n00Z0YADeF1Mw8Lhn0fVTFrTGO7JdMetrHCJp/NA117RgroNG9Oa2XDfzdwv/7uo1vIpfVPokRTL+LR6Jorx98oFrgH6gidd19DG8psfa6pswiNq5oO25GBMq2AJIgRyCsvILChhd34pz3+9gU9W1AzeNrhHe1792X4OsVA1zv17NzdOgB2PcuMpHcrDXxtjDpoliBA47i+zKC2vedAtPiqcglJXTTTyiP0cWmJvVYRH/8RNC7k/8yec/RAcP2n/YjDGtEiWIJpQdmEpU95aXCs5ALww8TiWbc3hh817uGnk4fs+UHkJzLrP9fff2zDHvU5xw1e/egmsq2ee6V7D3RPUezbCr9ZAm04N/0DGmBbNEkQTuue95cxauatO+dDDEjmhT3LDD7R2Jsx9yr0CqZpKsrP3VPWFz8Dq6W7Gq/ydkNDZTSyz4UtI+6l7NsAYY/xYgmgiqsr7i2uPiHrNiYfx8xGHExm+j1FBVd2QGV89BEeMcbNl+TvvYfeMQWGWm49g49fQxXsYLT4Zjr3KPZuw6Vv3HEJ0m9oD8hljjB9LEE3g7R/Suf2/i6uXReCla4dxQp8koiP8nhvYtgjmPg3jnqp5pmDJf+Edr10gUFXRT16Go8bVLut9at3tYhNdkjDGmAYI5nwQBlianlMrOZx7dBc+vGU4p/XrUDc5gJtHYckbbma1Kh/9eu8n6TemkaI1xpgadgcRRDNX7OT6V2oe3jumR3uevMJnTKSSfNfgHO/T/pDpzSH99MlwzkPuiejiACOl3jgbOh0VnMCNMQZLEEF1w39qP9l942l+PZT+2s39nfSlm9tg6Vs16ypK4P1ba5ZPutUNZZHYy42q2nEfYzIZY8xBsgQRRJU+jyjM+MXw6rmggdrPL3x6P6z/NPBBuhzj2g6G3+7+gpsfwRhjgswSRJAUl9WaHZWObXzmG8jfBX/3mdS+vuRw+Zuu15IxxoSAJYggmfLW4lrL7WMjaxZyt7FX4/7lhrlIHR2EyIwxpmGCmiBEZAzwKG7CoOdV9YEA24wH7gMUWKyqE3zWtQVWAO+q6uRgxtrYZq/PrLUcFiZuhrcdS6H/2MA7Xfk/6HCkGz7bGGNCLGgJQkTCgSeBUbg5pueJyDRVXeGzTSpwF3Cyqu4REf+BiP4IfBWsGIPJv4oJcMkB6p+6s++ZwQvIGGP2UzCfgxgGrFPVDapaCrwBXOC3zfXAk6q6B0BVq8ehEJGhQCfAb37IQ0OhN/ieUMmnl7UJcTTGGLP/gpkgugFbfJbTvTJf/YB+IvKtiMz1qqQQkTDgH8CUIMYXFKrKy7M3VS8/2PVrDn/3fPhxduiCMsaYAxDqRuoIIBUYAXQHvhKRo4Ergemqmi57mZxGRCYBkwB69mweE89f/eL3fL12d/XyqMQdkIUbMdUYYw4hwUwQWwHfKdG6e2W+0oHvVLUM2Cgia3AJ40RguIjcBCQAUSKSr6p3+u6sqs8Cz4KbcjQ4H2P/+CaHTQ+cC1PfdgtaWc8ewPmPQlRCkCMzxpj9E8wEMQ9IFZHeuMRwGTDBb5t3gcuBf4tICq7KaYOqXlG1gYhMBNL8k0NzVFEZKEd5Ze/cUHfVab9xk/kMnRjMsIwx5oAELUGoarmITAY+xnVzfVFVl4vI/cB8VZ3mrRstIiuACuAOVc2s/6jN257C0ur3bWMioDgHMlbXv8PAS6BDvyaIzBhj9l9Q2yBUdTow3a/sXp/3Ctzuveo7xkvAS8GJsHFl5rsEcfqRHbnnvAHw0hjYuaz+HcIj619njDEhZsN9N5JNuwvYllMEwM+G96Z3SjzsWLL3ncJtJjdjTPMV6l5MLUJxWQUj/v4FAO3JIzk+Gt67ed872h2EMaYZszuIg1SSu4sr//gMAEfJJhbF3ECPBQ/AwlcD73DYKZByhHsfZvnZGNN82RXqIFW8eB5Tw1bTi/+jn7jnAuPmPVH/Dhc8DhExsPojiEtqoiiNMWb/2R3EQYrLdr2UNsVcQVfx64AVEettlAJhkXDzPEjqA227wnHXNXGkxhizfyxBHKSKsOjq9xM6ba69su8Z7u8RZ8O9u61LqzHmkGIJ4iCVRdYMxNcx1udp6RMn19wl9D6tiaMyxpiDZ20QB6ksIp6YEje8RuTW72tWxCXD4afDLT9A8uH17G2MMc2X3UEcpHKpp6tqVQ8lSw7GmEOUJYiDoKpkFNYzRmDPE5o2GGOMaWRWxXQQvl2XSVy51E2zd6VDtE0SZIw5tNkdxEG48oXvKAuUYy05GGNaAEsQB6lU7SbMGNMyWYI4SJX2FRpjWii7uh2kMPxmirMRWo0xLYQliANUXFYBQIR/goi18ZWMMS1DUBOEiIwRkdUisk5EAk4ZKiLjRWSFiCwXkde8ssEiMscrWyIilwYzzgOxc3cWm2ImcGL4Cso6Da5ZEZsYuqCMMaYRBa2FVUTCgSeBUUA6ME9EpqnqCp9tUoG7gJNVdY+IdPRWFQJXq+paEekKLBCRj1U1O1jx7q9dWzdymPc+rKKkZsX4l0MSjzHGNLZg3kEMA9ap6gZVLQXeAC7w2+Z64ElV3QOgqru8v2tUda33fhuwC+gQxFj32/bsgur34WFSs6LDESGIxhhjGl8wE0Q3YIvPcrpX5qsf0E9EvhWRuSIyxv8gIjIMiALWB1g3SUTmi8j8jIyMRgx933b6JAhjjGmJQt1IHQGkAiOAy4HnRKR91UoR6QL8B7hWVSv9d1bVZ1U1TVXTOnRouhuMhZv38PYCn6G964ZmjDGHvGAmiK1AD5/l7l6Zr3RgmqqWqepGYA0uYSAibYEPgd+p6twgxrnfLnxqdu3urZXloQvGGGOCpEEJQkTeFpFzRWR/Eso8IFVEeotIFHAZMM1vm3dxdw+ISAquymmDt/07wCuqOnU/ztlkIqmoWQiLhJ4nQof+oQvIGGMaWUMv+E8BE4C1IvKAiOyzJVZVy4HJwMfASuC/qrpcRO4XkbHeZh8DmSKyAvgcuENVM4HxwKnARBFZ5L0GBzhNyETgc9cQEQ0/nQE3N6sbHWOMOSgN6uaqqrOAWSLSDtdWMEtEtgDPAa+qalk9+00HpvuV3evzXoHbvZfvNq8Cr+7H52hS7eMiOaFDAuz0CiJjQxqPMcYEQ4OrjEQkGZgI/AxYCDwKHAvMDEpkzVRecRnZhWX07+STFCJiQheQMcYESYPuIETkHeAIXI+i81V1u7fqTRGZH6zgmqN3Frp29h4ROTWFh58eomiMMSZ4Gvok9WOq+nmgFaqa1ojxNHvrd+UzQDYx6Ie7awpPuiV0ARljTJA0tIppgN/zCYkiclOQYmrWMvJLmB7929qFIoE3NsaYQ1hDE8T1vuMgeUNjXB+ckJq33XmloQ7BGGOaREMTRLhIzc9kbyC+VjnxQUZ+yb43MsaYFqChbRAzcA3Sz3jLN3hlrU5GXglYjZIxphVoaIL4DS4p3OgtzwSeD0pEzVhhaTn5JeVgvVqNMa1AQx+UqwSe9l6t1s7cEkBDHYYxxjSJhj4HkQr8FRiAz+9nVe0TpLianfKKSs74xxeEWYIwxrQSDW2k/jfu7qEcGAm8QjMeCiMYNuwuoFIhEhu51RjTOjQ0QcSq6qeAqOqPqnofcG7wwmp+1uzMAyDCdxRXY4xpwRqaIEq8ob7XishkEbkQSAhiXM1ORp7r3vrF7SeHOBJjjGkaDU0QtwFxwK3AUOBK4JpgBdUc7c4vITxMSI4J9SR8xhjTNPbZSO09FHepqk4B8oFrgx5VM5SZX0pyfBRhVsVkjGkl9vlzWFUrgFOaIJZmbXd+CckJ0VARcOoLY4xpcRpaX7JQRKaJyFUiclHVa187icgYEVktIutE5M56thkvIitEZLmIvOZTfo2IrPVeIa/O2p1fSp/YgtrzT497Gi55MXRBGWNMEDX0SeoYIBPwnfhAgbfr28GrmnoSGAWkA/NEZJqqrvDZJhW4CzhZVfeISEevPAn4PZDmnWeBt++eBn+yRjZqz5vcXP4y7H6zpnDwhFCFY4wxQdfQJ6kPpN1hGLBOVTcAiMgbwAXACp9trgeerLrwq+our/wsYKaqZnn7zgTGAK8fQByNYkLZ224MpnnPeRH+JVShGGNMk2jok9T/JsAYE6r6073s1g3Y4rOcDhzvt00/7/jfAuHAfao6o559uwWIaxIwCaBnz577/BwHqqCknHgK3cK6We5vyhFBO58xxjQHDa1i+sDnfQxwIbCtkc6fCowAugNficjRDd1ZVZ8FngVIS0sL2hgYmfml9BSf3kvtekDvU4N1OmOMaRYaWsX0P99lEXkd+GYfu20Fevgsd/fKfKUD36lqGbBRRNbgEsZWXNLw3feLhsQaDBn5JdS6PznpVoholdNhGGNakQN96isV6LiPbeYBqSLSW0SigMuAaX7bvIuXCEQkBVfltAH4GBjtTW2aCIz2ykJit/8kQZ0bfJNjjDGHrIa2QeRRuw1iB26OiHqparmITMZd2MOBF1V1uYjcD8xX1WnUJIIVQAVwh6pmeuf8Iy7JANxf1WAdCpn5ftOMduwfmkCMMaYJNbSKqc2BHFxVpwPT/cru9XmvwO3ey3/fF4Fm8ZBBnTuI6LahCcQYY5pQg6qYRORCEWnns9xeRMYFL6zmZWduce2CMBuPyRjT8jX0Svd7Vc2pWlDVbNyDbK3Clj1FoQ7BGGOaXEMTRKDtGtpF9pCXvjs31CEYY0yTa2iCmC8i/xSRw73XP4EFwQysuaioVHZk54c6DGOMaXINTRC3AKXAm8AbQDFwc7CCak4Wp2cjvgP0DbshdMEYY0wTamgvpgIg4GisLd1XazJqphk94/dwyi9DG5AxxjSRhvZimiki7X2WE0UkZA+uNaU9BaUkxYhbiG4DIqENyBhjmkhDq5hSvJ5LAHijr+7rSeoWIauwjJQ472sKjwxtMMYY04QamiAqRaR6OCIR6UWA0V1boj0FpSTHencNYZYgjDGtR0O7qv4O+EZEvsTNijAcb5jtlm5rdhGnJoW76ZLsDsIY04o06A7Cm6MhDViNm7TnV0CLf3qspLyCzVmF9E7yRm4NazWPfhhjTIMH6/sZcBtu2O1FwAnAHGpPQdriLN6SQ0WlkpoS5wrsDsIY04o0tA3iNuA44EdVHQkMAbL3vsuhb83OPACO6BDjCqwNwhjTijQ0QRSrajGAiESr6iqgxc+5mVtcBkCbKK89PtyqmIwxrUdDr3jp3nMQ7wIzRWQP8GPwwmoecovKiYoII7rqQblwm0XOGNN6NPRJ6gu9t/eJyOdAO2BG0KJqJnKLy2gbEwlF3lxFMe33voMxxrQg+z2xgap+qarTVLV0X9uKyBgRWS0i60SkzlAdIjJRRDJEZJH3+pnPur+JyHIRWSkij4k0/SPMuUVltI2NgILdriC+Q1OHYIwxIRO0SnURCQeeBEYB6cA8EZmmqiv8Nn1TVSf77XsScDIwyCv6BjgN+CJY8QayO7+EpLgoKMx0BXHJTXl6Y4wJqWBOjTYMWKeqG7y7jTeACxq4rwIxQBQQDUQCO4MSZT0qKpW5G7Lo1DYGcrdCbCJEWBuEMab1CGaC6AZs8VlO98r8XSwiS0Rkqoj0AFDVOcDnwHbv9bGqrvTfUUQmich8EZmfkZHRqMF/utLlo02ZBZCxGlJafKctY4ypJdSTK78P9FLVQcBM4GUAEekL9Mc9mNcNOF1EhvvvrKrPqmqaqqZ16NC47QO7810Tyy2np0L2Zkjq3ajHN8aY5i6YCWIr0MNnubtXVk1VM1W1xFt8Hhjqvb8QmKuq+aqaD3wEnBjEWOvIKnBhjTiiAxRmWfuDMabVCWaCmAekikhvEYkCLgOm+W4gIl18FscCVdVIm4HTRCRCRCJxDdR1qpiCaXd+KQnREcRQCuVFrg3CGGNakaD1YlLVchGZDHwMhAMvqupyEbkfmK+q04BbRWQsUA5kARO93afixnlaimuwnqGq7wcr1kByi8poFxsJRXtcQVxSU57eGGNCLqhjR6jqdGC6X9m9Pu/vAu4KsF8FENLJn/NLykmIjqhJEHYHYYxpZULdSN1sFZZWEBcd7tofAGLtDsIY07pYgqiH3UEYY1o7SxABlFVUsmiLN5p51ThM1gZhjGllbPzqAL5Z58ZemrN2B2Tc62aSs26uxphWxu4gAsgtcvNAvDhwKRTnwJCrIDI2xFEZY0zTsgQRwI6cYgBOjFrvCsY8EMJojDEmNCxBBLAjt5j4qHAiS3Kg21CIjAl1SMYY0+QsQQSwM7eYTu1ioLwYIuNCHY4xxoSEJYgAduaW0LltDJQVQoTdPRhjWidLEAHsyCl280CUFVnjtDGm1bIE4aeyUtmVV8yAyO2QscoShDGm1bIE4SersJSyCuX6JZe5AksQxphWyhKEn525xbULIixBGGNaJ0sQfuokCGOMaaUsQfjZkVNSuyAiKjSBGGNMiAU1QYjIGBFZLSLrROTOAOsnikiGiCzyXj/zWddTRD4RkZUiskJEegUz1io7cosR8SmIbtsUpzXGmGYnaIP1iUg48CQwCkgH5onINFVd4bfpm6o6OcAhXgH+rKozRSQBqAxWrL525hSTkhANZV5BzyadCtsYY5qNYN5BDAPWqeoGVS0F3gAuaMiOIjIAiFDVmQCqmq+qhcELtcbOvGI6tYmCsEgYdBn0OrkpTmuMMc1OMBNEN2CLz3K6V+bvYhFZIiJTRaSHV9YPyBaRt0VkoYg85N2R1CIik0RkvojMz8jIaJSg9xSW0SlOoLIMOvRrlGMaY8yhKNSN1O8DvVR1EDATeNkrjwCGA1OA44A+wET/nVX1WVVNU9W0Dh06NEpAuUVldIzyGqpj2jXKMY0x5lAUzASxFejhs9zdK6umqpmqWtVt6HlgqPc+HVjkVU+VA+8CxwYx1mo5RWV0jPS6ukZbgjDGtF7BTBDzgFQR6S0iUcBlwDTfDUSki8/iWGClz77tRaTqtuB0wL9xu9GpKjlFZfRghyuIt1nkjDGtV9B6MalquYhMBj4GwoEXVXW5iNwPzFfVacCtIjIWKAey8KqRVLVCRKYAn4qIAAuA54IVa5WsglIqKpW+xcvdNKOHWQO1Mab1Cuqc1Ko6HZjuV3avz/u7gLvq2XcmMCiY8flbvi0XgE4x5RAVDxHRTXl6Y4xpVkLdSN2sLN2aA0ByVDlEJYQ4GmOMCS1LED7W7syjW/tYoiqLbCY5Y0yrZwnCR05RGUnxUVBaAFGWIIwxrZslCB95xeUkREfA2k8A2ef2xhjTklmC8JFfUs4A2egWti8KbTDGGBNiliA8xWUVrNqRR5+yNa7g5F+ENiBjjAkxSxCez1ftAmD7ju2u4LTfhDAaY4wJPUsQnqKyCgAuGJAIiM1FbYxp9SxBeLIKSgHo2UZdF1exRmpjTOtmCcKzp7CU8DAhqrLE7h6MMQZLENWyCspIjItCygrtGQhjjMESRLWsghKS4iOhrNCeojbGGCxBVNtTUEZibCSsnGZVTMYYgyWIapkFJfSI9SYKirN5IIwxxhIEbqKgbdnF9I7zEsQxl4c2IGOMaQaCOh/EoSIjr4Sisgr6xHmzn8YlhTYgY4xpBoJ6ByEiY0RktYisE5E7A6yfKCIZIrLIe/3Mb31bEUkXkSeCGee2HHfn0DWq0BXEWoIwxpig3UGISDjwJDAKSAfmicg0VfWfW/pNVZ1cz2H+CHwVrBgBSssr+XJ1BgDHfHuzK2zTZS97GGNM6xDMO4hhwDpV3aCqpcAbwAUN3VlEhgKdgE+CFB/g5oB4eNaa2oUJHYN5SmOMOSQEM0F0A7b4LKd7Zf4uFpElIjJVRHoAiEgY8A9gyt5OICKTRGS+iMzPyMg4oCDbxUYCEEG574EP6FjGGNOShLoX0/tAL1UdBMwEXvbKbwKmq2r63nZW1WdVNU1V0zp06HBAAURFuK8gBjcWE6P/dEDHMcaYliaYvZi2Aj18lrt7ZdVUNdNn8Xngb977E4HhInITkABEiUi+qtZp6G4sMZS5NxExwTqFMcYcUoKZIOYBqSLSG5cYLgMm+G4gIl1U1ZuAgbHASgBVvcJnm4lAWjCTA0CMeHcQ9hS1McYAQUwQqlouIpOBj4Fw4EVVXS4i9wPzVXUacKuIjAXKgSxgYrDi2Zs/jhvI8GX3uFYSu4MwxhgARFVDHUOjSEtL0/nz5x/4Ae5r5/5e/AIcfUnjBGWMMc2ciCxQ1bRA60LdSN38FBxYbyhjjGlpLEFUSerj/g5o8KMaxhjTolmCqBKbCIefDm27hjoSY4xpFixBVCnOhZh2oY7CGGOaDUsQVUpyIbptqKMwxphmwxJEleIciLEEYYwxVSxBAJSXQnmxVTEZY4wPSxDgqpcAoi1BGGNMFUsQ4KqXwKqYjDHGhyUIqHk4Li4ltHEYY0wzYgkCIMcbVbxd99DGYYwxzYglCPBJEIHmMzLGmNbJEgS4BBHTDqLbhDoSY4xpNixBgEsQ7XrseztjjGlFLEEA5KZDW6teMsYYX5YgwLuDsAZqY4zxFdQEISJjRGS1iKwTkTpThorIRBHJEJFF3utnXvlgEZkjIstFZImIXBq0IEsLoGiPNVAbY4yfoE05KiLhwJPAKNxknvNEZJqqrvDb9E1VnexXVghcraprRaQrsEBEPlbV7EYPtKwYBl4CXQY3+qGNMeZQFrQEAQwD1qnqBgAReQO4APBPEHWo6hqf99tEZBfQAWj8BBGfDJe80OiHNcaYQ10wq5i6AVt8ltO9Mn8Xe9VIU0WkTlciERkGRAHrA6ybJCLzRWR+RoZNFWqMMY0p1I3U7wO9VHUQMBN42XeliHQB/gNcq6qV/jur6rOqmqaqaR06dGiSgI0xprUIZoLYCvjeEXT3yqqpaqaqlniLzwNDq9aJSFvgQ+B3qjo3iHEaY4wJIJgJYh6QKiK9RSQKuAyY5ruBd4dQZSyw0iuPAt4BXlHVqUGM0RhjTD2C1kitquUiMhn4GAgHXlTV5SJyPzBfVacBt4rIWKAcyAImeruPB04FkkWkqmyiqi4KVrzGGGNqE1UNdQyNIi0tTefPnx/qMIwx5pAiIgtUNS3QulA3UhtjjGmmLEEYY4wJqMVUMYlIBvDjQRwiBdjdSOEcKuwzt3yt7fOCfeb9dZiqBnxOoMUkiIMlIvPrq4drqewzt3yt7fOCfebGZFVMxhhjArIEYYwxJiBLEDWeDXUAIWCfueVrbZ8X7DM3GmuDMMYYE5DdQRhjjAnIEoQxxpiAWn2C2Ne0qIcqEekhIp+LyApv6tbbvPIkEZkpImu9v4leuYjIY973sEREjg3tJzhwIhIuIgtF5ANvubeIfOd9tje9wSARkWhveZ23vlco4z5QItLem09llYisFJETW/q/s4j80vvvepmIvC4iMS3t31lEXhSRXSKyzKdsv/9dReQab/u1InLN/sTQqhOEz7SoZwMDgMtFZEBoo2o05cCvVHUAcAJws/fZ7gQ+VdVU4FNvGdx3kOq9JgFPN33IjeY2vJGBPQ8CXT9yLgAABNBJREFUD6tqX2APcJ1Xfh2wxyt/2NvuUPQoMENVj4T/b+/+QqQqwziOf3+xYamhbpSYQWZBRJFrRWkWSIaFRHVhlJmFdRmEV8VSIXUd/bmIWijKaqmwtMIbwy0EL9I0thLL0oza0FaitgwKs6eL9z3ruJ3YmV3dcc7+PnDwnPe8DOeZx+WZ886Z92UOKfbK5lnSTOBB4MqIuJQ0GeidVC/PrwA3DWlrKK+S2oHVwNWkVT5XF0WlLhExbjdgPrCx5rgT6Gz2dZ2gWN8jrQ++G5iR22YAu/N+F7Cspv9gv1baSOuO9ADXAxsAkX5h2jY056SZhufn/bbcT82OocF4pwD7hl53lfPM0dUq23PeNgA3VjHPwCxg50jzCiwDumraj+k33Dau7yCof1nUlpZvqecCW4HpEbE/nzoATM/7VXkvngEeAooVCM8Efo2Iv/NxbVyDMefzA7l/KzkfOAi8nIfVXpQ0iQrnOSJ+BJ4Evgf2k/K2g2rnudBoXkeV7/FeICpP0mTgHWBVRPxWey7SR4rKPOcs6WagPyJ2NPtaxlAbcDnwfETMBf7g6LADUMk8TwNuJRXHc4BJ/HcopvLGIq/jvUAMuyxqK5N0Kqk4dEfEutz8U7GSX/63P7dX4b1YANwi6TvgTdIw07PAVEnF4li1cQ3GnM9PAX4eyws+DvqAvojYmo/fJhWMKuf5BmBfRByMiMPAOlLuq5znQqN5HVW+x3uBGHZZ1FYlScBLwJcR8VTNqfeB4kmGe0nfTRTt9+SnIeYBAzW3si0hIjoj4tyImEXK5YcRsRz4CFiauw2NuXgvlub+LfVJOyIOAD9Iuig3LQJ2UeE8k4aW5kmamP+fFzFXNs81Gs3rRmCxpGn5zmtxbqtPs7+EafYGLAG+BvYCjzT7eo5jXNeSbj8/B3rztoQ09toDfANsAtpzf5Ge6NoLfEF6QqTpcYwi/oXAhrw/G9gG7AHWAhNy+2n5eE8+P7vZ1z3CWDuA7TnX7wLTqp5n4HHgK2An8BowoWp5Bt4gfcdymHSneP9I8grcl2PfA6xs5Bo81YaZmZUa70NMZmb2P1wgzMyslAuEmZmVcoEwM7NSLhBmZlbKBcLsJCBpYTH7rNnJwgXCzMxKuUCYNUDS3ZK2SeqV1JXXnjgk6em8PkGPpLNy3w5JH+f5+dfXzN1/oaRNkj6T9KmkC/LLT65Z16E7/0rYrGlcIMzqJOli4A5gQUR0AEeA5aTJ4rZHxCXAZtL8+wCvAg9HxGWkX7cW7d3AcxExB7iG9GtZSDPuriKtTTKbNL+QWdO0Dd/FzLJFwBXAJ/nD/emkydL+Ad7KfV4H1kmaAkyNiM25fQ2wVtIZwMyIWA8QEX8C5NfbFhF9+biXtBbAlhMfllk5Fwiz+glYExGdxzRKjw3pN9L5a/6q2T+C/z6tyTzEZFa/HmCppLNhcH3g80h/R8UsoncBWyJiAPhF0nW5fQWwOSJ+B/ok3ZZfY4KkiWMahVmd/AnFrE4RsUvSo8AHkk4hzbL5AGmRnqvyuX7S9xSQpmN+IReAb4GVuX0F0CXpifwat49hGGZ182yuZqMk6VBETG72dZgdbx5iMjOzUr6DMDOzUr6DMDOzUi4QZmZWygXCzMxKuUCYmVkpFwgzMyv1L2Rewiwf2CVuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKcVOt9eBe7",
        "outputId": "abe38b44-86c2-4aa4-fcaa-0b26596fe447"
      },
      "source": [
        "Xnew=np.array([[1.73,2.03,30,54,0.46,0.17,0.471,0.5,1.07,0.68,0.7,1.07,77.9,0.68,0.47,1.00,3.3,1.05,0.68,0.67,1.12,80.0,0.67,0.48,0.98,5.9,1.02,0.7,0.68,1.06,73.9,0.68,0.59,0.97,5.2,0.96,0.65,0.67,0.89,65.0,0.64,0.36,0.99,3.2,1.025,0.6775,0.68,1.0350000000000001,74.2,0.6675000000000001,0.475,0.9850000000000001,4.3999999999999995,1.1,0.72,0.72,1.07,83.8,0.73,0.51,1.01,7.7,1.03,0.75,0.65,1.26,78.6,0.7,0.52,0.94,4.5,0.94,0.69,0.69,0.91,64.9,0.6,0.35,0.88,3.6,0.93,0.68,0.72,0.78,65.5,0.56,0.52,0.82,3.8,0.9,0.72,0.68,0.86,65.0,0.57,0.57,0.79,3.7],\n",
        "                [1.3,3.3,9,36,0.6,0.47,0.505,0.533,1.13,0.61,0.7,1.21,72.6,0.71,0.24,1.17,2.3,1.12,0.63,0.72,1.07,78.0,0.72,0.52,1.16,5.7,1.1,0.7,0.68,1.16,83.7,0.71,0.54,1.02,11.2,0.95,0.65,0.7,0.85,66.4,0.57,0.56,0.89,6.5,0.95,0.7,0.69,0.92,67.3,0.63,0.57,0.89,6.0,1.15,0.65,0.69,1.21,78.0,0.78,0.29,1.20,2.4,1.09,0.61,0.72,0.97,76.2,0.67,0.39,1.10,5.5,1.04,0.7,0.67,1.13,77.8,0.7,0.48,1.00,3.5,0.97,0.69,0.69,0.89,70.7,0.62,0.52,0.90,5.5,0.87,0.69,0.65,0.86,61.2,0.55,0.55,0.80,3.9],\n",
        "                [2.56,1.44,100,83,0.53,0.44,0.5,0.5,1.23,0.57,0.75,1.25,73.9,0.77,0.36,1.35,3.6,1.19,0.65,0.7,1.29,84.4,0.74,0.54,1.15,6.0,1.09,0.71,0.7,1.06,78.6,0.73,0.53,1.03,4.7,1.06,0.66,0.72,1.08,73.3,0.65,0.51,0.97,4.7,0.96,0.63,0.69,0.81,66.8,0.57,0.43,0.90,3.7,1.17,0.62,0.73,1.24,80.0,0.81,0.23,1.31,1.3,1.08,0.69,0.68,1.22,78.2,0.76,0.55,1.10,3.5,1.0,0.74,0.67,1.22,79.3,0.66,0.46,0.88,4.5,0.95,0.71,0.71,0.94,71.8,0.63,0.56,0.89,3.8,0.85,0.69,0.67,0.73,66.9,0.54,0.38,0.78,4.4],\n",
        "                [1.53,2.33,2,15,0.64,0.61,0.464,0.5,1.29,0.59,0.75,1.32,86.3,0.83,0.37,1.41,1.5,1.13,0.65,0.72,1.11,81.9,0.71,0.49,1.10,5.2,1.1,0.58,0.72,1.02,70.4,0.69,0.67,1.20,4.3,1.01,0.58,0.74,0.81,67.3,0.58,0.5,1.01,4.9,0.89,0.67,0.69,0.81,62.5,0.52,0.38,0.77,4.4,1.33,0.65,0.76,1.45,93.9,0.85,0.56,1.31,6.8,1.13,0.54,0.74,1.03,69.3,0.67,0.3,1.23,4.3,1.1,0.6,0.73,0.97,75.0,0.71,0.52,1.19,5.5,1.09,0.67,0.73,1.12,74.5,0.7,0.63,1.04,4.6,1.01,0.63,0.73,0.85,70.4,0.61,0.56,0.96,6.7],\n",
        "                [2.9,1.38,55,17,0.62,0.67,0.493,0.479,1.29,0.55,0.78,1.29,81.0,0.8,0.24,1.44,5.7,1.13,0.64,0.69,1.19,78.3,0.74,0.5,1.16,7.4,1.1,0.64,0.75,1.08,72.6,0.68,0.64,1.06,4.6,1.05,0.63,0.74,0.93,71.4,0.65,0.52,1.03,5.3,0.97,0.66,0.72,0.83,67.8,0.56,0.53,0.86,6.4,1.1,0.66,0.71,1.12,77.9,0.69,0.52,1.04,5.3,1.09,0.64,0.72,1.06,76.4,0.69,0.54,1.08,4.3,1.06,0.63,0.74,0.94,73.1,0.64,0.38,1.02,6.7,1.04,0.65,0.71,1.01,69.8,0.67,0.43,1.03,3.2,1.0725000000000002,0.645,0.72,1.0325,74.3,0.6725,0.46749999999999997,1.0425,4.875],\n",
        "               [2.15,1.65,47,52,0.53,0.39,0.523,0.543,1.11,0.63,0.72,1.08,74.3,0.72,0.27,1.14,5.3,1.05,0.74,0.67,1.23,78.7,0.71,0.45,0.97,5.6,1.01,0.68,0.7,0.94,74.0,0.66,0.44,0.96,6.4,0.97,0.65,0.71,0.81,65.3,0.63,0.53,0.96,3.6,0.96,0.71,0.67,0.98,74.0,0.6,0.47,0.84,8.2,1.15,0.63,0.71,1.19,76.0,0.74,0.28,1.19,3.3,1.04,0.68,0.71,0.98,74.5,0.67,0.49,0.98,4.2,1.03,0.69,0.71,1.03,74.3,0.65,0.46,0.95,6.6,0.93,0.71,0.64,0.99,69.8,0.59,0.46,0.84,5.7,0.86,0.65,0.67,0.68,60.1,0.54,0.55,0.83,2.9],\n",
        "               [1.45,2.5,19,34,0.61,0.75,0.5,0.571,1.34,0.6,0.76,1.37,87.5,0.9,0.39,1.50,2.7,1.08,0.69,0.72,1.09,76.5,0.69,0.58,1.00,4.0,1.07,0.63,0.74,0.95,73.2,0.64,0.55,1.03,4.5,1.02,0.69,0.7,0.97,74.6,0.66,0.6,0.97,4.3,1.1275,0.6525,0.73,1.095,77.94999999999999,0.7225,0.53,1.125,3.875,1.37,0.59,0.77,1.44,87.2,0.89,0.33,1.50,2.5,1.27,0.58,0.78,1.19,83.8,0.78,0.55,1.36,5.4,1.18,0.64,0.72,1.17,82.2,0.77,0.47,1.21,4.5,1.12,0.59,0.75,1.01,72.9,0.66,0.47,1.13,4.1,1.06,0.66,0.71,1.06,73.5,0.65,0.55,0.99,4.7]\n",
        "               ])\n",
        "Xnew=norm.fit_transform(Xnew)\n",
        "Xnew = scaler.fit_transform(Xnew)\n",
        "\n",
        "ynew=(model.predict([Xnew]))\n",
        "#ynew=(model.predict_classes([Xnew]))\n",
        "print(ynew)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 98) dtype=float32>,)\n",
            "Consider rewriting this model with the Functional API.\n",
            "[[0.21813457 0.7818655 ]\n",
            " [0.53288627 0.4671137 ]\n",
            " [0.08224434 0.91775566]\n",
            " [0.9392726  0.0607274 ]\n",
            " [0.05673881 0.94326127]\n",
            " [0.37697977 0.62302023]\n",
            " [0.03277234 0.9672277 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}