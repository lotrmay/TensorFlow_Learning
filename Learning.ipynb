{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3T3E28adbw6bDRJeSFdoZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotrmay/TensorFlow_Learning/blob/master/Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOXdSLbPx3pu"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "t=tf.zeros([2,2,2,2]) #vytvoří tensor, zaplněn nulami s dimenzemi v závorkách\n",
        "t=tf.reshape(t,[2,-1]) #přeskupí vybraný tensor, na jiný tensor, s jinými dimenzemi, které si určíme, můžeme si také dimenzi dopočítat zadáním -1\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFO1G2uw_X_S"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc #\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Load dataset.\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
        "#print(dftrain.head()) #vypíše nám prvních 5 záznamů a hlavičky dat\n",
        "#print(dftrain[\"age\"]) #vypíše sloupec age\n",
        "y_train = dftrain.pop('survived') #vyjme z dat sloupec survived a uloží ho do y_train\n",
        "y_eval = dfeval.pop('survived')\n",
        "#print(dftrain.loc[0])#vypíše 1. řádek dat\n",
        "#dftrain.describe() je metoda vhodná pro statistiky, dává nám údaje o datech jako vážený průměr, počet, min, max atd.\n",
        "#dftrain.shape nám vrátí počet řádků a počet sloupců dat\n",
        "#print(dftrain.age.hist(bins=20)) #vytvoří histogram, který reprezentuje data\n",
        "#print(dftrain.sex.value_counts().plot(kind='barh')) vytvoří graf zobrazujicí počet pohlaví\n",
        "#pd.concat([dftrain,y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')# graf, jenž nám zobrazí jakou má které pohlaví šanci na přežití\n",
        "\n",
        "CATEGORICAL_COLUMNS=['sex','n_siblings_spouses','parch','class','deck','embark_town','alone']\n",
        "NUMERIC_COLUMNS=['age','fare']\n",
        "\n",
        "feature_columns=[]\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary=dftrain[feature_name].unique() #projede všechny řádky a zjistí každou unikátní hodnotu\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32))\n",
        "\n",
        "#print(feature_columns)\n",
        "\n",
        "#následujicí kód nám poslouží abychom získali dataset object, kterému náš model bude rozumět\n",
        "#epochs=kolikrát uvidí náš model data\n",
        "#batch_size=Počet řádků, které uvidí každým průchodem, aby nedošlo k přehlcení paměti\n",
        "\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():#vnitřní funkce, která bude vrácena\n",
        "    ds=tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))# vytvoří tf.data.Dataset object a naplní ho daty \n",
        "    if shuffle: #slouží k tomu aby náš model nahlížel data i zjiné perspektivy\n",
        "      ds=ds.shuffle(1000)#promíchá naše data\n",
        "    ds=ds.batch(batch_size).repeat(num_epochs) # rozdělí dataset do 32 řádkových batchů a opakuje tolikrát kolik máme epochů\n",
        "    return ds #vrátí nám batch datasetu\n",
        "  return input_function # vrátí funkci pro náš objekt\n",
        "\n",
        "train_input_fn=make_input_fn(dftrain,y_train) # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n",
        "\n",
        "linear_est=tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "\n",
        "linear_est.train(train_input_fn)#train\n",
        "result=linear_est.evaluate(eval_input_fn)#výsledky toho, jak si model vedl\n",
        "\n",
        "clear_output()#vyčistí konzoli\n",
        "print(result['accuracy'])#vypíše nám výsledek, ale result obsahuje i například průměrný loss, jenž zde je 0.5, protože je to binární problém\n",
        "#print(result)\n",
        "\n",
        "#následujicí kód zkouší predikovat na základě vybraných dat\n",
        "\n",
        "result=list(linear_est.predict(eval_input_fn))\n",
        "print(dfeval.loc[5])\n",
        "print(y_eval.loc[5])\n",
        "print(result[5]['probabilities'][1])#index 1 nám zobrazí šanci, že přežil\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5GtjyIvVb2y"
      },
      "source": [
        "#Klasifikace 1:55:03\n",
        "#https://www.youtube.com/watch?v=tPYj3fFJGjk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOhdxp7EKrW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b12d9928-872e-4063-8394-ae3c4962a357"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np #better arrays in python, lepší práce s multidimenzionálními poli\n",
        "import pandas as pd #data analytics tool, lepší manipulace s daty, dokáže například cut outnout column\n",
        "import matplotlib.pyplot as plt #vizualizace tabulek a grafů\n",
        "from IPython.display import clear_output #jen pro tenhle notebook\n",
        "from six.moves import urllib\n",
        "\n",
        "\n",
        "CSV_COLUMN_NAMES=['SpelaLength','SepalWidth','PetalLength','PetalWidth','Species']\n",
        "SPECIES=['Setosa','Versicolor','Virginica']\n",
        "\n",
        "train_path=tf.keras.utils.get_file(\"iris_training.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path=tf.keras.utils.get_file(\"iris_test.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train=pd.read_csv(train_path,names=CSV_COLUMN_NAMES,header=0)\n",
        "test=pd.read_csv(test_path,names=CSV_COLUMN_NAMES,header=0)\n",
        "#načítání dat pomocí kerasu a panda\n",
        "#print(train.head())\n",
        "train_y=train.pop('Species')\n",
        "test_y=test.pop('Species')\n",
        "\n",
        "#train.head()#nyní jsou data bez Species\n",
        "#train.shape #120 řádků a 4 sloupce\n",
        "\n",
        "def input_fn(features,labels,training=True,batch_size=256):\n",
        "  #Nyní vložíme naše data do datasetu\n",
        "  dataset=tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  #Promíchej a opakuj pokud trénuješ\n",
        "  if training:\n",
        "    dataset=dataset.shuffle(1000).repeat()\n",
        "  \n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "#Feature columns popisují jak použít náš input\n",
        "\n",
        "my_feature_columns=[]\n",
        "for key in train.keys():#train.keys() vrací všechny sloupce, mohli jsme loopovat přes CSV_COLUMN_NAMES, pokud bychom odebrali SPECIES v poli\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "#print(my_feature_columns)\n",
        "\n",
        "classifier=tf.estimator.DNNClassifier(feature_columns=my_feature_columns,hidden_units=[30,10], n_classes=3)\n",
        "#n_classes říká počet tříd, a hiddent units znamená, že budeme mít 2 vrstvy a první bude mít 30 a druhá 10 nodes\n",
        "\n",
        "classifier.train(input_fn=lambda: input_fn(train,train_y,training=True),steps=5000)#využití input funkce co jsme udělalli pro trénování\n",
        "#lambda je v podstatě def funkce(): v jedné řádce\n",
        "#steps je podobné jako epochs, steps označuje kolik záznamů musí model vidět pro ukončení\n",
        "\n",
        "\n",
        "eval_result=classifier.evaluate(input_fn=lambda:input_fn(test,test_y,training=False))\n",
        "#print('\\nTest set accuracy:{accuracy:0.3f}\\n'.format(**eval_result))\n",
        "\n",
        "def input_fn(features,batch_size=256):\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features=['SpelaLength','SepalWidth','PetalLength','PetalWidth']\n",
        "predict={}\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "\n",
        "for feature in features:\n",
        "  valid=True\n",
        "  while valid:\n",
        "    val=input(feature+\": \")\n",
        "    if not val.isdigit(): valid=False\n",
        "\n",
        "  predict[feature]=[float(val)]\n",
        "\n",
        "predictions=classifier.predict(input_fn=lambda:input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "  class_id=pred_dict['class_ids'][0]\n",
        "  probability=pred_dict['probabilities'][class_id]\n",
        "\n",
        "  print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id],100*probability))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpu9hjyb9a\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpu9hjyb9a', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpu9hjyb9a/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.6380961, step = 0\n",
            "INFO:tensorflow:global_step/sec: 340.068\n",
            "INFO:tensorflow:loss = 1.2060114, step = 100 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.922\n",
            "INFO:tensorflow:loss = 1.1381403, step = 200 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.396\n",
            "INFO:tensorflow:loss = 1.0452157, step = 300 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.107\n",
            "INFO:tensorflow:loss = 1.0204182, step = 400 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.067\n",
            "INFO:tensorflow:loss = 0.9755648, step = 500 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.018\n",
            "INFO:tensorflow:loss = 0.95161057, step = 600 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.481\n",
            "INFO:tensorflow:loss = 0.9297652, step = 700 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.109\n",
            "INFO:tensorflow:loss = 0.9212452, step = 800 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.589\n",
            "INFO:tensorflow:loss = 0.9034555, step = 900 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.213\n",
            "INFO:tensorflow:loss = 0.8885236, step = 1000 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.911\n",
            "INFO:tensorflow:loss = 0.85129976, step = 1100 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.345\n",
            "INFO:tensorflow:loss = 0.864702, step = 1200 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.31\n",
            "INFO:tensorflow:loss = 0.8525083, step = 1300 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.638\n",
            "INFO:tensorflow:loss = 0.84330416, step = 1400 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.096\n",
            "INFO:tensorflow:loss = 0.83130133, step = 1500 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.335\n",
            "INFO:tensorflow:loss = 0.8440088, step = 1600 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.626\n",
            "INFO:tensorflow:loss = 0.8234957, step = 1700 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.628\n",
            "INFO:tensorflow:loss = 0.81026375, step = 1800 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.521\n",
            "INFO:tensorflow:loss = 0.8015411, step = 1900 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.298\n",
            "INFO:tensorflow:loss = 0.7949325, step = 2000 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.139\n",
            "INFO:tensorflow:loss = 0.78670347, step = 2100 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.409\n",
            "INFO:tensorflow:loss = 0.79309857, step = 2200 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.261\n",
            "INFO:tensorflow:loss = 0.7758645, step = 2300 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.561\n",
            "INFO:tensorflow:loss = 0.7689026, step = 2400 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.738\n",
            "INFO:tensorflow:loss = 0.7766535, step = 2500 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.434\n",
            "INFO:tensorflow:loss = 0.76127005, step = 2600 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.452\n",
            "INFO:tensorflow:loss = 0.7609646, step = 2700 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.977\n",
            "INFO:tensorflow:loss = 0.74296373, step = 2800 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.937\n",
            "INFO:tensorflow:loss = 0.7575594, step = 2900 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.227\n",
            "INFO:tensorflow:loss = 0.75679064, step = 3000 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.197\n",
            "INFO:tensorflow:loss = 0.7525703, step = 3100 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.239\n",
            "INFO:tensorflow:loss = 0.75452477, step = 3200 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.779\n",
            "INFO:tensorflow:loss = 0.73939526, step = 3300 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.437\n",
            "INFO:tensorflow:loss = 0.7310183, step = 3400 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.275\n",
            "INFO:tensorflow:loss = 0.70941836, step = 3500 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.599\n",
            "INFO:tensorflow:loss = 0.7286505, step = 3600 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.865\n",
            "INFO:tensorflow:loss = 0.7271492, step = 3700 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.52\n",
            "INFO:tensorflow:loss = 0.7223871, step = 3800 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.943\n",
            "INFO:tensorflow:loss = 0.72026235, step = 3900 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.601\n",
            "INFO:tensorflow:loss = 0.7301817, step = 4000 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.399\n",
            "INFO:tensorflow:loss = 0.73702776, step = 4100 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.104\n",
            "INFO:tensorflow:loss = 0.7238439, step = 4200 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.815\n",
            "INFO:tensorflow:loss = 0.73058337, step = 4300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.46\n",
            "INFO:tensorflow:loss = 0.6932993, step = 4400 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.915\n",
            "INFO:tensorflow:loss = 0.7137424, step = 4500 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.615\n",
            "INFO:tensorflow:loss = 0.6849615, step = 4600 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 487.303\n",
            "INFO:tensorflow:loss = 0.7129702, step = 4700 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.117\n",
            "INFO:tensorflow:loss = 0.7039778, step = 4800 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.527\n",
            "INFO:tensorflow:loss = 0.7034677, step = 4900 (0.188 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpu9hjyb9a/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.6805345.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-29T07:54:12\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpu9hjyb9a/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.31841s\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-29-07:54:13\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.73333335, average_loss = 0.73195994, global_step = 5000, loss = 0.73195994\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpu9hjyb9a/model.ckpt-5000\n",
            "Please type numeric values as prompted.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f997365408b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\": \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxcFtMOsUQ5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90e39055-ddcf-49ba-d9f8-b30e9953109d"
      },
      "source": [
        "#print(pred_dict['class_ids'][0]) #class_ids obsahuje predikovaný index rostliny v poli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}